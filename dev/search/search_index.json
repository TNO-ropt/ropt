{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>ropt</code>: A Python module for robust optimization","text":""},{"location":"#overview","title":"Overview","text":"<p><code>ropt</code> is a module designed for implementing and executing robust optimization workflows. In classical optimization problems, a deterministic function is optimized. However, in robust optimization, the function is expected to exhibit a stochastic nature and is represented by an ensemble of functions (realizations) for different values of some (possibly unknown) random parameters. The optimal solution is then determined by optimizing the value of a statistic, such as the mean, over the ensemble.</p> <p><code>ropt</code> can be employed to construct optimization workflows directly in Python or as a building block in optimization applications. At a minimum, the user needs to provide additional code to calculate the values for each function realization in the ensemble. This can range from simply calling a Python function that returns the objective values to initiating a long-running simulation on an HPC cluster and reading the results. Furthermore, <code>ropt</code> exposes all intermediate results of the optimization, such as objective and gradient values, but functionality to report or store any of these values must be added by the user. Optional functionality to assist with this is included with <code>ropt</code>.</p> <p><code>ropt</code> provides several features for efficiently solving complex robust optimization problems:</p> <ul> <li>Robust optimization over an ensemble of models, i.e., optimizing the average   of a set of objective functions. Alternative objectives can be implemented   using plugins, for instance, to implement risk-aware optimization, such as   Conditional Value at Risk (CVaR) or standard-deviation-based functions.</li> <li>Support for black-box optimization of arbitrary functions.</li> <li>Support for running complex optimization workflows, such as multiple runs with   different optimization settings or even different optimization methods.</li> <li>Support for nested optimization, allowing sub-sets of the variables to be   optimized by optimization workflows that run as part of the black-box function   to be optimized.</li> <li>An interface for running various continuous and discrete optimization methods.   By default, optimizers from the   <code>scipy.optimize</code>   package are included, but additional optimizers can be added via a plugin   mechanism. The most common options of these optimizers can be configured in a   uniform manner, although algorithm- or package-specific options can still be   passed.</li> <li>Efficient estimation of gradients using a Stochastic Simplex Approximate   Gradient (StoSAG) approach. Additional samplers for generating perturbed   values for gradient estimation can be added via a plugin mechanism.</li> <li>Support for linear and non-linear constraints, if supported by the chosen   optimizer.</li> <li>Flexible configuration of the optimization process using   <code>pydantic</code>.</li> <li>Support for tracking and processing optimization results generated during the   optimization process.</li> <li>Optional support for exporting results as   <code>pandas</code> data frames.</li> </ul>"},{"location":"#related-packages","title":"Related packages","text":""},{"location":"#plugins","title":"Plugins","text":"<p>Additional backend optimizers can be installed separately and used via the plugin system:</p> <ul> <li>The <code>ropt-dakota</code> plugin provides   access to algorithms from the Dakota package.</li> <li>The <code>ropt-nomad</code> plugin implements   the MADS algorithm based on the   NOMAD package.</li> <li>The <code>ropt-pymoo</code> makes the   algorithms from the <code>pymoo</code> package available to <code>ropt</code>.</li> </ul>"},{"location":"#applications","title":"Applications","text":"<p>The <code>ropt</code> package is used  by the Everest decision-making tool as its core optimization engine.</p>"},{"location":"reference/basic_optimizer/","title":"Basic Optimizer","text":""},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer","title":"ropt.plan.BasicOptimizer","text":"<p>A class for executing single optimization runs.</p> <p>The <code>BasicOptimizer</code> is designed to simplify the process of setting up and executing optimization workflows that consist primarily of a single optimization run. It offers a more streamlined approach compared to directly defining and managing a full <code>Plan</code> object, making it ideal for straightforward optimization tasks.</p> <p>This class provides a user-friendly interface for common optimization operations, including:</p> <ul> <li>Initiating a Single Optimization:  Easily start an optimization   process with a provided configuration and evaluator.</li> <li>Observing Optimization Events: Register observer functions to monitor   and react to various events that occur during the optimization, such as   the start of an evaluation or the availability of new results.</li> <li>Abort Conditions: Define a callback function that can be used to check   for abort conditions during the optimization.</li> <li>Result Reporting: Define a callback function that will be called   whenever new results become available.</li> <li>Accessing Results: After the optimization is complete, the optimal   results, corresponding variables, and the optimization's exit code are   readily accessible.</li> <li>Customizable Steps and Handlers: While designed for single runs, it   allows for the addition of custom plan steps and event handlers to the   underlying <code>Plan</code> for more complex scenarios.</li> </ul> <p>By encapsulating the core elements of an optimization run, the <code>BasicOptimizer</code> reduces the boilerplate code required for simple optimization tasks, allowing users to focus on defining the optimization problem and analyzing the results.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.results","title":"results  <code>property</code>","text":"<pre><code>results: FunctionResults | None\n</code></pre> <p>Return the optimal result found during the optimization.</p> <p>This property provides access to the best <code>FunctionResults</code> object discovered during the optimization process. It encapsulates the objective function value, constraint values, and other relevant information about the optimal solution.</p> <p>Returns:</p> Type Description <code>FunctionResults | None</code> <p>The optimal result.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.variables","title":"variables  <code>property</code>","text":"<pre><code>variables: NDArray[float64] | None\n</code></pre> <p>Return the optimal variables found during the optimization.</p> <p>This property provides access to the variable values that correspond to the optimal <code>FunctionResults</code> object. These variables represent the solution that yielded the best objective function value found during the optimization process.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>The variables corresponding to the optimal result.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.exit_code","title":"exit_code  <code>property</code>","text":"<pre><code>exit_code: ExitCode\n</code></pre> <p>Return the exit code of the optimization run.</p> <p>This property provides access to the <code>ExitCode</code> that indicates the outcome of the optimization process. It can be used to determine whether the optimization completed successfully, was aborted, or encountered an error.</p> <p>Returns:</p> Type Description <code>ExitCode</code> <p>The exit code of the optimization run.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: dict[str, Any],\n    evaluator: Callable[\n        [NDArray[float64], EvaluatorContext],\n        EvaluatorResult,\n    ],\n    *,\n    transforms: OptModelTransforms | None = None,\n    constraint_tolerance: float = 1e-10,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Initialize a <code>BasicOptimizer</code> object.</p> <p>This constructor sets up the necessary components for a single optimization run. It requires an optimization configuration, optional domain transforms, and an evaluator, which together define the optimization problem and how to evaluate potential solutions. If a constraint value is within the <code>constraint_tolerance</code> of zero, it is considered satisfied. The <code>kwargs</code> may be used to define custom steps and event handlers to modify the behavior of the optimization process.</p> Custom  steps <p>The optional keyword arguments (<code>kwargs</code>) provide a mechanism to inject a custom step into the optimization process. The behavior is as follows:</p> <ol> <li>Custom Step Execution: If a single keyword argument is     provided, the <code>BasicOptimizer</code> checks if a step with the same     name exists. If so, that step is executed immediately, receiving     the key-value pair as a keyword input, in addition to the     evaluator function (via the <code>evaluator</code> keyword). Only one     custom step can be executed this way, if other keyword arguments     are present an error is raised. The custom step receives the     <code>Plan</code> object and may return a custom function to execute.</li> <li>Default Optimization: If no custom step is run, or if the     custom step does not return a custom run function, the default     optimization process is used.</li> <li>Callback Installation and Execution: Finally, any callbacks     added via <code>set_abort_callback</code> or <code>set_results_callback</code> are     installed, and the appropriate run function is executed.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>dict[str, Any]</code> <p>The configuration for the optimization.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>The transforms to apply to the model.</p> <code>None</code> <code>evaluator</code> <code>Callable[[NDArray[float64], EvaluatorContext], EvaluatorResult]</code> <p>The evaluator object.</p> required <code>constraint_tolerance</code> <code>float</code> <p>The constraint violation tolerance.</p> <code>1e-10</code> <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments.</p> <code>{}</code>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.run","title":"run","text":"<pre><code>run(initial_values: ArrayLike) -&gt; Self\n</code></pre> <p>Run the optimization process.</p> <p>This method initiates the optimization workflow defined by the <code>BasicOptimizer</code> object. It executes the underlying <code>Plan</code>, which manages the optimization steps, result handling, and event processing. After the optimization is complete, the optimal results, variables, and exit code can be accessed via the corresponding properties.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.set_abort_callback","title":"set_abort_callback","text":"<pre><code>set_abort_callback(callback: Callable[[], bool]) -&gt; Self\n</code></pre> <p>Set a callback to check for abort conditions.</p> <p>The provided callback function will be invoked repeatedly during the optimization process. If the callback returns <code>True</code>, the optimization will be aborted, and the <code>BasicOptimizer</code> will exit with an <code>ExitCode.USER_ABORT</code>.</p> <p>The callback function should have no arguments and return a boolean value.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[], bool]</code> <p>The callable to check for abort conditions.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.set_results_callback","title":"set_results_callback","text":"<pre><code>set_results_callback(callback: Callable[..., None]) -&gt; Self\n</code></pre> <p>Set a callback to report new results.</p> <p>The provided callback function will be invoked whenever new results become available during the optimization process. This allows for real-time monitoring and analysis of the optimization's progress.</p> <p>The required signature of the callback function should be:</p> <pre><code>def callback(results: tuple[FunctionResults, ...]) -&gt; None:\n    ...\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[..., None]</code> <p>The callable that will be invoked to report new results.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/default_function_estimator_plugin/","title":"Default Function Estimator Plugin","text":""},{"location":"reference/default_function_estimator_plugin/#ropt.plugins.function_estimator.default.DefaultFunctionEstimator","title":"ropt.plugins.function_estimator.default.DefaultFunctionEstimator","text":"<p>               Bases: <code>FunctionEstimator</code></p> <p>The default implementation for function estimation strategies.</p> <p>This class provides methods for combining objective function values and gradients from an ensemble of realizations into a single representative value or gradient. The specific method is configured via the <code>FunctionEstimatorConfig</code> in the main <code>EnOptConfig</code>.</p> <p>Supported Methods:</p> <ul> <li> <p><code>mean</code> (or <code>default</code>):     Calculates the combined function value as the weighted mean of the     individual realization function values. The combined gradient is     calculated as the weighted mean of the individual realization gradients     (unless <code>merge_realizations</code> is true, in which case the pre-merged     gradient is used directly).</p> </li> <li> <p><code>stddev</code>:     Calculates the combined function value as the weighted standard     deviation of the individual realization function values. The combined     gradient is calculated using the chain rule based on the standard     deviation formula. This method requires at least two realizations with     non-zero weights and is incompatible with <code>merge_realizations=True</code>     for gradient calculation.</p> </li> </ul>"},{"location":"reference/default_plan_plugin/","title":"Default Plan Plugins","text":""},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default","title":"ropt.plugins.plan.default","text":"<p>This module provides the default plugin implementations for steps and event handlers.</p> <p>It defines <code>DefaultPlanStepPlugin</code> and <code>DefaultEventHandlerPlugin</code>, which serve as factories for the built-in plan components, enabling the creation of standard optimization plans out-of-the-box.</p> <p>Supported Components:</p> <ul> <li>Steps:<ul> <li><code>ensemble_evaluator</code>: Performs ensemble evaluations     (<code>DefaultEnsembleEvaluatorStep</code>).</li> <li><code>optimizer</code>: Runs an optimization algorithm using a configured optimizer     plugin     (<code>DefaultOptimizerStep</code>).</li> </ul> </li> <li>Handlers:<ul> <li><code>tracker</code>: Tracks the 'best' or 'last' valid result based on objective     value and constraints     (<code>DefaultTrackerHandler</code>).</li> <li><code>store</code>: Accumulates all results from specified sources     (<code>DefaultStoreHandler</code>).</li> <li><code>observer</code>: Listens for events from specified sources, and calls a   callback for each event     (<code>DefaultObserverHandler</code>).</li> </ul> </li> <li>Evaluators:<ul> <li><code>function_evaluator</code>: Evaluator that forwards calculations to a given evaluation function.   (<code>DefaultFunctionEvaluator</code>)</li> <li><code>caching_evaluator</code>: Evaluator that uses caching to find results that were   already evaluated before forwarding to another evaluator.   (<code>DefaultCachedEvaluator</code>)</li> </ul> </li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultPlanStepPlugin","title":"ropt.plugins.plan.default.DefaultPlanStepPlugin","text":"<p>               Bases: <code>PlanStepPlugin</code></p> <p>The default plugin for creating built-in plan steps.</p> <p>This plugin acts as a factory for the standard <code>PlanStep</code> implementations provided by <code>ropt</code>. It allows the <code>PluginManager</code> to instantiate these steps when requested by a <code>Plan</code>.</p> <p>Supported Steps:</p> <ul> <li><code>ensemble_evaluator</code>: Creates a     <code>DefaultEnsembleEvaluatorStep</code>     instance, which performs ensemble evaluations.</li> <li><code>optimizer</code>: Creates a     <code>DefaultOptimizerStep</code>     instance, which runs an optimization algorithm using a configured     optimizer plugin.</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultEventHandlerPlugin","title":"ropt.plugins.plan.default.DefaultEventHandlerPlugin","text":"<p>               Bases: <code>EventHandlerPlugin</code></p> <p>The default plugin for creating built-in event handlers.</p> <p>This plugin acts as a factory for the standard <code>EventHandler</code> implementations provided by <code>ropt</code>. It allows the <code>PluginManager</code> to instantiate these event handlers when requested by a <code>Plan</code>.</p> <p>Supported Handlers:</p> <ul> <li><code>tracker</code>: Creates a     <code>DefaultTrackerHandler</code>     instance, which tracks either the 'best' or 'last' valid result based on     objective value and constraints.</li> <li><code>store</code>: Creates a     <code>DefaultStoreHandler</code>     instance, which accumulates all results received from specified sources.</li> <li><code>observer</code>: Creates a     <code>DefaultObserverHandler</code>     instance, which calls a callback for each event received from specified     sources.</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultEvaluatorPlugin","title":"ropt.plugins.plan.default.DefaultEvaluatorPlugin","text":"<p>               Bases: <code>EvaluatorPlugin</code></p> <p>The default plugin for creating evaluators.</p> <p>This plugin acts as a factory for the standard evaluator implementations provided by <code>ropt</code>. It allows the <code>PluginManager</code> to instantiate these steps when requested by a <code>Plan</code>.</p> <p>Supported Evaluators:</p> <ul> <li><code>function_evaluator</code>: Creates a     <code>DefaultFunctionEvaluator</code>     instance, which uses function calls to calculated individual objectives     and constraints.</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.ensemble_evaluator.DefaultEnsembleEvaluatorStep","title":"ropt.plugins.plan.ensemble_evaluator.DefaultEnsembleEvaluatorStep","text":"<p>               Bases: <code>PlanStep</code></p> <p>The default ensemble evaluator step for optimization plans.</p> <p>This step performs one or more ensemble evaluations based on the provided <code>variables</code>. It yields a tuple of <code>FunctionResults</code> objects, one for each input variable vector evaluated.</p> <p>The step emits the following events:</p> <ul> <li><code>START_ENSEMBLE_EVALUATOR_STEP</code>:   Emitted before the evaluation process begins.</li> <li><code>START_EVALUATION</code>: Emitted   just before the underlying ensemble evaluation is called.</li> <li><code>FINISHED_EVALUATION</code>: Emitted   after the evaluation completes, carrying the generated <code>FunctionResults</code>   in its <code>data</code> dictionary under the key <code>\"results\"</code>. Event handlers   typically listen for this event.</li> <li><code>FINISHED_ENSEMBLE_EVALUATOR_STEP</code>:   Emitted after the entire step, including result emission, is finished.</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.ensemble_evaluator.DefaultEnsembleEvaluatorStep.run_step_from_plan","title":"run_step_from_plan","text":"<pre><code>run_step_from_plan(\n    config: EnOptConfig,\n    variables: ArrayLike,\n    *,\n    transforms: OptModelTransforms | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; ExitCode\n</code></pre> <p>Run the ensemble evaluator step to perform ensemble evaluations.</p> <p>This method executes the core logic of the ensemble evaluator step. It requires an optimizer configuration (<code>EnOptConfig</code>) and optionally accepts specific variable vectors to evaluate.</p> <p>If <code>metadata</code> is provided, it is attached to the <code>Results</code> objects emitted via the <code>FINISHED_EVALUATION</code> event.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>Optimizer configuration.</p> required <code>variables</code> <code>ArrayLike</code> <p>Variable vector(s) to evaluate.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms to apply to the variables,         objectives, and constraints.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional dictionary to attach to emitted <code>FunctionResults</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExitCode</code> <p>An <code>ExitCode</code> indicating the outcome.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep","title":"ropt.plugins.plan.optimizer.DefaultOptimizerStep","text":"<p>               Bases: <code>PlanStep</code></p> <p>The default optimizer step for optimization plans.</p> <p>This step executes an optimization algorithm based on a provided configuration (<code>EnOptConfig</code> or a compatible dictionary). It iteratively performs function and potentially gradient evaluations, yielding a sequence of <code>FunctionResults</code> and <code>GradientResults</code> objects.</p> <p>While initial variable values are typically specified in the configuration, they can be overridden by passing them directly to the <code>run</code> method.</p> <p>The step emits the following events during its execution:</p> <ul> <li><code>START_OPTIMIZER_STEP</code>:   Emitted just before the optimization process begins.</li> <li><code>START_EVALUATION</code>: Emitted   immediately before an ensemble evaluation (for functions or gradients)   is requested from the underlying optimizer.</li> <li><code>FINISHED_EVALUATION</code>: Emitted   after an evaluation completes. This event carries the generated   <code>Results</code> object(s) in its <code>data</code> dictionary   under the key <code>\"results\"</code>. Event handlers typically listen for this event   to process or track optimization progress.</li> <li><code>FINISHED_OPTIMIZER_STEP</code>:   Emitted after the entire optimization process concludes (successfully,   or due to termination conditions or errors).</li> </ul> <p>This step also supports nested optimization. If a <code>nested_optimization</code> function is provided to the <code>run</code> method, the optimizer will execute a nested optimization at as part of each function evaluation. Each nested optimization run is done by creating a new plan. The provided function is then executed, passing the new plan and the variables. The <code>nested_optimization</code> function is expected to return a single <code>FunctionResults</code> object.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.run_step_from_plan","title":"run_step_from_plan","text":"<pre><code>run_step_from_plan(\n    config: EnOptConfig,\n    variables: ArrayLike,\n    *,\n    transforms: OptModelTransforms | None = None,\n    nested_optimization: NestedOptimizationCallable\n    | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; ExitCode\n</code></pre> <p>Run the optimizer step to perform an optimization.</p> <p>This method executes the core logic of the optimizer step. It requires an optimizer configuration (<code>EnOptConfig</code>) and optionally accepts specific initial variable vectors, and/or a nested optimization plan, and metadata.</p> <p>If <code>variables</code> are not provided, the initial values specified in the <code>config</code> are used. If <code>variables</code> are provided, they override the config's initial values.</p> <p>If <code>metadata</code> is provided, it is attached to the <code>Results</code> objects emitted via the <code>FINISHED_EVALUATION</code> event.</p> <p>If a <code>nested_optimization</code> callable is provided, a fresh plan will be constructed, and the callable will be called passing that plan and the initial variables to use. The callable should return a a single <code>FunctionResults</code> object that should contain the results of the nested optimization.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>Optimizer configuration.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms to apply to the variables,                  objectives, and constraints.</p> <code>None</code> <code>variables</code> <code>ArrayLike</code> <p>Optional initial variable vector(s) to start from.</p> required <code>nested_optimization</code> <code>NestedOptimizationCallable | None</code> <p>Optional callable to run a nested plan.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional dictionary to attach to emitted <code>Results</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExitCode</code> <p>An exit code indicating the outcome of the optimization.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler","title":"ropt.plugins.plan._tracker.DefaultTrackerHandler","text":"<p>               Bases: <code>EventHandler</code></p> <p>The default event handler for tracking optimization results.</p> <p>This event handler listens for <code>FINISHED_EVALUATION</code> events emitted by specified <code>sources</code> (plan steps). It processes the <code>Results</code> objects contained within these events and selects a single <code>FunctionResults</code> object to retain based on defined criteria.</p> <p>The criteria for selection are:</p> <ul> <li><code>what='best'</code> (default): Tracks the result with the lowest weighted   objective value encountered so far.</li> <li><code>what='last'</code>: Tracks the most recently received valid result.</li> </ul> <p>Optionally, results can be filtered based on constraint violations using the <code>constraint_tolerance</code> parameter. If provided, any result violating constraints beyond this tolerance is ignored.</p> <p>The selected result (in the optimizer domain) is stored internally. The result accessible via dictionary access (<code>handler[\"results\"]</code>) is the selected result, potentially transformed to the user domain.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._store.DefaultStoreHandler","title":"ropt.plugins.plan._store.DefaultStoreHandler","text":"<p>               Bases: <code>EventHandler</code></p> <p>The default event handler for storing optimization results.</p> <p>This event handler listens for <code>FINISHED_EVALUATION</code> events emitted by specified <code>sources</code> (plan steps). It collects all <code>Results</code> objects contained within these events and stores them sequentially in memory.</p> <p>The <code>sources</code> parameter filters which steps' results are collected. The accumulated results are stored as a tuple and can be accessed via dictionary access using the key <code>\"results\"</code> (e.g., <code>handler[\"results\"]</code>). Each time new results are received from a valid source, they are appended to this tuple.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._observer.DefaultObserverHandler","title":"ropt.plugins.plan._observer.DefaultObserverHandler","text":"<p>               Bases: <code>EventHandler</code></p> <p>The default event handler for observing events.</p> <p>This event handler listens for events emitted by specified <code>sources</code> (plan steps) and forwards them to one or more callback functions.</p> <p>The <code>sources</code> parameter filters which events are observed.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._function_evaluator.DefaultFunctionEvaluator","title":"ropt.plugins.plan._function_evaluator.DefaultFunctionEvaluator","text":"<p>               Bases: <code>Evaluator</code></p> <p>An evaluator that forwards calls to an evaluator function.</p> <p>This class acts as an adapter, allowing a standard Python callable (which matches the signature of the <code>eval</code> method) to be used as an <code>Evaluator</code> within an optimization <code>Plan</code>.</p> <p>It is initialized with an <code>evaluator</code> callable. When the <code>eval</code> method of this class is invoked by the plan, it simply delegates the call, along with all arguments, to the wrapped <code>evaluator</code> function.</p> <p>This is useful for integrating existing evaluation logic that is not already structured as an <code>Evaluator</code> subclass into a <code>ropt</code> plan.</p> <p>The <code>clients</code> parameter acts as a filter, determining which plan steps this evaluator should serve.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.cached_evaluator.DefaultCachedEvaluator","title":"ropt.plugins.plan.cached_evaluator.DefaultCachedEvaluator","text":"<p>               Bases: <code>Evaluator</code></p> <p>An evaluator that caches results to avoid redundant computations.</p> <p>This evaluator attempts to retrieve previously computed function results from a cache before delegating to another evaluator. The cache is populated from <code>FunctionResults</code> objects stored by <code>EventHandler</code> instances specified as <code>sources</code>.</p> <p>When an evaluation is requested, for each variable vector and its corresponding realization, this evaluator searches through the <code>results</code> attribute of its <code>sources</code>. If a <code>FunctionResults</code> object is found where the <code>variables</code> match the input (within a small tolerance) and the <code>realization</code> also matches, the cached <code>objectives</code> and <code>constraints</code> from that <code>FunctionResults</code> object are used.</p> <p>If some, but not all, requested evaluations are found in the cache, this evaluator will mark the cached ones as inactive for the next evaluator in the chain and then call that evaluator to compute only the missing results. The final combined results (cached and newly computed) are then returned.</p> <p>This is particularly useful in scenarios where the same variable sets might be evaluated multiple times, for example, in iterative optimization algorithms or when restarting optimizations.</p>"},{"location":"reference/default_realization_filter_plugin/","title":"Default Realization Filter Plugin","text":""},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.DefaultRealizationFilter","title":"ropt.plugins.realization_filter.default.DefaultRealizationFilter","text":"<p>               Bases: <code>RealizationFilter</code></p> <p>The default implementation for realization filtering strategies.</p> <p>This class provides several methods for calculating realization weights based on objective or constraint values. The specific method and its parameters are configured via the <code>RealizationFilterConfig</code> in the main <code>EnOptConfig</code>.</p> <p>Supported Methods:</p> <ul> <li> <p><code>sort-objective</code>:     Sorts realizations based on a weighted sum of specified objective     function values. It then assigns zero weights to realizations outside of     a defined index range (<code>first</code> to <code>last</code>) in the sorted list. Requires     options defined by     <code>SortObjectiveOptions</code>.</p> </li> <li> <p><code>sort-constraint</code>:     Sorts realizations based on the value of a single specified constraint     function. It assigns zero weights to realizations outside of a defined     index range (<code>first</code> to <code>last</code>) in the sorted list. Requires options     defined by     <code>SortConstraintOptions</code>.</p> </li> <li> <p><code>cvar-objective</code>:     Calculates realization weights using the Conditional Value-at-Risk (CVaR)     method applied to a weighted sum of specified objective function values.     Weights are assigned based on a specified <code>percentile</code> of the worst-performing     realizations (highest objective values for minimization). Interpolation is     used if the percentile boundary falls between realizations.     Requires options defined by     <code>CVaRObjectiveOptions</code>.</p> </li> <li> <p><code>cvar-constraint</code>:     Calculates realization weights using the CVaR method applied to the     value of a single specified constraint function. Weights are assigned     based on a specified <code>percentile</code> of the worst-performing realizations     (definition of \"worst\" depends on the constraint type: LE, GE, or EQ).     Interpolation is used if the percentile boundary falls between     realizations.     Requires options defined by     <code>CVaRConstraintOptions</code>.</p> </li> </ul>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.SortObjectiveOptions","title":"ropt.plugins.realization_filter.default.SortObjectiveOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-objective</code> realization filter.</p> <p>This method sorts realizations based on a weighted sum of objective function values and assigns weights only to those within a specified rank range.</p> <p>How it works:</p> <ol> <li>A weighted sum is calculated for each realization using the objective    values specified by the <code>sort</code> indices and the corresponding weights from    the main <code>EnOptConfig</code>. If only one objective    index is provided in <code>sort</code>, no weighting is applied.</li> <li>Realizations are sorted based on this calculated value (ascending).</li> <li>Realizations whose rank falls within the range [<code>first</code>, <code>last</code>]    (inclusive) are selected.</li> <li>The original weights (from <code>EnOptConfig.realizations.weights</code>) of the    selected realizations are retained; all other realizations receive a    weight of zero. Failed realizations (NaN objective values) are effectively    given the lowest rank and are excluded before selection.</li> </ol> <p>Attributes:</p> Name Type Description <code>sort</code> <code>list[NonNegativeInt]</code> <p>List of objective function indices to use for sorting.</p> <code>first</code> <code>NonNegativeInt</code> <p>The starting rank (0-based index) of realizations to select after sorting.</p> <code>last</code> <code>NonNegativeInt</code> <p>The ending rank (0-based index) of realizations to select after sorting.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.SortConstraintOptions","title":"ropt.plugins.realization_filter.default.SortConstraintOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-constraint</code> realization filter.</p> <p>This method sorts realizations based on the value of a single constraint function and assigns weights only to those within a specified rank range.</p> <p>How it works:</p> <ol> <li>The values of the constraint function specified by the <code>sort</code> index are    retrieved for each realization.</li> <li>Realizations are sorted based on these constraint values (ascending).</li> <li>Realizations whose rank falls within the range [<code>first</code>, <code>last</code>]    (inclusive) are selected.</li> <li>The original weights (from <code>EnOptConfig.realizations.weights</code>) of the    selected realizations are retained; all other realizations receive a    weight of zero. Failed realizations (NaN constraint values) are effectively    given the lowest rank and are excluded before selection.</li> </ol> <p>Attributes:</p> Name Type Description <code>sort</code> <code>NonNegativeInt</code> <p>The index of the constraint function to use for sorting.</p> <code>first</code> <code>NonNegativeInt</code> <p>The starting rank (0-based index) of realizations to select after sorting.</p> <code>last</code> <code>NonNegativeInt</code> <p>The ending rank (0-based index) of realizations to select after sorting.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.CVaRObjectiveOptions","title":"ropt.plugins.realization_filter.default.CVaRObjectiveOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-objective</code> realization filter.</p> <p>This method calculates realization weights using the Conditional Value-at-Risk (CVaR) approach applied to a weighted sum of objective function values. It focuses on the \"tail\" of the distribution representing the worst-performing realizations.</p> <p>How it works:</p> <ol> <li>A weighted sum is calculated for each realization using the objective    values specified by the <code>sort</code> indices and the corresponding weights    from the main <code>EnOptConfig</code>. If only    one objective index is provided in <code>sort</code>, no weighting is applied.</li> <li>Realizations are conceptually sorted based on this calculated value    (ascending, assuming minimization).</li> <li>The method identifies the subset of realizations corresponding to the    <code>percentile</code> worst outcomes (i.e., the highest weighted objective values).</li> <li>Weights are assigned to these worst-performing realizations based on the    CVaR calculation. If the <code>percentile</code> boundary falls between two    realizations, interpolation is used to assign partial weights. All other    realizations receive a weight of zero.</li> <li>Failed realizations (NaN objective values) are effectively excluded from    the CVaR calculation.</li> </ol> <p>Attributes:</p> Name Type Description <code>sort</code> <code>list[NonNegativeInt]</code> <p>List of objective function indices to use for the weighted sum.</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile (0.0 to 1.0) defining the portion of         worst realizations to consider. Defaults to 0.5.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.CVaRConstraintOptions","title":"ropt.plugins.realization_filter.default.CVaRConstraintOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-constraint</code> realization filter.</p> <p>This method calculates realization weights using the Conditional Value-at-Risk (CVaR) approach applied to the values of a single constraint function. It focuses on the \"tail\" of the distribution representing the realizations that most severely violate or are furthest from satisfying the constraint.</p> <p>How it works:</p> <ol> <li>The values of the constraint function specified by the <code>sort</code> index are    retrieved for each realization. These values typically represent the    constraint function evaluated minus its right-hand-side value (e.g.,    <code>g(x) - rhs</code>).</li> <li>Realizations are conceptually sorted based on how \"badly\" they perform    with respect to the constraint type:<ul> <li>LE (<code>&lt;=</code>) constraints: Realizations with the largest positive   values (most violated) are considered the worst.</li> <li>GE (<code>&gt;=</code>) constraints: Realizations with the smallest negative   values (most violated) are considered the worst.</li> <li>EQ (<code>==</code>) constraints: Realizations with the largest absolute   values (furthest from zero) are considered the worst.</li> </ul> </li> <li>The method identifies the subset of realizations corresponding to the    <code>percentile</code> worst outcomes based on the sorting defined above.</li> <li>Weights are assigned to these worst-performing realizations based on the    CVaR calculation. If the <code>percentile</code> boundary falls between two    realizations, interpolation is used to assign partial weights. All other    realizations receive a weight of zero.</li> <li>Failed realizations (NaN constraint values) are effectively excluded from    the CVaR calculation.</li> </ol> <p>Attributes:</p> Name Type Description <code>sort</code> <code>NonNegativeInt</code> <p>The index of the constraint function to use.</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile (0.0 to 1.0) defining the portion of         worst realizations to consider. Defaults to 0.5.</p>"},{"location":"reference/domain_transforms/","title":"Domain transforms","text":""},{"location":"reference/domain_transforms/#ropt.transforms","title":"ropt.transforms","text":"<p>Domain Transformation Framework.</p> <p>This module provides a flexible framework for transforming optimization variables, objectives, and constraints between user-defined domains and the domains used internally by the optimizer. These transformations are essential for:</p> <ul> <li>Improving Optimizer Performance: Scaling, shifting, and other   transformations can significantly enhance the efficiency, stability, and   convergence of optimization algorithms.</li> <li>Implementing Custom Mappings:  Beyond simple scaling, this framework   supports complex, user-defined mappings between domains, allowing for   tailored problem representations.</li> <li>Handling Diverse Units and Scales: Transformations enable the optimizer   to work with variables and functions that may have vastly different units   or scales, improving numerical stability.</li> </ul> <p>Key Components:</p> <ul> <li>Abstract Base Classes: Transform classes derive from abstract base classes   that define the specific mapping logic between domains.<ul> <li><code>VariableTransform</code>:   Defines the interface for transforming variables between user and   optimizer domains.</li> <li><code>ObjectiveTransform</code>:   Defines the interface for transforming objective values between user   and optimizer domains.</li> <li><code>NonLinearConstraintTransform</code>:   Defines the interface for transforming non-linear constraint values   between user and optimizer domains.</li> </ul> </li> <li><code>OptModelTransforms</code>:   A container class for conveniently grouping and   passing multiple transformation objects (variable, objective, and   nonlinear constraint).</li> </ul> <p>Workflow and Integration:</p> <ol> <li>Configuration: Transformation objects are passed to the     <code>EnOptConfig</code> during configuration validation,     using an <code>OptModelTransforms</code>     instance. This ensures that the entire optimization process is aware of and     configured for the transformed space. The trnsformation objects are stored     in the configuration object.</li> <li>Optimization Plan: The same transformation objects are passed to the     relevant optimization steps within the <code>Plan</code> via the     configuraiton object. (See, for example, the default implementation of an     optimizer step in     <code>DefaultOptimizerStep.run</code>).</li> <li>Evaluation: When the optimizer requests an evaluation of a variable     vector, the following occurs:<ul> <li>Transformation to the User Domain: The variable vector is      transformed from the optimizer       domain back to the user domain using the <code>from_optimizer</code> method of       the <code>VariableTransform</code>.</li> <li>Function Evaluation: Objective and constraint values are calculated       in the user domain.</li> <li>Transformation to the Optimizer Domain: The resulting objective and      constraint values are       transformed to the optimizer domain using the <code>to_optimizer</code> methods       of the <code>ObjectiveTransform</code> and <code>NonLinearConstraintTransform</code>.</li> </ul> </li> <li>Optimization: The optimizer proceeds using the transformed values.</li> <li>Results: The <code>Results</code> objects produced during     optimization hold values in the optimizer domain. To obtain results in the     user domain, the     <code>transform_from_optimizer</code>     method is used to create new <code>Results</code> objects with the transformed values.     For example,     <code>DefaultOptimizerStep.run</code>     emits events that include a dictionary with a <code>\"results\"</code> key That contains     <code>Results</code> objects in the  optimizer domain. To obtain results in the user     domain they must be converted using the     <code>transform_from_optimizer</code>     method.</li> </ol> <p>Classes:</p> Name Description <code>OptModelTransforms</code> <p>A data class for conveniently grouping and passing                 multiple transformation objects.</p> <code>VariableScaler</code> <p>A concrete implementation of <code>VariableTransform</code>                 that performs linear scaling and shifting.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms","title":"ropt.transforms.OptModelTransforms  <code>dataclass</code>","text":"<p>A container for optimization model transformers.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.variables","title":"variables  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>variables: VariableTransform | None = None\n</code></pre> <p>A <code>VariableTransform</code> object that defines the transformation for variables.</p> <p>If <code>None</code>, no transformation is applied to variables.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.objectives","title":"objectives  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>objectives: ObjectiveTransform | None = None\n</code></pre> <p>An <code>ObjectiveTransform</code> object that defines the transformation for objectives.</p> <p>If <code>None</code>, no transformation is applied to objectives.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.nonlinear_constraints","title":"nonlinear_constraints  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>nonlinear_constraints: (\n    NonLinearConstraintTransform | None\n) = None\n</code></pre> <p>A <code>NonLinearConstraintTransform</code> object that defines the transformation for nonlinear constraints.</p> <p>If <code>None</code>, no transformation is applied to nonlinear constraints.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform","title":"ropt.transforms.base.VariableTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for variable transformations.</p> <p>This class defines the interface for transforming variables between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of transformation.</p> <p>When implementing a variable transformation, the following aspects must be considered:</p> <ul> <li>Variable Value Transformation: Mapping variable values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Perturbation Magnitude Transformation: Stochastic gradient-based   algorithms use perturbations with specified magnitudes (see   <code>perturbation_magnitudes</code>). These magnitudes   are typically defined in the user domain and must be transformed to the   optimizer domain using the   <code>magnitudes_to_optimizer</code>   method.</li> <li>Bound Constraint Difference Transformation: To report violations of   variable bounds, the differences between variable values and their   lower/upper bounds must be transformed from the optimizer domain back   to the user domain. This is done using the   <code>bound_constraint_diffs_from_optimizer</code>   method.</li> <li>Linear Constraint Transformation: Linear constraints are generally   defined by coefficients and right-hand-side values in the user domain.   These must be transformed to the optimizer domain using the   <code>linear_constraints_to_optimizer</code>   method.</li> <li>Linear Constraint Difference Transformation: To report violations of   linear constraints, the differences between the linear constraint   values and their right-hand-side values must be transformed back to the   user domain. This is done using the   <code>linear_constraints_diffs_from_optimizer</code>   method.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform values from the user domain to the optimizer domain.</p> <p>This method maps variable values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform values from the optimizer domain to the user domain.</p> <p>This method maps variable values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.magnitudes_to_optimizer","title":"magnitudes_to_optimizer  <code>abstractmethod</code>","text":"<pre><code>magnitudes_to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform perturbation magnitudes to the optimizer domain.</p> <p>This method transforms perturbation magnitudes, typically used in stochastic gradient-based algorithms, from the user-defined domain to the optimizer's internal domain. The transformation ensures that the perturbations are applied correctly in the optimizer's space, which may have different scaling or units than the user domain.</p> <p>For example, if variables are scaled down in the optimizer domain, the perturbation magnitudes should also be scaled down proportionally.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The perturbation magnitudes in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed perturbation magnitudes in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.bound_constraint_diffs_from_optimizer","title":"bound_constraint_diffs_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>bound_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform bound constraint differences to the user domain.</p> <p>This method transforms the differences between variable values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if variables are scaled in the optimizer domain, the differences between the variables and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their lower bounds in the optimizer domain.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their upper bounds in the optimizer domain.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.linear_constraints_to_optimizer","title":"linear_constraints_to_optimizer","text":"<pre><code>linear_constraints_to_optimizer(\n    coefficients: NDArray[float64],\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Transform linear constraints from the user domain to the optimizer domain.</p> <p>This method transforms linear constraints, defined by their coefficients and right-hand-side bounds, from the user-defined domain to the optimizer's internal domain. This is essential to maintain the validity of the constraints after variable transformations.</p> <p>For instance, if variables are scaled or shifted in the optimizer domain, the coefficients and bounds of the linear constraints must be adjusted accordingly to ensure the constraints remain consistent.</p> <p>The linear constraints are defined by the equation <code>A * x = b</code>, where <code>A</code> is the coefficient matrix, <code>x</code> is the variable vector, and <code>b</code> represents the right-hand-side bounds.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>NDArray[float64]</code> <p>The coefficient matrix.</p> required <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed coefficient matrix and bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.linear_constraints_diffs_from_optimizer","title":"linear_constraints_diffs_from_optimizer","text":"<pre><code>linear_constraints_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform linear constraint differences to the user domain.</p> <p>This method transforms the differences between linear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if linear constraints are scaled in the optimizer domain, the differences between the constraint values and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform","title":"ropt.transforms.base.ObjectiveTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for objective transformations.</p> <p>This class defines the interface for transforming objective values between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of objective transformation.</p> <p>When implementing an objective transformation, the following aspects must be considered:</p> <ul> <li>Objective Value Transformation: Mapping objective values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Weighted Objective Transformation: The optimizer works with a   single, weighted objective value. If the transformation affects the   weighted objective, the   <code>weighted_objective_from_optimizer</code>   method should be overridden to handle this.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    objectives: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform objective values to the optimizer domain.</p> <p>This method maps objective values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>objectives</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the objective values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objective values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed objective values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    objectives: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform objective values to the user domain.</p> <p>This method maps objective values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>objectives</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the objective values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objective values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed objective values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.weighted_objective_from_optimizer","title":"weighted_objective_from_optimizer","text":"<pre><code>weighted_objective_from_optimizer(\n    weighted_objective: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform the weighted objective to the user domain.</p> <p>The optimizer uses a single, weighted objective value evaluated in the optimizer domain. This method reverses that transformation, mapping the weighted objective back to the user domain.</p> <p>For example, if the transformation to the optimizer domain involved a sign change to convert a maximization problem into a minimization problem, this method would change the sign back.</p> Note <p>This method may be applied to the weighted objective itself or to its gradient. Therefore, the input may be a scalar or a vector of values.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted objective value(s) to transform.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed weighted objective value(s).</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform","title":"ropt.transforms.base.NonLinearConstraintTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for nonlinear constraint transformations.</p> <p>This class defines the interface for transforming nonlinear constraint values between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of nonlinear constraint transformation.</p> <p>When implementing a nonlinear constraint transformation, the following aspects must be considered:</p> <ul> <li>Constraint Value Transformation: Mapping constraint values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Right-Hand-Side Bound Transformation: Mapping the right-hand-side   bounds of the constraints between the user and optimizer domains. This is   achieved by overriding the   <code>bounds_to_optimizer</code>   method.</li> <li>Constraint Difference Transformation: To report violations of   nonlinear constraints, the differences between constraint values and their   lower/upper bounds must be transformed from the optimizer domain back to   the user domain. This is done using the   <code>nonlinear_constraint_diffs_from_optimizer</code>   method.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    constraints: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform constraint values to the optimizer domain.</p> <p>This method maps nonlinear constraint values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>constraints</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the constraint values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>constraints</code> <code>NDArray[float64]</code> <p>The nonlinear constraint values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed nonlinear constraint values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    constraints: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform constraint values to the user domain.</p> <p>This method maps nonlinear constraint values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>constraints</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the constraint values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>constraints</code> <code>NDArray[float64]</code> <p>The nonlinear constraint values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed nonlinear constraint values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.bounds_to_optimizer","title":"bounds_to_optimizer  <code>abstractmethod</code>","text":"<pre><code>bounds_to_optimizer(\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform the right-hand-side bounds to the optimizer domain.</p> <p>This method transforms the lower and upper bounds of the nonlinear constraints from the user-defined domain to the optimizer's internal domain. This transformation is necessary to ensure that the constraints remain valid after the variables have been transformed.</p> <p>For example, if constraint values are scaled or shifted in the optimizer domain, the bounds must be adjusted accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values in the user domain.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values in the user domain.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.nonlinear_constraint_diffs_from_optimizer","title":"nonlinear_constraint_diffs_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>nonlinear_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform nonlinear constraint differences to the user domain.</p> <p>This method transforms the differences between nonlinear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if constraint values are scaled in the optimizer domain, the differences between the constraint values and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the nonlinear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the nonlinear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler","title":"ropt.transforms.VariableScaler","text":"<p>               Bases: <code>VariableTransform</code></p> <p>Linearly scales and shifts variables between domains.</p> <p>This class implements a linear transformation for variables, allowing for scaling and shifting between the user-defined domain and the optimizer's internal domain. The transformation is defined by a scaling factor and an offset for each variable.</p> <p>The transformation from the user domain to the optimizer domain is given by:</p> \\[x_{opt} = \\frac{(x_{\\textrm{user}} - \\textrm{offset})}{\\textrm{scale}}\\] <p>The transformation from the optimizer domain back to the user domain is:</p> \\[x_{user} = x_{\\textrm{opt}} * {\\textrm{scale}} + {\\textrm{offset}}\\] <p>This transformation can be used to improve the performance of the optimizer by working with variables that are scaled to a more suitable range or centered around a specific value.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.__init__","title":"__init__","text":"<pre><code>__init__(\n    scales: NDArray[float64] | None,\n    offsets: NDArray[float64] | None,\n) -&gt; None\n</code></pre> <p>Initialize the variable scaler.</p> <p>This scaler applies a linear transformation to variables, defined by scaling factors and offset values.</p> <p>If both <code>scales</code> and <code>offsets</code> are provided, they are broadcasted to ensure they have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>scales</code> <code>NDArray[float64] | None</code> <p>The scaling factors for each variable.</p> required <code>offsets</code> <code>NDArray[float64] | None</code> <p>The offset values for each variable.</p> required"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.to_optimizer","title":"to_optimizer","text":"<pre><code>to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform variable values to the optimizer domain.</p> <p>This method applies the linear scaling and offset transformation to variable values, mapping them from the user-defined domain to the optimizer's internal domain.</p> <p>The transformation is defined as: <code>x_opt = (x_user - offset) / scale</code>.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.from_optimizer","title":"from_optimizer","text":"<pre><code>from_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform variable values to the user domain.</p> <p>This method applies the inverse linear scaling and offset transformation to variable values, mapping them from the optimizer's internal domain back to the user-defined domain.</p> <p>The transformation is defined as: <code>x_user = x_opt * scale + offset</code>.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.magnitudes_to_optimizer","title":"magnitudes_to_optimizer","text":"<pre><code>magnitudes_to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform perturbation magnitudes to the optimizer domain.</p> <p>This method transforms perturbation magnitudes, typically used in stochastic gradient-based algorithms, from the user-defined domain to the optimizer's internal domain. The transformation ensures that the perturbations are applied correctly in the optimizer's space, which may have different scaling or units than the user domain.</p> <p>The transformation is defined as: <code>x_opt = x_user / scale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The perturbation magnitudes in the user domain.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed perturbation magnitudes in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.linear_constraints_to_optimizer","title":"linear_constraints_to_optimizer","text":"<pre><code>linear_constraints_to_optimizer(\n    coefficients: NDArray[float64],\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Transform linear constraints to the optimizer domain.</p> <p>This method transforms linear constraints, defined by their coefficients and right-hand-side bounds, from the user-defined domain to the optimizer's internal domain. This transformation accounts for the scaling and shifting applied to the variables and ensures that the constraints remain valid in the optimizer's space.</p> <p>The set of linear constraints can be represented by a matrix equation: \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\).</p> <p>When linearly transforming variables to the optimizer domain, the coefficients (\\(\\mathbf{A}\\)) and right-hand-side values (\\(\\mathbf{b}\\)) must be converted to remain valid (see also the configuration for linear constraints). If the linear transformation of the variables to the optimizer domain is given by:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{S} \\mathbf{x} + \\mathbf{o}\\] <p>then the coefficients and right-hand-side values must be transformed as follows:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A} \\mathbf{S}^{-1} \\\\ \\hat{\\mathbf{b}}     &amp;= \\mathbf{b} + \\mathbf{A}\\mathbf{S}^{-1}\\mathbf{o} \\end{align}\\] <p>where \\(S\\) is a diagonal matrix with scaling factors on the diagonal and \\(o\\) are the offsets.</p> <p>The resulting equations are further scaled by dividing them by maximum of the absolute values of the coefficients in each equation.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>NDArray[float64]</code> <p>The coefficient matrix of the linear constraints.</p> required <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed coefficient matrix and bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.bound_constraint_diffs_from_optimizer","title":"bound_constraint_diffs_from_optimizer","text":"<pre><code>bound_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform bound constraint differences to the user domain.</p> <p>This method transforms the differences between variable values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if variables are scaled in the optimizer domain, the differences between the variables and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>The transformation is defined as: <code>x_user = x_opt * scale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.linear_constraints_diffs_from_optimizer","title":"linear_constraints_diffs_from_optimizer","text":"<pre><code>linear_constraints_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform linear constraint differences to the user domain.</p> <p>This method transforms the differences between linear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>This is implemented by re-scaling the equations with the weights that were determined and stored by the <code>linear_constraints_to_optimizer</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/enopt_config/","title":"Configuration","text":""},{"location":"reference/enopt_config/#ropt.config","title":"ropt.config","text":"<p>The <code>ropt.config</code> module provides configuration classes for optimization workflows.</p> <p>This module defines a set of classes that are used to configure various aspects of an optimization process, including variables, objectives, constraints, realizations, samplers, and more.</p> <p>The central configuration class for optimization is <code>EnOptConfig</code>, which encapsulates the complete configuration for a single optimization step. It is designed to be flexible and extensible, allowing users to customize the optimization process to their specific needs.</p> <p>These configuration classes are built using <code>pydantic</code>, which provides robust data validation and parsing capabilities. This ensures that the configuration data is consistent and adheres to the expected structure.</p> <p>Configuration objects are typically created from dictionaries of configuration values using the <code>model_validate</code> method provided by <code>pydantic</code>.</p> <p>Key Features:</p> <ul> <li>Modular Design: The configuration is broken down into smaller, manageable   components, each represented by a dedicated class.</li> <li>Validation: <code>pydantic</code> ensures that the configuration data is valid and   consistent.</li> <li>Extensibility: The modular design allows for easy extension and   customization of the optimization process.</li> <li>Centralized Configuration: The   <code>EnOptConfig</code> class provides a single point   of entry for configuring an optimization step.</li> </ul> <p>Parsing and Validation</p> <p>The configuration classes are built using <code>pydantic</code>, which provides robust data validation. The primary configuration class is <code>EnOptConfig</code>, and it contains nested configuration classes for various aspects of the optimization. To parse a configuration from a dictionary, use the <code>model_validate</code> class method. ```</p> <p>Classes:     EnOptConfig:                The main configuration class for an optimization step.     VariablesConfig:            Configuration for variables.     ObjectiveFunctionsConfig:   Configuration for objective functions.     LinearConstraintsConfig:    Configuration for linear constraints.     NonlinearConstraintsConfig: Configuration for non-linear constraints.     RealizationsConfig:         Configuration for realizations.     OptimizerConfig:            Configuration for the optimizer.     GradientConfig:             Configuration for gradient calculations.     FunctionEstimatorConfig:    Configuration for function estimators.     RealizationFilterConfig:    Configuration for realization filters.     SamplerConfig:              Configuration for samplers.</p>"},{"location":"reference/enopt_config/#ropt.config.EnOptConfig","title":"EnOptConfig","text":"<p>The primary configuration class for an optimization step.</p> <p><code>EnOptConfig</code> orchestrates the configuration of an entire optimization workflow. It contains nested configuration classes that define specific aspects of the optimization, such as variables, objectives, constraints, realizations, and the optimizer itself.</p> <p><code>realization_filters</code>, <code>function_estimators</code>, and <code>samplers</code> are configured as tuples. Other configuration fields reference these objects by their index within the tuples. For example, <code>GradientConfig</code> uses a <code>samplers</code> field, which is an array of indices specifying the sampler to use for each variable.</p> <p>The optional <code>names</code> attribute is a dictionary that stores the names of the various entities, such as variables, objectives, and constraints. The supported name types are defined in the <code>AxisName</code> enumeration. This information is optional, as it is not strictly necessary for the optimization, but it can be useful for labeling and interpreting results. For instance, when present, it is used to create a multi-index results that are exported as data frames.</p> Info <p>Many nested configuration classes use <code>numpy</code> arrays. These arrays typically have a size determined by a configured property (e.g., the number of variables) or a size of one. In the latter case, the single value is broadcasted to all relevant elements. For example, <code>VariablesConfig</code> defines properties like initial values and bounds as <code>numpy</code> arrays, which must either match the number of variables or have a size of one.</p> <p>Attributes:</p> Name Type Description <code>variables</code> <code>VariablesConfig</code> <p>Configuration for the optimization variables.</p> <code>objectives</code> <code>ObjectiveFunctionsConfig</code> <p>Configuration for the objective functions.</p> <code>linear_constraints</code> <code>LinearConstraintsConfig | None</code> <p>Configuration for linear constraints.</p> <code>nonlinear_constraints</code> <code>NonlinearConstraintsConfig | None</code> <p>Configuration for non-linear constraints.</p> <code>realizations</code> <code>RealizationsConfig</code> <p>Configuration for the realizations.</p> <code>optimizer</code> <code>OptimizerConfig</code> <p>Configuration for the optimization algorithm.</p> <code>gradient</code> <code>GradientConfig</code> <p>Configuration for gradient calculations.</p> <code>realization_filters</code> <code>tuple[RealizationFilterConfig, ...]</code> <p>Configuration for realization filters.</p> <code>function_estimators</code> <code>tuple[FunctionEstimatorConfig, ...]</code> <p>Configuration for function estimators.</p> <code>samplers</code> <code>tuple[SamplerConfig, ...]</code> <p>Configuration for samplers.</p> <code>names</code> <code>dict[str, tuple[str | int, ...]]</code> <p>Optional mapping of axis types to names.</p>"},{"location":"reference/enopt_config/#ropt.config.VariablesConfig","title":"VariablesConfig","text":"<p>Configuration class for optimization variables.</p> <p>This class, <code>VariablesConfig</code>, defines the configuration for optimization variables. It is used in an <code>EnOptConfig</code> object to specify the initial values, bounds, types, and an optional mask for the variables.</p> <p>The <code>variables</code> field is required and determines the number of variables, including both free and fixed variables.</p> <p>The <code>lower_bounds</code> and <code>upper_bounds</code> fields define the bounds for each variable. These are also <code>numpy</code> arrays and are broadcasted to match the number of variables. By default, they are set to negative and positive infinity, respectively. <code>numpy.nan</code> values in these arrays indicate unbounded variables and are converted to <code>numpy.inf</code> with the appropriate sign.</p> <p>The optional <code>types</code> field allows assigning a <code>VariableType</code> to each variable. If not provided, all variables are assumed to be continuous real-valued (<code>VariableType.REAL</code>).</p> <p>The optional <code>mask</code> field is a boolean <code>numpy</code> array that indicates which variables are free to change during optimization. <code>True</code> values in the mask indicate that the corresponding variable is free, while <code>False</code> indicates a fixed variable.</p> <p>Variable perturbations</p> <p>The <code>VariablesConfig</code> class also stores information that is needed to generate perturbed variables, for instance to calculate stochastic gradients.</p> <p>Perturbations are generated by sampler objects that are configured separately as a tuple of <code>SamplerConfig</code> objects in the configuration object used by a plan step. For instance, <code>EnOptConfig</code> object defines the available samplers in its <code>samplers</code> field. The <code>samplers</code> field of the <code>VariablesConfig</code> object specifies, for each variable, the index of the sampler to use. A random number generator is created to support samplers that require random numbers.</p> <p>The generated perturbation values are scaled by the values of the <code>perturbation_magnitudes</code> field and can be modified based on the <code>perturbation_types</code>. See <code>PerturbationType</code> for details on available perturbation types.</p> <p>Perturbed variables may violate the defined variable bounds. The <code>boundary_types</code> field specifies how to handle such violations. See <code>BoundaryType</code> for details on available boundary handling methods.</p> <p>The <code>perturbation_types</code> and <code>boundary_types</code> fields use values from the <code>PerturbationType</code> and <code>BoundaryType</code> enumerations, respectively.</p> Seed for Samplers <p>The <code>seed</code> value ensures consistent results across repeated runs with the same configuration. To obtain unique results for each optimization run, modify the seed. A common approach is to use a tuple with a unique ID as the first element, ensuring reproducibility across nested and parallel plan evaluations.</p> <p>Attributes:</p> Name Type Description <code>types</code> <code>ArrayEnum</code> <p>Optional variable types.</p> <code>variable_count</code> <code>int</code> <p>Number of variables.</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the variables (default: \\(-\\infty\\)).</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the variables (default: \\(+\\infty\\)).</p> <code>mask</code> <code>Array1DBool</code> <p>Optional boolean mask indicating free variables.</p> <code>perturbation_magnitudes</code> <code>Array1D</code> <p>Magnitudes of the perturbations for each variable (default: <code>DEFAULT_PERTURBATION_MAGNITUDE</code>).</p> <code>perturbation_types</code> <code>ArrayEnum</code> <p>Type of perturbation for each variable (see <code>PerturbationType</code>, default: <code>DEFAULT_PERTURBATION_TYPE</code>).</p> <code>boundary_types</code> <code>ArrayEnum</code> <p>How to handle perturbations that violate boundary conditions (see <code>BoundaryType</code>, default: <code>DEFAULT_PERTURBATION_BOUNDARY_TYPE</code>).</p> <code>samplers</code> <code>Array1DInt</code> <p>Indices of the samplers to use for each variable.</p> <code>seed</code> <code>ItemOrTuple[int]</code> <p>Seed for the random number generator used by the samplers.</p>"},{"location":"reference/enopt_config/#ropt.config.ObjectiveFunctionsConfig","title":"ObjectiveFunctionsConfig","text":"<p>Configuration class for objective functions.</p> <p>This class, <code>ObjectiveFunctionsConfig</code>, defines the configuration for objective functions. for instance, as part of an <code>EnOptConfig</code> object.</p> <p><code>ropt</code> supports multi-objective optimization. Multiple objectives are combined into a single value by summing them after weighting. The <code>weights</code> field, a <code>numpy</code> array, determines the weight of each objective function. The length of this array defines the number of objective functions. The weights are automatically normalized to sum to 1 (e.g., <code>[1, 1]</code> becomes <code>[0.5, 0.5]</code>).</p> <p>Objective functions can optionally be processed using <code>realization filters</code> and <code>function estimators</code>.The <code>realization_filters</code> and <code>function_estimators</code> attributes, if provided, must be arrays of integer indices. Each index in the <code>realization_filters</code> array corresponds to a objective (by position) and specifies which filter to use. The available filters must be defined elsewhere as a tuple of realization filter configurations. For instance, for optimization these are defined in the <code>EnOptConfig.realization_filters</code> configuration class. The same logic applies to the <code>function_estimators</code> array . If an index is invalid (e.g., out of bounds for the corresponding object tuple), no filter or estimator is applied to that specific objective. If these attributes are not provided (<code>None</code>), no filters or estimators are applied at all.</p> <p>Attributes:</p> Name Type Description <code>weights</code> <code>Array1D</code> <p>Weights for the objective functions (default: 1.0).</p> <code>realization_filters</code> <code>Array1DInt</code> <p>Optional indices of realization filters.</p> <code>function_estimators</code> <code>Array1DInt</code> <p>Optional indices of function estimators.</p>"},{"location":"reference/enopt_config/#ropt.config.LinearConstraintsConfig","title":"LinearConstraintsConfig","text":"<p>Configuration class for linear constraints.</p> <p>This class, <code>LinearConstraintsConfig</code>, defines linear constraints used in an optimization, for instance as part of an <code>EnOptConfig</code> object.</p> <p>Linear constraints are defined by a set of linear equations involving the optimization variables. These equations can represent equality or inequality constraints. The <code>coefficients</code> field is a 2D <code>numpy</code> array where each row represents a constraint, and each column corresponds to a variable.</p> <p>The <code>lower_bounds</code> and <code>upper_bounds</code> fields specify the bounds on the right-hand side of each constraint equation. These fields are converted and broadcasted to <code>numpy</code> arrays with a length equal to the number of constraint equations.</p> <p>Less-than and greater-than inequality constraints can be specified by setting the lower bounds to \\(-\\infty\\), or the upper bounds to \\(+\\infty\\), respectively. Equality constraints are specified by setting the lower bounds equal to the upper bounds.</p> <p>Attributes:</p> Name Type Description <code>coefficients</code> <code>Array2D</code> <p>Matrix of coefficients for the linear constraints.</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the right-hand side of the constraint equations.</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the right-hand side of the constraint equations.</p> Linear transformation of variables. <p>The set of linear constraints can be represented by a matrix equation: \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\).</p> <p>When linearly transforming variables to the optimizer domain, the coefficients (\\(\\mathbf{A}\\)) and right-hand-side values (\\(\\mathbf{b}\\)) must be converted to remain valid. If the linear transformation of the variables to the optimizer domain is given by:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{S} \\mathbf{x} + \\mathbf{o}\\] <p>then the coefficients and right-hand-side values must be transformed as follows:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A} \\mathbf{S}^{-1} \\\\ \\hat{\\mathbf{b}}     &amp;= \\mathbf{b} + \\mathbf{A}\\mathbf{S}^{-1}\\mathbf{o} \\end{align}\\]"},{"location":"reference/enopt_config/#ropt.config.NonlinearConstraintsConfig","title":"NonlinearConstraintsConfig","text":"<p>Configuration class for non-linear constraints.</p> <p>This class, <code>NonlinearConstraintsConfig</code>, defines non-linear constraints , for instance as part of an <code>EnOptConfig</code> object.</p> <p>Non-linear constraints are defined by comparing a constraint function to a right-hand-side value, allowing for equality or inequality constraints. The <code>lower_bounds</code> and <code>upper_bounds</code> fields, which are <code>numpy</code> arrays, specify the bounds on these right-hand-side values. The length of these arrays determines the number of constraint functions.</p> <p>Less-than and greater-than inequality constraints can be specified by setting the lower bounds to \\(-\\infty\\), or the upper bounds to \\(+\\infty\\), respectively. Equality constraints are specified by setting the lower bounds equal to the upper bounds.</p> <p>Non-linear constraints can optionally be processed using <code>realization filters</code> and <code>function estimators</code>.The <code>realization_filters</code> and <code>function_estimators</code> attributes, if provided, must be arrays of integer indices. Each index in the <code>realization_filters</code> array corresponds to a constraint function (by position) and specifies which filter to use. The available filters must be defined elsewhere as a tuple of realization filter configurations. For instance, for optimization these are defined in the <code>EnOptConfig.realization_filters</code> configuration class. The same logic applies to the <code>function_estimators</code> array . If an index is invalid (e.g., out of bounds for the corresponding object tuple), no filter or estimator is applied to that specific constraint function. If these attributes are not provided (<code>None</code>), no filters or estimators are applied at all.</p> <p>Attributes:</p> Name Type Description <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the right-hand-side values.</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the right-hand-side values.</p> <code>realization_filters</code> <code>Array1DInt</code> <p>Optional indices of realization filters.</p> <code>function_estimators</code> <code>Array1DInt</code> <p>Optional indices of function estimators.</p>"},{"location":"reference/enopt_config/#ropt.config.RealizationsConfig","title":"RealizationsConfig","text":"<p>Configuration class for realizations.</p> <p>This class, <code>RealizationsConfig</code>, defines the configuration for realizations used when calculating objectives and constraints.</p> <p>To optimize an ensemble of functions, a set of realizations is defined. When the optimizer requests a function value or a gradient, these are calculated for each realization and then combined into a single value. Typically, this combination is a weighted sum, but other methods are possible.</p> <p>The <code>weights</code> field, a <code>numpy</code> array, determines the weight of each realization. The length of this array defines the number of realizations. The weights are automatically normalized to sum to 1 (e.g., <code>[1, 1]</code> becomes <code>[0.5, 0.5]</code>).</p> <p>If function value calculations for some realizations fail (e.g., due to a simulation error), the total function and gradient values can still be calculated by excluding the missing values. However, a minimum number of successful realizations may be required. The <code>realization_min_success</code> field specifies this minimum. By default, it is set equal to the number of realizations, meaning no missing values are allowed.</p> Note <p>Setting <code>realization_min_success</code> to zero allows the optimization to proceed even if all realizations fail. While some optimizers can handle this, most will treat it as if the value were one, requiring at least one successful realization.</p> <p>Attributes:</p> Name Type Description <code>weights</code> <code>Array1D</code> <p>Weights for the realizations (default: 1.0).</p> <code>realization_min_success</code> <code>NonNegativeInt | None</code> <p>Minimum number of successful realizations (default:                     equal to the number of realizations).</p>"},{"location":"reference/enopt_config/#ropt.config.OptimizerConfig","title":"OptimizerConfig","text":"<p>Configuration class for the optimization algorithm.</p> <p>This class, <code>OptimizerConfig</code>, defines the configuration for the optimization algorithm used in an <code>EnOptConfig</code> object.</p> <p>While optimization methods can have diverse parameters, this class provides a standardized set of settings that are commonly used and forwarded to the optimizer:</p> <ul> <li><code>max_iterations</code>: The maximum number of iterations allowed. The   optimizer may choose to ignore this.</li> <li><code>max_functions</code>: The maximum number of function evaluations allowed.</li> <li><code>max_batches</code>: The maximum number of evaluations batches allowed. The   optimizer callback may ask to evaluate a batch of multiple functions and   gradients at once. This setting will limit the number of those calls.</li> <li><code>tolerance</code>: The convergence tolerance used as a stopping criterion.   The exact definition depends on the optimizer, and it may be ignored.</li> <li><code>parallel</code>: If <code>True</code>, allows the optimizer to use parallelized   function evaluations. This typically applies to gradient-free methods and   may be ignored.</li> <li><code>output_dir</code>: An optional output directory where the optimizer can   store files.</li> <li><code>options</code>: A dictionary or list of strings for generic optimizer   options. The required format and interpretation depend on the specific   optimization method.</li> <li><code>stdout</code>: Redirect optimizer standard output to the given file.</li> <li><code>stderr</code>: Redirect optimizer standard error to the given file.</li> </ul> Differences between <code>max_iterations</code>, <code>max_functions</code>, and <code>max_batches</code> <p>These three parameters provide different ways to limit the duration or computational cost of the optimization process:</p> <ul> <li> <p><code>max_iterations</code>: This limit is passed directly to the backend   optimization algorithm. Many optimizers define an \"iteration\" as a   distinct step in their process, which might involve one or more   function or gradient evaluations. The interpretation of <code>max_iterations</code>   depends on the specific backend optimizer; it typically caps the number   of these internal iterations. Some backends might ignore this setting if   they don't have a clear concept of iterations.</p> </li> <li> <p><code>max_batches</code>: This limit restricts the total number of calls made   to the evaluation function provided to <code>ropt</code>. An optimizer might request   a batch containing multiple function and/or gradient evaluations within   a single call. <code>max_batches</code> limits how many such batch requests are   processed sequentially. This is particularly useful for managing resource   usage when batches are evaluated in parallel (e.g., on an HPC cluster),   as it controls the number of sequential submission steps. The number of   batches does not necessarily correspond directly to the number of   optimizer iterations, especially if function and gradient evaluations   occur in separate batches.</p> </li> <li> <p><code>max_functions</code>: This imposes a hard limit on the total number of   individual objective function evaluations performed across all batches.   Since a single batch evaluation (limited by <code>max_batches</code>) can involve   multiple function evaluations, setting <code>max_functions</code> provides more   granular control over the total computational effort spent on function   calls. It can serve as an alternative stopping criterion if the backend   optimizer doesn't support <code>max_iterations</code> or if you need to strictly   limit the function evaluation count. Note that exceeding this limit might   cause the optimization to terminate mid-batch, potentially earlier than   a corresponding <code>max_batches</code> limit would.</p> </li> </ul> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the optimization method.</p> <code>max_iterations</code> <code>PositiveInt | None</code> <p>Maximum number of iterations (optional).</p> <code>max_functions</code> <code>PositiveInt | None</code> <p>Maximum number of function evaluations (optional).</p> <code>max_batches</code> <code>PositiveInt | None</code> <p>Maximum number of batch evaluations (optional).</p> <code>tolerance</code> <code>NonNegativeFloat | None</code> <p>Convergence tolerance (optional).</p> <code>parallel</code> <code>bool</code> <p>Allow parallelized function evaluations (default: <code>False</code>).</p> <code>output_dir</code> <code>Path | None</code> <p>Output directory for the optimizer (optional).</p> <code>options</code> <code>dict[str, Any] | list[str] | None</code> <p>Generic options for the optimizer (optional).</p> <code>stdout</code> <code>Path | None</code> <p>File to redirect optimizer standard output (optional).</p> <code>stderr</code> <code>Path | None</code> <p>File to redirect optimizer standard error (optional).</p>"},{"location":"reference/enopt_config/#ropt.config.GradientConfig","title":"GradientConfig","text":"<p>Configuration class for gradient calculations.</p> <p>This class, <code>GradientConfig</code>, defines the configuration of gradient calculations. It is used in an <code>EnOptConfig</code> object as the <code>gradient</code> field to specify how gradients are calculated in gradient-based optimizers.</p> <p>Gradients are estimated using function values calculated from perturbed variables and the unperturbed variables. The <code>number_of_perturbations</code> field determines the number of perturbed variables used, which must be at least one.</p> <p>If function evaluations for some perturbed variables fail, the gradient may still be estimated as long as a minimum number of evaluations succeed. The <code>perturbation_min_success</code> field specifies this minimum. By default, it equals <code>number_of_perturbations</code>.</p> <p>Gradients are calculated for each realization individually and then combined into a total gradient. If <code>number_of_perturbations</code> is low, or even just one, individual gradient calculations may be unreliable. In this case, setting <code>merge_realizations</code> to <code>True</code> directs the optimizer to combine the results of all realizations directly into a single gradient estimate.</p> <p>The <code>evaluation_policy</code> option controls how and when objective functions and gradients are calculated. It accepts one of three string values:</p> <ul> <li><code>\"speculative\"</code>: Evaluate the gradient whenever the objective function     is requested, even if the optimizer hasn't explicitly asked for the     gradient at that point. This approach can potentially improve load     balancing on HPC clusters by initiating gradient work earlier, though     its effectiveness depends on whether the optimizer can utilize these     speculatively computed gradients.</li> <li><code>\"separate\"</code>: Always launch function and gradient evaluations as     distinct operations, even if the optimizer requests both simultaneously.     This is particularly useful when employing realization filters (see     <code>RealizationFilterConfig</code>) that     might disable certain realizations, as it can potentially reduce the     number of gradient evaluations needed.</li> <li><code>\"auto\"</code>: Evaluate functions and/or gradients strictly according to the     optimizer's requests. Calculations are performed only when the     optimization algorithm explicitly requires them.</li> </ul> <p>Attributes:</p> Name Type Description <code>number_of_perturbations</code> <code>PositiveInt</code> <p>Number of perturbations (default: <code>DEFAULT_NUMBER_OF_PERTURBATIONS</code>).</p> <code>perturbation_min_success</code> <code>PositiveInt | None</code> <p>Minimum number of successful function evaluations for perturbed variables (default: equal to <code>number_of_perturbations</code>).</p> <code>merge_realizations</code> <code>bool</code> <p>Merge all realizations for the final gradient calculation (default: <code>False</code>).</p> <code>evaluation_policy</code> <code>Literal['speculative', 'separate', 'auto']</code> <p>How to evaluate functions and gradients.</p>"},{"location":"reference/enopt_config/#ropt.config.FunctionEstimatorConfig","title":"FunctionEstimatorConfig","text":"<p>Configuration class for function estimators.</p> <p>This class, <code>FunctionEstimatorConfig</code>, defines the configuration for function estimators. Function estimators are generally configured as a tuple of <code>FunctionEstimatorConfig</code> objects in a configuration class of a plan step. For instance, <code>function_estimators</code> field of the <code>EnOptConfig</code> defines the available estimators for the optimization.</p> <p>By default, objective and constraint functions, as well as their gradients, are calculated from individual realizations using a weighted sum. Function estimators provide a way to modify this default calculation.</p> <p>The <code>method</code> field specifies the function estimator method to use for combining the individual realizations. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the function estimator method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the function estimator.</p>"},{"location":"reference/enopt_config/#ropt.config.RealizationFilterConfig","title":"RealizationFilterConfig","text":"<p>Configuration class for realization filters.</p> <p>This class, <code>RealizationFilterConfig</code>, defines the configuration for realization filters. Realization filters are generally configured as a tuple in another configuration object. For instance, the <code>realization_filters</code> field of the <code>EnOptConfig</code> defines the available filters for the optimization.</p> <p>By default, objective and constraint functions, as well as their gradients, are calculated as a weighted function of all realizations. Realization filters provide a way to modify the weights of individual realizations. For example, they can be used to select a subset of realizations for calculating the final objective and constraint functions and their gradients by setting the weights of the other realizations to zero.</p> <p>The <code>method</code> field specifies the realization filter method to use for adjusting the weights. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the realization filter method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the realization filter.</p>"},{"location":"reference/enopt_config/#ropt.config.SamplerConfig","title":"SamplerConfig","text":"<p>Configuration class for samplers.</p> <p>This class, <code>SamplerConfig</code>, defines the configuration for samplers used in an <code>EnOptConfig</code> object. Samplers are configured as a tuple in the <code>samplers</code> field of the <code>EnOptConfig</code>, defining the available samplers for the optimization. The <code>samplers</code> field in the <code>GradientConfig</code> specifies the index of the sampler to use for each variable.</p> <p>Samplers generate perturbations added to variables for gradient calculations. These perturbations can be deterministic or stochastic.</p> <p>The <code>method</code> field specifies the sampler method to use for generating perturbations. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>By default, each realization uses a different set of perturbed variables. Setting the <code>shared</code> flag to <code>True</code> directs the sampler to use the same set of perturbed values for all realizations.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the sampler method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the sampler.</p> <code>shared</code> <code>bool</code> <p>Whether to share perturbation values between realizations (default: <code>False</code>).</p>"},{"location":"reference/enopt_config/#ropt.config.constants","title":"ropt.config.constants","text":"<p>Default values used by the configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.constants.DEFAULT_SEED","title":"DEFAULT_SEED  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SEED: Final = 1\n</code></pre> <p>Default seed for random number generators.</p> <p>The seed is used as the base value for random number generators within various components of the optimization process, such as samplers. Using a consistent seed ensures reproducibility across multiple runs with the same configuration. To obtain unique results for each optimization run, modify this seed.</p>"},{"location":"reference/enopt_config/#ropt.config.constants.DEFAULT_NUMBER_OF_PERTURBATIONS","title":"DEFAULT_NUMBER_OF_PERTURBATIONS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_NUMBER_OF_PERTURBATIONS: Final = 5\n</code></pre> <p>Default number of perturbations for gradient estimation.</p> <p>This value defines the default number of perturbed variables used to estimate gradients. A higher number of perturbations can lead to more accurate gradient estimates but also increases the number of function evaluations required.</p>"},{"location":"reference/enopt_config/#ropt.config.constants.DEFAULT_PERTURBATION_MAGNITUDE","title":"DEFAULT_PERTURBATION_MAGNITUDE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_MAGNITUDE: Final = 0.005\n</code></pre> <p>Default magnitude for variable perturbations.</p> <p>This value specifies the default value of the scaling factor applied to the perturbation values generated by samplers. The magnitude can be interpreted as an absolute value or as a relative value, depending on the selected perturbation type.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.constants.DEFAULT_PERTURBATION_BOUNDARY_TYPE","title":"DEFAULT_PERTURBATION_BOUNDARY_TYPE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_BOUNDARY_TYPE: Final = MIRROR_BOTH\n</code></pre> <p>Default perturbation boundary handling type.</p> <p>This value determines how perturbations that violate the defined variable bounds are handled. The default, <code>BoundaryType.MIRROR_BOTH</code>, mirrors perturbations back into the valid range if they exceed either the lower or upper bound.</p> <p>See also: <code>BoundaryType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.constants.DEFAULT_PERTURBATION_TYPE","title":"DEFAULT_PERTURBATION_TYPE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_TYPE: Final = ABSOLUTE\n</code></pre> <p>Default perturbation type.</p> <p>This value determines how the perturbation magnitude is interpreted. The default, <code>PerturbationType.ABSOLUTE</code>, means that the perturbation magnitude is added directly to the variable value. Other options, such as <code>PerturbationType.RELATIVE</code>, scale the perturbation magnitude based on the variable's bounds.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.options","title":"ropt.config.options","text":"<p>This module defines utilities for validating plugin options.</p> <p>This module provides classes and functions to define and validate options for plugins. It uses Pydantic to create models that represent the schema of plugin options, allowing for structured and type-safe configuration.</p> <p>Classes:</p> Name Description <code>OptionsSchemaModel</code> <p>Represents the overall schema for plugin options.</p> <code>MethodSchemaModel</code> <p>Represents the schema for a specific method within a plugin, including its name and options.</p>"},{"location":"reference/enopt_config/#ropt.config.options.OptionsSchemaModel","title":"OptionsSchemaModel","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the overall schema for plugin options.</p> <p>This class defines the structure for describing the methods and options available for a plugin. The methods are described in a list of [<code>MethodSchemaModel][ropt.config.options.MethodSchemaModel</code>] objects, each describing a method supported by the plugin.</p> <p>Attributes:</p> Name Type Description <code>methods</code> <code>dict[str, MethodSchemaModel[Any]]</code> <p>A list of method schemas.</p> <p>Example: <pre><code>from ropt.config.options import OptionsSchemaModel\n\nschema = OptionsSchemaModel.model_validate(\n    {\n        \"methods\": [\n            {\n                \"options\": {\"a\": float}\n            },\n            {\n                \"options\": {\"b\": int | str},\n            },\n        ]\n    }\n)\n\noptions = schema.get_options_model(\"method\")\nprint(options.model_validate({\"a\": 1.0, \"b\": 1}))  # a=1.0 b=1\n</code></pre></p>"},{"location":"reference/enopt_config/#ropt.config.options.OptionsSchemaModel.get_options_model","title":"get_options_model","text":"<pre><code>get_options_model(method: str) -&gt; type[BaseModel]\n</code></pre> <p>Creates a Pydantic model for validating options of a specific method.</p> <p>This method dynamically generates a Pydantic model tailored to validate the options associated with a given method. It iterates through the defined methods, collecting option schemas from those matching the specified <code>method</code> name. The resulting model can then be used to validate dictionaries of options against the defined schema.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The name of the method for which to create the options model.</p> required <p>Returns:</p> Type Description <code>type[BaseModel]</code> <p>A Pydantic model class capable of validating options for the specified method.</p>"},{"location":"reference/enopt_config/#ropt.config.options.MethodSchemaModel","title":"MethodSchemaModel","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Represents the schema for a specific method within a plugin.</p> <p>This class defines the structure for describing one or more methods supported by a plugin. It contains a dictionary describing an option for this method.</p> <p>Attributes:</p> Name Type Description <code>options</code> <code>dict[str, T]</code> <p>A list of option dictionaries.</p> <code>url</code> <code>HttpUrl | None</code> <p>An optional URL for the plugin.</p>"},{"location":"reference/enopt_config/#ropt.config.options.gen_options_table","title":"gen_options_table","text":"<pre><code>gen_options_table(schema: dict[str, Any]) -&gt; str\n</code></pre> <p>Generates a Markdown table documenting plugin options.</p> <p>This function takes a schema dictionary, validates it against the <code>OptionsSchemaModel</code>, and then generates a Markdown table that summarizes the available methods and their options. Each row in the table represents a method, and the columns list the method's name and its configurable options. If a URL is provided for a method, the method name will be hyperlinked to that URL in the table.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict[str, Any]</code> <p>A dictionary representing the schema of plugin options.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string containing a Markdown table that documents the plugin options.</p>"},{"location":"reference/enums/","title":"Enumerations","text":""},{"location":"reference/enums/#ropt.enums","title":"ropt.enums","text":"<p>Enumerations used within the <code>ropt</code> library.</p>"},{"location":"reference/enums/#ropt.enums.VariableType","title":"VariableType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of optimization variables.</p> <p>Specified in <code>VariablesConfig</code>, this information allows optimization backends to adapt their behavior.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.REAL","title":"REAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REAL = 1\n</code></pre> <p>Continuous variables represented by real values.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.INTEGER","title":"INTEGER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTEGER = 2\n</code></pre> <p>Discrete variables represented by integer values.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType","title":"BoundaryType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates strategies for handling variable boundary violations.</p> <p>When variables are perturbed during optimization, their values might fall outside the defined lower and upper bounds. This enumeration defines different methods to adjust these perturbed values back within the valid range. The chosen strategy is configured in the <code>GradientConfig</code>.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.NONE","title":"NONE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONE = 1\n</code></pre> <p>Do not modify the value.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.TRUNCATE_BOTH","title":"TRUNCATE_BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TRUNCATE_BOTH = 2\n</code></pre> <p>Truncate the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     l_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     b_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.BoundaryType.MIRROR_BOTH","title":"MIRROR_BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MIRROR_BOTH = 3\n</code></pre> <p>Mirror the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     2l_i - v_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     2b_i - v_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i        &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.PerturbationType","title":"PerturbationType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates methods for scaling perturbation samples.</p> <p>Before a generated perturbation sample is added to a variable's current value (during gradient estimation, for example), it can be scaled. This enumeration defines the available scaling methods, configured in the <code>GradientConfig</code>.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.ABSOLUTE","title":"ABSOLUTE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABSOLUTE = 1\n</code></pre> <p>Use the perturbation value as is.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.RELATIVE","title":"RELATIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RELATIVE = 2\n</code></pre> <p>Multiply the perturbation value \\(p_i\\) by the range defined by the bounds of the variables \\(c_i\\): \\(\\hat{p}_i = (c_{i,\\text{max}} - c_{i,\\text{min}}) \\times p_i\\). The bounds will generally be defined in the configuration for the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.EventType","title":"EventType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of events emitted during optimization plan execution.</p> <p>Events signal significant occurrences within the optimization process, such as the start or end of a plan step or an evaluation. Callbacks can be registered to listen for specific event types.</p> <p>When an event occurs, registered callbacks receive an <code>Event</code> object containing:</p> <ul> <li><code>event_type</code>: The type of the event (a value from this enumeration).</li> <li><code>config</code>: The configuration object associated with the source.</li> <li><code>source</code>: The unique ID (UUID) of the plan component that emitted the event.</li> <li><code>data</code>: A dictionary containing event-specific data, such as   <code>Results</code> objects.</li> </ul> <p>Refer to the documentation of individual event types and plan components for details on the specific data they provide.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATION","title":"START_EVALUATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_EVALUATION = 1\n</code></pre> <p>Emitted before evaluating new functions.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATION","title":"FINISHED_EVALUATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_EVALUATION = 2\n</code></pre> <p>Emitted after finishing the evaluation.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_OPTIMIZER_STEP","title":"START_OPTIMIZER_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_OPTIMIZER_STEP = 3\n</code></pre> <p>Emitted just before starting an optimizer step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_OPTIMIZER_STEP","title":"FINISHED_OPTIMIZER_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_OPTIMIZER_STEP = 4\n</code></pre> <p>Emitted immediately after an optimizer step finishes.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_ENSEMBLE_EVALUATOR_STEP","title":"START_ENSEMBLE_EVALUATOR_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_ENSEMBLE_EVALUATOR_STEP = 5\n</code></pre> <p>Emitted just before starting an evaluation step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_ENSEMBLE_EVALUATOR_STEP","title":"FINISHED_ENSEMBLE_EVALUATOR_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_ENSEMBLE_EVALUATOR_STEP = 6\n</code></pre> <p>Emitted immediately after an evaluation step finishes.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode","title":"ExitCode","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the reasons for terminating an optimization.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = 0\n</code></pre> <p>Unknown cause of termination.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.TOO_FEW_REALIZATIONS","title":"TOO_FEW_REALIZATIONS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TOO_FEW_REALIZATIONS = 1\n</code></pre> <p>Returned when too few realizations are evaluated successfully.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.MAX_FUNCTIONS_REACHED","title":"MAX_FUNCTIONS_REACHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MAX_FUNCTIONS_REACHED = 2\n</code></pre> <p>Returned when the maximum number of function evaluations is reached.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.MAX_BATCHES_REACHED","title":"MAX_BATCHES_REACHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MAX_BATCHES_REACHED = 3\n</code></pre> <p>Returned when the maximum number of evaluation batches is reached.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.NESTED_OPTIMIZER_FAILED","title":"NESTED_OPTIMIZER_FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NESTED_OPTIMIZER_FAILED = 4\n</code></pre> <p>Returned when a nested optimization fails to find an optimal value.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.USER_ABORT","title":"USER_ABORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>USER_ABORT = 5\n</code></pre> <p>Returned when the optimization is aborted by the user.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.OPTIMIZER_STEP_FINISHED","title":"OPTIMIZER_STEP_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OPTIMIZER_STEP_FINISHED = 6\n</code></pre> <p>Returned when an optimization step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.ExitCode.EVALUATOR_STEP_FINISHED","title":"EVALUATOR_STEP_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EVALUATOR_STEP_FINISHED = 7\n</code></pre> <p>Returned when an evaluation step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.AxisName","title":"AxisName","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumerates the semantic meaning of axes in data arrays.</p> <p>The optimization workflow includes variables, objectives, constraints, realizations, and the optimizer. Each of these components can have multiple instances, leading to multidimensional data arrays. In particular, the <code>Results</code> objects store optimization data (like variable values, objective function values, constraint values, etc.) in multidimensional NumPy arrays.</p> <p>The <code>AxisName</code> enumeration  provides standardized labels to identify what each dimension (axis) of these arrays represents. For example, an array might have dimensions corresponding to different realizations, different objective functions, or different variables.</p> <p>This information is stored as metadata within the <code>Results</code> object and can be accessed using methods like <code>get_axes</code> on result fields. It is used internally, for instance, during data export to correctly label axes or retrieve associated names (like variable names) from the configuration.</p>"},{"location":"reference/enums/#ropt.enums.AxisName.VARIABLE","title":"VARIABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VARIABLE = 'variable'\n</code></pre> <p>The axis index corresponds to the index of the variable.</p>"},{"location":"reference/enums/#ropt.enums.AxisName.OBJECTIVE","title":"OBJECTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OBJECTIVE = 'objective'\n</code></pre> <p>The axis index corresponds to the index of the objective function.</p>"},{"location":"reference/enums/#ropt.enums.AxisName.LINEAR_CONSTRAINT","title":"LINEAR_CONSTRAINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINEAR_CONSTRAINT = 'linear_constraint'\n</code></pre> <p>The axis index corresponds to the index of the linear constraint.</p>"},{"location":"reference/enums/#ropt.enums.AxisName.NONLINEAR_CONSTRAINT","title":"NONLINEAR_CONSTRAINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONLINEAR_CONSTRAINT = 'nonlinear_constraint'\n</code></pre> <p>The axis index corresponds to the index of the constraint function.</p>"},{"location":"reference/enums/#ropt.enums.AxisName.REALIZATION","title":"REALIZATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REALIZATION = 'realization'\n</code></pre> <p>The axis index corresponds to the index of the realization.</p>"},{"location":"reference/enums/#ropt.enums.AxisName.PERTURBATION","title":"PERTURBATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PERTURBATION = 'perturbation'\n</code></pre> <p>The axis index corresponds to the index of the perturbation.</p>"},{"location":"reference/evaluator/","title":"Function Evaluations","text":""},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator","title":"ropt.ensemble_evaluator.EnsembleEvaluator","text":"<p>Construct functions and gradients from an ensemble of functions.</p> <p>The <code>EnsembleEvaluator</code> class is responsible for calculating functions and gradients from an ensemble of functions. It leverages the settings defined in an <code>EnOptConfig</code> configuration object to guide the calculations.</p> <p>The core functionality relies on an evaluator callable, (usually provided by an <code>Evaluator</code> object), which is used to evaluate the individual functions within the ensemble. The evaluator provides the raw function values, which are then processed by the <code>EnsembleEvaluator</code> to produce the final function and gradient estimates.</p>"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.__init__","title":"__init__","text":"<pre><code>__init__(\n    config: EnOptConfig,\n    transforms: OptModelTransforms | None,\n    evaluator: Callable[\n        [NDArray[float64], EvaluatorContext],\n        EvaluatorResult,\n    ],\n    plugin_manager: PluginManager,\n) -&gt; None\n</code></pre> <p>Initialize the EnsembleEvaluator.</p> <p>This method sets up the <code>EnsembleEvaluator</code> with the necessary configuration, evaluator, and plugins.</p> <p>The <code>config</code> object contains all the settings required for the ensemble evaluation, such as the number of realizations, the function estimators, and the gradient settings. The <code>transforms</code> object defines the domain transforms that should be applied to variables, objectives and constraints. The <code>evaluator</code> callable is usually provide by a <code>Evaluator</code> object. The <code>plugin_manager</code> is used to load the realization filters, function estimators, and samplers.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration object.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>The domain transforms to apply.</p> required <code>evaluator</code> <code>Callable[[NDArray[float64], EvaluatorContext], EvaluatorResult]</code> <p>The callable for evaluating individual functions.</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>A plugin manager to load required plugins.</p> required"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.calculate","title":"calculate","text":"<pre><code>calculate(\n    variables: NDArray[float64],\n    *,\n    compute_functions: bool,\n    compute_gradients: bool,\n) -&gt; tuple[Results, ...]\n</code></pre> <p>Evaluate the given variable vectors.</p> <p>This method calculates functions, gradients, or both, based on the provided variable vectors and the specified flags.</p> <p>The <code>variables</code> argument can be a single vector or a matrix where each row is a variable vector.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vectors to evaluate.</p> required <code>compute_functions</code> <code>bool</code> <p>Whether to calculate functions.</p> required <code>compute_gradients</code> <code>bool</code> <p>Whether to calculate gradients.</p> required <p>Returns:</p> Type Description <code>tuple[Results, ...]</code> <p>The results for function evaluations and/or gradient evaluations.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext","title":"ropt.evaluator.EvaluatorContext  <code>dataclass</code>","text":"<p>Capture additional details for the function evaluator.</p> <p>Function evaluators (see <code>Evaluator</code>) primarily receive variable vectors to evaluate objective and constraint functions. However, they may also benefit from additional information to optimize their calculations. This <code>EvaluatorContext</code> object provides that supplementary information.</p> <p>Specifically, it provides:</p> <ul> <li>The configuration object for the current optimization step.</li> <li>A boolean vector (<code>active</code>) indicating which variable rows require   evaluation.</li> <li>The realization index for each variable vector. This can be used to   determine the correct function from an ensemble to use with each variable   vector.</li> <li>The perturbation index for each variable vector (if applicable). A value   less than 0 indicates that the vector is not a perturbation.</li> </ul> <p>Attributes:</p> Name Type Description <code>config</code> <code>EnOptConfig</code> <p>Configuration of the optimizer.</p> <code>active</code> <code>NDArray[bool_]</code> <p>Indicates which variable rows require evaluation.</p> <code>realizations</code> <code>NDArray[intc]</code> <p>Realization numbers for each requested evaluation.</p> <code>perturbations</code> <code>NDArray[intc] | None</code> <p>Perturbation numbers for each requested evaluation.                 A value less than 0 indicates that the vector is                 not a perturbation.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext.get_active_evaluations","title":"get_active_evaluations","text":"<pre><code>get_active_evaluations(array: NDArray[T]) -&gt; NDArray[T]\n</code></pre> <p>Filter an array based on the active property.</p> <p>This is a utility method, which can be used if only the active property is used to exclude variable rows that are inactive, i.e. where none of the objects or constraints are needed.</p> <p>This method filters a one- or two-dimensional array by retaining only those entries or rows that correspond to active. The activity of realizations is determined by the <code>self.active</code> boolean array (where <code>True</code> indicates active).</p> <p>If <code>self.active</code> is <code>None</code> (indicating that all variable rows are to be considered active), no filtering is applied, and the original input is returned.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[T]</code> <p>The array to filter.</p> required <p>Returns:</p> Type Description <code>NDArray[T]</code> <p>The filtered results.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext.insert_inactive_results","title":"insert_inactive_results","text":"<pre><code>insert_inactive_results(\n    array: NDArray[T], *, fill_value: float = 0.0\n) -&gt; NDArray[T]\n</code></pre> <p>Expand an array by inserting fill values for inactive variables.</p> <p>This is a utility method, which can be used if only the active property is used to exclude variable rows that are fully inactive.</p> <p>This method takes an array and expands it to its original dimensions by inserting a specified <code>fill_value</code> at positions corresponding to inactive rows. If the array is one-dimensional, zero entries are inserted, if it is two-dimensional rows of zero values are inserted.</p> <p>If <code>self.active</code> is <code>None</code> (implying all rows were considered active or no filtering was applied), the input <code>array</code> is returned unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[T]</code> <p>The array to expand.</p> required <code>fill_value</code> <code>float</code> <p>The value to insert for inactive entries.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>NDArray[T]</code> <p>An expanded array matching the original number of variables.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorResult","title":"ropt.evaluator.EvaluatorResult  <code>dataclass</code>","text":"<p>Store the results of a function evaluation.</p> <p>This class stores the results of evaluating objective and constraint functions for a set of variable vectors.</p> <p>The <code>objectives</code> and <code>constraints</code> are stored as matrices. Each column in these matrices corresponds to a specific objective or constraint, and each row corresponds to a variable vector.</p> <p>When the evaluator is asked to evaluate functions, some variable vectors may be marked as inactive. The results for these inactive vectors should be set to zero. All active variable vectors should be evaluated. If an evaluation fails for any reason, the corresponding values should be set to <code>numpy.nan</code>.</p> <p>A <code>batch_id</code> can be set to identify this specific set of evaluation results.</p> <p>The <code>evaluation_info</code> dictionary can store additional metadata for each evaluation. This information is not used internally by <code>ropt</code> and can have an arbitrary structure, to be interpreted by the application. This can be used, for example, to uniquely identify the results calculated for each variable vector, allowing them to be linked back to their corresponding input vectors.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The calculated objective values.</p> required <code>constraints</code> <code>NDArray[float64] | None</code> <p>Optional calculated constraint values.</p> <code>None</code> <code>batch_id</code> <code>int | None</code> <p>Optional batch ID to identify this set of results.</p> <code>None</code> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional info for each evaluation.</p> <code>dict()</code>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#ropt.exceptions","title":"ropt.exceptions","text":"<p>Exceptions raised within the <code>ropt</code> library.</p>"},{"location":"reference/exceptions/#ropt.exceptions.ConfigError","title":"ConfigError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an configuration error occurs.</p>"},{"location":"reference/exceptions/#ropt.exceptions.StepAborted","title":"StepAborted","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a step is aborted prematurely.</p> <p>This exception signals that a plan step could not complete its intended task due to a specific condition (e.g., insufficient valid realizations, user request).</p> <p>It must be initialized with an <code>ExitCode</code> indicating the reason for the abortion.</p>"},{"location":"reference/exceptions/#ropt.exceptions.StepAborted.__init__","title":"__init__","text":"<pre><code>__init__(exit_code: ExitCode) -&gt; None\n</code></pre> <p>Initialize the StepAborted exception.</p> <p>Stores the reason for the abortion, which can be accessed via the <code>exit_code</code> attribute.</p> <p>Parameters:</p> Name Type Description Default <code>exit_code</code> <code>ExitCode</code> <p>The code indicating why the optimization step was aborted.</p> required"},{"location":"reference/exceptions/#ropt.exceptions.PlanAborted","title":"PlanAborted","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization plan is aborted prematurely.</p> <p>This exception signals that the execution of a <code>Plan</code> was stopped before completion. This typically occurs when a step or event handler within the plan explicitly sets the plan's <code>aborted</code> flag (e.g., due to a user request via a signal or an unrecoverable error condition detected by an event handler).</p> <p>Any subsequent attempts to execute further steps in an already aborted plan will raise this exception.</p>"},{"location":"reference/external_optimizer_plugin/","title":"External Optimizer Plugin","text":""},{"location":"reference/external_optimizer_plugin/#ropt.plugins.optimizer.external.ExternalOptimizer","title":"ropt.plugins.optimizer.external.ExternalOptimizer","text":"<p>               Bases: <code>Optimizer</code></p> <p>Plugin class for optimization using an external process.</p> <p>This class enables optimization via an external process, which performs the optimization independently and communicates with this class over pipes to request function evaluations, report optimizer states, and handle any errors.</p> <p>Typically, the optimizer is specified within an <code>OptimizerConfig</code> via the <code>method</code> field, which either provides the algorithm name directly or follows the form <code>plugin-name/method-name</code>. In the first case, <code>ropt</code> searches among all available optimizer plugins to find the specified method. In the second case, it checks if the plugin identified by <code>plugin-name</code> contains <code>method-name</code> and, if so, uses it. Both of these are not supported by the external optimizer class. Instead, it requires that the <code>method</code> field includes both the plugin and method names in the format <code>external/plugin-name/method-name</code> or <code>external/method-name</code>. This ensures the external optimizer can identify and launch the specified optimization method <code>method-name</code> and launch it as an external process.</p>"},{"location":"reference/function_estimator_plugins/","title":"Function estimator Plugins","text":""},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator","title":"ropt.plugins.function_estimator","text":"<p>Provides plugin functionality for adding function estimators.</p> <p>Function estimators are used by the optimization process to combine the results (objective function values and gradients) from a set of realizations into a single representative value. This module allows for the extension of <code>ropt</code> with custom strategies for aggregating ensemble results.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Function estimator plugins must inherit from the   <code>FunctionEstimatorPlugin</code>   base class. This class acts as a factory, defining a <code>create</code> method to   instantiate estimator objects.</li> <li>Estimator Implementation: The actual aggregation logic resides in classes   that inherit from the   <code>FunctionEstimator</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>) and the index of the   specific estimator configuration to use (<code>estimator_index</code>). The core   functionality is provided by the <code>calculate_function</code> and <code>calculate_gradient</code>   methods, which combine the function values and gradients from multiple   realizations, respectively, using realization weights.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>FunctionEstimatorPlugin</code> implementations (typically via entry   points) and uses them to create <code>FunctionEstimator</code> instances as needed   during plan execution.</li> </ul> <p>Built-in Function Estimator Plugins:</p> <p>The default <code>DefaultFunctionEstimator</code> class provides methods for calculating the weighted mean (<code>mean</code>) and standard deviation (<code>stddev</code>) of the realization results.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin","title":"ropt.plugins.function_estimator.base.FunctionEstimatorPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Function Estimator Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>FunctionEstimator</code> instances. These plugins act as factories for specific function estimation strategies.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate function estimator plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>FunctionEstimator</code> object that will perform the aggregation of ensemble results (function values and gradients).</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig, estimator_index: int\n) -&gt; FunctionEstimator\n</code></pre> <p>Factory method to create a concrete FunctionEstimator instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>FunctionEstimator</code> objects. Plugin implementations must override this method to return an instance of their specific <code>FunctionEstimator</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires a function estimator provided by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The main EnOpt configuration object.</p> required <code>estimator_index</code> <code>int</code> <p>Index into <code>enopt_config.function_estimators</code> for              this estimator.</p> required <p>Returns:</p> Type Description <code>FunctionEstimator</code> <p>An initialized FunctionEstimator object ready for use.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator","title":"ropt.plugins.function_estimator.base.FunctionEstimator","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Function Estimator Implementations.</p> <p>This class defines the fundamental interface for all concrete function estimator implementations within the <code>ropt</code> framework. Function estimator plugins provide classes derived from <code>FunctionEstimator</code> that encapsulate the logic for combining the objective function values and gradients from an ensemble of realizations into a single representative value. This aggregated value is then used by the core optimization algorithm.</p> <p>Instances of <code>FunctionEstimator</code> subclasses are created by their corresponding <code>FunctionEstimatorPlugin</code> factories. They are initialized with an <code>EnOptConfig</code> object detailing the optimization setup and the <code>estimator_index</code> identifying the specific estimator configuration to use from the config.</p> <p>The core functionality involves combining results using realization weights, performed by the <code>calculate_function</code> and <code>calculate_gradient</code> methods, which must be implemented by subclasses.</p> <p>Subclasses must implement:</p> <ul> <li><code>__init__</code>: To accept the configuration and index.</li> <li><code>calculate_function</code>: To combine function values from realizations.</li> <li><code>calculate_gradient</code>: To combine gradient values from realizations.</li> </ul>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig, estimator_index: int\n) -&gt; None\n</code></pre> <p>Initialize the function estimator object.</p> <p>The <code>function_estimators</code> field in the <code>enopt_config</code> is a tuple of estimator configurations (<code>FunctionEstimatorConfig</code>). The <code>estimator_index</code> identifies which configuration from this tuple should be used to initialize this specific estimator instance.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>estimator_index</code> <code>int</code> <p>The index of the estimator configuration to use.</p> required"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator.calculate_function","title":"calculate_function  <code>abstractmethod</code>","text":"<pre><code>calculate_function(\n    functions: NDArray[float64], weights: NDArray[float64]\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Combine function values from realizations into an expected value.</p> <p>This method takes the function (objective or constraint) values evaluated for each realization in the ensemble and combines them into a single representative value or vector of values, using the provided realization weights.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The function values for each realization.</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight for each realization.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A scalar or 1D array representing the combined function value(s).</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator.calculate_gradient","title":"calculate_gradient  <code>abstractmethod</code>","text":"<pre><code>calculate_gradient(\n    functions: NDArray[float64],\n    gradient: NDArray[float64],\n    weights: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Combine gradients from realizations into an expected gradient.</p> <p>This method takes the gradients evaluated for each realization and combines them into a single representative gradient vector or matrix, using the provided realization weights and potentially the function values themselves (e.g., for estimators like standard deviation where the chain rule applies).</p> Interaction with <code>merge_realizations</code> <p>The <code>merge_realizations</code> flag in the <code>GradientConfig</code> determines how the initial gradient estimate(s) are computed by <code>ropt</code> before being passed to this <code>calculate_gradient</code> method.</p> <ul> <li>If <code>False</code> (default): <code>ropt</code> estimates a separate gradient for each   realization that has a non-zero weight. The implementation   must then combine these gradients using the provided <code>weights</code>.</li> <li>If <code>True</code>: <code>ropt</code> computes a single, merged gradient estimate by   treating all perturbations across all realizations collectively.   The implementation must handle this input appropriately. For simple   averaging estimators, this might involve returning the input gradient   unchanged.</li> </ul> <p>The <code>merge_realizations=True</code> option allows gradient estimation even with a low number of perturbations (potentially just one) but is generally only suitable for estimators performing averaging-like operations. Estimator implementations should check this flag during initialization (<code>__init__</code>) and raise a <code>ConfigError</code> if <code>merge_realizations=True</code> is incompatible with the estimator's logic (e.g., standard deviation).</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization.</p> required <code>gradient</code> <code>NDArray[float64]</code> <p>The gradient for each realization.</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected gradients.</p>"},{"location":"reference/optimization/","title":"Optimization","text":""},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer","title":"ropt.optimization.EnsembleOptimizer","text":"<p>Optimizer for ensemble-based optimizations.</p> <p>The <code>EnsembleOptimizer</code> class provides the core functionality for running ensemble-based optimizations. Direct use of this class is generally discouraged. Instead, the <code>Plan</code> or <code>BasicOptimizer</code> classes are recommended for greater flexibility and ease of use.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.is_parallel","title":"is_parallel  <code>property</code>","text":"<pre><code>is_parallel: bool\n</code></pre> <p>Determine if the optimization supports parallel evaluations.</p> <p>The underlying optimization algorithm may request function evaluations via a callback. Parallel optimization, in this context, means that the algorithm may request multiple function evaluations in a single callback.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimization supports parallel evaluations, <code>False</code></p> <code>bool</code> <p>otherwise.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig,\n    transforms: OptModelTransforms | None,\n    ensemble_evaluator: EnsembleEvaluator,\n    plugin_manager: PluginManager,\n    signal_evaluation: SignalEvaluationCallback\n    | None = None,\n    nested_optimizer: NestedOptimizerCallback | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the EnsembleOptimizer.</p> <p>This class orchestrates ensemble-based optimizations. It requires an optimization configuration, an evaluator, and a plugin manager to function.</p> <p>The <code>EnsembleOptimizer</code> needs the following to define a single optimization run:</p> <ol> <li>An <code>EnOptConfig</code> object: This contains     all configuration settings for the optimization.</li> <li>A <code>OptModelTransforms</code> object:     This handles the transforms to apply to the variables, objectives and     constraints.</li> <li>An <code>EnsembleEvaluator</code>     object: This object is responsible for evaluating functions.</li> <li>A <code>PluginManager</code> object: This object     provides access to optimizer plugins.</li> </ol> <p>Additionally, two optional callbacks can be provided to extend the functionality:</p> <ol> <li>A     <code>SignalEvaluationCallback</code>:     This callback is invoked before and after each function evaluation.</li> <li>A     <code>NestedOptimizerCallback</code>:     This callback is invoked at each function evaluation to run a nested     optimization.</li> </ol> <p>The optimizer plugins are used by the ensemble optimizer to implement the actual optimization process. The <code>EnsembleOptimizer</code> class provides the callback function to these plugins needed (see OptimizerCallback)</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The ensemble optimization configuration.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>The transforms to apply to the model.</p> required <code>ensemble_evaluator</code> <code>EnsembleEvaluator</code> <p>The evaluator for function evaluations.</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>The plugin manager.</p> required <code>signal_evaluation</code> <code>SignalEvaluationCallback | None</code> <p>Optional callback to signal evaluations.</p> <code>None</code> <code>nested_optimizer</code> <code>NestedOptimizerCallback | None</code> <p>Optional callback for nested optimizations.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.start","title":"start","text":"<pre><code>start(variables: NDArray[float64]) -&gt; ExitCode\n</code></pre> <p>Start the optimization process.</p> <p>This method initiates the optimization process using the provided initial variables. The optimization will continue until a stopping criterion is met or an error occurs.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The initial variables for the optimization.</p> required <p>Returns:</p> Type Description <code>ExitCode</code> <p>An <code>ExitCode</code> indicating the reason for</p> <code>ExitCode</code> <p>termination.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback","title":"ropt.optimization.SignalEvaluationCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for a callback to signal the start and end of an evaluation.</p> <p>This callback is invoked before and after each evaluation, allowing for custom handling or tracking of evaluation events.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    results: tuple[Results, ...] | None = None,\n) -&gt; None\n</code></pre> <p>Callback protocol for signaling the start and end of evaluations.</p> <p>This callback is invoked by the ensemble optimizer before and after each evaluation. Before the evaluation starts, the callback is called with <code>results</code> set to <code>None</code>. After the evaluation completes, the callback is called again, this time with <code>results</code> containing the output of the evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>tuple[Results, ...] | None</code> <p>The results produced by the evaluation, or <code>None</code> if the      evaluation has not yet started.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback","title":"ropt.optimization.NestedOptimizerCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for functions that start a nested optimization.</p>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64],\n) -&gt; tuple[FunctionResults | None, bool]\n</code></pre> <p>Callback protocol for executing a nested optimization.</p> <p>This function is invoked by the ensemble optimizer during each function evaluation to initiate a nested optimization process. It receives the current variables as input and is expected to perform a nested optimization using these variables as a starting point. The function should return a tuple containing the result of the nested optimization and a boolean indicating whether the nested optimization was aborted by the user. The result of the nested optimization should be a <code>FunctionResults</code> object, or <code>None</code> if no result is available.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variables to use as the starting point.</p> required <p>Returns:</p> Type Description <code>tuple[FunctionResults | None, bool]</code> <p>The result and a boolean indicating if the user aborted.</p>"},{"location":"reference/optimization/#ropt.optimization.OptimizerCallback","title":"ropt.optimization.OptimizerCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Defines the call signature for the optimizer evaluation callback.</p> <p>Optimizers uses this callback to request function and gradient evaluations from the <code>ropt</code> core during the optimization process.</p>"},{"location":"reference/optimization/#ropt.optimization.OptimizerCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64],\n    /,\n    *,\n    return_functions: bool,\n    return_gradients: bool,\n) -&gt; OptimizerCallbackResult\n</code></pre> <p>Request function and/or gradient evaluations from the <code>ropt</code> core.</p> <p>This method is called by the optimizer implementation to obtain objective function values, constraint values, and their gradients for one or more sets of variable values. In addition other update information, such as non-linear constraint bounds may be returned.</p> <p>The <code>variables</code> argument can be a 1D array (single vector) or a 2D array (matrix where each row is a variable vector). Parallel or batch-based optimizers might provide a matrix, while others typically provide a single vector.</p> <p>The <code>return_functions</code> and <code>return_gradients</code> flags control what is computed and returned in a <code>OptimizerCallbackResult</code> structure.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>A 1D or 2D array of variable values to evaluate.</p> required <code>return_functions</code> <code>bool</code> <p>If <code>True</code>, compute and return function/constraint values.</p> required <code>return_gradients</code> <code>bool</code> <p>If <code>True</code>, compute and return gradient values.</p> required <p>Returns:</p> Type Description <code>OptimizerCallbackResult</code> <p>A data structure with the results.</p>"},{"location":"reference/optimization/#ropt.optimization.OptimizerCallbackResult","title":"ropt.optimization.OptimizerCallbackResult  <code>dataclass</code>","text":"<p>Holds the results from an optimizer callback evaluation.</p> <p>This dataclass is used to structure the output of the <code>OptimizerCallback</code>. It bundles the objective function values, gradient values, and any updated non-linear constraint bounds that result from an evaluation request.</p> <p>The <code>functions</code> attribute will contain a NumPy array of the objective function value(s) if they were requested and successfully computed, otherwise it will be <code>None</code>. Similarly, the <code>gradients</code> attribute will hold a NumPy array of gradient values if requested and computed, and <code>None</code> otherwise.</p> <p>The <code>nonlinear_constraint_bounds</code> attribute is a tuple containing two NumPy arrays: the first for lower bounds and the second for upper bounds of any non-linear constraints. This will be <code>None</code> if there are no non-linear constraints or if their bounds were not updated during the callback.</p> <p>The <code>functions</code> and <code>gradients</code> fields must be structured as follows:</p> <ul> <li> <p>Functions Array: This array contains the objective and non-linear     constraint values. If <code>variables</code> was a vector, it's a 1D array:</p> <pre><code>[objective, constraint1, constraint2, ...]\n</code></pre> <p>If <code>variables</code> was a matrix, it's a 2D array where each row corresponds to a row in the input <code>variables</code>, with the same structure:</p> <pre><code>[\n    [obj_row1, con1_row1, ...],\n    [obj_row2, con2_row2, ...],\n    ...\n]\n</code></pre> </li> <li> <p>Gradients Array: This array contains the gradients of the objective     and non-linear constraints. It's always a 2D array where rows correspond     to the objective/constraints and columns correspond to the variables:</p> <pre><code>[\n    [grad_obj_var1,  grad_obj_var2,  ...],\n    [grad_con1_var1, grad_con1_var2, ...],\n    ...\n]\n</code></pre> </li> </ul> <p>Attributes:</p> Name Type Description <code>functions</code> <code>NDArray[float64] | None</code> <p>Objective function value(s).</p> <code>gradients</code> <code>NDArray[float64] | None</code> <p>Gradient values.</p> <code>nonlinear_constraint_bounds</code> <code>tuple[NDArray[float64], NDArray[float64]] | None</code> <p>Updated non-linear constraint lower and upper bounds.</p>"},{"location":"reference/optimizer_plugins/","title":"Optimizer Plugins","text":""},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer","title":"ropt.plugins.optimizer","text":"<p>Framework and Implementations for Optimizer Plugins.</p> <p>This module provides the necessary components for integrating optimization algorithms into <code>ropt</code> via its plugin system. Optimizer plugins allow <code>ropt</code> to utilize various optimization techniques, either built-in or provided by third-party packages.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Optimizer plugins must inherit from the   <code>OptimizerPlugin</code> base class.   This class acts as a factory, defining a <code>create</code> method to instantiate   optimizer objects.</li> <li>Optimizer Implementation: The actual optimization logic resides in classes   that inherit from the <code>Optimizer</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>) and an   <code>OptimizerCallback</code>. The callback is   used by the optimizer to request function and gradient evaluations from   <code>ropt</code>. The optimization process is initiated by calling the optimizer's   <code>start</code> method.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>OptimizerPlugin</code> implementations (typically via entry points) and   uses them to create <code>Optimizer</code> instances as needed during plan execution.</li> </ul> <p>Utilities:</p> <p>The <code>ropt.plugins.optimizer.utils</code> module offers helper functions for common tasks within optimizer plugins, such as validating constraint support and handling normalized constraints.</p> <p>Built-in Optimizers:</p> <p><code>ropt</code> includes the following optimizers by default:</p> <ul> <li><code>SciPyOptimizer</code>: Provides   access to various algorithms from the <code>scipy.optimize</code> library.</li> <li><code>ExternalOptimizer</code>:   Enables running other optimizer plugins in a separate external process, useful   for isolation or specific execution environments.</li> </ul>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin","title":"ropt.plugins.optimizer.base.OptimizerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Optimizer Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>Optimizer</code> instances. These plugins act as factories for specific optimization algorithms or backends.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate optimizer plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>Optimizer</code> object that will perform the optimization.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    config: EnOptConfig,\n    optimizer_callback: OptimizerCallback,\n) -&gt; Optimizer\n</code></pre> <p>Create an Optimizer instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>Optimizer</code> objects. Plugin implementations must override this method to return an instance of their specific <code>Optimizer</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires an optimizer provided by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The  configuration object containing the                 optimization settings.</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The callback function used by the optimizer to                 request evaluations.</p> required <p>Returns:</p> Type Description <code>Optimizer</code> <p>An initialized instance of an <code>Optimizer</code> subclass.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.validate_options","title":"validate_options  <code>classmethod</code>","text":"<pre><code>validate_options(\n    method: str, options: dict[str, Any] | list[str] | None\n) -&gt; None\n</code></pre> <p>Validate the optimizer-specific options for a given method.</p> <p>This class method is intended to check if the <code>options</code> dictionary, typically provided in the <code>OptimizerConfig</code>, contains valid keys and values for the specified optimization <code>method</code> supported by this plugin.</p> <p>This default implementation performs no validation. Subclasses should override this method to implement validation logic specific to the methods they support, potentially using schema validation tools like Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The specific optimization method name (e.g., \"slsqp\",      \"my_optimizer/variant1\").</p> required <code>options</code> <code>dict[str, Any] | list[str] | None</code> <p>The dictionary or a list of strings of options.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the provided options are invalid for the specified        method.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer","title":"ropt.plugins.optimizer.base.Optimizer","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Optimizer Implementations.</p> <p>This class defines the fundamental interface for all concrete optimizer implementations within the <code>ropt</code> framework. Optimizer plugins provide classes derived from <code>Optimizer</code> that encapsulate the logic of specific optimization algorithms.</p> <p>Instances of <code>Optimizer</code> subclasses are created by their corresponding <code>OptimizerPlugin</code> factories. They are initialized with an <code>EnOptConfig</code> object detailing the optimization setup and an <code>OptimizerCallback</code> function. The callback is crucial as it allows the optimizer to request function and gradient evaluations from the <code>ropt</code> core during its execution.</p> <p>The optimization process itself is initiated by calling the <code>start</code> method, which must be implemented by subclasses.</p> <p>Subclasses must implement: - <code>__init__</code>: To accept the configuration and callback. - <code>start</code>: To contain the main optimization loop.</p> <p>Subclasses can optionally override: - <code>allow_nan</code>:   To indicate if the algorithm can handle NaN function values. - <code>is_parallel</code>: To indicate if the algorithm may perform parallel evaluations.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.allow_nan","title":"allow_nan  <code>property</code>","text":"<pre><code>allow_nan: bool\n</code></pre> <p>Indicate whether the optimizer can handle NaN function values.</p> <p>If an optimizer algorithm can gracefully handle <code>NaN</code> (Not a Number) objective function values, its implementation should override this property to return <code>True</code>.</p> <p>This is particularly relevant in ensemble-based optimization where evaluations might fail for all realizations. When <code>allow_nan</code> is <code>True</code>, setting <code>realization_min_success</code> to zero allows the evaluation process to return <code>NaN</code> instead of raising an error, enabling the optimizer to potentially continue.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimizer supports NaN function values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.is_parallel","title":"is_parallel  <code>property</code>","text":"<pre><code>is_parallel: bool\n</code></pre> <p>Indicate whether the optimizer alows parallel evaluations.</p> <p>If an optimizer algorithm is designed to evaluate multiple variable vectors concurrently, its implementation should override this property to return <code>True</code>.</p> <p>This information can be used by <code>ropt</code> or other components to manage resources or handle parallel execution appropriately.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimizer allows parallel evaluations.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    config: EnOptConfig,\n    optimizer_callback: OptimizerCallback,\n) -&gt; None\n</code></pre> <p>Initialize an optimizer object.</p> <p>The <code>config</code> object provides the desired configuration for the optimization process and should be used to set up the optimizer correctly before starting the optimization. The optimization will be initiated using the <code>start</code> method and will repeatedly require function and gradient evaluations at given variable vectors. The <code>optimizer_callback</code> argument provides the function that should be used to calculate the function and gradient values, which can then be forwarded to the optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used.</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.start","title":"start  <code>abstractmethod</code>","text":"<pre><code>start(initial_values: NDArray[float64]) -&gt; None\n</code></pre> <p>Initiate the optimization process.</p> <p>This abstract method must be implemented by concrete <code>Optimizer</code> subclasses to start the optimization process. It takes the initial set of variable values as input.</p> <p>During execution, the implementation should use the <code>OptimizerCallback</code> (provided during initialization) to request necessary function and gradient evaluations from the <code>ropt</code> core.</p> <p>Parameters:</p> Name Type Description Default <code>initial_values</code> <code>NDArray[float64]</code> <p>A 1D NumPy array representing the starting variable             values for the optimization.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils","title":"ropt.plugins.optimizer.utils","text":"<p>Utility functions for use by optimizer plugins.</p> <p>This module provides utility functions to validate supported constraints, filter linear constraints, and to retrieve the list of supported optimizers.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints","title":"NormalizedConstraints","text":"<p>Class for handling normalized constraints.</p> <p>This class can be used to normalize non-linear constraints into the form C(x) = 0, C(x) &lt;= 0, or C(x) &gt;= 0. By default this is done by subtracting the right-hand side value, and multiplying with -1, if necessary.</p> <p>The right hand sides are provided by the <code>lower_bounds</code> and <code>upper_bound</code> values. If corresponding entries in these arrays are equal (within a 1e-15 tolerance), the corresponding constraint is assumed to be a equality constraint. If they are not, they are considered inequality constraints, if one or both values are finite. If the lower bounds are finite, the constraint is added as is, after subtracting of the lower bound. If the upper bound is finite, the same is done, but the constraint is multiplied by -1. If both are finite, both constraints are added, effectively splitting a two-sided constraint into two normalized constraints.</p> <p>By default this normalizes inequality constraints to the form C(x) &gt; 0, by setting the <code>flip</code> flag, this can be changed to C(x) &lt; 0.</p> <p>Usage:</p> <ol> <li>Initialize with the lower and upper bounds.</li> <li>Before each new function/gradient evaluation with a new variable     vector, reset the normalized constraints by calling the <code>reset</code>     method.</li> <li>The constraint values are given by the <code>constraints</code> property. Before     accessing it, call the <code>set_constraints</code> with the raw constraints. If     necessary, this will calculate and cache the normalized values. Since     values are cached, calling this method and accessing <code>constraints</code>     multiple times is cheap.</li> <li>Use the same procedure for gradients, using the <code>gradients</code> property     and <code>set_gradients</code>. Raw gradients must be provided as a matrix,     where the rows are the gradients of each constraint.</li> <li>Use the <code>is_eq</code> property to retrieve a vector of boolean flags to     check which constraints are equality constraints.</li> </ol> <p>See the <code>scipy</code> optimization backend in the <code>ropt</code> source code for an example of usage.</p> Parallel evaluation. <p>The raw constraints may be a vector of constraints, or may be a matrix of constraints for multiple variables to support parallel evaluation. In the latter case, the constraints for different variables are given by the columns of the matrix. In this case, the <code>constraints</code> property will have the same structure. Note that this is only supported for the constraint values, not for the gradients. Hence, parallel evaluation of multiple gradients is not supported.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.is_eq","title":"is_eq  <code>property</code>","text":"<pre><code>is_eq: list[bool]\n</code></pre> <p>Return flags indicating which constraints are equality constraints.</p> <p>Returns:</p> Type Description <code>list[bool]</code> <p>A list of booleans, <code>True</code> for constraints that are equality constraints.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.constraints","title":"constraints  <code>property</code>","text":"<pre><code>constraints: NDArray[float64] | None\n</code></pre> <p>Return the cached normalized constraint values.</p> <p>These are the constraint values after applying the normalization logic (subtracting RHS, potential sign flipping) based on the bounds provided during initialization.</p> <p>This property should be accessed after calling <code>set_constraints</code> with the raw constraint values for the current variable vector. Returns <code>None</code> if <code>set_constraints</code> has not been called since the last <code>reset</code>.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>A NumPy array containing the normalized constraint values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.gradients","title":"gradients  <code>property</code>","text":"<pre><code>gradients: NDArray[float64] | None\n</code></pre> <p>Return the cached normalized constraint gradients.</p> <p>These are the gradients of the constraints after applying the normalization logic (potential sign flipping) based on the bounds provided during initialization.</p> <p>This property should be accessed after calling <code>set_gradients</code> with the raw constraint gradients for the current variable vector. Returns <code>None</code> if <code>set_gradients</code> has not been called since the last <code>reset</code>.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>A 2D NumPy array containing the normalized constraint gradients.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.__init__","title":"__init__","text":"<pre><code>__init__(*, flip: bool = False) -&gt; None\n</code></pre> <p>Initialize the normalization class.</p> <p>Parameters:</p> Name Type Description Default <code>flip</code> <code>bool</code> <p>Whether to flip the sign of the constraints.</p> <code>False</code>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_bounds","title":"set_bounds","text":"<pre><code>set_bounds(\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; None\n</code></pre> <p>Set the bounds of the normalization class.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right hand sides.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right hand sides.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset cached normalized constraints and gradients.</p> <p>This must be called when the stored constraints and their gradients are no longer valid. This is typically done after a new function/gradient evaluation. The <code>set_constraints</code> and <code>set_gradients</code> methods can then be called to set the new values.</p> <p>After calling this method, the <code>constraints</code> and <code>gradients</code> properties will return <code>None</code> until new values are set. This can be utilized to check if new values need to be calculated.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_constraints","title":"set_constraints","text":"<pre><code>set_constraints(values: NDArray[float64]) -&gt; None\n</code></pre> <p>Calculate and cache normalized constraint values.</p> <p>This method takes the raw constraint values (evaluated at the current variable vector) and applies the normalization logic defined during initialization (subtracting RHS, potential sign flipping). The results are stored internally and made available via the <code>constraints</code> property.</p> <p>This supports parallel evaluation: if <code>values</code> is a 2D array, each row is treated as the constraint values for a separate variable vector evaluation.</p> <p>If there are already cached values, this method will not overwrite them, the <code>reset</code> method must be called first.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>A 1D or 2D NumPy array of raw constraint values. If 2D,     rows represent different evaluations.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_gradients","title":"set_gradients","text":"<pre><code>set_gradients(values: NDArray[float64]) -&gt; None\n</code></pre> <p>Calculate and cache normalized constraint gradients.</p> <p>This method takes the raw constraint gradients (evaluated at the current variable vector) and applies the normalization logic defined during initialization (potential sign flipping). The results are stored internally and made available via the <code>gradients</code> property.</p> <p>If there are already cached values, this method will not overwrite them, the <code>reset</code> method must be called first.</p> Note <p>Unlike <code>set_constraints</code>, this method does not support parallel evaluation; it expects gradients corresponding to a single variable vector.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>A 2D NumPy array of raw constraint gradients (rows are     gradients of original constraints, columns are variables).</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.validate_supported_constraints","title":"validate_supported_constraints","text":"<pre><code>validate_supported_constraints(\n    config: EnOptConfig,\n    method: str,\n    supported_constraints: dict[str, set[str]],\n    required_constraints: dict[str, set[str]],\n) -&gt; None\n</code></pre> <p>Validate if the configured constraints are supported by the chosen method.</p> <p>This function checks if the constraints defined in the <code>config</code> object (bounds, linear, non-linear) are compatible with the specified optimization <code>method</code>. It uses dictionaries mapping constraint types to sets of methods that support or require them.</p> <p>Constraint types are identified by keys like <code>\"bounds\"</code>, <code>\"linear:eq\"</code>, <code>\"linear:ineq\"</code>, <code>\"nonlinear:eq\"</code>, and <code>\"nonlinear:ineq\"</code>.</p> <p>Example <code>supported_constraints</code> dictionary: <pre><code>{\n    \"bounds\": {\"L-BFGS-B\", \"TNC\", \"SLSQP\"},\n    \"linear:eq\": {\"SLSQP\"},\n    \"linear:ineq\": {\"SLSQP\"},\n    \"nonlinear:eq\": {\"SLSQP\"},\n    \"nonlinear:ineq\": {\"SLSQP\"},\n}\n</code></pre> A similar structure is used for <code>required_constraints</code>.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimization configuration object.</p> required <code>method</code> <code>str</code> <p>The name of the optimization method being used.</p> required <code>supported_constraints</code> <code>dict[str, set[str]]</code> <p>Dict mapping constraint types to sets of methods                    that support them.</p> required <code>required_constraints</code> <code>dict[str, set[str]]</code> <p>Dict mapping constraint types to sets of methods                    that require them.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If a configured constraint is not supported by the                  method, or if a required constraint is missing.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.create_output_path","title":"create_output_path","text":"<pre><code>create_output_path(\n    base_name: str,\n    base_dir: Path | None = None,\n    name: str | None = None,\n    suffix: str | None = None,\n) -&gt; Path\n</code></pre> <p>Construct a unique output path, appending an index if necessary.</p> <p>This function generates a file or directory path based on the provided components. If the resulting path already exists, it automatically appends or increments a numerical suffix (e.g., \"-001\", \"-002\") to ensure uniqueness.</p> <p>Parameters:</p> Name Type Description Default <code>base_name</code> <code>str</code> <p>The core name for the path.</p> required <code>base_dir</code> <code>Path | None</code> <p>Optional parent directory for the path.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Optional identifier (e.g., step name) to include in the path.</p> <code>None</code> <code>suffix</code> <code>str | None</code> <p>Optional file extension or suffix for the path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>A unique <code>pathlib.Path</code> object.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.get_masked_linear_constraints","title":"get_masked_linear_constraints","text":"<pre><code>get_masked_linear_constraints(\n    config: EnOptConfig, initial_values: NDArray[float64]\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Adjust linear constraints based on a variable mask.</p> <p>When an optimization problem uses a variable mask (<code>config.variables.mask</code>) to optimize only a subset of variables, the linear constraints need to be adapted. This function performs that adaptation.</p> <p>It removes columns from the constraint coefficient matrix (<code>config.linear_constraints.coefficients</code>) that correspond to the masked (fixed) variables. The contribution of these fixed variables (using their <code>initial_values</code>) is then calculated and subtracted from the original lower and upper bounds (<code>config.linear_constraints.lower_bounds</code>, <code>config.linear_constraints.upper_bounds</code>) to produce adjusted bounds for the optimization involving only the active variables.</p> <p>Additionally, any constraint rows that originally involved only masked variables (i.e., all coefficients for active variables in that row are zero) are removed entirely, as they become trivial constants.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The <code>EnOptConfig</code> object             containing the variable mask and linear constraints.</p> required <code>initial_values</code> <code>NDArray[float64]</code> <p>The initial values to use.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>The adjusted coefficients and bounds.</p>"},{"location":"reference/plan/","title":"Optimization Plans","text":""},{"location":"reference/plan/#ropt.plan","title":"ropt.plan","text":"<p>Code for executing optimization plans.</p> <p>The <code>Plan</code> class orchestrates optimization workflows by managing steps and event handlers.</p> <p>A plan consists of <code>PlanStep</code> objects, which define individual actions, and <code>EventHandler</code> objects, which process and store data generated during execution. Both steps and event handlers are implemented using a plugin mechanism, making it easy to extend the range of supported actions and data processing. The <code>ropt</code> library provides default implementations through the default plan handler and default plan step plugins. These provide basic steps and event handlers to support a wide range of optimization workflows.</p> <p>Setting up and executing a <code>Plan</code> object for simple optimization cases can be complex. The <code>BasicOptimizer</code> class simplifies this process by providing a convenient way to build and execute straightforward plans involving a single optimization.</p>"},{"location":"reference/plan/#ropt.plan.Plan","title":"ropt.plan.Plan","text":"<p>Plan class for executing optimization workflows.</p> <p>The <code>Plan</code> object is the core component for executing optimization workflows. It orchestrates the execution of individual steps, manages evaluators for function computations, and processes data and results through event handlers.</p> <p>Building a Plan:</p> <p>A <code>Plan</code> is constructed by adding three main types of components, typically instantiated via the <code>PluginManager</code>:</p> <ol> <li>Steps (<code>PlanStep</code>): These define     individual actions or operations within the optimization workflow. Steps     are added using the <code>add_step</code> method.</li> <li>Event Handlers (<code>EventHandler</code>):     These components process data, track results, or react to events     emitted during plan execution. Event handlers are added using the     <code>add_event_handler</code> method.</li> <li>Evaluators (<code>Evaluator</code>): These     are responsible for performing function evaluations (e.g., objective     functions, constraints). Evaluators are added using the     <code>add_evaluator</code> method and can be     passed to steps that need them.</li> </ol> <p>Tags:</p> <p>Steps, event handlers, and evaluators can be assigned one or more tags. These tags can be used to identify the components instead of their unique IDs. Unlike ID's, tags do not need to be unique. This is useful when the components are created dynamically or if multiple components are to be identified as a group. For example, when specifying the source of events that a handler should process, its <code>sources</code> argument may contain both component objects, which identifies by their ID, or tags, which could refer to multiple components that have that tag.</p> <p>Executing a Plan:</p> <p>Once a plan is assembled, the <code>run</code> method can be invoked for each step individually. This approach allows for the integration of complex logic and custom functions, leveraging the full capabilities of Python.</p> <p>PluginManager:</p> <p>A <code>PluginManager</code> object can be provided that is used by the plan object to find and instantiate step, event handler, and evaluator objects. This manager can also be used by these components to implement further plugin-based functionality.</p> <p>Events:</p> <p>Steps can communicate events by retrieving a list of handlers using the <code>get_event_handlers</code> method. Event handlers can respond to these events, enabling actions such as processing optimization results. Event handlers are added to the plan using the <code>add_event_handler</code> method. To connect the event handlers to steps, they generally accept a set of steps via the <code>sources</code> argument. The steps must be part of the same plan, or a child plan (if existent).</p> <p>Evaluators:</p> <p>Evaluators (<code>Evaluator</code>) are key components responsible for performing function evaluations, such as computing objective functions or constraint values. They are added to the plan using the <code>add_evaluator</code> method. They connect to the steps in the plan, or in child plans, via the <code>clients</code> argument.</p> <p>Nested Plans:</p> <p>Multiple plans can be defined. A step within one plan can trigger the execution of another plan, enabling nested workflows. In nested plans, the <code>set_parent</code> method establishes a parent-child relationship. This allows events to propagate up the hierarchy to the parent plan.</p> <p>Aborting a Plan:</p> <p>A plan's execution can be terminated, either programmatically from within a step or event handler, or externally by directly calling the <code>abort</code> method. The <code>aborted</code> property can be used to check if a plan has been aborted.</p> <p>Handler Data:</p> <p>Individual event handlers may store values that they accumulate or calculate from the events that they handle. Code outside of the event handlers, such as the optimization workflow code that runs the steps, can set and retrieve these values using the <code>[]</code> operator.</p>"},{"location":"reference/plan/#ropt.plan.Plan.aborted","title":"aborted  <code>property</code>","text":"<pre><code>aborted: bool\n</code></pre> <p>Check if the plan was aborted.</p> <p>Determines whether the plan's execution has been aborted.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the plan was aborted; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.plugin_manager","title":"plugin_manager  <code>property</code>","text":"<pre><code>plugin_manager: PluginManager\n</code></pre> <p>Return the plugin manager.</p> <p>Retrieves the <code>PluginManager</code> object associated with this plan.</p> <p>Returns:</p> Type Description <code>PluginManager</code> <p>The plugin manager stored by the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.__init__","title":"__init__","text":"<pre><code>__init__(\n    plugin_manager: PluginManager,\n    parent: Plan | None = None,\n) -&gt; None\n</code></pre> <p>Initialize a plan object.</p> <p>Constructs a new plan, associating it with an evaluator, and optionally with a plugin manager and/or a parent plan.</p> <p>The <code>plugin_manager</code> is used by the plan, and possibly by steps and event handlers to add plugin functionality.</p> <p>If a <code>parent</code> plan is specified, this plan becomes a child, enabling communication up the plan hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_manager</code> <code>PluginManager</code> <p>A plugin manager.</p> required <code>parent</code> <code>Plan | None</code> <p>An optional parent plan.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.Plan.add_event_handler","title":"add_event_handler","text":"<pre><code>add_event_handler(\n    name: str,\n    tags: set[str] | None = None,\n    sources: set[PlanComponent | str] | None = None,\n    **kwargs: Any,\n) -&gt; EventHandler\n</code></pre> <p>Add an event handler to the plan.</p> <p>Constructs and registers an event handler with the plan. The handler's type is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding handler class. Any additional keyword arguments are passed to the handler's constructor.</p> <p>The <code>sources</code> parameter acts as a filter, determining which plan steps this event handler should listen to. It should be a set containing the <code>PlanStep</code> instances whose event you want to receive. When an event is received, this event handler checks if the step that emitted the event (<code>event.source</code>) is present in the <code>sources</code> set. If <code>sources</code> is <code>None</code>, events from all sources will be processed.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the event handler to add.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>sources</code> <code>set[PlanComponent | str] | None</code> <p>The steps whose events should be processed.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for the handler's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>EventHandler</code> <p>The newly added event handler.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_step","title":"add_step","text":"<pre><code>add_step(\n    name: str, tags: set[str] | None = None, **kwargs: Any\n) -&gt; PlanStep\n</code></pre> <p>Add a step to the plan.</p> <p>Registers a step with the plan. The step's type is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding step class. Any additional keyword arguments are passed to the step's constructor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the step to add.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for the step's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PlanStep</code> <p>The newly added step.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_evaluator","title":"add_evaluator","text":"<pre><code>add_evaluator(\n    name: str,\n    tags: set[str] | None = None,\n    clients: set[PlanComponent | str] | None = None,\n    **kwargs: Any,\n) -&gt; Evaluator\n</code></pre> <p>Add an evaluator object to the plan.</p> <p>Creates an evaluator of a type that is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding evaluator class. Any additional keyword arguments are passed to the evaluators's constructor.</p> <p>The <code>clients</code> parameter acts as a filter, determining which plan steps this evaluator should serve. It should be a set containing the <code>PlanStep</code> instances that should be handled. When an evaluation is requested, this evaluator checks if the step is present in the <code>client</code> set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the evaluator to add.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>clients</code> <code>set[PlanComponent | str] | None</code> <p>The clients that should be served by this evaluator.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for the evaluators's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Evaluator</code> <p>The new evaluator object.</p>"},{"location":"reference/plan/#ropt.plan.Plan.run_step","title":"run_step","text":"<pre><code>run_step(step: PlanStep, **kwargs: Any) -&gt; Any\n</code></pre> <p>Run a step in the plan.</p> <p>Executes a specific step within the plan. The step's <code>run</code> method is called with the provided keyword arguments. If the plan has been aborted, a <code>PlanAborted</code> exception is raised before the step is executed.</p> <p>The step is executed only once. The value returned by the step's <code>run</code> method is returned by this method.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>PlanStep</code> <p>The step to run.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments to pass to the step's <code>run</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value returned by the step's <code>run</code> method.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>step</code> ID is not valid.</p> <code>PlanAborted</code> <p>If the plan has been aborted.</p>"},{"location":"reference/plan/#ropt.plan.Plan.get_event_handlers","title":"get_event_handlers","text":"<pre><code>get_event_handlers(\n    source: PlanComponent, event_types: set[EventType]\n) -&gt; dict[EventType, list[Callable[[Event], None]]]\n</code></pre> <p>Get the event handlers for a given source and event types.</p> <p>When this method is called, all event handlers associated with the plan are searched for those that handle the <code>source</code>. Then, if the plan has a parent, the parent plan's <code>get_event_handlers</code> method is also called, find handlers further up the hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PlanComponent</code> <p>The source of the event.</p> required <code>event_types</code> <code>set[EventType]</code> <p>The event types that should be handled.</p> required <p>Returns:</p> Type Description <code>dict[EventType, list[Callable[[Event], None]]]</code> <p>A mapping of event types to a list of suitable handlers.</p>"},{"location":"reference/plan/#ropt.plan.Plan.get_evaluator","title":"get_evaluator","text":"<pre><code>get_evaluator(client: PlanComponent) -&gt; Evaluator\n</code></pre> <p>Retrieve the appropriate evaluator for a given client step.</p> <p>This method searches for an <code>Evaluator</code> that is configured to serve the specified <code>client</code> (<code>PlanStep</code>). The search starts in the current plan and, if no suitable evaluator is found and a parent plan exists, continues recursively up the plan hierarchy.</p> <p>An evaluator is considered suitable the <code>id</code> or <code>tags</code> of the <code>client</code> step is present in the <code>clients</code> set of the evaluator.</p> <p>The method expects to find exactly one suitable evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>PlanComponent</code> <p>The step for which an evaluator is being requested.</p> required <p>Returns:</p> Type Description <code>Evaluator</code> <p>The single evaluator instance configured to serve the client.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If no suitable evaluator is found, or if multiple             suitable evaluators are found.</p>"},{"location":"reference/plan/#ropt.plan.Plan.abort","title":"abort","text":"<pre><code>abort() -&gt; None\n</code></pre> <p>Abort the plan.</p> <p>Prevents further steps in the plan from being executed. This method does not interrupt a currently running step but ensures that no subsequent steps will be initiated. It can be used to halt the plan's execution due to a step failure or external intervention.</p> <p>The <code>aborted</code> property can be used to check if the plan has been aborted.</p>"},{"location":"reference/plan/#ropt.plan.Plan.set_parent","title":"set_parent","text":"<pre><code>set_parent(parent: Plan) -&gt; None\n</code></pre> <p>Set the parent of the plan.</p> <p>Establishes a parent-child relationship between this plan and another plan. This enables event propagation up the plan hierarchy. It also allows the <code>get_evaluation</code> method to inquire the parent for an evaluator object, if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>Plan</code> <p>The parent plan.</p> required"},{"location":"reference/plan/#ropt.plan.Event","title":"ropt.plan.Event  <code>dataclass</code>","text":"<p>Stores data related to an optimization event.</p> <p>During the execution of an optimization plan, events are triggered to signal specific occurrences. Callbacks can be registered to react to these events and will receive an <code>Event</code> object containing relevant information.</p> <p>The specific data within the <code>Event</code> object varies depending on the event type. See the <code>EventType</code> documentation for details.</p> <p>Attributes:</p> Name Type Description <code>event_type</code> <code>EventType</code> <p>The type of event that occurred.</p> <code>data</code> <code>dict[str, Any]</code> <p>A dictionary containing additional event-specific data.</p>"},{"location":"reference/plan_plugins/","title":"Plan Plugins","text":""},{"location":"reference/plan_plugins/#ropt.plugins.plan","title":"ropt.plugins.plan","text":"<p>Framework and Implementations for Optimization Plan Plugins.</p> <p>This module provides the core components and default implementations for extending <code>ropt</code>'s optimization plan capabilities (<code>Plan</code>) through plugins. It allows users to define custom sequences of operations (steps) and ways to process the results and events generated during plan execution (handlers).</p> <p>Core Concepts:</p> <ul> <li>Plan Steps: Represent individual actions within an optimization plan,     such as running an optimizer or performing evaluations.</li> <li>Plan Handlers: Process events emitted by the plan or its steps, enabling     tasks like result tracking, data storage, or logging.</li> <li>Evaluators: Perform the actual function evaluations (e.g., objective     functions, constraints) required by the optimization process.</li> </ul> <p>The implementation of these core concepts relies on classes derived from the following abstract base classes:</p> <ol> <li> <p>Plugin Base Classes:</p> <ul> <li><code>PlanStepPlugin</code>: The base for   plugins that create plan steps. These plugins are discovered by the   <code>PluginManager</code> and used to instantiate   actual <code>PlanStep</code> objects.</li> <li><code>EventHandlerPlugin</code>: The   base for plugins that create event handlers. Similar to step plugins,   these are used by the <code>PluginManager</code> to instantiate <code>EventHandler</code>   objects.</li> <li><code>EvaluatorPlugin</code>: The base for   plugins that create evaluators. These are used by the   <code>PluginManager</code> to instantiate <code>Evaluator</code> objects, which are   responsible for function computations.</li> </ul> </li> <li> <p>Component Base Classes:</p> <ul> <li><code>PlanStep</code>: The abstract base class   that all concrete plan step implementations must inherit from. It defines   the <code>run</code> method where the step's   logic resides.</li> <li><code>EventHandler</code>: The abstract base   class for all event handlers. It defines the   <code>handle_event</code> method   for processing events emitted during plan execution and allows storing   state using dictionary-like access.</li> <li><code>Evaluator</code>: The abstract base class   for all evaluators. It defines the   <code>eval</code> method responsible for   performing function computations.</li> </ul> </li> </ol> <p>By inheriting from these classes, developers can create custom steps and handlers that integrate seamlessly into the <code>ropt</code> optimization plan execution framework (<code>Plan</code>).</p> <p>Built-in Plan Plugins:</p> <p><code>ropt</code> includes default plugins providing common plan components:</p> <ul> <li>Steps (via     <code>DefaultPlanStepPlugin</code>):<ul> <li><code>evaluator</code>: Performs ensemble evaluations     (<code>DefaultEnsembleEvaluatorStep</code>).</li> <li><code>optimizer</code>: Runs an optimization algorithm using a configured optimizer     plugin     (<code>DefaultOptimizerStep</code>).</li> </ul> </li> <li>Handlers (via     <code>DefaultEventHandlerPlugin</code>):<ul> <li><code>tracker</code>: Tracks the 'best' or 'last' valid result based on objective     value and constraints     (<code>DefaultTrackerHandler</code>).</li> <li><code>store</code>: Accumulates all results from specified sources     (<code>DefaultStoreHandler</code>).</li> </ul> </li> <li>Evaluators (via     <code>DefaultEvaluatorPlugin</code>):<ul> <li><code>function_evaluator</code>: Forwards calculations to a given evaluation     function     (<code>DefaultFunctionEvaluator</code>).</li> </ul> </li> </ul> <p>These built-in components allow for the construction of standard optimization workflows out-of-the-box, while the plugin architecture enables customization and extension.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanComponent","title":"ropt.plugins.plan.base.PlanComponent","text":"<p>Base class for components that are part of an optimization plan.</p> <p>This class provides common functionality for components like steps, event handlers, and evaluators that are managed within a <code>Plan</code>.</p> <p>Each <code>PlanComponent</code> is assigned a unique identifier (<code>id</code>) upon initialization, an optional tag (<code>tag</code>), and maintains a reference to its parent <code>plan</code>.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanComponent.id","title":"id  <code>property</code>","text":"<pre><code>id: UUID\n</code></pre> <p>Return the unique identifier of the event handler.</p> <p>Returns:</p> Type Description <code>UUID</code> <p>A UUID object representing the unique identifier of the event handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanComponent.plan","title":"plan  <code>property</code>","text":"<pre><code>plan: Plan\n</code></pre> <p>Return the parent plan associated with this event handler.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The <code>Plan</code> object that owns this event handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanComponent.tags","title":"tags  <code>property</code>","text":"<pre><code>tags: set[str]\n</code></pre> <p>Return the optional tags.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>The tags.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanComponent.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan, tags: set[str] | None) -&gt; None\n</code></pre> <p>Initialize the PlanComponent.</p> <p>This constructor is called by subclasses to set up common attributes. It stores a reference to the parent <code>plan</code>, an optional <code>tag</code>, and assigns a unique <code>id</code>.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The parent <code>Plan</code> instance.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStepPlugin","title":"ropt.plugins.plan.base.PlanStepPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for plugins that create PlanStep instances.</p> <p>This class defines the interface for plugins that act as factories for <code>PlanStep</code> objects.</p> <p>The <code>PluginManager</code> uses the <code>create</code> class method of these plugins to instantiate <code>PlanStep</code> objects when they are added to an optimization <code>Plan</code> via <code>Plan.add_step</code>.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStepPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    name: str,\n    plan: Plan,\n    tags: set[str] | None = None,\n    **kwargs: Any,\n) -&gt; PlanStep\n</code></pre> <p>Create a PlanStep instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>PlanStep</code> objects. Plugin implementations must override this method to return an instance of their specific <code>PlanStep</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when a plan requests a step provided by this plugin via <code>Plan.add_step</code>.</p> <p>The <code>name</code> argument specifies the requested step, potentially in the format <code>\"plugin-name/method-name\"</code> or just <code>\"method-name\"</code>. Implementations can use this <code>name</code> to vary the created step if the plugin supports multiple step types.</p> <p>The optional <code>tags</code> argument assigns the given string tags to the plan step. Similar to its <code>id</code>, the <code>tags</code> can be used for identification. However, unlike an <code>id</code>, a tag does not need to be unique, allowing multiple components to be grouped under the same tag.</p> <p>Any additional keyword arguments (<code>kwargs</code>) passed during the <code>Plan.add_step</code> call are forwarded here, allowing for custom configuration of the step instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The requested step name (potentially plugin-specific).</p> required <code>plan</code> <code>Plan</code> <p>The parent <code>Plan</code> instance.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for custom configuration.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PlanStep</code> <p>An initialized instance of a <code>PlanStep</code> subclass.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandlerPlugin","title":"ropt.plugins.plan.base.EventHandlerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Plan Handler Plugins.</p> <p>This class defines the interface for plugins responsible for creating <code>EventHandler</code> instances within an optimization plan (<code>Plan</code>).</p> <p>During plan setup, the <code>PluginManager</code> identifies the appropriate event handler plugin based on a requested name and uses its <code>create</code> class method to instantiate the actual <code>EventHandler</code> object that will process events during plan execution.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandlerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    name: str,\n    plan: Plan,\n    tags: set[str] | None = None,\n    sources: set[PlanComponent | str] | None = None,\n    **kwargs: Any,\n) -&gt; EventHandler\n</code></pre> <p>Create a EventHandler instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>EventHandler</code> objects. Plugin implementations must override this method to return an instance of their specific <code>EventHandler</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when a plan requests an event handler provided by this plugin via <code>Plan.add_event_handler</code>.</p> <p>The <code>name</code> argument specifies the requested event handler, potentially in the format <code>\"plugin-name/method-name\"</code> or just <code>\"method-name\"</code>. Implementations can use this <code>name</code> to vary the created event handler if the plugin supports multiple event handler types.</p> <p>The optional <code>tags</code> argument assigns the given string tags to the event handler. Similar to its <code>id</code>, the <code>tags</code> can be used for identification. However, unlike an <code>id</code>, a tag does not need to be unique, allowing multiple components to be grouped under the same tag.</p> <p>The <code>sources</code> parameter acts as a filter, determining which plan steps this event handler should listen to. It should be a set containing the <code>PlanStep</code> instances whose event you want to receive. When an event is received, this event handler checks if the step that emitted the event (<code>event.source</code>) is present in the <code>sources</code> set. If <code>sources</code> is <code>None</code>, events from all sources will be processed.</p> <p>Any additional keyword arguments (<code>kwargs</code>) passed during the <code>Plan.add_event_handler</code> call are forwarded here, allowing for custom configuration of the event handler instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The requested event handler name (potentially plugin-specific).</p> required <code>plan</code> <code>Plan</code> <p>The parent <code>Plan</code> instance.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>sources</code> <code>set[PlanComponent | str] | None</code> <p>The steps whose events should be processed.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for custom configuration.</p> <code>{}</code> <p>Returns:</p> Type Description <code>EventHandler</code> <p>An initialized instance of a <code>EventHandler</code> subclass.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EvaluatorPlugin","title":"ropt.plugins.plan.base.EvaluatorPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for evaluator plugins.</p> <p>This class defines the interface for plugins responsible for creating plan-aware <code>Evaluator</code> instances within an optimization plan (<code>Plan</code>).</p> <p>During plan setup, the <code>PluginManager</code> identifies the appropriate evaluator plugin based on a requested name and uses its <code>create</code> class method to instantiate the actual <code>Evaluator</code> object that will perform evaluations during plan execution.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EvaluatorPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    name: str,\n    plan: Plan,\n    tags: set[str] | None = None,\n    clients: set[PlanComponent | str] | None = None,\n    **kwargs: Any,\n) -&gt; Evaluator\n</code></pre> <p>Create an Evaluator instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>Evaluator</code> objects. Plugin implementations must override this method to return an instance of their specific <code>Evaluator</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an evaluator provided by this plugin is requested.</p> <p>The <code>name</code> argument specifies the requested evaluator, potentially in the format <code>\"plugin-name/method-name\"</code> or just <code>\"method-name\"</code>. Implementations can use this <code>name</code> to vary the created evaluator if the plugin supports multiple evaluator types.</p> <p>The optional <code>tags</code> argument assigns the given string tags to the evaluator. Similar to its <code>id</code>, the <code>tags</code> can be used for identification. However, unlike an <code>id</code>, a tag does not need to be unique, allowing multiple components to be grouped under the same tag.</p> <p>The <code>clients</code> parameter acts as a filter, determining which plan steps this evaluator should serve. It should be a set containing the <code>PlanStep</code> instances that should be handled. When an evaluation is requested, this evaluator checks if the step  is present in the <code>client</code> set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The requested evaluator name (potentially plugin-specific).</p> required <code>plan</code> <code>Plan</code> <p>The parent <code>Plan</code> instance.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>clients</code> <code>set[PlanComponent | str] | None</code> <p>The clients that should be served by this evaluator.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for custom configuration.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Evaluator</code> <p>An initialized instance of an <code>Evaluator</code> subclass.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep","title":"ropt.plugins.plan.base.PlanStep","text":"<p>               Bases: <code>ABC</code>, <code>PlanComponent</code></p> <p>Abstract base class for optimization plan steps.</p> <p>This class defines the fundamental interface for all executable steps within an optimization <code>Plan</code>. Concrete step implementations, which perform specific actions like running an optimizer or evaluating functions, must inherit from this base class.</p> <p><code>PlanStep</code> objects are typically created by corresponding <code>PlanStepPlugin</code> factories, which are managed by the <code>PluginManager</code>. Once instantiated and added to a <code>Plan</code>, their <code>run_step_from_plan</code> method is called by the plan during execution. This is generally done indirectly by calling the <code>run</code> method on the step object.</p> <p>Subclasses must implement the abstract <code>run_step_from_plan</code> method to define the step's specific behavior.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan, tags: set[str] | None = None) -&gt; None\n</code></pre> <p>Initialize the PlanStep.</p> <p>Associates the step with its parent <code>Plan</code> and assigns a unique ID. The parent plan is accessible via the <code>plan</code> property.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The <code>Plan</code> instance that owns this step.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.run","title":"run","text":"<pre><code>run(*args: Any, **kwargs: Any) -&gt; Any\n</code></pre> <p>Execute this plan step.</p> <p>This method initiates the execution of the current plan step. It delegates the actual execution to the parent <code>Plan</code> object's <code>run_step</code> method, passing itself (the step instance) along with any provided arguments.</p> <p>The parent <code>Plan</code> then calls the concrete <code>run_step_from_plan</code> method implemented by the subclass of this <code>PlanStep</code>. This allows the plan to do some bookkeeping, for instance to check if the plan was aborted.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Positional arguments to be passed to the step's specific <code>run_step</code> method.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments to be passed to the step's specific <code>run_step</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The result returned by the step's specific <code>run_step_from_plan</code> method.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.run_step_from_plan","title":"run_step_from_plan  <code>abstractmethod</code>","text":"<pre><code>run_step_from_plan(*args: Any, **kwargs: Any) -&gt; Any\n</code></pre> <p>Execute the logic defined by this plan step.</p> <p>This abstract method must be implemented by concrete <code>PlanStep</code> subclasses to define the specific action the step performs within the optimization <code>Plan</code>.</p> <p>The <code>Plan</code> object calls this method during its execution sequence, passing any arguments provided when the step was invoked via <code>Plan.run_step</code>. The return value and type can vary depending on the specific step implementation.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>Positional arguments passed from <code>Plan.run_step</code>.</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Keyword arguments passed from <code>Plan.run_step</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The result of the step's execution, if any.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler","title":"ropt.plugins.plan.base.EventHandler","text":"<p>               Bases: <code>ABC</code>, <code>PlanComponent</code></p> <p>Abstract Base Class for Optimization Plan Result Handlers.</p> <p>This class defines the fundamental interface for all event handlers within an optimization <code>Plan</code>. Concrete handler implementations, which process events emitted during plan execution (e.g., tracking results, storing data, logging), must inherit from this base class.</p> <p><code>EventHandler</code> objects are typically created by corresponding <code>EventHandlerPlugin</code> factories, managed by the <code>PluginManager</code>. Once instantiated and added to a <code>Plan</code>, their <code>handle_event</code> method is called by the plan whenever an <code>Event</code> is emitted.</p> <p>Handlers can also store state using dictionary-like access (<code>[]</code>), allowing them to accumulate information or make data available to subsequent steps or event handlers within the plan.</p> <p>Subclasses must implement the abstract <code>handle_event</code> method to define their specific event processing logic.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler.sources","title":"sources  <code>property</code>","text":"<pre><code>sources: set[UUID | str]\n</code></pre> <p>Return the source IDs or tags that are listened to.</p> <p>Returns:</p> Type Description <code>set[UUID | str]</code> <p>The source IDs or tags this event handler is interested in.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler.event_types","title":"event_types  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>event_types: set[EventType]\n</code></pre> <p>Return the event types that are handled.</p> <p>Returns:</p> Type Description <code>set[EventType]</code> <p>A set of event types that are handled.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler.__init__","title":"__init__","text":"<pre><code>__init__(\n    plan: Plan,\n    tags: set[str] | None = None,\n    sources: set[PlanComponent | str] | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the EventHandler.</p> <p>Associates the event handler with its parent <code>Plan</code>, assigns a unique ID, and initializes an internal dictionary for storing state. The parent plan is accessible via the <code>plan</code> property.</p> <p>The <code>sources</code> parameter acts as a filter, determining which plan steps this event handler should listen to. It should be a set containing the components or tags that should be handled. When an event is received, this event handler checks if the component, or one of its tag, is present in the  <code>sources</code> set.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The <code>Plan</code> instance that owns this event handler.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>sources</code> <code>set[PlanComponent | str] | None</code> <p>Optional set of steps whose events should be processed.</p> <code>None</code>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler.handle_event","title":"handle_event  <code>abstractmethod</code>","text":"<pre><code>handle_event(event: Event) -&gt; None\n</code></pre> <p>Process an event emitted by the optimization plan.</p> <p>This abstract method must be implemented by concrete <code>EventHandler</code> subclasses. It defines the event handler's core logic for reacting to <code>Event</code> objects emitted during the execution of the parent <code>Plan</code>.</p> <p>Implementations should inspect the <code>event</code> object (its <code>event_type</code> and <code>data</code>) and perform actions accordingly, such as storing results, logging information, or updating internal state.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event object containing details about what occurred in the plan.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key: str) -&gt; Any\n</code></pre> <p>Retrieve a value from the event handler's internal state.</p> <p>This method enables dictionary-like access (<code>handler[key]</code>) to the values stored within the event handler's internal state dictionary. This allows handlers to store and retrieve data accumulated during plan execution.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The string key identifying the value to retrieve.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value associated with the specified key.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>key</code> does not exist in the             event handler's stored values.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.EventHandler.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key: str, value: Any) -&gt; None\n</code></pre> <p>Store or update a value in the event handler's internal state.</p> <p>This method enables dictionary-like assignment (<code>handler[key] = value</code>) to store arbitrary data within the event handler's internal state dictionary. This allows event handlers to accumulate information or make data available to other components of plan.</p> <p>The key must be a valid Python identifier.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The string key identifying the value to store (must be an identifier).</p> required <code>value</code> <code>Any</code> <p>The value to associate with the key.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>key</code> is not a valid identifier.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.Evaluator","title":"ropt.plugins.plan.base.Evaluator","text":"<p>               Bases: <code>ABC</code>, <code>PlanComponent</code></p> <p>abstract base class for evaluator components within an optimization plan.</p> <p>Subclasses must implement the abstract <code>eval</code> method, which is responsible for performing the actual evaluation of variables using an <code>EvaluatorContext</code> and returning an <code>EvaluatorResult</code>.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.Evaluator.clients","title":"clients  <code>property</code>","text":"<pre><code>clients: set[UUID | str]\n</code></pre> <p>Return the client IDs or tags that are served.</p> <p>Returns:</p> Type Description <code>set[UUID | str]</code> <p>The IDs of the clients, or the tags, this evaluator will handle.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.Evaluator.__init__","title":"__init__","text":"<pre><code>__init__(\n    plan: Plan,\n    tags: set[str] | None = None,\n    clients: set[PlanComponent | str] | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the Evaluator.</p> <p>Associates the evaluator with its parent <code>Plan</code>, and assigns a unique ID. The parent plan is accessible via the <code>plan</code> property.</p> <p>The <code>clients</code> parameter acts as a filter, determining which plan steps this evaluator should serve. It should be a set containing the the components or tags that should be handled. When an evaluation is requested, this evaluator checks if the component, or one of its tags, is present in the <code>client</code> set.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The <code>Plan</code> instance that owns this evaluator.</p> required <code>tags</code> <code>set[str] | None</code> <p>Optional tags</p> <code>None</code> <code>clients</code> <code>set[PlanComponent | str] | None</code> <p>The steps that use this evaluator.</p> <code>None</code>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.Evaluator.eval","title":"eval  <code>abstractmethod</code>","text":"<pre><code>eval(\n    variables: NDArray[float64], context: EvaluatorContext\n) -&gt; EvaluatorResult\n</code></pre> <p>Evaluate objective and constraint functions for given variables.</p> <p>This method defines function evaluator callback, which calculates objective and constraint functions for a set of variable vectors, potentially for a subset of realizations and perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate. Each row represents        a variable vector.</p> required <code>context</code> <code>EvaluatorContext</code> <p>The evaluation context, providing additional information        about the evaluation.</p> required <p>Returns:</p> Type Description <code>EvaluatorResult</code> <p>An evaluation results object containing the calculated values.</p> Reusing Objectives and Constraints <p>When defining multiple objectives, there may be a need to reuse the same objective or constraint value multiple times. For instance, a total objective could consist of the mean of the objectives for each realization, plus the standard deviation of the same values. This can be implemented by defining two objectives: the first calculated as the mean of the realizations, and the second using a function estimator to compute the standard deviations. The optimizer is unaware that both objectives use the same set of realizations. To prevent redundant calculations, the evaluator should compute the results of the realizations once and return them for both objectives.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.Evaluator.add_clients","title":"add_clients","text":"<pre><code>add_clients(\n    clients: PlanComponent\n    | str\n    | Sequence[PlanComponent | str]\n    | set[PlanComponent | str],\n) -&gt; None\n</code></pre> <p>Add one or more clients to the evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>clients</code> <code>PlanComponent | str | Sequence[PlanComponent | str] | set[PlanComponent | str]</code> <p>The clients to add.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.Evaluator.remove_clients","title":"remove_clients","text":"<pre><code>remove_clients(\n    clients: PlanComponent\n    | str\n    | Sequence[PlanComponent | str]\n    | set[PlanComponent | str],\n) -&gt; None\n</code></pre> <p>Remove one or more clients from the evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>clients</code> <code>PlanComponent | str | Sequence[PlanComponent | str] | set[PlanComponent | str]</code> <p>The clients to remove.</p> required"},{"location":"reference/plugin_manager/","title":"Plugins","text":""},{"location":"reference/plugin_manager/#ropt.plugins","title":"ropt.plugins","text":"<p>Extending <code>ropt</code> with Plugins.</p> <p>The <code>ropt.plugins</code> module provides the framework for extending <code>ropt</code>'s capabilities through a plugin system. Plugins allow for the integration of custom or third-party components, installed as separate packages.</p> <p><code>ropt</code> supports several types of plugins, each addressing a specific aspect of the optimization workflow:</p> <ul> <li><code>plan</code>: Defines components for constructing and executing   optimization plans   (<code>EventHandlerPlugin</code>,   <code>PlanStepPlugin</code> and   <code>EvaluatorPlugin</code>).</li> <li><code>optimizer</code>: Implements optimization algorithms.</li> <li><code>sampler</code>: Generates parameter perturbations, which   are used for gradient estimation.</li> <li><code>realization_filter</code>: Selects subsets of   ensemble realizations for calculating objectives or constraints.</li> <li><code>function_estimator</code>: Computes final   objective function values and gradients from individual realization results.</li> </ul> <p>Plugin Management and Discovery</p> <p>The <code>PluginManager</code> class is central to the plugin system. It discovers and manages available plugins. Plugins are typically discovered automatically using Python's standard entry points mechanism.</p> <p>Each plugin type has a corresponding abstract base class that custom plugins must inherit from:</p> <ul> <li>Plan: <code>EventHandlerPlugin</code>,   <code>PlanStepPlugin</code>, and   <code>EvaluatorPlugin</code></li> <li>Optimizer: <code>OptimizerPlugin</code></li> <li>Sampler: <code>SamplerPlugin</code></li> <li>Realization Filter: <code>RealizationFilterPlugin</code></li> <li>Function Estimator: <code>FunctionEstimatorPlugin</code></li> </ul> <p>Using Plugins</p> <p>The <code>PluginManager.get_plugin</code> method is used internally by <code>ropt</code> to retrieve the appropriate plugin implementation based on a specified type and method name. The <code>PluginManager.is_supported</code> method can check if a specific method is available.</p> <p>Plugins can implement multiple named methods. To request a specific method (<code>method-name</code>) from a particular plugin (<code>plugin-name</code>), use the format <code>\"plugin-name/method-name\"</code>. If only a method name is provided, the plugin manager searches through all registered plugins (that allow discovery) for one that supports the method. Using <code>\"plugin-name/default\"</code> typically selects the primary or default method offered by that plugin, although specifying \"default\" without a plugin name is not permitted.</p> <p>Plugins retrieved by the <code>PluginManager.get_plugin</code> method generally implement a <code>create</code> factory method that will be used to instantiate the objects that implement the desired functionality. These objects must inherit from the base class for the corresponding plugin type:</p> <ul> <li>Plan: <code>EventHandler</code> and   <code>PlanStep</code></li> <li>Optimizer: <code>Optimizer</code></li> <li>Sampler: <code>Sampler</code></li> <li>Realization Filter: <code>RealizationFilter</code></li> <li>Function Estimator: <code>FunctionEstimator</code></li> </ul> <p>Pre-installed Plugins Included with <code>ropt</code></p> <p><code>ropt</code> comes bundled with a set of pre-installed plugins:</p> <ul> <li>Plan: The built-in   <code>default</code> event handler   and <code>default</code> step plugins,   providing components for executing complex optimization plans.</li> <li>Optimizer: The <code>scipy</code>   plugin, leveraging algorithms from <code>scipy.optimize</code>, and the   <code>ExternalOptimizer</code>,   which is used to launch optimizers in separate processes.</li> <li>Sampler: The <code>scipy</code> plugin,   using distributions from <code>scipy.stats</code>.</li> <li>Realization Filter: The   <code>default</code>   plugin, offering filters based on ranking and for CVaR optimization.</li> <li>Function Estimator: The   <code>default</code>   plugin, supporting objectives based on mean or standard deviation.</li> </ul>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager","title":"PluginManager","text":"<p>Manages the discovery and retrieval of <code>ropt</code> plugins.</p> <p>The <code>PluginManager</code> is responsible for finding available plugins based on Python's entry points mechanism and providing access to them. It serves as a central registry for different types of plugins used within <code>ropt</code>, such as optimizers, samplers, and plan components.</p> <p>Upon initialization, the manager scans for entry points defined under the <code>ropt.plugins.*</code> groups (e.g., <code>ropt.plugins.optimizer</code>). Plugins found this way are loaded and stored internally, categorized by their type.</p> <p>The primary way to interact with the manager is through the <code>get_plugin</code> method, which retrieves a specific plugin class based on its type and a method name it supports. The <code>is_supported</code> method can be used to check for the availability of a plugin method without retrieving it.</p> <p>Example: Registering a Custom Optimizer Plugin</p> <p>To make a custom optimizer plugin available to <code>ropt</code>, you would typically define an entry point in your package's <code>pyproject.toml</code>:</p> <pre><code>[project.entry-points.\"ropt.plugins.optimizer\"]\nmy_optimizer = \"my_package.my_module:MyOptimizer\"\n</code></pre> <p>When <code>ropt</code> initializes the <code>PluginManager</code>, it will discover and load <code>MyOptimizer</code> from <code>my_package.my_module</code>, making it accessible via <code>plugin_manager.get_plugin(\"optimizer\", \"my_optimizer/some_method\")</code> or potentially <code>plugin_manager.get_plugin(\"optimizer\", \"some_method\")</code> if discovery is allowed and the method is unique.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the plugin manager.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.get_plugin","title":"get_plugin","text":"<pre><code>get_plugin(plugin_type: PluginType, method: str) -&gt; Any\n</code></pre> <p>Retrieve a plugin class by its type and a supported method name.</p> <p>This method finds and returns the class of a plugin that matches the specified <code>plugin_type</code> and supports the given <code>method</code>.</p> <p>The <code>method</code> argument can be specified in two ways:</p> <ol> <li>Explicit Plugin: Use the format <code>\"plugin-name/method-name\"</code>.     This directly requests the <code>method-name</code> from the plugin named     <code>plugin-name</code>.</li> <li>Implicit Plugin: Provide only the <code>method-name</code>. The manager     will search through all registered plugins of the specified     <code>plugin_type</code> that allow discovery (see     <code>Plugin.allows_discovery</code>).     It returns the first plugin found that supports the <code>method-name</code>.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The category of the plugin (e.g., \"optimizer\", \"sampler\").</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin must support, potentially          prefixed with the plugin name and a slash (<code>/</code>).</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The plugin class that matches the criteria.</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If no matching plugin is found for the given type and          method, or if \"default\" is used as a method name without          specifying a plugin name.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.is_supported","title":"is_supported","text":"<pre><code>is_supported(plugin_type: PluginType, method: str) -&gt; bool\n</code></pre> <p>Check if a specific plugin method is available.</p> <p>Verifies whether a plugin of the specified <code>plugin_type</code> supports the given <code>method</code>. This is useful for checking availability before attempting to retrieve a plugin with <code>get_plugin</code>.</p> <p>The <code>method</code> argument can be specified in two ways:</p> <ol> <li>Explicit Plugin: <code>\"plugin-name/method-name\"</code> checks if the specific     plugin named <code>plugin-name</code> supports <code>method-name</code>.</li> <li>Implicit Plugin: <code>\"method-name\"</code> searches through all discoverable     plugins of the given <code>plugin_type</code> to see if any support <code>method-name</code>.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The category of the plugin (e.g., \"optimizer\", \"sampler\").</p> required <code>method</code> <code>str</code> <p>The name of the method to check, potentially prefixed          with the plugin name and a slash (<code>/</code>).</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if a matching plugin supports the specified method.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginType","title":"PluginType  <code>module-attribute</code>","text":"<pre><code>PluginType = Literal[\n    \"optimizer\",\n    \"sampler\",\n    \"realization_filter\",\n    \"function_estimator\",\n    \"event_handler\",\n    \"plan_step\",\n    \"evaluator\",\n]\n</code></pre> <p>Represents the valid types of plugins supported by <code>ropt</code>.</p> <p>This type alias defines the string identifiers used to categorize different plugins within the <code>ropt</code> framework. Each identifier corresponds to a specific role in the optimization process:</p> <ul> <li><code>\"optimizer\"</code>: Plugins implementing optimization algorithms   (<code>OptimizerPlugin</code>).</li> <li><code>\"sampler\"</code>: Plugins for generating parameter samples   (<code>SamplerPlugin</code>).</li> <li><code>\"realization_filter\"</code>: Plugins for filtering ensemble realizations   (<code>RealizationFilterPlugin</code>).</li> <li><code>\"function_estimator\"</code>: Plugins for estimating objective functions and gradients   (<code>FunctionEstimatorPlugin</code>).</li> <li><code>\"event_handler\"</code>: Plugins that create event handlers for processing plan   results (<code>EventHandlerPlugin</code>).</li> <li><code>\"plan_step\"</code>: Plugins that define executable steps within an optimization plan   (<code>PlanStepPlugin</code>).</li> <li><code>\"evaluator\"</code>: Plugins that define evaluators within an optimization plan   (<code>EvaluatorPlugin</code>).</li> </ul>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin","title":"Plugin","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all <code>ropt</code> plugins.</p> <p>This class serves as the fundamental building block for all plugins within the <code>ropt</code> framework. Any class intended to function as a plugin (e.g., an optimizer, sampler, step, or event handler) must inherit from this base class.</p> <p>It defines the core interface that all plugins must adhere to, ensuring consistency and enabling the <code>PluginManager</code> to discover and manage them effectively.</p> <p>Subclasses must implement the <code>is_supported</code> class method to indicate which named methods (functionalities) they provide. They can optionally override the <code>allows_discovery</code> class method if they should not be automatically selected by the plugin manager when a method name is provided without an explicit plugin name.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.is_supported","title":"is_supported  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>is_supported(method: str) -&gt; bool\n</code></pre> <p>Verify if this plugin supports a specific named method.</p> <p>This class method is used by the <code>PluginManager</code> (specifically its <code>is_supported</code> method) to determine if this plugin class provides the functionality associated with the given <code>method</code> name.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The string identifier of the method to check for support.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the plugin supports the specified method, <code>False</code> otherwise.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.allows_discovery","title":"allows_discovery  <code>classmethod</code>","text":"<pre><code>allows_discovery() -&gt; bool\n</code></pre> <p>Determine if the plugin allows implicit discovery by method name.</p> <p>By default (<code>True</code>), plugins can be found by the <code>PluginManager</code> when a user provides only a method name (without specifying the plugin, e.g., <code>\"method-name\"</code>).</p> <p>If a plugin should only be used when explicitly named (e.g., <code>\"plugin-name/method-name\"</code>), it must override this class method to return <code>False</code>.</p> <p>For instance, the <code>external</code> optimizer plugin acts as a wrapper for other optimizers run in separate processes. It doesn't provide methods directly and must always be explicitly requested, so it overrides this method to return <code>False</code>.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the plugin can be discovered implicitly by method name.</p>"},{"location":"reference/realization_filter_plugins/","title":"Realization Filter Plugins","text":""},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter","title":"ropt.plugins.realization_filter","text":"<p>Provides plugin functionality for adding realization filters.</p> <p>Realization filters are used by the optimization process to determine how the results from a set of realizations should be weighted when evaluating the overall objective and constraint functions. This module allows for the extension of <code>ropt</code> with custom realization filtering strategies.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Realization filter plugins must inherit from the   <code>RealizationFilterPlugin</code>   base class. This class acts as a factory, defining a <code>create</code> method to   instantiate filter objects.</li> <li>Filter Implementation: The actual filtering logic resides in classes that   inherit from the   <code>RealizationFilter</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>) and the index of the   specific filter configuration to use (<code>filter_index</code>). The core functionality   is provided by the <code>get_realization_weights</code> method, which calculates and   returns weights for each realization based on their objective and constraint   values.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>RealizationFilterPlugin</code> implementations (typically via entry   points) and uses them to create <code>RealizationFilter</code> instances as needed during   plan execution.</li> </ul> <p>Built-in Realization Filter Plugins:</p> <p>The default <code>DefaultRealizationFilter</code> class provides several filtering methods, including sorting by objective/constraint values and Conditional Value-at-Risk (CVaR) based weighting.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin","title":"ropt.plugins.realization_filter.base.RealizationFilterPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Realization Filter Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>RealizationFilter</code> instances. These plugins act as factories for specific realization filtering strategies.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate realization filter plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>RealizationFilter</code> object that will calculate the realization weights.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig, filter_index: int\n) -&gt; RealizationFilter\n</code></pre> <p>Factory method to create a concrete RealizationFilter instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>RealizationFilter</code> objects. Plugin implementations must override this method to return an instance of their specific <code>RealizationFilter</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires realization weights calculated by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The main EnOpt configuration object.</p> required <code>filter_index</code> <code>int</code> <p>Index into <code>enopt_config.realization_filters</code> for           this filter.</p> required <p>Returns:</p> Type Description <code>RealizationFilter</code> <p>An initialized RealizationFilter object ready for use.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter","title":"ropt.plugins.realization_filter.base.RealizationFilter","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for realization filter classes.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig, filter_index: int\n) -&gt; None\n</code></pre> <p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>filter_index</code> <code>int</code> <p>The index of the filter to use.</p> required"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter.get_realization_weights","title":"get_realization_weights  <code>abstractmethod</code>","text":"<pre><code>get_realization_weights(\n    objectives: NDArray[float64],\n    constraints: NDArray[float64] | None,\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Return the updated weights of the realizations.</p> <p>This method is called by the optimizer with the current values of the objectives and constraints. Based on these values it must decide how much weight each realization should be given, and return those as a vector.</p> <p>The objectives and the constraints are passed as matrices, where the columns contain the values of the objectives or constraints. The index along the row axis corresponds to the number of the realization.</p> Normalization <p>The weights will be normalized to a sum of one by the optimizer before use, hence any non-negative weight value is permissable.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objectives of all realizations.</p> required <code>constraints</code> <code>NDArray[float64] | None</code> <p>The constraints for all realizations.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A vector of weights of the realizations.</p>"},{"location":"reference/results/","title":"Optimization Results","text":""},{"location":"reference/results/#ropt.results","title":"ropt.results","text":"<p>Data classes for storing intermediate optimization results.</p> <p>During the optimization process, the calculation of functions and gradients generates data that needs to be reported. To facilitate this, new results are passed to callbacks as a sequence of <code>Results</code> objects. These objects can be instances of either the <code>FunctionResults</code> or <code>GradientResults</code> classes, which store the results of function and gradient evaluations, respectively.</p> <p>Much of the data within these result objects is multi-dimensional. For example, the <code>objectives</code> field, which is part of the nested <code>evaluations</code> object within <code>FunctionResults</code>, is a two-dimensional <code>numpy</code> array. In this array, each column represents a different objective, and each row corresponds to a specific realization number.</p> <p>To simplify exporting and reporting, the identity of the axes in these multi-dimensional arrays is stored as metadata associated with each field. These fields are derived from the <code>ResultField</code> class, which provides a <code>get_axes</code> class method for retrieving the axes. For instance, for the <code>objectives</code> field, this method would return:</p> <p><pre><code>&gt;&gt;&gt; from ropt.results import FunctionEvaluations\n&gt;&gt;&gt; FunctionEvaluations.get_axes(\"objectives\")\n(&lt;AxisName.REALIZATION: 'realization'&gt;, &lt;AxisName.OBJECTIVE: 'objective'&gt;)\n</code></pre> Given that the first axis denotes realizations and the second axis denotes objectives, each row in the array represents the set of objective values for a specific realization. This metadata provides the necessary context for exporting and reporting code to associate each element in the result matrix with its corresponding realization and objective, as specified in the optimizer configuration. The pandas exporting code, for example, utilizes this information to construct a multi-index for the output DataFrame and to transform the multi-dimensional data into multiple columns.</p> <p>The <code>AxisName</code> enumeration currently defines the following axes:</p> <ul> <li><code>AxisName.OBJECTIVE</code> The index along this   axis refers to the objective number as specified in the   <code>EnOptConfig</code> configuration.</li> <li><code>AxisName.NONLINEAR_CONSTRAINT</code>   The index along this axis corresponds to the non-linear constraint index   defined in the <code>EnOptConfig</code> configuration.</li> <li><code>AxisName.LINEAR_CONSTRAINT</code> The   index along this axis corresponds to the linear constraint index defined in   the <code>EnOptConfig</code> configuration.</li> <li><code>AxisName.VARIABLE</code> The index along this axis   refers to the variable number as specified by the   <code>EnOptConfig</code> configuration.</li> <li><code>AxisName.REALIZATION</code>: When results   involve an ensemble, this axis represents the different realizations, where   the index corresponds to the realization number.</li> <li><code>AxisName.PERTURBATION</code> For gradient   calculations, multiple variable perturbations are used. The objectives and   constraints calculated for each perturbation are reported along this axis,   which represents the perturbation index.</li> </ul> <p>Refer to the documentation of the individual result classes for the exact dimensions of each result field. The dimensionality of the data and the order of the axes are fixed and listed sequentially for every field.</p> Note <p>The dimensionality associated with a result axis is fixed. For instance, even with only a single objective, results containing objective values will still include a <code>AxisName.OBJECTIVE</code> axis of length one.</p>"},{"location":"reference/results/#ropt.results.Results","title":"ropt.results.Results  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for storing optimization results.</p> <p>The <code>Results</code> class serves as a foundation for storing various types of optimization results. It is not intended to be instantiated directly but rather serves as a base for derived classes like <code>FunctionResults</code> and <code>GradientResults</code>, which hold the actual data.</p> <p>This class provides storage for the following generic information:</p> <ul> <li>Batch ID: An optional identifier, potentially generated by the     function evaluator, that uniquely identifies a group of function     evaluations passed to the evaluator by teh optimizer.</li> <li>Metadata: A dictionary for storing additional information generated     during optimization. This metadata can include various primitive values     that are not directly interpreted by the optimization code but are     useful for reporting and analysis.</li> <li>Names: The optional <code>names</code> attribute is a dictionary that stores     the names of the various entities, such as variables, objectives, and     constraints. The supported name types are defined in the     <code>AxisName</code> enumeration. This information is     optional, as it is not strictly necessary for the optimization, but it     can be useful for labeling and interpreting results. For instance, when     present, it is used to create a multi-index results that are exported as     data frames.</li> </ul> <p>The derived classes, <code>FunctionResults</code> and <code>GradientResults</code>, extend this base class with specific attributes for storing function evaluation results and gradient evaluation results, respectively. These derived classes also provide methods for exporting the stored data.</p> <p>One key method provided by the <code>Results</code> class is <code>to_dataframe</code>, which allows exporting the contents of a specific field, or a subset of its sub-fields, to a <code>pandas</code> DataFrame for further data analysis and reporting.</p> <p>Attributes:</p> Name Type Description <code>batch_id</code> <code>int | None</code> <p>The ID of the evaluation batch.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>A dictionary of metadata.</p> <code>names</code> <code>dict[str, tuple[str | int, ...]]</code> <p>Optional names of the various result axes.</p>"},{"location":"reference/results/#ropt.results.Results.transform_from_optimizer","title":"transform_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>transform_from_optimizer(\n    transforms: OptModelTransforms,\n) -&gt; Results\n</code></pre> <p>Transform results from the optimizer domain to the user domain.</p> <p>During optimization, variables, objectives, and constraints are often transformed to a different domain (the optimizer domain) to enhance the performance and stability of the optimization algorithm. The <code>Results</code> objects produced during optimization are initially in the optimizer domain. This method reverses these transformations, mapping the results back to the user-defined domain. The transformations between the user and optimizer domains are defined by the classes in the <code>ropt.transforms</code> module.</p> <p>For instance, variables might have been scaled and shifted to a range more suitable for the optimizer. This method, using the provided <code>OptModelTransforms</code> object, applies the inverse scaling and shifting to restore the variables to their original scale and offset. Similarly, objectives and constraints are transformed back to the user domain.</p> <p>These transformations are defined and managed by the <code>OptModelTransforms</code> object, which encapsulates the specific transformations for variables, objectives, and nonlinear constraints.</p> <p>Parameters:</p> Name Type Description Default <code>transforms</code> <code>OptModelTransforms</code> <p>The transforms to apply.</p> required <p>Returns:</p> Type Description <code>Results</code> <p>A new <code>FunctionResults</code> object with all relevant data transformed</p> <code>Results</code> <p>back to the user domain.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe(\n    field_name: str,\n    select: Iterable[str],\n    unstack: Iterable[AxisName] | None = None,\n) -&gt; pd.DataFrame\n</code></pre> <p>Export a field to a pandas DataFrame.</p> <p>Exports the values of a single field to a <code>pandas</code> DataFrame. The field to export is selected by the <code>field_name</code> argument. Typically, such a field contains multiple sub-fields. By default, all sub-fields are exported as columns in the DataFrame, but a subset can be selected using the <code>select</code> argument.</p> <p>Sub-fields may be multi-dimensional arrays, which are exported in a stacked manner. Using the axis types found in the metadata, the exporter constructs a multi-index labeled with the corresponding names provided via the <code>names</code> field. If <code>names</code> does not contain a key/value pair for the the axis, numerical indices are used. These multi-indices can optionally be unstacked into multiple columns by providing the axis types to unstack via the <code>unstack</code> argument.</p> The DataFrame Index <p>The index of the resulting DataFrame may be a multi-index constructed from axis indices or labels. In addition, the <code>batch_id</code> (if not <code>None</code>) is prepended to the index.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field to export.</p> required <code>select</code> <code>Iterable[str]</code> <p>Select the sub-fields to export. By default, all         sub-fields are exported.</p> required <code>unstack</code> <code>Iterable[AxisName] | None</code> <p>Select axes to unstack. By default, no axes are         unstacked.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>pandas</code> module is not installed.</p> <code>ValueError</code> <p>If the field name is incorrect.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas</code> DataFrame containing the results.</p> Warning <p>This function requires the <code>pandas</code> module to be installed.</p>"},{"location":"reference/results/#ropt.results.ResultField","title":"ropt.results.ResultField  <code>dataclass</code>","text":"<p>Base class for fields within <code>Results</code> objects.</p> <p>The <code>ResultField</code> class serves as a foundation for defining the various data fields that can be stored within <code>Results</code> objects. These fields typically hold multi-dimensional numerical data, such as objective values, constraint values, or gradients.</p> <p>This class provides a standardized way to:</p> <ul> <li>Store metadata about the axes of multi-dimensional arrays.</li> <li>Retrieve the axes associated with a specific field.</li> </ul> <p>Derived classes, such as <code>FunctionEvaluations</code> or <code>Gradients</code>, extend this base class to define specific data structures for different types of optimization results.</p>"},{"location":"reference/results/#ropt.results.ResultField.get_axes","title":"get_axes  <code>classmethod</code>","text":"<pre><code>get_axes(name: str) -&gt; tuple[AxisName, ...]\n</code></pre> <p>Retrieve the axes associated with a specific field.</p> <p>Fields within a <code>ResultField</code> object that store multi-dimensional <code>numpy</code> arrays, contain metadata that describes the meaning of each dimension in the array. This method retrieves the axes of a field within a ResultField object from that meta-data, returning a tuple of <code>AxisName</code>][ropt.enums.AxisName] enums.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the field (sub-field) within the   <code>ResultField</code> instance or class.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided field name is not recognized.</p> <p>Returns:</p> Type Description <code>tuple[AxisName, ...]</code> <p>A tuple of <code>AxisName</code> enums, representing the axes of the field.</p>"},{"location":"reference/results/#ropt.results.FunctionResults","title":"ropt.results.FunctionResults  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>Stores results related to function evaluations.</p> <p>The <code>FunctionResults</code> class extends the base <code>Results</code> class to store data specific to function evaluations. This includes:</p> <ol> <li> <p>Evaluations: The results of the function evaluations, including the    variable values, objective values, and constraint values for each    realization. See    <code>FunctionEvaluations</code>.</p> </li> <li> <p>Realizations: Information about the realizations, such as weights for    objectives and constraints, and whether each realization was successful.    See <code>Realizations</code>.</p> </li> <li> <p>Functions: The calculated objective and constraint function values,    typically aggregated across realizations. See    <code>Functions</code>.</p> </li> <li> <p>Constraint Info: Details about constraint differences and violations.    See <code>ConstraintInfo</code>.</p> </li> </ol> <p>Attributes:</p> Name Type Description <code>evaluations</code> <code>FunctionEvaluations</code> <p>Results of the function evaluations.</p> <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations.</p> <code>functions</code> <code>Functions | None</code> <p>The calculated functions.</p> <code>constraint_info</code> <code>ConstraintInfo | None</code> <p>Information on constraint differences and violations.</p>"},{"location":"reference/results/#ropt.results.GradientResults","title":"ropt.results.GradientResults  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>Stores results related to gradient evaluations.</p> <p>The <code>GradientResults</code> class extends the base <code>Results</code> class to store data specific to gradient evaluations. This includes:</p> <ol> <li> <p>Evaluations: The results of the function evaluations for perturbed    variables, including the perturbed variable values, objective values, and    constraint values for each realization and perturbation. See    <code>GradientEvaluations</code>.</p> </li> <li> <p>Realizations: Information about the realizations, such as weights for    objectives and constraints, and whether each realization was successful.    See <code>Realizations</code>.</p> </li> <li> <p>Gradients: The calculated gradients of the objectives and constraints.    See <code>Gradients</code>.</p> </li> </ol> <p>Attributes:</p> Name Type Description <code>evaluations</code> <code>GradientEvaluations</code> <p>Results of the function evaluations for perturbed           variables.</p> <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations.</p> <code>gradients</code> <code>Gradients | None</code> <p>The calculated gradients.</p>"},{"location":"reference/results/#ropt.results.Functions","title":"ropt.results.Functions  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the calculated objective and constraint function values.</p> <p>The <code>Functions</code> class stores the calculated values of the objective and constraint functions. These values are typically derived from the evaluations performed across all realizations, often through a process like averaging. The optimizer may handle multiple objectives and constraints. Multiple objectives are combined into a single weighted sum, which is stored in the <code>weighted_objective</code> field. Multiple constraints are handled individually by the optimizer.</p> <p>Fields</p> Weighted ObjectiveObjectivesConstraints <p><code>weighted_objective</code>: The overall objective calculated as a weighted sum over the objectives. This is a single floating point values. It is defined as a <code>numpy</code> array of dimensions 0, hence it has no axes:</p> <ul> <li>Shape: \\(()\\)</li> <li>Axis type: <code>None</code></li> </ul> <p><code>objectives</code>: The calculated objective function values. This is a one-dimensional array of floating point values:</p> <ul> <li>Shape \\((n_o,)\\), where:<ul> <li>\\(n_o\\) is the number of objectives.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.OBJECTIVE</code></li> </ul> </li> </ul> <p><code>constraints</code>: The calculated constraint function values. This is a one-dimensional array of floating point values:</p> <ul> <li>Shape \\((n_c,)\\), where:<ul> <li>\\(n_c\\) is the number of constraints.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.NONLINEAR_CONSTRAINT</code></li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective values.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each individual objective.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The value of each individual constraint.</p>"},{"location":"reference/results/#ropt.results.Gradients","title":"ropt.results.Gradients  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the calculated objective and constraint gradients.</p> <p>The <code>Gradients</code> class stores the calculated gradients of the objective and constraint functions. These gradients are typically derived from function evaluations across all realizations, often through a process like averaging. The optimizer may handle multiple objectives and constraints. Multiple objective gradients are combined into a single weighted sum, which is stored in the <code>weighted_objective</code> field. Multiple constraint gradients are handled individually by the optimizer.</p> <p>Fields</p> Weighted Objective GradientObjective  GradientsConstraint Gradients <p><code>weighted_objective</code>: The gradient of the weighted objective with respect to each variable:</p> <ul> <li>Shape: \\((n_v,)\\), where:<ul> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <p><code>objectives</code>: The calculated gradients of each objective with respect to each variable. This is a two-dimensional array of floating point values:</p> <ul> <li>Shape \\((n_o, n_v)\\), where:<ul> <li>\\(n_o\\) is the number of objectives.</li> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.OBJECTIVE</code></li> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <p><code>constraints</code>: The calculated gradients of each nonlinear constraint with respect to each variable. This is a two-dimensional array of floating point values:</p> <ul> <li>Shape \\((n_c, n_v)\\), where:<ul> <li>\\(n_c\\) is the number of constraints.</li> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.NONLINEAR_CONSTRAINT</code></li> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective gradients.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The gradient of each individual objective.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The gradient of each individual constraint.</p>"},{"location":"reference/results/#ropt.results.FunctionEvaluations","title":"ropt.results.FunctionEvaluations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the results of function evaluations.</p> <p>The <code>FunctionEvaluations</code> class stores the results of evaluating the objective and constraint functions for a set of variables.</p> <p>Fields</p> VariablesObjectivesConstraintsEvaluation Info <p><code>variables</code>: The vector of variable values at which the functions were evaluated:</p> <ul> <li>Shape: \\((n_v,)\\), where:<ul> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <p><code>objectives</code>: The calculated objective function values for each realization. This is a two-dimensional array of floating point values where each row corresponds to a realization and each column corresponds to an objective:</p> <ul> <li>Shape \\((n_r, n_o)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> <li>\\(n_o\\) is the number of objectives.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.REALIZATION</code></li> <li><code>AxisName.OBJECTIVE</code></li> </ul> </li> </ul> <p><code>constraints</code>: The calculated constraint function values for each realization. Only provided if non-linear constraints are defined. This is a two-dimensional array of floating point values where each row corresponds to a realization and each column corresponds to a constraint:</p> <ul> <li>Shape \\((n_r, n_c)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> <li>\\(n_c\\) is the number of constraints.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.REALIZATION</code></li> <li><code>AxisName.NONLINEAR_CONSTRAINT</code></li> </ul> </li> </ul> <p><code>evaluation_info</code>: Optional metadata associated with each realization, potentially provided by the evaluator. If provided, each value in the info dictionary must be a one-dimensional array of arbitrary type supported by <code>numpy</code> (including objects):</p> <ul> <li>Shape: \\((n_r,)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.REALIZATION</code></li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>variables</code> <code>NDArray[float64]</code> <p>The variable vector:</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The objective function values for each realization.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The constraint function values for each realization.</p> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional metadata for each evaluated realization.</p>"},{"location":"reference/results/#ropt.results.GradientEvaluations","title":"ropt.results.GradientEvaluations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the results of evaluations for gradient calculations.</p> <p>The <code>GradientEvaluations</code> class stores the results of evaluating the objective and constraint functions for perturbed variables, which is necessary for gradient calculations.</p> <p>Fields</p> VariablesPerturbed VariablesPerturbed ObjectivesPerturbed ConstraintsEvaluation Info <p><code>variables</code>: The vector of unperturbed variable values:</p> <ul> <li>Shape: \\((n_v,)\\), where:<ul> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <p><code>perturbed_variables</code>: A three-dimensional array of perturbed variable values for each realization and perturbation:</p> <ul> <li>Shape: \\((n_r, n_p, n_v)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> <li>\\(n_p\\) is the number of perturbations.</li> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.REALIZATION</code></li> <li><code>AxisName.PERTURBATION</code></li> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <p><code>perturbed_objectives</code>: A three-dimensional array of perturbed calculated objective function values for each realization and perturbation:</p> <ul> <li>Shape \\((n_r, n_p, n_o)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> <li>\\(n_p\\) is the number of perturbations.</li> <li>\\(n_o\\) is the number of objectives.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.REALIZATION</code></li> <li><code>AxisName.PERTURBATION</code></li> <li><code>AxisName.OBJECTIVE</code></li> </ul> </li> </ul> <p><code>perturbed_constraints</code>: A three-dimensional array of perturbed calculated non-linear constraint values for each realization and perturbation:</p> <ul> <li>Shape \\((n_r, n_p, n_c)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> <li>\\(n_p\\) is the number of perturbations.</li> <li>\\(n_c\\) is the number of constraints.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.REALIZATION</code></li> <li><code>AxisName.PERTURBATION</code></li> <li><code>AxisName.NONLINEAR_CONSTRAINT</code></li> </ul> </li> </ul> <p><code>evaluation_info</code>: Optional metadata associated with each realization, potentially provided by the evaluator. If provided, each value in the info dictionary must be a two-dimensional array of arbitrary type supported by <code>numpy</code> (including objects):</p> <ul> <li>Shape: \\((n_r, n_p)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> <li>\\(n_p\\) is the number of perturbations.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.REALIZATION</code></li> <li><code>AxisName.PERTURBATION</code></li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> <code>perturbed_variables</code> <code>NDArray[float64]</code> <p>The perturbed variable values for each                    realization and perturbation.</p> <code>perturbed_objectives</code> <code>NDArray[float64]</code> <p>The objective function values for each                    realization and perturbation.</p> <code>perturbed_constraints</code> <code>NDArray[float64] | None</code> <p>The constraint function values for each                    realization and perturbation.</p> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional metadata for each evaluated                    realization and perturbation.</p>"},{"location":"reference/results/#ropt.results.Realizations","title":"ropt.results.Realizations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores information about the realizations.</p> <p>The <code>Realizations</code> class stores data related to the individual realizations used in the optimization process.</p> <p>Fields</p> Active RealizationsFailed RealizationsObjective WeightsConstraint Weights <p><code>active_realizations</code>: A boolean array indicating whether each realization's evaluation was evaluated. <code>True</code> indicates that a realization was evaluated:</p> <ul> <li>Shape \\((n_r,)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.REALIZATION</code></li> </ul> </li> </ul> <p><code>failed_realizations</code>: A boolean array indicating whether each realization's evaluation was successful. <code>True</code> indicates a failed realization, while <code>False</code> indicates a successful one:</p> <ul> <li>Shape \\((n_r,)\\), where:<ul> <li>\\(n_r\\) is the number of realizations.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.REALIZATION</code></li> </ul> </li> </ul> <p><code>objective_weights</code>: A two-dimensional array of weights used for each objective in each realization:</p> <ul> <li>Shape \\((n_o, n_r)\\), where:<ul> <li>\\(n_o\\) is the number of objectives.</li> <li>\\(n_r\\) is the number of realizations.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.OBJECTIVE</code></li> <li><code>AxisName.REALIZATION</code></li> </ul> </li> </ul> <p>These weights may change during optimization, depending on the type of objective calculation</p> <p><code>constraint_weights</code>: A two-dimensional array of weights used for each constraint in each realization:</p> <ul> <li>Shape \\((n_c, n_r)\\), where:<ul> <li>\\(n_c\\) is the number of constraints.</li> <li>\\(n_r\\) is the number of realizations.</li> </ul> </li> <li>Axis types:<ul> <li><code>AxisName.NONLINEAR_CONSTRAINT</code></li> <li><code>AxisName.REALIZATION</code></li> </ul> </li> </ul> <p>These weights may change during optimization, depending on the type of constraint calculation</p> <p>Attributes:</p> Name Type Description <code>active_realizations</code> <code>NDArray[bool_]</code> <p>Boolean array indicating active realizations.</p> <code>failed_realizations</code> <code>NDArray[bool_]</code> <p>Boolean array indicating failed realizations.</p> <code>objective_weights</code> <code>NDArray[float64] | None</code> <p>Weights for each objective in each realization.</p> <code>constraint_weights</code> <code>NDArray[float64] | None</code> <p>Weights for each constraint in each realization.</p>"},{"location":"reference/results/#ropt.results.ConstraintInfo","title":"ropt.results.ConstraintInfo  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores information about constraint differences and violations.</p> <p>The <code>ConstraintInfo</code> class stores the differences between variable or constraint values and their respective bounds. It also calculates and stores constraint violations. This information is useful for assessing how well the optimization process is satisfying the imposed constraints.</p> <p>Constraint differences</p> <p>These represent the difference between a variable or constraint value and its corresponding bound. Whether this difference signifies a violation depends on the bound type:</p> <ul> <li>Lower Bounds: A negative difference means the value is below the lower   bound, thus violating the constraint.</li> <li>Upper Bounds: A positive difference means the value is above the upper   bound, thus violating the constraint.</li> </ul> <p>The class stores the following information on the differences:</p> <p>Constraint Violations</p> <p>Constraint violations are calculated based on the constraint differences. If a bound is violated, the violation value is the absolute value of the difference. If the bound is not violated, the violation value is zero.</p> <p>Fields</p> <p>The class stores the following information for bound, linear constraint, and non-linear constraint differences and violations as one-dimensional vectors:</p> Bound ConstraintsLinear ConstraintsNonlinear Constraints <ul> <li>Differences: <code>bound_lower</code> and <code>bound_upper</code></li> <li>Violations: <code>bound_violation</code></li> <li>Shape: \\((n_v,)\\), where:<ul> <li>\\(n_v\\) is the number of variables.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.VARIABLE</code></li> </ul> </li> </ul> <ul> <li>Differences: <code>linear_lower</code> and <code>linear_upper</code></li> <li>Violations: <code>linear_violation</code></li> <li>Shape: \\((n_l,)\\), where:<ul> <li>\\(n_l\\) is the number of linear constraints.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.LINEAR_CONSTRAINT</code></li> </ul> </li> </ul> <ul> <li>Differences: <code>nonlinear_lower</code> and <code>nonlinear_upper</code></li> <li>Violations: <code>nonlinear_violation</code></li> <li>Shape: \\((n_c,)\\), where:<ul> <li>\\(n_c\\) is the number of non-linear constraints.</li> </ul> </li> <li>Axis type:<ul> <li><code>AxisName.NONLINEAR_CONSTRAINT</code></li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>bound_lower</code> <code>NDArray[float64] | None</code> <p>Difference between variables and their lower bounds.</p> <code>bound_upper</code> <code>NDArray[float64] | None</code> <p>Difference between variables and their upper bounds.</p> <code>linear_lower</code> <code>NDArray[float64] | None</code> <p>Difference between linear constraints and their lower                 bounds.</p> <code>linear_upper</code> <code>NDArray[float64] | None</code> <p>Difference between linear constraints and their upper                 bounds.</p> <code>nonlinear_lower</code> <code>NDArray[float64] | None</code> <p>Difference between nonlinear constraints and their                 lower bounds.</p> <code>nonlinear_upper</code> <code>NDArray[float64] | None</code> <p>Difference between nonlinear constraints and their                 upper bounds.</p> <code>bound_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the variable bounds.</p> <code>linear_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the linear constraints.</p> <code>nonlinear_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the nonlinear constraints.</p>"},{"location":"reference/results/#ropt.results.results_to_dataframe","title":"ropt.results.results_to_dataframe","text":"<pre><code>results_to_dataframe(\n    results: Sequence[Results],\n    fields: set[str],\n    result_type: Literal[\"functions\", \"gradients\"],\n) -&gt; pd.DataFrame\n</code></pre> <p>Combine a sequence of results into a single pandas DataFrame.</p> <p>This function aggregates results from multiple <code>FunctionResults</code> or <code>GradientResults</code> objects into a single <code>pandas</code> DataFrame. It is designed to be used with observers that produce results during the optimization process.</p> <p>The <code>fields</code> argument determines which data fields to include in the DataFrame. These fields can be any of the attributes defined within <code>FunctionResults</code> or <code>GradientResults</code>. Nested fields are specified using dot notation (e.g., <code>evaluations.variables</code> to include the <code>variables</code> field within the <code>evaluations</code> object).</p> <p>The <code>evaluation_info</code> sub-fields, found within the <code>evaluations</code> fields of <code>functions</code> and <code>gradient</code> results, respectively, are dictionaries. To include specific keys from these dictionaries, use the format <code>evaluations.evaluation_info.key</code>, where <code>key</code> is the name of the desired key.</p> <p>Many fields may result in multiple columns in the DataFrame. For example, <code>evaluations.variables</code> will generate a separate column for each variable. If available, variable names will be used as column labels. Multi-dimensional fields, such as those with named realizations and objectives, will have column names that are tuples of the corresponding names.</p> <p>The <code>result_type</code> argument specifies whether to include function evaluation results (<code>functions</code>) or gradient results (<code>gradients</code>).</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Sequence[Results]</code> <p>A sequence of <code>Results</code> objects          to combine.</p> required <code>fields</code> <code>set[str]</code> <p>The names of the fields to include in the DataFrame.</p> required <code>result_type</code> <code>Literal['functions', 'gradients']</code> <p>The type of results to include (\"functions\" or          \"gradients\").</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas</code> DataFrame containing the combined results.</p>"},{"location":"reference/sampler_plugins/","title":"Sampler Plugins","text":""},{"location":"reference/sampler_plugins/#ropt.plugins.sampler","title":"ropt.plugins.sampler","text":"<p>Provides plugin functionality for adding sampler plugins.</p> <p>Samplers are used by the optimization process to generate perturbed variable vectors. This module allows for the extension of <code>ropt</code> with custom samplers.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Sampler plugins must inherit from the   <code>SamplerPlugin</code> base class.   This class acts as a factory, defining a <code>create</code> method to instantiate   sampler objects.</li> <li>Sampler Implementation: The actual sampling logic resides in classes that   inherit from the <code>Sampler</code> abstract base   class. These classes are initialized with the optimization configuration   (<code>EnOptConfig</code>), the index of the specific sampler   configuration to use (<code>sampler_index</code>), an optional variable mask (<code>mask</code>),   and a random number generator (<code>rng</code>). Samples are generated by calling the   sampler's <code>generate_samples</code> method.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>SamplerPlugin</code> implementations (typically via entry points) and   uses them to create <code>Sampler</code> instances as needed during plan execution.</li> </ul> <p>Built-in Sampler Plugins:</p> <p>By default, the <code>SciPySampler</code> sampler is installed, which provides several sampling methods based on the <code>scipy.stats</code> and <code>scipy.stats.qmc</code> packages.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin","title":"ropt.plugins.sampler.base.SamplerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Sampler Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>Sampler</code> instances. These plugins act as factories for specific sampling algorithms or strategies.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate sampler plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>Sampler</code> object that will generate the perturbation samples.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig,\n    sampler_index: int,\n    mask: NDArray[bool_] | None,\n    rng: Generator,\n) -&gt; Sampler\n</code></pre> <p>Factory method to create a concrete Sampler instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>Sampler</code> objects. Plugin implementations must override this method to return an instance of their specific <code>Sampler</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires samples generated by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The main EnOpt configuration object.</p> required <code>sampler_index</code> <code>int</code> <p>Index into <code>enopt_config.samplers</code> for this sampler.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>Optional boolean mask for variable subset sampling.</p> required <code>rng</code> <code>Generator</code> <p>NumPy random number generator instance.</p> required <p>Returns:</p> Type Description <code>Sampler</code> <p>An initialized Sampler object ready for use.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler","title":"ropt.plugins.sampler.base.Sampler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Sampler Implementations.</p> <p>This class defines the fundamental interface for all concrete sampler implementations within the <code>ropt</code> framework. Sampler plugins provide classes derived from <code>Sampler</code> that encapsulate the logic of specific sampling algorithms or strategies used to generate perturbed variable vectors for the optimization process.</p> <p>Instances of <code>Sampler</code> subclasses are created by their corresponding <code>SamplerPlugin</code> factories. They are initialized with an <code>EnOptConfig</code> object detailing the optimization setup, the <code>sampler_index</code> identifying the specific sampler configuration to use from the config, an optional variable <code>mask</code> indicating which variables this sampler instance handles, and a NumPy random number generator (<code>rng</code>) for stochastic methods.</p> <p>The core functionality, generating samples, is performed by the <code>generate_samples</code> method, which must be implemented by subclasses.</p> <p>Subclasses must implement:</p> <ul> <li><code>__init__</code>: To accept the configuration, index, mask, and RNG.</li> <li><code>generate_samples</code>: To contain the sample generation logic.</li> </ul>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig,\n    sampler_index: int,\n    mask: NDArray[bool_] | None,\n    rng: Generator,\n) -&gt; None\n</code></pre> <p>Initialize the sampler object.</p> <p>The <code>samplers</code> field in the <code>enopt_config</code> is a tuple of sampler configurations (<code>SamplerConfig</code>). The <code>sampler_index</code> identifies which configuration from this tuple should be used to initialize this specific sampler instance.</p> <p>If a boolean <code>mask</code> array is provided, it indicates that this sampler instance is responsible for generating samples only for the subset of variables where the mask is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler configuration to use.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>Optional mask indicating variables handled by this sampler.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for stochastic methods.</p> required"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler.generate_samples","title":"generate_samples  <code>abstractmethod</code>","text":"<pre><code>generate_samples() -&gt; NDArray[np.float64]\n</code></pre> <p>Generate and return an array of sampled perturbation values.</p> <p>This method must return a three-dimensional NumPy array containing the generated perturbation samples. The shape of the array should be <code>(n_realizations, n_perturbations, n_variables)</code>, where:</p> <ul> <li><code>n_realizations</code> is the number of realizations in the ensemble.</li> <li><code>n_perturbations</code> is the number of perturbations requested.</li> <li><code>n_variables</code> is the total number of optimization variables.</li> </ul> <p>If the <code>shared</code> flag is <code>True</code> in the associated <code>SamplerConfig</code>, the first dimension (realizations) should have a size of 1. The framework will broadcast these shared samples across all realizations.</p> <p>If a boolean <code>mask</code> was provided during initialization, this sampler instance is responsible only for a subset of variables (where the mask is <code>True</code>). The returned array must still have the full <code>n_variables</code> size along the last axis. However, values corresponding to variables not handled by this sampler (where the mask is <code>False</code>) must be zero.</p> Sample Scaling and Perturbation Magnitudes <p>The generated samples represent unscaled perturbations. During the gradient estimation process, these samples will be multiplied element-wise by the <code>perturbation_magnitudes</code> defined in the <code>GradientConfig</code>.</p> <p>Therefore, it is generally recommended that sampler implementations produce samples with a characteristic scale of approximately one (e.g., drawn from a distribution with a standard deviation of 1, or uniformly distributed within <code>[-1, 1]</code>). This allows the <code>perturbation_magnitudes</code> to directly control the effective size of the perturbations applied to the variables.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A 3D NumPy array of sampled perturbation values.</p>"},{"location":"reference/scipy_optimizer_plugin/","title":"SciPy Optimizer Plugin","text":""},{"location":"reference/scipy_optimizer_plugin/#ropt.plugins.optimizer.scipy.SciPyOptimizer","title":"ropt.plugins.optimizer.scipy.SciPyOptimizer","text":"<p>               Bases: <code>Optimizer</code></p> <p>SciPy optimization backend for ropt.</p> <p>This class provides an interface to several optimization algorithms from SciPy's <code>scipy.optimize</code> module, enabling their use within <code>ropt</code>.</p> <p>To select an optimizer, set the <code>method</code> field within the <code>optimizer</code> section of the <code>EnOptConfig</code> configuration object to the desired algorithm's name. Most methods support the general options defined in the <code>EnOptConfig</code> object. For algorithm-specific options, use the <code>options</code> dictionary within the <code>optimizer</code> section.</p> <p>The table below lists the included methods together with the method-specific options that are supported. Click on the method name to consult the corresponding <code>scipy.optimize</code> documentation:</p> Method Method Options Nelder-Mead disp, maxiter, maxfev, xatol, fatol, adaptive Powell disp, maxiter, maxfev, xtol, ftol CG disp, maxiter, gtol, norm, eps, finite_diff_rel_step, c1, c2 BFGS disp, maxiter, gtol, norm, eps, finite_diff_rel_step, xrtol, c1, c2 Newton-CG disp, maxiter, xtol, eps, c1, c2 L-BFGS-B disp, maxiter, maxcor, ftol, gtol, eps, maxfun, iprint, maxls, finite_diff_rel_step TNC disp, maxfun, eps, scale, offset, maxCGit, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, finite_diff_rel_step COBYLA disp, maxiter, rhobeg, tol, catol SLSQP disp, maxiter, ftol, eps, finite_diff_rel_step differential_evolution disp, maxiter, strategy, popsize, tol, mutation, recombination, rng, polish, init, atol, updating"},{"location":"reference/scipy_sampler_plugin/","title":"SciPy Sampler Plugin","text":""},{"location":"reference/scipy_sampler_plugin/#ropt.plugins.sampler.scipy.SciPySampler","title":"ropt.plugins.sampler.scipy.SciPySampler","text":"<p>               Bases: <code>Sampler</code></p> <p>A sampler implementation utilizing SciPy's statistical functions.</p> <p>This sampler leverages functions from the <code>scipy.stats</code> and <code>scipy.stats.qmc</code> modules to generate perturbation samples for optimization.</p> <p>Supported Sampling Methods:</p> <ul> <li> <p>From Probability Distributions   (<code>scipy.stats</code>):</p> <ul> <li><code>norm</code>: Samples from a standard normal distribution (mean 0,   standard deviation 1). This is the default method if none is   specified or if \"default\" is requested.</li> <li><code>truncnorm</code>: Samples from a truncated normal distribution (mean 0,   std dev 1), truncated to the range <code>[-1, 1]</code> by default.</li> <li><code>uniform</code>: Samples from a uniform distribution. Defaults to the   range <code>[-1, 1]</code>.</li> </ul> </li> <li> <p>From Quasi-Monte Carlo Sequences   (<code>scipy.stats.qmc</code>):</p> <ul> <li><code>sobol</code>: Uses Sobol' sequences.</li> <li><code>halton</code>: Uses Halton sequences.</li> <li><code>lhs</code>: Uses Latin Hypercube Sampling. (Note: QMC samples are generated in the unit hypercube <code>[0, 1]^d</code> and then scaled to the hypercube <code>[-1, 1]^d</code>)</li> </ul> </li> </ul> <p>Configuration:</p> <p>The specific sampling method is chosen via the <code>method</code> field in the <code>SamplerConfig</code>. Additional method-specific parameters (e.g., distribution parameters like <code>loc</code>, <code>scale</code>, <code>a</code>, <code>b</code> for <code>stats</code> methods, or engine parameters for <code>qmc</code> methods) can be passed through the <code>options</code> dictionary within the <code>SamplerConfig</code>. Refer to the <code>scipy.stats</code> and documentation for available options.</p>"},{"location":"reference/utilities/","title":"Utilities","text":""},{"location":"reference/utilities/#ropt.config.utils","title":"ropt.config.utils","text":"<p>Utilities for checking and converting configuration values.</p> <p>This module provides helper functions primarily designed for use within Pydantic model validation logic. These functions facilitate the conversion of configuration inputs into standardized, immutable NumPy arrays and handle common validation tasks like checking enum values or broadcasting arrays to required dimensions.</p>"},{"location":"reference/utilities/#ropt.config.utils.normalize","title":"normalize","text":"<pre><code>normalize(array: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Normalize a NumPy array so its elements sum to one.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[float64]</code> <p>The input NumPy array (1D).</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A new immutable NumPy array with the same shape as the input, where</p> <code>NDArray[float64]</code> <p>the elements have been scaled to sum to 1.0.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the sum of the input array elements is not positive         (i.e., less than or equal to machine epsilon).</p>"},{"location":"reference/utilities/#ropt.config.utils.immutable_array","title":"immutable_array","text":"<pre><code>immutable_array(\n    array_like: ArrayLike, **kwargs: Any\n) -&gt; NDArray[Any]\n</code></pre> <p>Convert input to an immutable NumPy array.</p> <p>This function takes various array-like inputs (e.g., lists, tuples, other NumPy arrays) and converts them into a NumPy array. It then sets the <code>writeable</code> flag of the resulting array to <code>False</code>, making it immutable.</p> <p>Parameters:</p> Name Type Description Default <code>array_like</code> <code>ArrayLike</code> <p>The input data to convert (e.g., list, tuple, NumPy array).</p> required <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments passed directly to <code>numpy.array</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>A new NumPy array, with its <code>writeable</code> flag set to <code>False</code>.</p>"},{"location":"reference/utilities/#ropt.config.utils.broadcast_arrays","title":"broadcast_arrays","text":"<pre><code>broadcast_arrays(*args: Any) -&gt; tuple[NDArray[Any], ...]\n</code></pre> <p>Broadcast arrays to a common shape and make them immutable.</p> <p>This function takes multiple NumPy arrays (or array-like objects) and uses <code>numpy.broadcast_arrays</code> to make them conform to a common shape according to NumPy's broadcasting rules. Each resulting array is then made immutable by setting its <code>writeable</code> flag to <code>False</code>.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>A variable number of NumPy arrays or array-like objects.</p> <code>()</code> <p>Returns:</p> Type Description <code>tuple[NDArray[Any], ...]</code> <p>A tuple containing the broadcasted, immutable NumPy arrays.</p>"},{"location":"reference/utilities/#ropt.config.utils.broadcast_1d_array","title":"broadcast_1d_array","text":"<pre><code>broadcast_1d_array(\n    array: NDArray[Any], name: str, size: int\n) -&gt; NDArray[Any]\n</code></pre> <p>Broadcast an array to a 1D array of a specific size and make it immutable.</p> <p>This function takes an input array and attempts to broadcast it to a one-dimensional array of the specified <code>size</code> using NumPy's broadcasting rules. If successful, the resulting array is made immutable.</p> <p>This is useful for ensuring configuration parameters (like weights or magnitudes) have the correct dimension corresponding to the number of variables, objectives, etc., allowing users to provide a single scalar value that applies to all elements.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[Any]</code> <p>The input NumPy array or array-like object.</p> required <code>name</code> <code>str</code> <p>A descriptive name for the array (used in error messages).</p> required <code>size</code> <code>int</code> <p>The target size (number of elements) for the 1D array.</p> required <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>A new, immutable 1D NumPy array of the specified <code>size</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input <code>array</code> cannot be broadcast to the target <code>size</code>.</p>"},{"location":"reference/utilities/#ropt.config.utils.check_enum_values","title":"check_enum_values","text":"<pre><code>check_enum_values(\n    value: NDArray[ubyte], enum_type: type[IntEnum]\n) -&gt; None\n</code></pre> <p>Check if enum values in a NumPy array are valid members of an IntEnum.</p> <p>This function verifies that all integer values within the input NumPy array correspond to valid members of the specified <code>IntEnum</code> type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NDArray[ubyte]</code> <p>A NumPy array containing integer values (typically <code>np.ubyte</code>)        representing potential enum members.</p> required <code>enum_type</code> <code>type[IntEnum]</code> <p>The <code>IntEnum</code> class to validate against.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If any value in the <code>value</code> array does not correspond to a         member of the <code>enum_type</code>.</p>"},{"location":"reference/utilities/#ropt.config.validated_types","title":"ropt.config.validated_types","text":"<p>Annotated types for Pydantic models providing input conversion and validation.</p> <p>These types leverage Pydantic's <code>BeforeValidator</code> to automatically convert input values (like lists or scalars) into standardized, immutable NumPy arrays or Python collections (sets, tuples) during model initialization.</p> <p>NumPy Array Types:</p> <ul> <li><code>Array1D</code>: Converts input to an   immutable 1D <code>np.float64</code> array.</li> <li><code>Array2D</code>: Converts input to an   immutable 2D <code>np.float64</code> array.</li> <li><code>ArrayEnum</code>: Converts input to an   immutable 1D <code>np.ubyte</code> array (suitable for integer enum values).</li> <li><code>Array1DInt</code>: Converts input to an   immutable 1D <code>np.intc</code> array.</li> <li><code>Array1DBool</code>: Converts input to an   immutable 1D <code>np.bool_</code> array.</li> </ul> <p>Collection Types:</p> <ul> <li><code>ItemOrSet[T]</code>: Ensures the value is a   <code>set[T]</code>, converting single items or sequences.</li> <li><code>ItemOrTuple[T]</code>: Ensures the value is a   <code>tuple[T, ...]</code>, converting single items or sequences.</li> </ul>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1D","title":"Array1D  <code>module-attribute</code>","text":"<pre><code>Array1D = Annotated[\n    NDArray[float64], BeforeValidator(_convert_1d_array)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of floating point values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array2D","title":"Array2D  <code>module-attribute</code>","text":"<pre><code>Array2D = Annotated[\n    NDArray[float64], BeforeValidator(_convert_2d_array)\n]\n</code></pre> <p>Convert to an immutable 2D numpy array of floating point values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ArrayEnum","title":"ArrayEnum  <code>module-attribute</code>","text":"<pre><code>ArrayEnum = Annotated[\n    NDArray[ubyte], BeforeValidator(_convert_enum_array)\n]\n</code></pre> <p>Convert to an immutable numpy array of numerical enumeration values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1DInt","title":"Array1DInt  <code>module-attribute</code>","text":"<pre><code>Array1DInt = Annotated[\n    NDArray[intc], BeforeValidator(_convert_1d_array_intc)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of integer values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1DBool","title":"Array1DBool  <code>module-attribute</code>","text":"<pre><code>Array1DBool = Annotated[\n    NDArray[bool_], BeforeValidator(_convert_1d_array_bool)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of boolean values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ItemOrSet","title":"ItemOrSet  <code>module-attribute</code>","text":"<pre><code>ItemOrSet = Annotated[set[T], BeforeValidator(_convert_set)]\n</code></pre> <p>Convert to single value to a set containing that value, passes sets unchanged.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ItemOrTuple","title":"ItemOrTuple  <code>module-attribute</code>","text":"<pre><code>ItemOrTuple = Annotated[\n    tuple[T, ...], BeforeValidator(_convert_tuple)\n]\n</code></pre> <p>Convert to single value to a tuple containing that value, passes sets unchanged.</p>"},{"location":"usage/robust_optimization/","title":"Introduction: Ensemble-based robust optimization","text":"<p>Constraint optimization is the process of optimizing an objective function \\(f(\\mathbf{x})\\) with respect to a vector of variables \\(\\mathbf{x}\\) in the presence of one or more inequality constraints \\(g_j(\\mathbf{x})\\) and/or equality constraints \\(h_k(\\mathbf{x})\\).</p> \\[ \\begin{align*} \\textrm{minimize} \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{subject to} \\quad &amp; g_j(\\mathbf{x}) \\le 0, \\quad \\quad j=1, \\ldots, J \\\\ &amp; h_k(\\mathbf{x}) = 0, \\quad \\quad k=1, \\ldots, K \\\\ &amp; \\mathbf{x}^L \\le \\mathbf{x} \\le \\mathbf{x}^U \\end{align*} \\] <p>In this context, the function \\(f(\\mathbf{x})\\) is assumed to have a deterministic nature, meaning it is well-defined for given parameters. However, in realistic scenarios, \\(f(\\mathbf{x})\\) may be part of a larger set of functions, especially if it depends on uncertain parameters drawn from some, possibly unknown, probability distribution.</p> <p>Ensemble-based robust optimization aims to optimize an ensemble of functions \\(f_i(\\mathbf{x})\\) with respect to \\(\\mathbf{x}\\). The set of realizations \\(f_i\\) captures the uncertainty that may exist in the model, which can be, for instance, constructed by varying some parameters according to a given probability distribution. When given a set of realizations, ensemble-based optimization proceeds by combining the functions \\(f_i(\\mathbf{x})\\) into a single objective function. For example, using a weighted sum, the problem becomes (ignoring constraints):</p> \\[ \\textrm{minimize} \\quad \\sum_i w_i f_i(\\mathbf{x}), \\] <p>where \\(w_i\\) represents the weights assigned to the different realizations. In more complex settings, the realizations may also be combined in different ways, and the set of realizations may be modified during optimization. For instance, risk-aware objectives may be constructed by minimizing the standard deviation of the functions or by selecting some of the worst-performing realizations at each iteration.</p> <p>In practice, the optimization task often becomes complex due to additional factors. The evaluation of functions might be computationally expensive, and calculating their gradients analytically can be challenging or even impossible. For example, the functions may involve lengthy simulations of a physical process with numerous variables, utilizing numerical calculations that preclude straightforward analytical differentiation.</p> <p><code>ropt</code> leverages standard optimization algorithms, such as those available in the SciPy package. These methods typically follow an iterative approach, necessitating repeated assessments of the objective function and, in many cases, its gradient. Currently, it is assumed that the functions are not easily differentiated analytically. One of the core functions of <code>ropt</code> is to calculate gradients efficiently using stochastic methods.</p> <p><code>ropt</code> is responsible for configuring and executing the optimization algorithm, building the overall function and gradient values from individual realizations, and monitoring both intermediate and final optimization results. It delegates the actual calculations of functions to external code that is provided by the user.</p> <p>While many optimization scenarios involve a single run of a particular method, there are cases where it proves beneficial to conduct multiple runs using the same or different algorithms. For example, when dealing with a mix of continuous and discrete variables, it might be advantageous to employ different methods for each variable type. <code>ropt</code> facilitates this by offering a mechanism to run a workflow containing multiple optimizers, potentially of different types, in an alternating or nested fashion.</p>"}]}