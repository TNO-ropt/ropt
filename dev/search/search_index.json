{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>ropt</code>: A Python module for robust optimization","text":"<p><code>ropt</code> is a module designed for implementing and executing robust optimization workflows. In classical optimization problems, a deterministic function is optimized. However, in robust optimization, the function is expected to exhibit a stochastic nature and is represented by an ensemble of functions (realizations) for different values of some (possibly unknown) random parameters. The optimal solution is then determined by optimizing the value of a statistic, such as the mean, over the ensemble.</p> <p><code>ropt</code> can be employed to construct optimization workflows directly in Python or as a building block in optimization applications. At a minimum, the user needs to provide additional code to calculate the values for each function realization in the ensemble. This can range from simply calling a Python function that returns the objective values to initiating a long-running simulation on an HPC cluster and reading the results. Furthermore, <code>ropt</code> exposes all intermediate results of the optimization, such as objective and gradient values, but functionality to report or store any of these values must be added by the user. Optional functionality to assist with this is included with <code>ropt</code>.</p> <p><code>ropt</code> provides several features for efficiently solving complex robust optimization problems:</p> <ul> <li>Robust optimization over an ensemble of models, i.e., optimizing the average   of a set of objective functions. Alternative objectives can be implemented   using plugins, for instance, to implement risk-aware optimization, such as   Conditional Value at Risk (CVaR) or standard-deviation-based functions.</li> <li>Support for black-box optimization of arbitrary functions.</li> <li>Support for running complex optimization workflows, such as multiple runs with   different optimization settings or even different optimization methods.</li> <li>Support for nested optimization, allowing sub-sets of the variables to be   optimized by optimization workflows that run as part of the black-box function   to be optimized.</li> <li>An interface for running various continuous and discrete optimization methods.   By default, optimizers from the   <code>scipy.optimize</code>   package are included, but additional optimizers can be added via a plugin   mechanism. The most common options of these optimizers can be configured in a   uniform manner, although algorithm- or package-specific options can still be   passed.</li> <li>Efficient estimation of gradients using a Stochastic Simplex Approximate   Gradient (StoSAG) approach. Additional samplers for generating perturbed   values for gradient estimation can be added via a plugin mechanism.</li> <li>Support for linear and non-linear constraints, if supported by the chosen   optimizer.</li> <li>Flexible configuration of the optimization process using   <code>pydantic</code>.</li> <li>Support for tracking and processing optimization results generated during the   optimization process.</li> <li>Support for generating formatted tables of the results.</li> <li>Optional support for exporting results as   <code>pandas</code> data frames or   <code>xarray</code> data sets, and saving in the <code>netCDF</code> format   using the <code>netCDF4</code> module.</li> <li>Optional support for running function evaluations on distributed resources,   such as HPC clusters, via the <code>Parsl</code> library   for parallel scripting.</li> </ul>"},{"location":"reference/enopt_config/","title":"Optimizer configuration","text":""},{"location":"reference/enopt_config/#ropt.config.enopt","title":"<code>ropt.config.enopt</code>","text":"<p>The <code>ropt.config.enopt</code> module contains optimization configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.EnOptConfig","title":"<code>EnOptConfig</code>","text":"<p>               Bases: <code>_EnOptBaseModel</code></p> <p>The primary configuration class for a single optimization step.</p> <p>The fields of the <code>EnOptConfig</code> class are nested configuration classes that specify specific aspects of a single optimization run.</p> <p>Upon initialization and validation of an <code>EnOptConfig</code> object, the contents of some of these fields may be modified, depending on the content of other fields. A good example is the scaling of variables: The <code>offsets</code> and <code>scales</code> field in the <code>variables</code> field of an <code>EnOptConfig</code> object define a linear transformation of the variables. Upon initialization, values of the <code>linear_constraints</code> field will be transformed accordingly so that the constraints remain valid for the transformed variables.</p> <p>The <code>realization_filters</code>, <code>function_transforms</code>, and <code>samplers</code> fields are defined as tuples of configurations for realization filter, function transform, and sampler objects, respectively. Other configuration fields will refer to these objects by their index into these tuples. For example, the <code>gradient</code> field is implemented by the <code>GradientConfig</code> class, which contains a <code>samplers</code> field that is an array of indices, indicating for each variable which sampler should be used.</p> <p>The original values of all fields used to create the object will be stored internally and are available via the <code>original_inputs</code> field.</p> Info <p>Many of these nested classes contain fields that are <code>numpy</code> arrays of values. In general, these arrays must have a given size defined by the configured property or a size of one. For instance, the <code>variables</code> field must be an object of the <code>VariablesConfig</code> class, which contains information about the variables to be optimized. This includes such properties as initial values, bounds, and so on, which are defined as <code>numpy</code> arrays. The size of these arrays must be either equal to the number of variables or equal to one, in which case that single value is used for all variables.</p> <p>Attributes:</p> Name Type Description <code>variables</code> <code>VariablesConfig</code> <p>Configuration of the variables</p> <code>objective_functions</code> <code>ObjectiveFunctionsConfig</code> <p>Configuration of the objective functions</p> <code>linear_constraints</code> <code>Optional[LinearConstraintsConfig]</code> <p>Configuration of linear constraints</p> <code>nonlinear_constraints</code> <code>Optional[NonlinearConstraintsConfig]</code> <p>Configuration of non-linear constraints</p> <code>realizations</code> <code>RealizationsConfig</code> <p>Configuration of the realizations</p> <code>optimizer</code> <code>OptimizerConfig</code> <p>Configuration of the optimizer</p> <code>gradient</code> <code>GradientConfig</code> <p>Configuration for gradient calculations</p> <code>realization_filters</code> <code>Tuple[RealizationFilterConfig, ...]</code> <p>Configuration of realization filters</p> <code>function_transforms</code> <code>Tuple[FunctionTransformConfig, ...]</code> <p>Configuration of function transforms</p> <code>samplers</code> <code>Tuple[SamplerConfig, ...]</code> <p>Configuration of samplers</p> <code>original_inputs</code> <code>Optional[Dict[str, Any]]</code> <p>The original input to the constructor</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.VariablesConfig","title":"<code>VariablesConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for variables.</p> <p>This configuration class, configured by the <code>variables</code> field in an <code>EnOptConfig</code> object defines essential aspects of the variables: the initial values and the bounds. These are given by the <code>initial_values</code>, <code>lower_bounds</code>, and <code>upper_bounds</code> fields, which are <code>numpy</code> arrays. Initial values must be provided, while bounds are set to \\(-\\infty\\) and \\(+\\infty\\) by default. The <code>lower_bounds</code> and <code>upper_bounds</code> fields may contain <code>numpy.nan</code> values, indicating that corresponding variables have no lower or upper bounds, respectively. These values are converted to <code>numpy.inf</code> values with an appropriate sign.</p> <p>The <code>names</code> field is optional since variable names are not strictly needed by the optimizer. However, if the <code>names</code> field is given, it determines the number of variables, and the <code>initial_values</code>, <code>lower_bounds</code>, and <code>upper_bounds</code> fields are broadcasted accordingly. If <code>names</code> is not provided, these fields are broadcasted to each other, and their final size determines the number of variables.</p> Variable Names <p><code>ropt</code> does not use the names itself, and names can be of arbitrary type, as long as they are unique. However, some optimizers or external code might need a string representation of each name, which can be obtained using the <code>get_formatted_names</code> method. The <code>delimiters</code> attribute is used by this method to convert the special case of names consisting of tuples of strings.</p> <p>The optional <code>types</code> field can be used to assign types to each variable, according to the <code>VariableType</code> enumeration. The values can be used to configure the optimizer accordingly. If not provided, all variables are assumed to be continuous and of real data type (corresponding to <code>VariableType.REAL</code>)</p> <p>The <code>offsets</code> and <code>scales</code> fields are optional: if given, they are broadcasted to the number of variables and used for scaling. The elements \\(x_i\\) of <code>initial_values</code>, <code>lower_bounds</code>, and <code>upper_bounds</code> fields are rescaled by the elements \\(o_i\\) and \\(s_i\\) of <code>offsets</code> and <code>scales</code>: \\((x_i - o_i) / s_i\\).</p> Transformation of Linear Constraints <p>Any linear constraints defined in the <code>EnOptConfig</code> object via its <code>linear_constraints</code> field will also be transformed using any offsets and scales passed via the <code>VariablesConfig</code> object. See: <code>LinearConstraintsConfig</code>.</p> <p>The optional <code>indices</code> field contains the indices of the variables considered to be free to change. During optimization, only these variables should change while others remain fixed.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>Optional names of the variables</p> <code>types</code> <code>Optional[ArrayEnum]</code> <p>The type of the variables (optional).</p> <code>initial_values</code> <code>Array1D</code> <p>The initial values of the variables</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bound of the variables (default: \\(-\\infty\\))</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bound of the variables (default: \\(+\\infty\\))</p> <code>offsets</code> <code>Optional[Array1D]</code> <p>Optional offsets, used for scaling the variables</p> <code>scales</code> <code>Optional[Array1D]</code> <p>Optional scales, used for scaling the variables</p> <code>indices</code> <code>Optional[ArrayIndices]</code> <p>Optional indices of variables to optimize.</p> <code>delimiters</code> <code>str</code> <p>Delimiters used to construct names from tuples</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.VariablesConfig.get_formatted_names","title":"<code>get_formatted_names()</code>","text":"<p>Return string representations of the variable names.</p> <p>This method converts the variable names to a tuple of strings. Each name is converted using its string representation unless the name is a tuple. In that case, the tuple items are converted to strings and joined using the delimiters taken from the <code>delimiter</code> field in the <code>Variables</code> object. This field is a string that may consist of multiple delimiters used in turn. If it contains fewer items than needed, the last one is used for the missing ones. By default, the <code>:</code> character is used as the delimiter.</p> <p>Returns:</p> Type Description <code>Optional[Tuple[str, ...]]</code> <p>A tuple of formatted variable names.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.ObjectiveFunctionsConfig","title":"<code>ObjectiveFunctionsConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for objective functions.</p> <p>This configuration class defines objective functions configured by the <code>objective_functions</code> field in an <code>EnOptConfig</code> object.</p> <p><code>ropt</code> supports optimization over multiple objectives, which are summed after weighting with values passed via the <code>weights</code> field. This field is a <code>numpy</code> array, with a length equal to the number of objective functions. Its values will be normalized to have a sum equal to 1. For example, when <code>weights</code> is set to <code>[1, 1]</code>, the stored values will be <code>[0.5, 0.5]</code>.</p> <p>The <code>names</code> field is optional. If given, the number of objective functions is set equal to its length. The <code>weights</code> array will then be broadcasted to the number of objective values. For example, if <code>names = [\"f1\", \"f2\"]</code> and <code>weights = 1.0</code>, the optimizer assumes two objective functions weighted by <code>[0.5, 0.5]</code>. If <code>names</code> is not set, the number of objectives is determined by the length of <code>weights</code>.</p> <p>The <code>scales</code> field contains scaling values for the objectives. These values are used to scale the objective function values to a desired order of magnitude. Each time new objective function values are obtained during optimization, they are divided by these values. The <code>auto_scale</code> field can be used to direct the optimizer to obtain an additional scaling by multiplying the values of <code>scales</code> by the values of the objective functions at the start of the optimization. Both the <code>scales</code> and <code>auto_scale</code> arrays will be broadcasted to have a size equal to the number of objective functions.</p> Info <p>Both the <code>scales</code> values and the values obtained by auto-scaling will be applied. Thus, if <code>scales</code> is not supplied, auto-scaling will scale the objectives such that their initial values will be equal to one. Setting <code>scales</code> also allows for scaling to different initial values.</p> <p>The objective functions may be subject to realization filters and function transforms. The <code>realization_filters</code> and <code>function_transforms</code> fields contain indices to the realization filter or function transform objects to use. The objects referred to are configured in the parent <code>EnOptConfig</code> object. Refer to the sections Realization filters and Function transforms for more details.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>Optional names of the objective functions</p> <code>weights</code> <code>Array1D</code> <p>Objective functions weights (default: 1.0)</p> <code>scales</code> <code>Array1D</code> <p>The scaling factors (default: 1.0)</p> <code>auto_scale</code> <code>Array1DBool</code> <p>Enable/disable auto-scaling (default: <code>False</code>)</p> <code>realization_filters</code> <code>Optional[Array1DInt]</code> <p>Optional realization filter indices</p> <code>function_transforms</code> <code>Optional[Array1DInt]</code> <p>Optional function transform indices</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.LinearConstraintsConfig","title":"<code>LinearConstraintsConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for linear constraints.</p> <p>This class defines linear constraints configured by the <code>linear_constraints</code> field in an <code>EnOptConfig</code> object.</p> <p>Linear constraints can be described by a set of linear equations on the variables, including equality or non-equality constraints. The <code>coefficients</code> field is a 2D <code>numpy</code> array where the number of rows equals the number of constraints, and the number of columns equals the number of variables.</p> <p>The right-hand sides of the equations are given in the <code>rhs_values</code> field, which will be converted and broadcasted to a <code>numpy</code> array with a length equal to the number of equations.</p> <p>The <code>types</code> field determines the type of each equation: equality (\\(=\\)) or inequality (\\(\\leq\\) or \\(\\geq\\)), and it is broadcasted to a length equal to the number of equations. The <code>types</code> field is defined as an integer array, but its values are limited to those of the <code>ConstraintType</code> enumeration.</p> <p>Attributes:</p> Name Type Description <code>coefficients</code> <code>Array2D</code> <p>The matrix of coefficients</p> <code>rhs_values</code> <code>Array1D</code> <p>The right-hand-sides of the constraint equations</p> <code>types</code> <code>ArrayEnum</code> <p>The type of each equation           (see <code>ConstraintType</code>)</p> Rescaled variables <p>If a <code>LinearConstraintsConfig</code> object is part of an <code>EnOptConfig</code> object, it may be modified during initialization. If the <code>EnOptConfig</code> object defines a rescaling of the variables, the linear coefficients (\\(\\mathbf{A}\\)) and offsets (\\(\\mathbf{b}\\)) are converted to remain valid for the scaled variables:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A}\\mathbf{S} \\\\     \\hat{\\mathbf{b}} &amp;= \\mathbf{b} - \\mathbf{A}\\mathbf{o} \\end{align} \\] <p>where \\(\\mathbf{S}\\) is a diagonal matrix containing the variable scales, and \\(\\mathbf{o}\\) is a vector containing the variable offsets.</p> <p>It is important to realize that this does not mean that the constraints themselves are scaled. The equations and right-hand values are transformed, ensuring they yield the same results with scaled variables as the original equations and right-hand side values would with unscaled variables. This should be taken into account when comparing the difference between the equations and right-hand side to a tolerance.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.NonlinearConstraintsConfig","title":"<code>NonlinearConstraintsConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for non-linear constraints.</p> <p>This class defines non-linear constraints configured by the <code>nonlinear_constraints</code> field in an <code>EnOptConfig</code> object.</p> <p>Non-linear constraints require that some constraint function is compared to a right-hand-side value, either for equality or inequality. The <code>rhs_values</code> field, which is a <code>numpy</code> array with a length equal to the number of constraint functions, provides the right-hand-side values.</p> <p>The <code>names</code> field is optional. If given, the number of constraint functions is set equal to its length. The <code>rhs_values</code> array will then be broadcasted to the number of constraint functions. For example, if <code>names = [\"c1\", \"c2\"]</code> and <code>rhs_values = 0.0</code>, the optimizer assumes two constraint functions and stores <code>rhs_values = [0.0, 0.0]</code>. If <code>names</code> is not set, the number of constraints is determined by the length of <code>rhs_values</code>.</p> <p>The <code>scales</code> field contains scaling values for the constraints. These values scale the constraint function values to a desired order of magnitude. Each time new constraint function values are obtained during optimization, they are divided by these values. The <code>auto_scale</code> field can be used to direct the optimizer to obtain additional scaling by multiplying the values of <code>scales</code> by the values of the constraint functions at the start of the optimization. Both the <code>scales</code> and <code>auto_scale</code> arrays will be broadcasted to have a size equal to the number of constraint functions.</p> Info <p>Both the <code>scales</code> values and the values obtained by auto-scaling will be applied. If <code>scales</code> is not supplied, auto-scaling will scale the constraints such that their initial values will be equal to one. Setting <code>scales</code> additionally allows for scaling to different initial values.</p> <p>The <code>types</code> field determines the type of each constraint: equality (\\(=\\)) or inequality (\\(\\le\\) or \\(\\ge\\)), and is broadcasted to a length equal to the number of constraints. The <code>types</code> field is defined as an integer array, but its values are limited to those of the <code>ConstraintType</code> enumeration.</p> <p>The non-linear constraints may be subject to realization filters and function transforms. The <code>realization_filters</code> and <code>function_transform</code> fields contain indices to the realization filter or function transform objects to use. These objects are configured in the parent <code>EnOptConfig</code> object. Refer to the sections Realization filters and Function transforms for more details.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>The names of the constraint functions (optional)</p> <code>rhs_values</code> <code>Array1D</code> <p>The right-hand-side values</p> <code>scales</code> <code>Array1D</code> <p>The scaling factors (default: 1.0)</p> <code>auto_scale</code> <code>Array1DBool</code> <p>Enable/disable auto-scaling (default: <code>False</code>)</p> <code>types</code> <code>ArrayEnum</code> <p>The type of each non-linear constraint                  (<code>ConstraintType</code>)</p> <code>realization_filters</code> <code>Optional[Array1DInt]</code> <p>Optional realization filter indices</p> <code>function_transforms</code> <code>Optional[Array1DInt]</code> <p>Optional function transform indices</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationsConfig","title":"<code>RealizationsConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for realizations.</p> <p>This class defines realizations configured by the <code>realizations</code> field in an <code>EnOptConfig</code> object.</p> <p>To optimize an ensemble of functions, a set of realizations is defined. When the optimizer requests a function value or a gradient, the functions and gradients are calculated for each realization and combined into a single function or gradient. Usually, this will be a (weighted) sum, but other ways of combining realizations are possible (see Realization filters and Function transforms for more details).</p> <p>The <code>weights</code> field is a <code>numpy</code> array, with a length equal to the number of realizations. Its values will be normalized to have a sum equal to 1. For example, when <code>weights</code> is set to <code>[1, 1]</code>, the stored values will be <code>[0.5, 0.5]</code>.</p> <p>The <code>names</code> field is optional. If given, the number of realizations is set equal to its length. The <code>weights</code> array will then be broadcasted to the number of objective values. For example, if <code>names = [\"r1\", \"r2\"]</code> and <code>weights = 1.0</code>, the optimizer assumes two realizations weighted by <code>[0.5, 0.5]</code>. If <code>names</code> is not set, the number of realizations is determined by the length of <code>weights</code>.</p> <p>If during the calculation of the function values for each realization one or more values are missing, for instance due to failure of a complex simulation, the total function and gradient values can still be calculated by leaving the missing values out. However, this may be undesirable, or there may be a hard minimum to the amount of values that is needed. The <code>realization_min_success</code> field can be set to the minimum number of successful realizations. By default, it is set equal to the number of realizations, i.e., there are no missing values allowed by default.</p> Note <p>The value of <code>realization_min_success</code> can be set to zero. Some optimizers can handle this and will proceed with the optimization even if all realizations fail. However, most optimizers cannot handle this and will behave as if the value is set to one.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>Optional names of the realizations</p> <code>weights</code> <code>Array1D</code> <p>The weights of the realizations (default: 1)</p> <code>realization_min_success</code> <code>Optional[NonNegativeInt]</code> <p>The minimum number of successful realizations                      (default: equal to the number of realizations)</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.OptimizerConfig","title":"<code>OptimizerConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for optimizers used in the optimization.</p> <p>This class defines the configuration for optimizers, configured by the <code>optimizer</code> field in an <code>EnOptConfig</code> object.</p> <p>Although there may be significant differences in the parameters that can be used for different optimization methods, there are a few standard settings defined in this configuration object, which are forwarded to the optimizer:</p> <ul> <li>The maximum number of iterations allowed before the optimization should be   aborted by this optimizer. The optimizer may choose to ignore this option.</li> <li>The maximum number of function evaluations allowed before the optimization   is aborted.</li> <li>The convergence tolerance used as a stopping criterion. The exact   definition of the criterion depends on the optimizer. The optimizer may   choose to ignore this option.</li> <li>Whether gradients should be evaluated early, even if the optimizer does   not strictly need it yet. When evaluating on a distributed HPC cluster,   this may lead to better load-balancing for some methods. This option is   only applied if the optimization algorithm knows how to make use of it.</li> <li>Whether calculations for functions and gradients should be done   separately, even if the optimizer requests them to be evaluated together.   This option is useful when a filter is specified that deactivates some   realizations (see   <code>RealizationFilterConfig</code>).   In this case, after evaluation of the functions, it may be possible to   reduce the number of evaluations for a following gradient calculation.</li> <li>Whether the optimizer may use parallelized function evaluations. This   option currently only applies to gradient-free methods and may be ignored   by the optimizer.</li> <li>An optional location of an output directory, where the optimizer may store   files.</li> <li>Generic optimizer options that may be passed as an arbitrary dictionary,   or as a list of strings. It depends on the method what form is required   and how it is interpreted.</li> </ul> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the optimization method used</p> <code>max_iterations</code> <code>Optional[PositiveInt]</code> <p>Optional maximum number of iterations</p> <code>max_functions</code> <code>Optional[PositiveInt]</code> <p>Optional maximum number of function evaluations</p> <code>tolerance</code> <code>Optional[NonNegativeFloat]</code> <p>Optional tolerance for convergence</p> <code>speculative</code> <code>bool</code> <p>Force gradient evaluations; disabled if               split_evaluations is True (default <code>False</code>)</p> <code>split_evaluations</code> <code>bool</code> <p>Evaluate function and gradient separately               (default: <code>False</code>)</p> <code>parallel</code> <code>bool</code> <p>Allow for parallelized evaluation (default: <code>False</code>)</p> <code>output_dir</code> <code>Optional[Path]</code> <p>Optional output directory for use by the optimizer</p> <code>options</code> <code>Optional[Union[Dict[str, Any], List[str]]]</code> <p>Optional generic options for use by the optimizer</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.GradientConfig","title":"<code>GradientConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for gradient calculations.</p> <p>This class defines the configuration for gradient calculations, configured by the <code>gradients</code> field in an <code>EnOptConfig</code> object.</p> <p>If the optimizer requires gradient information, it is estimated from a set of function values calculated from perturbed variables and from the unperturbed variables. The number of perturbations is determined by the <code>number_of_perturbations</code> field, which should be at least one and may be larger than the number of variables.</p> <p>Some function evaluations for the perturbed variables may fail, for instance due to an error in a long-running simulation. As long as not too many evaluations fail, the gradient may still be estimated. The <code>perturbation_min_success</code> field determines how many perturbed variables should be successfully evaluated. By default, this parameter is set equal to the number of perturbations.</p> <p>Perturbations are generally produced by sampler objects configured in the parent <code>EnOptConfig</code> object. The <code>samplers</code> field contains, for each variable, an index into the tuple of these configured samplers, indicating which sampler should be used to generate perturbation values for that variable.</p> <p>The generated perturbation values are added to the unperturbed variables after multiplication with the perturbation magnitudes given by the <code>perturbation_magnitudes</code> field. The perturbation values may be used directly or first modified in various ways. The <code>perturbation_types</code> field determines if and how this is done for each variable (see the <code>PerturbationType</code> enumeration for details).</p> <p>The perturbed variables can occasionally violate the bound constraints defined for the variables. This may be undesirable, for instance if the function evaluation may fail for variables that violate these constraints. The <code>boundary_types</code> array determines what action is taken to rectify such a situation (see the <code>BoundaryType</code> enumeration for more details).</p> <p>Both the <code>perturbation_types</code> and <code>boundary_types</code> fields are defined as integer arrays, but their values are limited to the values of the <code>PerturbationType</code> and <code>BoundaryType</code> enumerations, respectively.</p> <p>The gradient is calculated for each realization individually, and the resulting gradients are afterwards combined into a total gradient. If the number of perturbations is low, the calculation of the individual gradients may be unreliable. In particular, in the case of a single perturbation, the result is likely inaccurate. In such a case, the <code>merge_realizations</code> flag can be set to direct the optimizer to use a different calculation to combine the results of all realizations directly into an estimation of the total gradient.</p> <p>Attributes:</p> Name Type Description <code>number_of_perturbations</code> <code>PositiveInt</code> <p>The number of perturbations (default: <code>DEFAULT_NUMBER_OF_PERTURBATIONS</code>)</p> <code>perturbation_min_success</code> <code>Optional[PositiveInt]</code> <p>The minimum number of successful function                       evaluations for perturbed variables (default:                       equal to the number of perturbations)</p> <code>perturbation_magnitudes</code> <code>Array1D</code> <p>The magnitudes of the perturbations for each variable                       (default: <code>DEFAULT_PERTURBATION_MAGNITUDE</code>)</p> <code>perturbation_types</code> <code>ArrayEnum</code> <p>The type of perturbation for each variable                       (<code>PerturbationType</code>,                       default: <code>DEFAULT_PERTURBATION_TYPE</code>)</p> <code>boundary_types</code> <code>ArrayEnum</code> <p>How perturbations that violate boundary conditions                       are treated (see <code>BoundaryType</code>),                       default: <code>DEFAULT_PERTURBATION_BOUNDARY_TYPE</code>).</p> <code>samplers</code> <code>Optional[Array1DInt]</code> <p>The index of the sampler to use for each variable</p> <code>merge_realizations</code> <code>bool</code> <p>If all realizations should be merged for the final                       gradient calculation (default: <code>False</code>)</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.FunctionTransformConfig","title":"<code>FunctionTransformConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>Configuration class for function transforms.</p> <p>This class defines the configuration for function transforms, which are configured by the <code>function_transforms</code> field in an <code>EnOptConfig</code> object. That field contains a tuple of configuration objects that define which function transforms are available during the optimization.</p> <p>By default, the final objective and constraint functions and their gradients are calculated from the individual realizations by a weighted sum. Function transforms are optionally used to modify this calculation.</p> <p>The <code>method</code> field determines which method will be used to implement the calculation of the final function or gradient from the individual realizations. To further specify how such a method should function, the <code>options</code> field can be used to pass a dictionary of key-value pairs. The interpretation of these options depends on the chosen method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The function transform method</p> <code>options</code> <code>Dict[str, Any]</code> <p>Options to be passed to the transform</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationFilterConfig","title":"<code>RealizationFilterConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The configuration class for realization filters.</p> <p>This class defines the configuration for realization filters, which are configured by the <code>realization_filters</code> field in an <code>EnOptConfig</code> object. This field contains a tuple of configuration objects that define which realization filters are available during optimization.</p> <p>By default, the final objective and constraint functions and their gradients are calculated as a weighted function from all realizations. Realization filters are optionally used to change the weights of the individual realizations. For instance, this can be used to determine which subset of realizations should be used in calculating the final objective and constraint functions and their gradients by setting some weights to zero.</p> <p>The <code>method</code> field determines which method will be used to adjust the weights of the individual realizations. To further specify how such a method should function, the <code>options</code> field can be used to pass a dictionary of key-value pairs. The interpretation of these options depends on the| chosen method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The realization filter method</p> <code>options</code> <code>Dict[str, Any]</code> <p>Options to be passed to the filter</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.SamplerConfig","title":"<code>SamplerConfig</code>","text":"<p>               Bases: <code>EnOptBaseModel</code></p> <p>The sampler configuration class.</p> <p>This class defines the configuration for samplers, which are configured by the <code>samplers</code> field in an <code>EnOptConfig</code> object. That field contains a tuple of configuration objects that define which samplers are available during the optimization. The <code>samplers</code> field in the gradient configuration (<code>GradientConfig</code>) is used to specify the index of the sampler for each variable.</p> <p>Gradients are calculated from a set of perturbed variables, which may be deterministic or stochastic in nature. These perturbations are generally produced by sampler objects that produce perturbation values to add to the unperturbed variables.</p> <p>Perturbation values are produced by a sampler, which provides the methods that can be used. The <code>method</code> field determines which sampler method will be used. To further specify how such a method should function, the <code>options</code> field can be used to pass a dictionary of key-value pairs. The interpretation of these options depends on the chosen method.</p> <p>By default, a different set of perturbed variables is generated for each realization. By setting the <code>shared</code> flag to <code>True</code>, the sampler can be directed to use the same set of perturbed values for each realization.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The sampler method</p> <code>options</code> <code>Dict[str, Any]</code> <p>Options to be passed to the sampler</p> <code>shared</code> <code>bool</code> <p>Whether perturbation values should be shared between realizations     (default: <code>False</code>)</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants","title":"<code>ropt.config.enopt.constants</code>","text":"<p>Default values used by the configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_SEED","title":"<code>DEFAULT_SEED = 1</code>  <code>module-attribute</code>","text":"<p>Default random generator seed.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_NUMBER_OF_PERTURBATIONS","title":"<code>DEFAULT_NUMBER_OF_PERTURBATIONS = 5</code>  <code>module-attribute</code>","text":"<p>Default number of perturbations.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_MAGNITUDE","title":"<code>DEFAULT_PERTURBATION_MAGNITUDE = 0.005</code>  <code>module-attribute</code>","text":"<p>Default perturbation magnitude.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_BOUNDARY_TYPE","title":"<code>DEFAULT_PERTURBATION_BOUNDARY_TYPE = BoundaryType.MIRROR_BOTH</code>  <code>module-attribute</code>","text":"<p>Default perturbation boundary handling type.</p> <p>See also: <code>BoundaryType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_TYPE","title":"<code>DEFAULT_PERTURBATION_TYPE = PerturbationType.ABSOLUTE</code>  <code>module-attribute</code>","text":"<p>Default perturbation type.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enums/","title":"Enumerations","text":""},{"location":"reference/enums/#ropt.enums","title":"<code>ropt.enums</code>","text":"<p>Enumerations used by <code>ropt</code>.</p>"},{"location":"reference/enums/#ropt.enums.VariableType","title":"<code>VariableType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the variable types.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.REAL","title":"<code>REAL = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Continuous variables represented by real values.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.INTEGER","title":"<code>INTEGER = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discrete variables represented by integer values.</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType","title":"<code>ConstraintType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of linear or non-linear constraints.</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType.LE","title":"<code>LE = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Less or equal constraint (\\(\\le\\)).</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType.GE","title":"<code>GE = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Greater or equal constraint (\\(\\ge\\)).</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType.EQ","title":"<code>EQ = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Equality constraint (\\(=\\)).</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType","title":"<code>BoundaryType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the ways boundaries should be treated.</p> <p>When variables are perturbed their values may violate boundary constraints. This enumeration lists the ways these values can be modified to fix this.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.NONE","title":"<code>NONE = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Do not modify the value.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.TRUNCATE_BOTH","title":"<code>TRUNCATE_BOTH = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Truncate the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     l_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     b_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.BoundaryType.MIRROR_BOTH","title":"<code>MIRROR_BOTH = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Mirror the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     2l_i - v_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     2b_i - v_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i        &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.PerturbationType","title":"<code>PerturbationType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of perturbations that can be applied.</p> <p>When applying a perturbation to a variable, generally, some value is generated, which is then applied to the unperturbed values (usually by addition). This enumeration lists the ways how this perturbation value can be modified before being added to the unperturbed variable.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.ABSOLUTE","title":"<code>ABSOLUTE = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the perturbation value as is.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.RELATIVE","title":"<code>RELATIVE = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Multiply the perturbation value \\(p_i\\) by the range defined by the bounds of the variables \\(c_i\\): \\(\\hat{p}_i = (c_{i,\\text{max}} - c_{i,\\text{min}}) \\cdot p_i\\). The bounds will generally be defined in the configuration for the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.SCALED","title":"<code>SCALED = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Scale each perturbation \\(p_i\\) according to the scales (\\(s_i\\)) for each variable: \\(\\hat{p}_i = p_i/s_i\\). The scales \\(s_i\\) will generally be defined in the configuration of the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.EventType","title":"<code>EventType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the events emitted during optimization.</p> <p>The optimizer emits events during the execution of the optimization plan, and callbacks can be connected to these events using the <code>add_observer</code> method. When triggered by an event, the callbacks receive an OptimizationEvent object. This object contains at least the type of the event (a value of this enumeration) and the current configuration of the step in the plan that is executing. Additionally, depending on the event type, a tuple of result objects or an exit code may be present. Refer to the documentation of the individual event types for details.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATION","title":"<code>START_EVALUATION = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted before evaluating new functions.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATION","title":"<code>FINISHED_EVALUATION = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted after finishing the evaluation.</p> <p>Results may be passed to callback reacting to this event.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_OPTIMIZER_STEP","title":"<code>START_OPTIMIZER_STEP = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted just before starting an optimizer step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_OPTIMIZER_STEP","title":"<code>FINISHED_OPTIMIZER_STEP = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted immediately after an optimizer step finishes.</p> <p>Results and an exit code may be passed to callback reacting to this event.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATOR_STEP","title":"<code>START_EVALUATOR_STEP = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted just before starting an evaluation step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATOR_STEP","title":"<code>FINISHED_EVALUATOR_STEP = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted immediately after an evaluation step finishes.</p> <p>Results and an exit code may be passed to callback reacting to this event.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode","title":"<code>OptimizerExitCode</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the reasons for terminating an optimization.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.UNKNOWN","title":"<code>UNKNOWN = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Unknown cause of termination.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.TOO_FEW_REALIZATIONS","title":"<code>TOO_FEW_REALIZATIONS = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when too few realizations are evaluated successfully.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.MAX_FUNCTIONS_REACHED","title":"<code>MAX_FUNCTIONS_REACHED = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when the maximum number of function evaluations is reached.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.USER_ABORT","title":"<code>USER_ABORT = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when the optimization is aborted by the user.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.OPTIMIZER_STEP_FINISHED","title":"<code>OPTIMIZER_STEP_FINISHED = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when an optimization step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.EVALUATION_STEP_FINISHED","title":"<code>EVALUATION_STEP_FINISHED = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when an evaluation step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName","title":"<code>ResultAxisName</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumerates the possible axis names in a Results data object.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.VARIABLE","title":"<code>VARIABLE = 'variable'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the variable.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.OBJECTIVE","title":"<code>OBJECTIVE = 'objective'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the objective function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.LINEAR_CONSTRAINT","title":"<code>LINEAR_CONSTRAINT = 'linear_constraint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the linear constraint.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.NONLINEAR_CONSTRAINT","title":"<code>NONLINEAR_CONSTRAINT = 'nonlinear_constraint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the constraint function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.REALIZATION","title":"<code>REALIZATION = 'realization'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the realization.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.PERTURBATION","title":"<code>PERTURBATION = 'perturbation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the perturbation.</p>"},{"location":"reference/evaluator/","title":"Function evaluations","text":""},{"location":"reference/evaluator/#ropt.evaluator","title":"<code>ropt.evaluator</code>","text":"<p>Function Evaluations.</p> <p>An optimizer will repeatedly request function and gradient evaluations. In each iteration, it may require values for multiple variable vectors, and the gradients may be calculated from various perturbed variable vectors. To address this, the EnsembleOptimizer class requires a function evaluator callback upon initialization, conforming to the Evaluator signature.</p> <p>The callback accepts a matrix containing multiple variable vectors to evaluate together with a <code>EvaluatorContext</code> providing information usable by the evaluator. It returns an <code>EvaluatorResult</code> object with the calculated values of the objective and constraint functions for all variable vectors and realizations, and optionally some additional metadata.</p> Reusing Objective and Non-linear Constraint Values <p>When defining multiple objectives, there might be an intention to reuse the same objective value multiple times. For example, a total objective could consist of the mean of the objectives for each realization, plus the standard deviation of the same values. This can be implemented by defining two objectives: the first calculated as the mean of the realizations, and the second using a function transform to compute the standard deviations. The optimizer is unaware that both objectives use the same set of realizations. To prevent redundant calculations, the evaluator should compute the results of the realizations once and return them for both objectives.</p> <p>Non-linear constraint values may potentially appear multiple times in the <code>constraint_results</code> matrix. For instance, to express the constraint \\(a &lt; F_c \\le b\\), two constraints must be defined: \\(F_c \\ge a\\) and \\(F_c \\le b\\), sharing the same function value \\(F_c\\) but differing in types and right-hand-sides (<code>ConstraintType.GE</code>/<code>ConstraintType.LE</code> and \\(a\\)/\\(b\\)). The run method should ensure that the calculated value of \\(F_c\\) is the same in both cases, which is most efficiently achieved by evaluating \\(F_c\\) only once.</p>"},{"location":"reference/evaluator/#evaluator-callbacks","title":"Evaluator callbacks","text":""},{"location":"reference/evaluator/#ropt.evaluator.Evaluator","title":"<code>ropt.evaluator.Evaluator</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for evaluator objects or callables.</p> <p>The <code>EnsembleOptimizer</code> object, running an optimization, requires a callback argument upon initialization that follows this protocol.</p> Closing an evaluator. <p>An evaluator might be implemented as a callable object with an additional <code>close</code> method. If the evaluator has indeed such a method it will be called when the evaluator is not needed anymore.</p>"},{"location":"reference/evaluator/#ropt.evaluator.Evaluator.__call__","title":"<code>__call__(variables, context)</code>","text":"<p>The function evaluator callback signature.</p> <p>The first argument of the function should be a matrix where each column is a variable vector. Depending on the information passed by the second argument, all objective and constraint functions for all vectors or for a subset are to be calculated.</p> <p>The second argument is an <code>EvaluatorContext</code> object, providing supplementary information to the evaluation function.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate</p> required <code>context</code> <code>EvaluatorContext</code> <p>The evaluation context</p> required <p>Returns:</p> Type Description <code>EvaluatorResult</code> <p>An evaluation results object.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext","title":"<code>ropt.evaluator.EvaluatorContext</code>  <code>dataclass</code>","text":"<p>Capture additional details for the function evaluator.</p> <p>Function evaluator callbacks (see <code>Evaluator</code>) mainly require variable vectors to evaluate objective and constraint functions. However, depending on their implementation, evaluators may benefit from additional information. To accommodate this, function evaluators receive a <code>EvaluatorContext</code> object with the following details:</p> <ul> <li>The configuration object for the ongoing optimization step.</li> <li>Indices indicating the realization to which each variable vector belongs.</li> <li>A matrix indicating, for each function and realization, whether it is   active and needs computation.</li> <li>A matrix indicating, for each constraint and realization, whether it is   active and requires computation.</li> </ul> <p>The <code>active_objectives</code> and <code>active_constraints</code> fields are boolean matrices, where each column represents one realization, and each row signifies a function or a constraint. Entries marked as <code>True</code> are essential for the optimizer, while other combinations do not necessitate evaluation.</p> <p>In practical scenarios, these matrices may prove overly detailed for function evaluators. Typically, evaluators may only be capable of calculating all objective and constraint functions for a given realization or none at all. In such cases, it suffices to examine the <code>active</code> property, indicating the realizations requiring evaluation.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>EnOptConfig</code> <p>Configuration of the optimizer.</p> <code>realizations</code> <code>NDArray[intc]</code> <p>Realization numbers for each requested evaluation.</p> <code>active_objectives</code> <code>Optional[NDArray[bool_]]</code> <p>Signifies which function/realization evaluations are                 essential for the optimizer.</p> <code>active_constraints</code> <code>Optional[NDArray[bool_]]</code> <p>Signifies which constraint/realization evaluations are                 essential for the optimizer.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext.active","title":"<code>active: Optional[NDArray[np.bool_]]</code>  <code>cached</code> <code>property</code>","text":"<p>Return the set of active variable vectors.</p> <p>This property is useful for determining the realizations for which the objective and constraint functions need to be calculated. The index of each entry corresponds to the realization number and indicates whether the functions should be calculated.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[bool_]]</code> <p>A boolean array.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorResult","title":"<code>ropt.evaluator.EvaluatorResult</code>  <code>dataclass</code>","text":"<p>Store the results of a function evaluation.</p> <p>The objectives and constraint values are stored as a matrix, where the columns correspond to the index of the objective or constraint, and the rows correspond to the index of the variable vector for which they were calculated. Depending on context information passed to the evaluation function, not all results may have been calculated, in which case the corresponding entries should contain zeros. Entries may also contain <code>numpy.nan</code> values to signify that a calculation failed.</p> <p>Optionally, a batch ID can be returned to identify the batch of calculations. This can be useful for tracking or managing evaluations performed together.</p> <p>Additionally, evaluation IDs are provided as an option. These IDs can be used to uniquely identify the results calculated for each variable vector, offering a way to link specific evaluations back to their corresponding input vectors.</p> <p>Attributes:</p> Name Type Description <code>objectives</code> <code>NDArray[float64]</code> <p>The calculated objective values.</p> <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional calculated constraint values.</p> <code>batch_id</code> <code>Optional[int]</code> <p>Optional batch ID.</p> <code>evaluation_ids</code> <code>Optional[NDArray[intc]]</code> <p>Optional ID for each evaluation.</p>"},{"location":"reference/evaluator/#optional-implementations","title":"Optional implementations","text":""},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator","title":"<code>ropt.evaluator.ConcurrentEvaluator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for implementing a concurrent evaluator.</p> <p>This abstract base class provides the framework for implementing an evaluator that uses a concurrent executor.</p> <p>The <code>launch</code> method must be implemented to start an evaluation for one vector of variables, and return a future-like object, compatible with futures from the <code>concurrent.futures</code> module of Python, implementing at least the <code>done()</code>, <code>exception()</code>, and <code>result()</code> methods.</p> <p>To use a class derived from <code>ConcurrentEvaluator</code>, pass the object via the <code>evaluator</code> argument of the <code>EnsembleOptimizer</code> constructor.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator.polling","title":"<code>polling: float = 0.1</code>  <code>instance-attribute</code>","text":"<p>The time in seconds between polling for evaluation status.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator.launch","title":"<code>launch(batch_id, variables, context, active)</code>  <code>abstractmethod</code>","text":"<p>Launch the evaluations and return futures.</p> <p>This method must implement the process of launching a batch of function evaluations for a set of variable vectors passed via the <code>variables</code> parameter. A unique batch ID is passed via the <code>batch_id</code>, which can be optionally used.</p> <p>This method should return a dictionary mapping the indices of the jobs to the tasks that will contain the result. The tasks are objects deriving from the <code>ConcurrentTask</code> class, containing the future object representing the launched task and its result. Under the hood, other tasks may be launched, but only those that contain results should be returned.</p> <p>This method is called by the <code>__call__</code> method, which implements the <code>Evaluator</code> callback signature and can be passed by the <code>EnsembleOptimizer</code> object.</p> <p>The <code>context</code> argument with optional information is passed from the <code>__call__</code> method unchanged. The <code>active</code> document passes a boolean vector indicating which realizations are active. It not <code>None</code> it should take precedence over the corresponding field in the <code>context</code> variable.</p> <p>Parameters:</p> Name Type Description Default <code>batch_id</code> <code>Any</code> <p>The ID of the batch of evaluations to run.</p> required <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate.</p> required <code>context</code> <code>EvaluatorContext</code> <p>Evaluator context.</p> required <code>active</code> <code>Optional[NDArray[bool_]]</code> <p>Optional active realizations.</p> required <p>Returns:</p> Type Description <code>Dict[int, ConcurrentTask]</code> <p>A dictionary mapping the indices of launched evaluations to tasks.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator.monitor","title":"<code>monitor()</code>","text":"<p>Monitor the states of the running evaluations.</p> <p>This method is called regularly in the polling loop that checks the futures until all results are collected. If the status of the evaluations should be monitored, this method should be overridden.</p> <p>The time in seconds between calls in the polling loop can be modified by setting the <code>polling</code> attribute.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentTask","title":"<code>ropt.evaluator.ConcurrentTask</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract data class for tasks in a concurrent evaluator.</p> <p>These task objects should contain the future that represents the task and return the results of the evaluation.</p> <p>It should implement two functions to retrieve the objective function values and optional constraint values.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentTask.get_objectives","title":"<code>get_objectives()</code>  <code>abstractmethod</code>","text":"<p>Return the objectives calculated by the task.</p> <p>This method will only be called after the future is done, and if no exception was raised during the execution of the task.</p> Info <p>The return value might be None, as derived evaluator classes might also employ tasks that do not return results.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The calculated objectives.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentTask.get_constraints","title":"<code>get_constraints()</code>","text":"<p>Return the constraints calculated by the task, if available.</p> <p>This method will only be called after the future is done, and if no exception was raised during the execution of the task.</p> <p>This has a default implementation that returns <code>None</code> and is only usable when it is certain that there are no non-linear constraints. If there are non-linear constraints, this method should be overridden.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The calculated constraints or <code>None</code>.</p>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#ropt.exceptions","title":"<code>ropt.exceptions</code>","text":"<p>Exceptions raised by <code>ropt</code>.</p>"},{"location":"reference/exceptions/#ropt.exceptions.ConfigError","title":"<code>ConfigError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an configuration error occurs.</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted","title":"<code>OptimizationAborted</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization is aborted.</p> <p>When constructing the execption object an exit code must be passed that indicates the reason for aborting (see <code>OptimizerExitCode</code>).</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted.__init__","title":"<code>__init__(exit_code)</code>","text":"<p>Initialize an exception that aborts the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>exit_code</code> <code>OptimizerExitCode</code> <p>The exit code indicating the reason for the abort</p> required"},{"location":"reference/function_transforms/","title":"Function transforms","text":""},{"location":"reference/function_transforms/#ropt.plugins.function_transform","title":"<code>ropt.plugins.function_transform</code>","text":"<p>Plugin functionality for adding function transforms.</p> <p>This package contains the protocol that must be followed by function transform plugins, and the default function transforms that are part of <code>ropt</code>.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol","title":"<code>ropt.plugins.function_transform.protocol</code>","text":"<p>This module defines the protocol to be followed by function transforms.</p> <p>Function transforms can be added via the plugin mechanism to implement additional ways to functions and gradient ensembles. Any object that follows the <code>FunctionTransform</code> protocol may be installed as a plugin.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol.FunctionTransformProtocol","title":"<code>FunctionTransformProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol class for function transforms.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol.FunctionTransformProtocol.__init__","title":"<code>__init__(enopt_config, transform_index)</code>","text":"<p>Initialize the function transform object.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>transform_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol.FunctionTransformProtocol.calculate_function","title":"<code>calculate_function(functions, weights)</code>","text":"<p>Combine functions from realizations into an expected function.</p> Calculation from merged realizations <p>Normally the gradient is calculated for each realization separately and then combined into an overall gradient with <code>calculate_gradient</code> method. The <code>merge_realizations</code> flag in the ensemble optimizer configuration directs the optimizer to calculate the overall gradient from all realizations directly. This yields a reasonable estimation if the function transform is an averaging operation, but may not be appropriate in other cases.</p> <p>At initialization, the <code>merge_realizations</code> flag should be checked, and if necessary a <code>ConfigError</code> with an appropriate message should be raised.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected function values.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol.FunctionTransformProtocol.calculate_gradient","title":"<code>calculate_gradient(functions, gradient, weights)</code>","text":"<p>Combine gradients from realizations into an expected gradient.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization</p> required <code>gradient</code> <code>NDArray[float64]</code> <p>The gradient for each realization</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected gradients.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol.FunctionTranformPluginProtocol","title":"<code>FunctionTranformPluginProtocol</code>","text":"<p>               Bases: <code>PluginProtocol</code>, <code>Protocol</code></p> <p>The function transform plugin protocol.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.protocol.FunctionTranformPluginProtocol.create","title":"<code>create(enopt_config, transform_index)</code>","text":"<p>Initialize the function transform object.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>transform_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.default","title":"<code>ropt.plugins.function_transform.default</code>","text":"<p>This module implements the default function transform plugin.</p>"},{"location":"reference/function_transforms/#ropt.plugins.function_transform.default.DefaultFunctionTransform","title":"<code>ropt.plugins.function_transform.default.DefaultFunctionTransform</code>","text":"<p>               Bases: <code>FunctionTransformProtocol</code></p> <p>The default function transform plugin.</p> <p>This plugin currently implements two methods:</p> <code>mean</code>: Calculate the combined functions as a weighted mean of the function    values of each realization. Gradients are accordingly calculated as    a weighted sum. <code>stddev</code>: Calculate the combined functions as the standard deviation of function    values of each realization. Gradients are calculated accordingly using    the chain rule. The sign of the result is adjusted such that the standard    deviation is always minimized."},{"location":"reference/optimization/","title":"Ensemble optimizer","text":""},{"location":"reference/optimization/#ropt.optimization","title":"<code>ropt.optimization</code>","text":"<p>Code to run optimization workflows.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer","title":"<code>EnsembleOptimizer</code>","text":"<p>The Ensemble Optimizer Class.</p> <p>This class serves as the central component for executing an optimization plan. Upon initialization, an <code>EnsembleOptimizer</code> object accepts and stores a callback with the <code>Evaluator</code> signature. Before initiating the optimization, additional callbacks can be incorporated using the <code>add_observer</code> method to respond to events occurring during the optimization. The optimization plan is initiated with the <code>start_optimization</code> method. To prematurely halt the optimization workflow from within callback functions, the <code>abort_optimization</code> method is available. Upon the completion of the optimization process, the <code>results</code> property can be used to examine any stored results.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.results","title":"<code>results: Dict[str, Optional[FunctionResults]]</code>  <code>property</code>","text":"<p>Return the dictionary of results.</p> <p>Results may be stored during optimization and can be accessed by name via this property. Examples of such results include the optimal result encountered, but the exact nature of each result and the names to access them are determined by the optimization plan.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.__init__","title":"<code>__init__(evaluator, plugin_manager=None)</code>","text":"<p>Initialize an <code>EnsembleOptimizer</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>Evaluator</code> <p>An evaluator callback</p> required <code>plugin_manager</code> <code>Optional[PluginManager]</code> <p>Optional plugin manager</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.add_observer","title":"<code>add_observer(event, callback)</code>","text":"<p>Add a callback for an event.</p> <p>Throughout the optimization process, various events are triggered, offering opportunities to observe progress and capture intermediate results. This method facilitates the connection of callbacks to specific events. The callback should accept a single OptimizationEvent object and not return anything. The method can be called multiple times to add multiple callbacks to the same event, and each will be executed when that event occurs.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>EventType</code> <p>The event to respond to.</p> required <code>callback</code> <code>Callable[[OptimizationEvent], None]</code> <p>The callback function to be connected.</p> required"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.start_optimization","title":"<code>start_optimization(plan, seed=None)</code>","text":"<p>Start the optimization.</p> <p>This method executes the provide optimization plan. An optional seed can be provided to initialize the random number generator that can be used by the steps in the plan.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Sequence[Dict[str, Any]]</code> <p>The optimization plan to run</p> required <code>seed</code> <code>Optional[int]</code> <p>Optional seed of the random number generator</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[FunctionResults]</code> <p>The reason for the terminating the optimization.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.abort_optimization","title":"<code>abort_optimization()</code>  <code>staticmethod</code>","text":"<p>Abort the current optimization run.</p> <p>This method can be called from within callbacks to interrupt the ongoing optimization plan. The exact point at which the optimization is aborted depends on the step in the plan that is executing at that point. For example, within a running optimizer, the process will be interrupted after completing the current function evaluation.</p>"},{"location":"reference/optimization/#ropt.events","title":"<code>ropt.events</code>","text":"<p>The optimization event class.</p>"},{"location":"reference/optimization/#ropt.events.OptimizationEvent","title":"<code>OptimizationEvent</code>  <code>dataclass</code>","text":"<p>The <code>OptimizationEvent</code> class stores optimization event data.</p> <p>After initializing an <code>EnsembleOptimizer</code> object to run an optimization plan, callbacks can be connected to react to events triggered during the execution of the plan. These callbacks accept a single <code>OptimizationEvent</code> object containing information about the event.</p> <p>The actual data contained in the object depends on the nature of the event. Refer to the documentation of the <code>EventType</code> enumeration for more details.</p> <p>Attributes:</p> Name Type Description <code>event_type</code> <code>EventType</code> <p>The type of the event.</p> <code>config</code> <code>EnOptConfig</code> <p>The current configuration object of the executing plan.</p> <code>results</code> <code>Optional[Tuple[Results, ...]]</code> <p>Optional results passed with the event.</p> <code>exit_code</code> <code>Optional[OptimizerExitCode]</code> <p>An optional exit code.</p>"},{"location":"reference/optimization_steps/","title":"Optimization steps","text":""},{"location":"reference/optimization_steps/#ropt.plugins.optimization_steps","title":"<code>ropt.plugins.optimization_steps</code>","text":"<p>Plugin functionality for adding optimization steps.</p>"},{"location":"reference/optimizer_plugins/","title":"Optimizer plugins","text":""},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer","title":"<code>ropt.plugins.optimizer</code>","text":"<p>Plugin functionality for adding optimization plugins.</p> <p>Optimization plugins are managed by a <code>PluginManager</code> object, which returns classes or factory functions to create objects that implement one or more optimization methods. These objects must adhere to the <code>Optimizer</code> protocol. This protocol allows <code>ropt</code> to provide the optimizer with the callback used for evaluating functions and gradients and allows it to be started from an optimizer step in the optimization workflow.</p> <p>To support the implementation of the optimizer classes, the <code>ropt.plugins.optimizer.utils</code> module provides some utilities.</p> <p>Optimizers can be added via the plugin manager, by default the <code>SciPyOptimizer</code> plugin is installed which provides a number of methods from the <code>scipy.optimize</code> package.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol","title":"<code>ropt.plugins.optimizer.protocol</code>","text":"<p>This module defines the protocol to be followed by optimization plugins.</p> <p>Optimization plugins can be added via the plugin mechanism to implement additional optimization methods. Any object that follows the <code>Optimizer</code> protocol may be installed as a plugin.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerCallback","title":"<code>OptimizerCallback</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the optimizer callback.</p> <p>Optimization plugins implement optimizer classes according to the <code>Optimizer</code> protocol. Objects of these classes are initialized with a callback function that follows the call signature defined here. This callback should be used to request the function and gradient evaluations that the optimizer needs.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerCallback.__call__","title":"<code>__call__(variables, /, *, return_functions, return_gradients, allow_nan=False)</code>","text":"<p>The signature of the optimizer callback.</p> <p>The optimizer callback expects a vector or matrix with variables to evaluate. Discrete optimizers may request function evaluations for multiple variable vectors, passed as the rows of a matrix. Gradient-based methods may currently only pass a single variable vector at a time.</p> <p>The <code>return_functions</code> and <code>return_gradients</code> flags determine whether functions and/or gradients are to be evaluated. The results are returned as a tuple of arrays, one for functions and constraints, the other for gradients. If one of <code>return_functions</code> or <code>return_gradients</code> is <code>False</code>, the corresponding result is an empty array.</p> <p>Multiple function evaluations are returned as a matrix where the rows are the result vectors for each evaluation. The first element of a result vector is the value of the objective value, and the remaining elements are the values of the non-linear constraints.</p> <p>The gradients of the objective function and the non-linear constraints are returned as a matrix. The first row contains the gradient of the objective function, while the remaining rows contain the gradients of the non-linear constraints. Gradient-based methods currently support only a single evaluation, hence there is also only a single result.</p> <p>In most cases, the optimizer cannot handle failed function evaluations, which are indicated by <code>NaN</code> values. Some optimizers, in particular those that use multiple function evaluations do determine a next step are robust in this regard. By returning <code>allow_nan=True</code>, these optimizers can indicate that this is the case.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vector or matrix to evaluate</p> required <code>return_functions</code> <code>bool</code> <p>If <code>True</code>, evaluate and return functions</p> required <code>return_gradients</code> <code>bool</code> <p>If <code>True</code>, evaluate and return gradients</p> required <code>allow_nan</code> <code>bool</code> <p>If <code>True</code>, accept <code>NaN</code> values</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple with function and gradient values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerProtocol","title":"<code>OptimizerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for optimizer classes.</p> <p><code>ropt</code> employs plugins to implement optimizers that are called during an optimization workflow. Optimizers should adhere to the <code>Optimizer</code> protocol, which specifies the requirements for the class constructor (<code>__init__</code>) and also includes a <code>start</code> method used to initiate the optimization process.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerProtocol.allow_nan","title":"<code>allow_nan: bool</code>  <code>property</code>","text":"<p>Return <code>True</code> if a <code>NaN</code> is a valid function value.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>NaN</code> is allowed.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerProtocol.__init__","title":"<code>__init__(config, optimizer_callback)</code>","text":"<p>Initialize an optimizer object.</p> <p>The <code>config</code> object defines how the optimization run should be configured, while the <code>optimizer_callback</code> should be used to evaluate functions and gradients that are needed during optimization.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerProtocol.start","title":"<code>start(initial_values)</code>","text":"<p>Start the optimization.</p> <p>This method must be implemented to run the optimization, collecting functions and gradients as needed by calling the callback passed upon initialization.</p> <p>Parameters:</p> Name Type Description Default <code>initial_values</code> <code>NDArray[float64]</code> <p>Vector of variables to start the optimization with.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerPluginProtocol","title":"<code>OptimizerPluginProtocol</code>","text":"<p>               Bases: <code>PluginProtocol</code>, <code>Protocol</code></p> <p>Optimizer plugin protocol.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.protocol.OptimizerPluginProtocol.create","title":"<code>create(config, optimizer_callback)</code>","text":"<p>Create an optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils","title":"<code>ropt.plugins.optimizer.utils</code>","text":"<p>Utility functions for use by optimizer plugins.</p> <p>This module provides utility functions to validate supported constraints, filter linear constraints, and to retrieve the list of supported optimizers.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.filter_linear_constraints","title":"<code>filter_linear_constraints(config, variable_indices)</code>","text":"<p>Filter unnecessary constraints from a linear constraint configuration.</p> <p>In the case that the optimizer only optimizes a sub-set of the variables, linear constraints that are only formed from the unused variables are superfluous. This utility function removes those constraints from a  linear configuration constraint.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LinearConstraintsConfig</code> <p>The linear configuration constraint</p> required <code>variable_indices</code> <code>NDArray[intc]</code> <p>The indices of the variables used by the optimizer</p> required <p>Returns:</p> Type Description <code>LinearConstraintsConfig</code> <p>The filtered linear constraint configuration.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.validate_supported_constraints","title":"<code>validate_supported_constraints(config, method, supported_constraints, required_constraints)</code>","text":"<p>Check if the requested optimization features are supported or required.</p> <p>The keys of the supported_constraints and required_constraints dicts specify the type of the constraint as shown in the example below. The values are sets of method names that support or require the type of constraint specified by the key.</p> <p>For example: {     \"bounds\": {\"L-BFGS-B\", \"TNC\", \"SLSQP\"},     \"linear:eq\": {\"SLSQP\"},     \"linear:ineq\": {\"SLSQP\"},     \"nonlinear:eq\": {\"SLSQP\"},     \"nonlinear:ineq\": {\"SLSQP\"}, }</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>method</code> <code>str</code> <p>The method to check</p> required <code>supported_constraints</code> <code>Dict[str, Set[str]]</code> <p>Specify the supported constraints</p> required <code>required_constraints</code> <code>Dict[str, Set[str]]</code> <p>Specify the required constraints</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.create_output_path","title":"<code>create_output_path(base_name, base_dir=None, name=None, suffix=None)</code>","text":"<p>Create an output path name.</p> <p>If the path already exists, an index is appended to it.</p> <p>Parameters:</p> Name Type Description Default <code>base_name</code> <code>str</code> <p>Base name of the path</p> required <code>base_dir</code> <code>Optional[Path]</code> <p>Optional directory to base the path in</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Optional optimization step name to include in the name</p> <code>None</code> <code>suffix</code> <code>Optional[str]</code> <p>Optional suffix for the resulting path</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>The constructed path</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.scipy.SciPyOptimizer","title":"<code>ropt.plugins.optimizer.scipy.SciPyOptimizer</code>","text":"<p>               Bases: <code>OptimizerProtocol</code></p> <p>Plugin class for optimization via SciPy.</p> <p>This class implements several optimizers provided by SciPy in the <code>scipy.optimize</code> package:</p> <ul> <li>Nelder-Mead</li> <li>Powell</li> <li>CG</li> <li>BFGS</li> <li>Newton-CG</li> <li>L-BFGS-B</li> <li>TNC</li> <li>COBYLA</li> <li>SLSQP</li> <li>differential_evolution</li> </ul> <p>The optimizer to use is selected by setting the <code>method</code> field in the <code>optimizer</code> field of <code>EnOptConfig</code> to the name of the algorithm. Most of these methods support the general options set in the <code>EnOptConfig</code> object. However, specific options that are normally passed as arguments in the SciPy functions can be provided via the <code>options</code> dictionary in the configuration object. Consult the <code>scipy.optimize</code> manual for details on these options.</p> <p>Not all constraints are supported by all optimizers:</p> <ul> <li>Bound constraints: Nelder-Mead, L-BFGS-B, SLSQP, TNC,   differential_evolution</li> <li>Linear constraints: SLSQP, differential_evolution</li> <li>Nonlinear constraints: COBYLA (only inequality), SLSQP,   differential_evolution</li> </ul> Info <ul> <li>The Nelder-Mead algorithm only supports bound constraints if SciPy   version &gt;= 1.7.</li> <li>Some SciPy algorithms that require a Hessian or a Hessian-vector   product are not supported. These include dogleg, trust-ncg,   trust-exact, and trust-krylov.</li> </ul>"},{"location":"reference/plan_config/","title":"Plan configuration","text":""},{"location":"reference/plan_config/#ropt.config.plan","title":"<code>ropt.config.plan</code>","text":"<p>Configuration classes for steps within the <code>ropt.config.plan</code> module.</p> <p>These configuration classes are employed by the default steps included with <code>ropt</code>. They can also be utilized by steps implemented by external code, in which case similar functionality is anticipated.</p>"},{"location":"reference/plan_config/#ropt.config.plan.PlanConfig","title":"<code>PlanConfig</code>","text":"<p>Configuration for a single optimization plan.</p>"},{"location":"reference/plan_config/#ropt.config.plan.OptimizerStepConfig","title":"<code>OptimizerStepConfig</code>","text":"<p>The primary configuration class for an optimizer step.</p> <p>This configuration class is utilized within an optimization plan to specify that an optimizer should be executed.</p> <p>The optional <code>nested_plan</code> field can be employed to specify nested optimization plans that should be executed by the optimizer during each function evaluation. The <code>nested_result</code> is mandatory in this case and indicates which result tracker should be used to retrieve the final result of the nested optimization.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>Optional[str]</code> <p>Optional ID of the step.</p> <code>nested_plan</code> <code>Optional[PlanConfig]</code> <p>Optional nested optimization plan.</p> <code>nested_result</code> <code>Optional[str]</code> <p>The optimal nested result.</p>"},{"location":"reference/plan_config/#ropt.config.plan.TrackerStepConfig","title":"<code>TrackerStepConfig</code>","text":"<p>The configuration class for tracker steps.</p> <p>This configuration class is used within an optimization plan to specify a tracker object. The <code>source</code> option identifies the steps that produce the results to track. The <code>type</code> option determines what type of result is tracked:</p> <ul> <li><code>optimal</code> : The optimal result produced so far</li> <li><code>last</code>    : The last result produced</li> </ul> <p>If <code>constraint_tolerance</code> is given, the results are tested against this tolerance to filter out constraint violations.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The ID of the step</p> <code>source</code> <code>Union[str, Set[str]]</code> <p>Labels(s) of the step(s) that produce results</p> <code>type</code> <code>Union[str, Set[str]]</code> <p>What type of result to track</p> <code>constraint_tolerance</code> <code>Optional[float]</code> <p>Optional constraint tolerance</p>"},{"location":"reference/plan_config/#ropt.config.plan.RestartStepConfig","title":"<code>RestartStepConfig</code>","text":"<p>The configuration class for restart steps.</p> <p>This configuration class is employed within an optimization plan to specify that the plan should restart from the beginning at that point. The <code>max_restarts</code> field is utilized to determine the maximum number of times the plan is allowed to restart. For instance, with <code>max_restarts=1</code>, the plan will run twice up to the restart step. If the plan has already restarted <code>max_restarts</code> times, it will proceed with the next step after the restart step or finish if it was the last step.</p> <p>The <code>label</code> fields is optional and gives the ID of a label step. If given, the plan will restart at the position of the given label step.</p> <p>The <code>metadata_key</code> field can be used to provide a key into the metadata dictionary of every result produced during the restart. If present, the index of the current restart round will be added to the metadata with that key.</p> <p>Attributes:</p> Name Type Description <code>max_restarts</code> <code>int</code> <p>The maximum number of restarts</p> <code>label</code> <code>Optional[str]</code> <p>Label of the step to restart at</p> <code>metadata_key</code> <code>Optional[str]</code> <p>Optional key to use for storing a restart index</p>"},{"location":"reference/plan_config/#ropt.config.plan.UpdateConfigStepConfig","title":"<code>UpdateConfigStepConfig</code>","text":"<p>Configuration class for update steps.</p> <p>This class is employed within an optimization plan to modify the configuration of optimizer or evaluation steps that follow it.</p> <p>It can also be used to set initial variables from a tracker. The <code>initial_variables</code> field should contain the ID of a tracker step within the plan. The new values of the variables will be retrieved from the result tracked by the specified step.</p> <p>Attributes:</p> Name Type Description <code>updates</code> <code>Dict[str, Any]</code> <p>: Updates for the configuration</p> <code>initial_variables</code> <code>Optional[str]</code> <p>Step to set the initial variables from</p>"},{"location":"reference/plan_config/#ropt.config.plan.EvaluatorStepConfig","title":"<code>EvaluatorStepConfig</code>","text":"<p>Configuration class for evaluation steps.</p> <p>An evaluator step performs a single function evaluation using the optimization configuration currently set by the step.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>Optional[str]</code> <p>Optional ID of the step</p> Info <p>This configuration class has its <code>extra</code> property set to <code>\"allow\"</code>, as it is expected that external code may parse additional fields for further configuration.</p>"},{"location":"reference/plugins/","title":"Plugin manager","text":""},{"location":"reference/plugins/#ropt.plugins","title":"<code>ropt.plugins</code>","text":"<p>The <code>plugins</code> module facilitates the integration of <code>ropt</code> plugins.</p> <p>The core functionality of <code>ropt</code> can be extended through plugins, which can either be built-in, separately installed, or dynamically added at runtime.</p> <p>Various types of plugins provide specific functionalities. Currently, <code>ropt</code> supports the following plugin types:</p> <ol> <li><code>optimizer</code>:     Plugins that implement specific optimization methods.</li> <li><code>sampler</code>:     Plugins responsible for generating perturbations.</li> <li><code>realization_filter</code>:     Filters used to determine subsets of realizations.</li> <li><code>function_transform</code>:     Code used to compute objective and constraint values from realizations.</li> <li><code>optimization_step</code>:     Steps evaluated within an optimization plan.</li> </ol> <p>Plugins are managed by the <code>PluginManager</code> class. They can be built-in, installed separately using the standard entry points mechanism, or added dynamically using the <code>add_plugins</code> method. Protocols or abstract classes define the interface that plugin code must adhere to in order to implement the required functionality.</p> <p>The plugin manager object provides the <code>get_plugin</code> method, which <code>ropt</code> uses to retrieve the necessary plugin based on its type and name. Given the plugin's type and name, this method returns a callable (either a class or a factory function) that <code>ropt</code> uses to instantiate the plugin when needed.</p>"},{"location":"reference/plugins/#ropt.plugins.PluginType","title":"<code>PluginType = Literal['optimizer', 'sampler', 'realization_filter', 'function_transform', 'optimization_step']</code>  <code>module-attribute</code>","text":"<p>Plugin Types Supported by <code>ropt</code></p> <p><code>ropt</code> supports various types of plugins for different functionalities:</p> <code>optimizer</code>: These plugins implement optimizer plugins providing optimization methods.   The default plugin is <code>scipy</code>, utilizing the   <code>scipy.optimize</code>   module. <code>sampler</code>: These plugins implement sampler plugins generating perturbations for   estimating gradients. By default, a plugin based on   <code>scipy.stats</code> is   installed: <code>realization_filter</code>: These plugins implement filters for selecting a sub-set of realizations used   in calculating objective or constraint functions and their gradients. The   default plugin provides filters based on ranking and for CVaR optimization. <code>function_transform</code>: These plugins implement the final objective and gradient from sets of   objectives or constraints and their gradients for individual realizations. The   default built-in plugin supports objectives defined by the mean or standard   deviation of these values. <code>optimization_step</code>: Optimization step plugins implement the steps evaluated during the execution   plan. The built-in plugin offers a full set of steps for executing complex   plans."},{"location":"reference/plugins/#ropt.plugins.PluginManager","title":"<code>PluginManager</code>","text":"<p>The plugin manager.</p>"},{"location":"reference/plugins/#ropt.plugins.PluginManager.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the plugin manager.</p> <p>The plugin manager object is initialized via the entry points mechanism (see <code>importlib.metadata</code>).</p> <p>For instance, to install an additional optimizer plugin, implemented in an independent package, and assuming installation via a <code>pyproject.toml</code> file, add the following:</p> <pre><code>[project.entry-points.\"ropt.plugins.optimizer\"]\nmy_optimizer = \"my_optimizer_pkg.my_plugin:MyOptimizer\"\n</code></pre> <p>This will make the <code>MyOptimizer</code> class from the <code>my_optimizer_pkg</code> package available under the name <code>my_optimizer</code>.</p> <p>Plugins can also be added dynamically using the add_plugins method.</p>"},{"location":"reference/plugins/#ropt.plugins.PluginManager.add_plugins","title":"<code>add_plugins(plugin_type, plugins)</code>","text":"<p>Add a plugin at runtime.</p> <p>This method adds one or more plugins of a specific type to the plugin manager. The <code>plugins</code> argument maps the names of the new plugins to a callable that creates the plugin. The callable can be any function or class that creates a plugin object.</p> <p>The plugin names are case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>Type of the plugin.</p> required <code>plugins</code> <code>Dict[str, PluginProtocol]</code> <p>Dictionary of plugins.</p> required"},{"location":"reference/plugins/#ropt.plugins.PluginManager.get_plugin","title":"<code>get_plugin(plugin_type, method)</code>","text":"<p>Retrieve a plugin by type and method name.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of the plugin to retrieve.</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin should provide.</p> required"},{"location":"reference/plugins/#ropt.plugins.PluginManager.is_supported","title":"<code>is_supported(plugin_type, method)</code>","text":"<p>Check if a method is supported.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of the plugin to retrieve.</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin should provide.</p> required"},{"location":"reference/realization_filters/","title":"Realization filters","text":""},{"location":"reference/realization_filters/#ropt.plugins.realization_filter","title":"<code>ropt.plugins.realization_filter</code>","text":"<p>Plugin functionality for adding realization filters.</p> <p>This package contains the protocol that must be followed by realization filter plugins, and the default realization filters that are part of <code>ropt</code>.</p> <p>Realization filters are used by the optimizer to determine how a set of realizations should be used to calculate objective and constraint function values. They do this by calculating the weights that should be used for each realization when calculating the values of a given set of objectives and constraints.</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.protocol","title":"<code>ropt.plugins.realization_filter.protocol</code>","text":"<p>This module defines the protocol to be followed by realization filters.</p> <p>Realization filters can be added via the plugin mechanism to implement additional ways to filter the realizations that are used to calculate functions and gradients. Any object that follows the <code>RealizationFilter</code> protocol may be installed as a plugin.</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.protocol.RealizationFilterProtocol","title":"<code>RealizationFilterProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for realization filter classes.</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.protocol.RealizationFilterProtocol.__init__","title":"<code>__init__(enopt_config, filter_index)</code>","text":"<p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>filter_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.protocol.RealizationFilterProtocol.get_realization_weights","title":"<code>get_realization_weights(objectives, constraints)</code>","text":"<p>Return the updated weights of the realizations.</p> <p>This method is called by the optimizer with the current values of the objectives and constraints. Based on these values it must decide how much weight each realization should be given, and return those as a vector.</p> <p>The objectives and the constraints are passed as matrix, where the columns contain the values of the objectives or constraints. The index along the row axis corresponds to the number of the realization.</p> Normalization <p>The weights will be normalized to a sum of one by the optimizer before use, hence any non-negative weight value is permissable.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objectives of all realizations</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The constraints for all realizations</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A vector of weights of the realizations.</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.protocol.RealizationFilterPluginProtocol","title":"<code>RealizationFilterPluginProtocol</code>","text":"<p>               Bases: <code>PluginProtocol</code>, <code>Protocol</code></p> <p>RealizationFilter plugin protocol.</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.protocol.RealizationFilterPluginProtocol.create","title":"<code>create(enopt_config, filter_index)</code>","text":"<p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>filter_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.default","title":"<code>ropt.plugins.realization_filter.default</code>","text":"<p>This plugin contains realization filters that are installed by default.</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.default.DefaultRealizationFilter","title":"<code>ropt.plugins.realization_filter.default.DefaultRealizationFilter</code>","text":"<p>               Bases: <code>RealizationFilterProtocol</code></p> <p>The default realization filter plugin class.</p> <p>This plugin currently implements four methods:</p> <code>sort-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>SortObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects the set of realizations from a given index range. <code>sort-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>SortConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects the set of    realizations from a given index range. <code>cvar-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>CVaRObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects a percentile of the realizations, applying interpolation whenever    the number of selected realizations is not an integer number. <code>cvar-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>CVaRConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects a    percentile of the realizations, applying interpolation whenever the    number of selected realizations is not an integer number."},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.default.SortObjectiveOptions","title":"<code>ropt.plugins.realization_filter.default.SortObjectiveOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-objective</code> method.</p> <p>The <code>sort-objective</code> method sorts realizations according to the value of one or multiple objectives, and retains a number of realizations within a given index range in the sorted list. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>List[Union[StrictStr, NonNegativeInt]]</code> <p>The indices of the objectives to sort</p> <code>first</code> <code>NonNegativeInt</code> <p>Index of the first realization to use</p> <code>last</code> <code>NonNegativeInt</code> <p>Index of the last realization to use</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.default.SortConstraintOptions","title":"<code>ropt.plugins.realization_filter.default.SortConstraintOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-constraint</code> method.</p> <p>The <code>sort-constraint</code> method sorts realizations according to the value of a constraint, and retains a number of realizations within a given index range in the sorted list.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>Union[StrictStr, NonNegativeInt]</code> <p>The index of the constraint to sort</p> <code>first</code> <code>NonNegativeInt</code> <p>Index of the first realization to use</p> <code>last</code> <code>NonNegativeInt</code> <p>Index of the last realization to use</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.default.CVaRObjectiveOptions","title":"<code>ropt.plugins.realization_filter.default.CVaRObjectiveOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-objective</code> method.</p> <p>The <code>cvar-objective</code> method finds realizations weights by applying the CVaR method to the objective values. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. \"Worst\" is defined as those realizations having the highest values in case of a minimization and those having the lowest values in case of maximizing.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>List[Union[StrictStr, NonNegativeInt]]</code> <p>The indices of the objectives to sort</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile</p>"},{"location":"reference/realization_filters/#ropt.plugins.realization_filter.default.CVaRConstraintOptions","title":"<code>ropt.plugins.realization_filter.default.CVaRConstraintOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-constraint</code> method.</p> <p>The <code>cvar-constraint</code> method finds realizations weights by applying the CVaR method to the objective values.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. The definition of worst depends on the type of the constraints. After subtracting the right-hand-side value the following applies:</p> <ul> <li>For LE constraints, realizations with the largest values are the worst</li> <li>For GE constraints, realizations with the smallest values are the worst</li> <li>For EQ constraints, realizations with the largest absolute values are the worst</li> </ul> <p>Attributes:</p> Name Type Description <code>sort</code> <code>Union[StrictStr, NonNegativeInt]</code> <p>The index of the constraint to sort</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile</p>"},{"location":"reference/reporting/","title":"Reporting","text":""},{"location":"reference/reporting/#ropt.report","title":"<code>ropt.report</code>","text":"<p>Classes for reporting optimization results.</p> <p>The classes in this module are designed to gather multiple results generated during the execution of an optimization workflow. Currently, the results can be reported as a <code>pandas</code> DataFrame using the <code>ResultsDataFrame</code> class, or as a text file in a tabular format using the <code>ResultsTable</code> class.</p>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame","title":"<code>ResultsDataFrame</code>","text":"<p>Generate a results report in a <code>pandas</code> DataFrame.</p> <p>The class is intended to be used for gathering results from <code>Results</code> objects and storing them as a <code>pandas</code> DataFrame.</p> <p>New results can be added to the stored DataFrame as they become available using the <code>add_results</code> method. The content of the DataFrame is taken from the fields of the <code>Results</code> objects passed during each call to <code>add_results</code>. The updated table can be retrieved at any time via the <code>frame</code> property.</p>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame.frame","title":"<code>frame: pd.DataFrame</code>  <code>property</code>","text":"<p>Return the function results generated so far.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas data frame with the results.</p>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame.__init__","title":"<code>__init__(fields, *, table_type='functions')</code>","text":"<p>Initialize a ResultsDataFrame object.</p> <p>The set of fields used is determined by the <code>results_fields</code> argument passed when initializing the object. These can be any of the fields defined in a <code>FunctionResults</code> or a <code>GradientResults</code>. Most of the fields in these objects are nested, and the fields to export must be specified specifically in the form <code>field.subfield</code>. For instance, to specify the <code>variables</code> field of the <code>evaluations</code> field from a function result, the specification would be <code>evaluations.variables</code>.</p> <p>Note that many fields may, in fact, generate multiple columns in the resulting data frame. For instance, when specifying <code>evaluations.variables</code>, a column will be generated for each variable. If available, names specified in the optimizer configuration, such as variable names, will be used as column labels. Because the exported fields may be multi-dimensional with names defined along each axis, for instance, realizations and objectives, which both can be named, the final name may consist of a tuple of names.</p> <p>The <code>table_type</code> argument is used to determine which type of results should be reported: either function evaluation results (<code>functions</code>) or gradient results (<code>gradients</code>).</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Set[str]</code> <p>The fields of the results to store</p> required <code>table_type</code> <code>Literal['functions', 'gradients']</code> <p>The type of the table</p> <code>'functions'</code>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame.add_results","title":"<code>add_results(config, results)</code>","text":"<p>Add results to the table.</p> <p>This method can be called directly from any observers connected to events that produce results (see <code>add_observer</code>).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer generating the results</p> required <code>results</code> <code>Tuple[Results, ...]</code> <p>The results to add</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if a result was added, else False</p>"},{"location":"reference/reporting/#ropt.report.ResultsTable","title":"<code>ResultsTable</code>","text":"<p>               Bases: <code>ResultsDataFrame</code></p> <p>Generate files containing tables of optimization results.</p> <p>This class derives from the <code>ResultsDataFrame</code> class and writes the generated data frame in a tabular format to a text file.</p>"},{"location":"reference/reporting/#ropt.report.ResultsTable.__init__","title":"<code>__init__(columns, path, *, filters=None, table_type='functions', min_header_len=None)</code>","text":"<p>Initialize a results table.</p> <p>The <code>columns</code> parameter specifies which results are to be exported. The keys of the <code>columns</code> dictionary correspond to the <code>fields</code> parameter of the <code>ResultsDataFrame</code> parent class. The values are the corresponding titles of the columns of the table that is generated. As described in the documentation of the parent class, a single field may generate multiple columns, each with unique names (i.e., variable names). These are handled by adding the name to the column name below the main title. As a result, the header may consist of multiple lines, and the number of lines may vary according to requested fields. For a consistent result, the minimum number of header lines can be specified via the <code>min_header_len</code> argument. When needed, blank lines will be added to reach the specified minimum number of header lines.</p> <p>The optional <code>filters</code> argument can be used to pass functions that can be used to filter the rows before generating the table. The keys of the <code>filters</code> dictionary should be the columns to apply the filter function to, and the values the filter functions, which should expect a pandas series and transform those into an equally sized series of boolean values. For example, to retain only realizations with the name equal to 2:</p> <p><code>python filters = {\"realization\": lambda x: x == 2}</code></p> Reading the generated file. <p>The resulting table can be read using a reader that can handle fixed-width columns, such as the read_fwf function of pandas. However, the header will need to skip a number of header lines. The min_header_len argument can be used to set the minimum number of lines in the header. If the generated header has fewer lines than min_header_len, empty lines will be added. For example:</p> <pre><code># For a table generated with `min_header_len=3`:\nresults = pd.read_fwf(\n    \"results.txt\",\n    header=list(range(3)),\n    skip_blank_lines=False,\n    skiprows=[3],\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Dict[str, str]</code> <p>Mapping of column names for the results table</p> required <code>path</code> <code>Path</code> <p>Optional location of the result file</p> required <code>filters</code> <code>Optional[Dict[str, Callable[[Series[Any]], Series[bool]]]]</code> <p>Optional filter functions to remove rows</p> <code>None</code> <code>table_type</code> <code>Literal['functions', 'gradients']</code> <p>Type of the table</p> <code>'functions'</code> <code>min_header_len</code> <code>Optional[int]</code> <p>Minimal number of header lines</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the pandas or tabulate modules are not                  available</p>"},{"location":"reference/reporting/#ropt.report.ResultsTable.add_results","title":"<code>add_results(config, results)</code>","text":"<p>Add results to the table.</p> <p>This method can be called directly from any observers connected to events that produce results (see <code>add_observer</code>).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer generating the results</p> required <code>results</code> <code>Tuple[Results, ...]</code> <p>The results to add</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if a result was added, else False</p>"},{"location":"reference/results/","title":"Optimization results","text":""},{"location":"reference/results/#ropt.results","title":"<code>ropt.results</code>","text":"<p>Data Classes for Storing Intermediate Optimization Results.</p> <p>During the optimization process, functions and gradients are calculated and need to be reported. To streamline this process, events are triggered after new results become available, invoking connected callbacks with those results (see <code>EnsembleOptimizer.add_observer</code>). The <code>OptimizationEvent</code> object passed to the callbacks contains a <code>results</code> field, which consists of a tuple of <code>Results</code> objects. These may be instances of the derived <code>FunctionResults</code> or <code>GradientResults</code> classes, containing results for function and gradient evaluations, respectively.</p> <p>These classes are nested <code>dataclasses</code> with some added features:</p> <ul> <li>Variables may have scaling and offset factors associated with them. The   optimization will generally deal with scaled values. When the results object   is created, and variable scaling is configured, the values are scaled back and   added to the results object.</li> <li>Objective and constraint function values may also have a scaling factor   associated with them. These are generally handled in unscaled form, and when   the report object is created, scaled values are added.</li> <li>Methods are available to export the results to   <code>pandas</code> data frames or   <code>xarray</code> data sets.</li> <li>Methods are added to write and read netCDF version 4 files using the   <code>netcdf4</code> Python package.</li> </ul> <p>Much of the data stored in the result objects is of a multi-dimensional nature. For instance, the <code>objectives</code> field, which is part of the nested <code>evaluations</code> object in the <code>FunctionResults</code> object, is a two-dimensional <code>numpy</code> array. In this array, the columns correspond to the objectives, and the rows correspond to the realization number.</p> <p>To facilitate exporting and reporting the results, the identity of the axes in such multi-dimensional arrays is stored in metadata associated with the corresponding field. These fields derive from the <code>ResultField</code> class, which has a <code>get_axis_names</code> class method to retrieve the names. For the <code>objectives</code> example above, this retrieves the axis names:</p> <pre><code>&gt;&gt;&gt; from ropt.results import FunctionEvaluations\n&gt;&gt;&gt; FunctionEvaluations.get_axis_names(\"objectives\")\n(&lt;ResultAxisName.REALIZATION: 'realization'&gt;, &lt;ResultAxisName.OBJECTIVE: 'objective'&gt;)\n</code></pre> <p>Using this metadata, exporting or reporting code can refer to the optimizer configuration to associate realization and objective names with any entry in the result matrix. For instance, the <code>pandas</code> exporting code will use this to construct a multi-index for the generated data frame and optionally unstack such multi-dimensional data into multiple columns.</p>"},{"location":"reference/results/#ropt.results.Results","title":"<code>ropt.results.Results</code>  <code>dataclass</code>","text":"<p>The <code>Results</code> class serves as a base class for storing results.</p> <p>This class contains the following generic information:</p> <ol> <li>The evaluation ID, a unique integer value that is incremented as the    results become available.</li> <li>An optional batch ID, which may be generated by the function evaluator.    The interpretation of this ID depends on the evaluator code. It is    intended to be used as a unique identifier for the group of function    evaluations passed to the evaluator by the optimization code.</li> <li>A dictionary of metadata to be added by optimization steps. This contains    generic information, the nature of which depends on the steps producing    them. They are expected to be primitive values not interpreted by the    optimization code but can be exported and reported.</li> </ol> <p>Attributes:</p> Name Type Description <code>result_id</code> <code>int</code> <p>The ID of the function/gradient evaluation.</p> <code>batch_id</code> <code>Optional[int]</code> <p>The ID of the evaluation batch that contains the result.</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>The metadata.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataframe","title":"<code>to_dataframe(config, field_name, select=None, unstack=None)</code>","text":"<p>Export a field to a pandas dataframe.</p> <p>The function exports the values of a single field to a pandas data frame. The field to export is selected by the <code>field_name</code> argument. In general such a field is another data frame object with multiple fields. By default, these are all exported as columns in the pandas data frame, but a sub-set can be selected using the <code>select</code> argument.</p> <p>Any of the sub-fields in the field that is exported may be a multi-dimensional array, which is exported in a stacked manner. Using the axis types found in the metadata, the exporter will construct a multi-index labeled with the corresponding names found in the optimizer configuration (if available, otherwise numerical indices are used). Such multi-indices can optionally be unstacked into multiple columns by providing the axis types to unstack via the <code>unstack</code> argument.</p> The data frame index <p>As noted above, the index of the resulting data frame may be a multi-index constructed from axis indices or labels. In addition, the <code>result_id</code> field, and the <code>batch_id</code> (if not None), are also prepended to the index of the resulting frame. This has the beneficial effect that the data frames exported from multiple results can be concatenated and identified in the frame by result ID and/or batch ID.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>field_name</code> <code>str</code> <p>The field to export</p> required <code>select</code> <code>Optional[Iterable[str]]</code> <p>Select the sub-fields to export, by default all fields</p> <code>None</code> <code>unstack</code> <code>Optional[Iterable[ResultAxisName]]</code> <p>Select axes to unstack, by default none</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the pandas module is not installed.</p> <code>ValueError</code> <p>If the field name is incorrect.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas data frame containing the results.</p> Warning <p>This function is only available if <code>pandas</code> is installed.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataset","title":"<code>to_dataset(config, field_name, select=None, *, add_metadata=False)</code>","text":"<p>Export a field to an xarray dataset.</p> <p>The function exports the values of a single field to an xarray dataset. The field to export is selected by the <code>field_name</code> argument. In general, such a field is another data frame object with multiple fields. By default, these are all exported as data arrays in the xarray dataset, but a subset can be selected using the <code>select</code> argument.</p> <p>Any of the sub-fields in the field that is exported may be a multi-dimensional array, which is exported directly as an xarray data array. Using the axis types found in the metadata, the exporter will add coordinate labels constructed from the corresponding names found in the optimizer configuration (if available).</p> <p>The result ID and the batch ID (if not None) are added to the attributes of the dataset, using the <code>result_id</code> and <code>batch_id</code> keys. If metadata is present in the results, and the <code>add_metadata</code> flag is set, it is also added under the <code>metadata</code> key.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>field_name</code> <code>str</code> <p>The field to export</p> required <code>select</code> <code>Optional[Iterable[str]]</code> <p>Select the fields to export; by default, all fields</p> <code>None</code> <code>add_metadata</code> <code>bool</code> <p>If true, add the metadata as a field in the dataset attrs</p> <code>False</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>xarray</code> module is not installed.</p> <code>ValueError</code> <p>If the field name is incorrect.</p> <p>Returns:</p> Type Description <code>Dataset</code> <p>An xarray dataset containing the results.</p> Warning <p>This function is only available if <code>xarray</code> is installed.</p>"},{"location":"reference/results/#ropt.results.Results.to_netcdf","title":"<code>to_netcdf(config, filename)</code>","text":"<p>Write the results to a netCDF4 file.</p> <p>The fields of the result are converted to xarray datasets and each stored as a group in a netCDF4 file, using the name of the field as the group name. In addition, a special <code>__metadata__</code> group is added that contains the result ID, the batch ID (if not None), and a JSON dump of the metadata.</p> <p>By default, a file is written with a <code>.nc</code> extension. The filename may contain a replacement field for a variable named <code>result_id</code> or <code>batch_id</code>, which will be replaced by the corresponding field using the <code>format</code> string method. For example: <code>filename=\"results-{result_id:04d}\"</code> will result in a file named <code>results-0001.nc</code> if the result ID equals 1.</p> Reading results from a netCDF4 file <p>The results may be read back using the <code>from_netcdf</code> class method of either <code>FunctionResults</code> or <code>GradientResults</code>. Currently, no information is written about whether the results were function or gradient results. Therefore, to read back the result with the correct class, its type must be known.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration used to run the optimization.</p> required <code>filename</code> <code>Union[str, Path]</code> <p>The name of the file to write.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>xarray</code> or the <code>netCDF4</code> module is not installed.</p> Warning <p>Use of this method requires that the <code>xarray</code> and <code>netCDF4</code> modules are installed.</p>"},{"location":"reference/results/#ropt.results.ResultField","title":"<code>ropt.results.ResultField</code>  <code>dataclass</code>","text":"<p>Base class for <code>Results</code> fields.</p>"},{"location":"reference/results/#ropt.results.ResultField.get_axis_names","title":"<code>get_axis_names(name)</code>  <code>classmethod</code>","text":"<p>Return the axis names of a field in the given field class or object.</p> <p>When used with the class or an instance of that class for one of the fields of a <code>Results</code> object, retrieve the names of the axes of the stored <code>numpy</code> array from the metadata and return them.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the sub-field in the instance or class</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if an unknown field name is passed.</p> <p>Returns:</p> Type Description <code>Tuple[ResultAxisName, ...]</code> <p>A tuple listing the names of the axes.</p>"},{"location":"reference/results/#ropt.results.FunctionResults","title":"<code>ropt.results.FunctionResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>The <code>FunctionResults</code> class stores function related results.</p> <p>This class contains  the following additional information:</p> <ol> <li>The results of the function evaluations.</li> <li>The parameters of the realizations, such as weights for objectives and    constraints, and realization failures.</li> <li>The calculated objective and constraint function values.</li> <li>Information on constraint values and violations.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>evaluations</code> <code>FunctionEvaluations</code> <p>Results of the function evaluations</p> required <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations</p> required <code>functions</code> <code>Optional[Functions]</code> <p>The calculated functions</p> required <code>bound_constraints</code> <code>Optional[BoundConstraints]</code> <p>Bound constraints</p> <code>None</code> <code>linear_constraints</code> <code>Optional[LinearConstraints]</code> <p>Linear constraints</p> <code>None</code> <code>nonlinear_constraints</code> <code>Optional[NonlinearConstraints]</code> <p>Nonlinear constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.FunctionResults.from_netcdf","title":"<code>from_netcdf(filename)</code>  <code>classmethod</code>","text":"<p>Read results from a netCDF4 file.</p> <p>Use of this method requires that the <code>xarray</code> and <code>netCDF4</code> modules are installed.</p> <p>The filename is assumed to have an \".nc\" extension, which will be added if not present.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>The name or path of the file to read.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the xarray or the netCDF4 module is not installed.</p> <p>Returns:</p> Type Description <code>Results</code> <p>The loaded result.</p> Warning <p>This function is only available if <code>xarray</code> and <code>netCDF4</code> are installed.</p>"},{"location":"reference/results/#ropt.results.FunctionEvaluations","title":"<code>ropt.results.FunctionEvaluations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class contains the results of evaluations for function calculation.</p> <p>This class stores the variables with the calculated objective and constraint functions. It contains the following information:</p> <ol> <li>The vector of variables at which the functions are evaluated.</li> <li>The calculated objectives and constraints for each realization: A    two-dimensional array, with the objective or constraint values arranged    along the second axis. The first axis index indicates the realization    number.</li> <li>Unscaled versions of the variables if variable scaling was enabled.</li> <li>Scaled versions of the objective and constraint values if scaling was    enabled.</li> <li>Optional evaluation IDs that may have been passed from the evaluator,    identifying each calculated realization.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>The objective functions for each realization.</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The constraint functions for each realization.</p> <code>None</code> <code>unscaled_variables</code> <code>Optional[NDArray[float64]]</code> <p>Optional variables after scaling back.</p> <code>None</code> <code>scaled_objectives</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled objectives.</p> <code>None</code> <code>scaled_constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled constraints.</p> <code>None</code> <code>evaluation_ids</code> <code>Optional[NDArray[intc]]</code> <p>Optional id of each evaluated realization.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.Realizations","title":"<code>ropt.results.Realizations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores information on the realizations.</p> <p>The <code>failed_realizations</code> field is a boolean array that indicates for each realization whether the evaluation was successful or not.</p> <p>Depending on the type of objective or constraint calculation, the weights used for the realizations may change during optimization. This class stores for each objective and constraint a vector of weight values.</p> <p>All fields are two-dimensional matrices, where the first axis index denotes the function or constraint. The second axis index denotes the realization.</p> <p>Parameters:</p> Name Type Description Default <code>failed_realizations</code> <code>NDArray[bool_]</code> <p>Failed realizations</p> required <code>objective_weights</code> <code>Optional[NDArray[float64]]</code> <p>Realization weights for the objectives</p> <code>None</code> <code>constraint_weights</code> <code>Optional[NDArray[float64]]</code> <p>Realization weights for the constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.Functions","title":"<code>ropt.results.Functions</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Store the calculated objective and constraint functions.</p> <p>The objective and constraint functions used by the optimizer are calculated from their values evaluated for all realizations, for instance by averaging. There may be multiple objectives and constraints. Multiple objectives are handled by the optimizer using a weighted sum, stored in the <code>weighted_objective</code> field. Multiple constraints are directly handled by the optimizer.</p> <p>If scaling of objectives and/or constraint functions is enabled, also scaled versions of the objective or constraint values are stored.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objectives</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each objective</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The value of each constraint</p> <code>None</code> <code>scaled_objectives</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled objectives.</p> <code>None</code> <code>scaled_constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled constraints.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.BoundConstraints","title":"<code>ropt.results.BoundConstraints</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores bound constraint values and violations.</p> <p>The following information is stored:</p> <ol> <li>Differences between the current variable and the lower or upper bounds.</li> <li>Violations of constraints, defined as the absolute value of the    difference if the constraint is violated, or else zero.</li> <li>If variable scaling is configured, unscaled versions of all values.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>lower_values</code> <code>Optional[NDArray[float64]]</code> <p>Lower bound differences</p> <code>None</code> <code>lower_violations</code> <code>Optional[NDArray[float64]]</code> <p>Lower bound violations</p> <code>None</code> <code>upper_values</code> <code>Optional[NDArray[float64]]</code> <p>Upper bound differences</p> <code>None</code> <code>upper_violations</code> <code>Optional[NDArray[float64]]</code> <p>Upper bound violations</p> <code>None</code> <code>unscaled_lower_values</code> <code>Optional[NDArray[float64]]</code> <p>Optional unscaled lower bound differences</p> <code>None</code> <code>unscaled_lower_violations</code> <code>Optional[NDArray[float64]]</code> <p>Optional unscaled lower bound violations</p> <code>None</code> <code>unscaled_upper_values</code> <code>Optional[NDArray[float64]]</code> <p>Optional unscaled upper bound differences</p> <code>None</code> <code>unscaled_upper_violations</code> <code>Optional[NDArray[float64]]</code> <p>Optional unscaled upper bound violations</p> <code>None</code>"},{"location":"reference/results/#ropt.results.LinearConstraints","title":"<code>ropt.results.LinearConstraints</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores constraint values and violations.</p> <p>The following information is stored:</p> <ol> <li>Differences between the linear constraints and their right-hand-side    values.</li> <li>Violations of constraints, defined as the absolute value of the    difference if the constraint is violated, or else zero.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Optional[NDArray[float64]]</code> <p>Linear constraint values</p> <code>None</code> <code>violations</code> <code>Optional[NDArray[float64]]</code> <p>Violations of the linear constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.NonlinearConstraints","title":"<code>ropt.results.NonlinearConstraints</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores constraint values and violations.</p> <p>The following information is stored:</p> <ol> <li>Differences between the non-linear constraints and their right-hand-side    values.</li> <li>Violations of constraints, defined as the absolute value of the    difference if the constraint is violated, or else zero.</li> <li>Scaled versions for these values.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Optional[NDArray[float64]]</code> <p>Non-linear constraint values</p> <code>None</code> <code>violations</code> <code>Optional[NDArray[float64]]</code> <p>Violations of the nonlinear constraints</p> <code>None</code> <code>scaled_values</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled non-linear constraint values</p> <code>None</code> <code>scaled_violations</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled violations of the nonlinear constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.GradientResults","title":"<code>ropt.results.GradientResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>The <code>GradientResults</code> class stores gradient related results.</p> <p>This contains  the following additional information:</p> <ol> <li>The results of the function evaluations for perturbed variables.</li> <li>The parameters of the realizations, such as weights for objectives and    constraints, and realization failures.</li> <li>The gradients of the calculated objectives and constraints.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>evaluations</code> <code>GradientEvaluations</code> <p>Results of the function evaluations</p> required <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations</p> required <code>gradients</code> <code>Optional[Gradients]</code> <p>The calculated gradients</p> required"},{"location":"reference/results/#ropt.results.GradientResults.from_netcdf","title":"<code>from_netcdf(filename)</code>  <code>classmethod</code>","text":"<p>Read results from a netCDF4 file.</p> <p>Use of this method requires that the <code>xarray</code> and <code>netCDF4</code> modules are installed.</p> <p>The filename is assumed to have an \".nc\" extension, which will be added if not present.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>The name or path of the file to read.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the xarray or the netCDF4 module is not installed.</p> <p>Returns:</p> Type Description <code>TypeResults</code> <p>The loaded result.</p> Warning <p>This function is only available if <code>xarray</code> and <code>netCDF4</code> are installed.</p>"},{"location":"reference/results/#ropt.results.GradientEvaluations","title":"<code>ropt.results.GradientEvaluations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class contains the results of evaluations for gradient calculation.</p> <p>This class stores the variables with the calculated objective and constraints gradients. It contains the following information:</p> <ol> <li>The vector of variables at which the functions are evaluated.</li> <li>A three-dimensional array of perturbed variables, with variable values    arranged along the third axis. The second axis index indicates the    perturbation number, whereas the first axis index represents the    realization number.</li> <li>The objectives and constraints for each realization and perturbed    variable vector:  A three-dimensional array, with the objective or    constraint values arranged along the third axis. The second axis index    indicates the perturbation number, whereas the first axis index    represents the realization number.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> required <code>perturbed_variables</code> <code>NDArray[float64]</code> <p>The variables for each realization and perturbation.</p> required <code>perturbed_objectives</code> <code>NDArray[float64]</code> <p>The objective functions for each realization and                    perturbation.</p> required <code>perturbed_constraints</code> <code>Optional[NDArray[float64]]</code> <p>The constraint functions for each realization and                    perturbation.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.Gradients","title":"<code>ropt.results.Gradients</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores the calculated objective and constraint gradients.</p> <p>The objective and constraint gradients used by the optimizer are calculated from their values evaluated for all realizations, for instance by averaging. There may be multiple objectives and constraints. Multiple objectives are handled by the optimizer using a weighted sum of the individual gradients, stored in the <code>weighted_objective</code> field. Multiple constraints are directly handled by the optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective gradients</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each objective gradient</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The value of each constraint gradient</p> <code>None</code>"},{"location":"reference/sampler_plugins/","title":"Sampler plugins","text":""},{"location":"reference/sampler_plugins/#ropt.plugins.sampler","title":"<code>ropt.plugins.sampler</code>","text":"<p>Plugin functionality for adding sampler plugins.</p> <p>Sampler plugins are managed by a <code>PluginManager</code> object, which returns classes or factory functions to create objects that implement one or more sampling methods to produce perturbations. These objects must adhere to the <code>Sampler</code> protocol.</p> <p>Samplers can be added via the plugin manager, by default the <code>SciPySampler</code> plugin is installed which provides a number of methods from the <code>scipy.stats</code> package.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.protocol","title":"<code>ropt.plugins.sampler.protocol</code>","text":"<p>This module defines the protocol to be followed by samplers.</p> <p>Samplers can be added via the plugin mechanism to implement additional ways to generate perturbed variables. Any object that follows the <code>Sampler</code> protocol may be installed as a plugin.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.protocol.SamplerProtocol","title":"<code>SamplerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for sampler classes.</p> <p><code>ropt</code> employs plugins to implement samplers that are called during an optimization workflow to generate perturbed variable vectors. Samplers should adhere to the <code>Sampler</code> protocol, which specifies the requirements for the class constructor (<code>__init__</code>) and also includes a <code>generate_samples</code> method used to generate samples used to create perturbed values.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.protocol.SamplerProtocol.__init__","title":"<code>__init__(enopt_config, sampler_index, variable_indices, rng)</code>","text":"<p>Initialize the sampler object.</p> <p>The <code>samplers</code> field in the <code>enopt_config</code> configuration used by the optimization is a tuple of sampler configurations (see <code>SamplerConfig</code>). The <code>sampler_index</code> field is used to identify the configuration to use to initialize this sampler.</p> <p>The sampler may be used for a subset of the variables. The <code>variable_indices</code> array lists the indices of the variables that are handled by this sampler.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler to use.</p> required <code>variable_indices</code> <code>Optional[NDArray[intc]]</code> <p>The indices of the variables to sample.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for use by stochastic samplers.</p> required"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.protocol.SamplerProtocol.generate_samples","title":"<code>generate_samples()</code>","text":"<p>Return an array containing sampled values.</p> <p>The result should be a three-dimensional array of perturbation values. The variable values are stored along the last axis, for each realization and perturbation. The first axis indexes the realization, and the second axis indexes the perturbation.</p> <p>If the <code>shared</code> flag is set in the <code>SamplerConfig</code> configuration, the first dimension should have a length equal to one, since all realizations will use the same set of perturbations.</p> <p>The sampler may handle only a subset of the variables, as specified by the <code>variable_indices</code> argument of the constructor. In this case, only the corresponding values along the variables axis (the last axis) should be set, while other values should be zero.</p> Sample scaling <p>Samples will be multiplied by the values given by the <code>perturbation_magnitudes</code> field in the <code>gradients</code> section of the optimizer configuration. It makes therefore sense to generate samples that have an order of magnitude around one. For instance, by generating them on a <code>[-1, 1]</code> range, or with a unit standard deviation.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The sampled values.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.protocol.SamplerPluginProtocol","title":"<code>SamplerPluginProtocol</code>","text":"<p>               Bases: <code>PluginProtocol</code>, <code>Protocol</code></p> <p>Sampler plugin protocol.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.protocol.SamplerPluginProtocol.create","title":"<code>create(enopt_config, sampler_index, variable_indices, rng)</code>","text":"<p>Create a sampler.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler to use.</p> required <code>variable_indices</code> <code>Optional[NDArray[intc]]</code> <p>The indices of the variables to sample.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for use by stochastic samplers.</p> required"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.scipy.SciPySampler","title":"<code>ropt.plugins.sampler.scipy.SciPySampler</code>","text":"<p>               Bases: <code>SamplerProtocol</code></p> <p>Plugin class for producing sampling values via SciPy.</p> <p>This plugin implements the following sampling methods using the corresponding methods from the SciPy stats module:</p> <ul> <li> <p>Sampling from probability   distributions:</p> <code>uniform</code> Uniform distribution with a default range of [-1, 1]. <code>norm</code> Normal distribution with mean zero and standard deviation 1. <code>truncnorm</code> Truncated normal distribution with mean zero and standard   deviation 1 truncated a the range [-1, 1]. </li> <li> <p>Sampling using methods from the Quasi-Monte Carlo   submodule:</p> <code>sobol</code> Using Sobol sequences, scaled to -1 and 1. <code>halton</code> Using Halton sequences, scaled to -1 and 1. <code>lhs</code> Using Latin Hypercube sampling, scaled to -1 and 1. </li> </ul> <p>Specific options that are normally passed as arguments in the SciPy functions can be provided via the options dictionary in the configuration object. Consult the <code>scipy.stats</code> manual for details on these options.</p>"},{"location":"reference/utilities/","title":"Utilities","text":""},{"location":"reference/utilities/#ropt.utils","title":"<code>ropt.utils</code>","text":"<p>The <code>ropt.utils</code> module contains various utility functions.</p>"},{"location":"reference/utilities/#ropt.utils.update_dict","title":"<code>update_dict(mapping, values)</code>","text":"<p>Recursively update a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>Dict[str, Any]</code> <p>The dictionary to update</p> required <code>values</code> <code>Dict[str, Any]</code> <p>The values to be updated or added</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The updated dictionary.</p>"},{"location":"reference/utilities/#ropt.utils.scaling","title":"<code>ropt.utils.scaling</code>","text":"<p>Functions for scaling variables and functions.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_variables","title":"<code>scale_variables(config, variables, axis)</code>","text":"<p>Scale Back Variables.</p> <p>Given an ensemble optimizer configuration object and a vector of variables, this function applies an offset and scale to their values.</p> <p>As the <code>variables</code> input may be a multi-dimensional array, the index of the axis that designates the variables should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object.</p> required <code>variables</code> <code>NDArray[float64]</code> <p>The scaled variables.</p> required <code>axis</code> <code>int</code> <p>The variables axis.</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The unscaled variables, or <code>None</code> if no scaling is applied.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_back_variables","title":"<code>scale_back_variables(config, variables, axis, *, correct_offsets=True)</code>","text":"<p>Scale back variables.</p> <p>Given an ensemble optimizer configuration object and a vector of scaled variables, scale their values back to the original range. Normally this includes correcting for offsets, but if a difference value is being rescaled, the <code>correct_offsets</code> flag can be used to disable this.</p> <p>As the <code>variables</code> input may be a multi-dimensional array, the index of the axis that designates the variables should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>variables</code> <code>NDArray[float64]</code> <p>The scaled variables</p> required <code>axis</code> <code>int</code> <p>The variables axis</p> required <code>correct_offsets</code> <code>bool</code> <p>If True also correct for offsets.</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The unscaled variables, or <code>None</code> if no scaling is applied.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_objectives","title":"<code>scale_objectives(config, objectives, scales, axis)</code>","text":"<p>Scale Objective Functions.</p> <p>Given an ensemble optimizer configuration object, this function scales the provided objective values. It divides them by the scale values given in the configuration object (if not <code>None</code>), and optionally also by the values given in the <code>scales</code> argument.</p> <p>As the <code>objectives</code> input may be a multi-dimensional array, the index of the axis that designates the objectives should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object.</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>Objective functions.</p> required <code>scales</code> <code>Optional[NDArray[float64]]</code> <p>Optional additional scales.</p> required <code>axis</code> <code>int</code> <p>The objectives axis.</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The scaled objectives or <code>None</code> if no scaling was applied.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_constraints","title":"<code>scale_constraints(config, constraints, scales, axis)</code>","text":"<p>Scale constraint functions.</p> <p>Given an ensemble optimizer configuration object, this function scales the provided constraint values. It divides them by the scale values given in the configuration object (if not <code>None</code>), and optionally also by the values given in the <code>scales</code> argument.</p> <p>As the <code>constraints</code> input may be a multi-dimensional array, the index of the axis that designates the constraints should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>Constraint functions</p> required <code>scales</code> <code>Optional[NDArray[float64]]</code> <p>Optional additional scales.</p> required <code>axis</code> <code>int</code> <p>The constraints axis</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The scaled constraints or <code>None</code> if no scaling was applied.</p>"},{"location":"usage/robust_optimization/","title":"Introduction: Ensemble-based robust optimization","text":"<p>Constraint optimization is the process of optimizing an objective function \\(f(\\mathbf{x})\\) with respect to a vector of variables \\(\\mathbf{x}\\) in the presence of one or more inequality constraints \\(g_j(\\mathbf{x})\\) and/or equality constraints \\(h_k(\\mathbf{x})\\).</p> \\[ \\begin{align} \\textrm{minimize} \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{subject to} \\quad &amp; g_j(\\mathbf{x}) \\le 0, \\quad j=1, \\ldots, J \\\\ &amp; h_k(\\mathbf{x}) = 0, \\quad k=1, \\ldots, K \\\\ &amp; \\mathbf{x}^L \\le \\mathbf{x} \\le \\mathbf{x}^U \\end{align} \\] <p>In this context, the function \\(f(\\mathbf{x})\\) is assumed to have a deterministic nature, meaning it is well-defined for given parameters. However, in realistic scenarios, \\(f(\\mathbf{x})\\) may be part of a larger set of functions, especially if it depends on uncertain parameters drawn from some, possibly unknown, probability distribution.</p> <p>Ensemble-based robust optimization aims to optimize an ensemble of functions \\(f_i(\\mathbf{x})\\) with respect to \\(\\mathbf{x}\\). The set of realizations \\(f_i\\) captures the uncertainty that may exist in the model, which can be, for instance, constructed by varying some parameters according to a given probability distribution. When given a set of realizations, ensemble-based optimization proceeds by combining the functions \\(f_i(\\mathbf{x})\\) into a single objective function. For example, using a weighted sum, the problem becomes (ignoring constraints):</p> \\[ \\textrm{minimize} \\quad \\sum_i w_i f_i(\\mathbf{x}), \\] <p>where \\(w_i\\) represents the weights assigned to the different realizations. In more complex settings, the realizations may also be combined in different ways, and the set of realizations may be modified during optimization. For instance, risk-aware objectives may be constructed by minimizing the standard deviation of the functions or by selecting the worst-performing realizations at each iteration.</p> <p>In practice, the optimization task often becomes complex due to additional factors. The evaluation of functions might be computationally expensive, and calculating their gradients analytically can be challenging or even impossible. For example, the functions may involve lengthy simulations of a physical process with numerous variables, utilizing numerical calculations that preclude straightforward analytical differentiation.</p> <p><code>ropt</code> leverages standard optimization algorithms, such as those available in the SciPy package. These methods typically follow an iterative approach, necessitating repeated assessments of the objective function and, in many cases, its gradient. Currently, it is assumed that the functions are not easily differentiated analytically. One of the core functions of <code>ropt</code> is to calculate gradients efficiently using stochastic methods.</p> <p><code>ropt</code> is responsible for configuring and executing the optimization algorithm, building the overall function and gradient values from individual realizations, and monitoring both intermediate and final optimization results. It also offers the flexibility to delegate the actual calculations of functions to external code, for example, utilizing distributed resources like HPC clusters. <code>ropt</code> optionally provides its own code for this purpose.</p> <p>While many optimization scenarios involve a single run of a particular method, there are cases where it proves beneficial to conduct multiple runs using the same or different algorithms. For example, when dealing with a mix of continuous and discrete variables, it might be advantageous to employ different methods for each variable type. <code>ropt</code> facilitates this by offering a mechanism to run a workflow containing multiple optimizers, potentially of different types, in an alternating or nested fashion.</p>"},{"location":"usage/running/","title":"Running a basic optimization script","text":"<p>To demonstrate basic optimization with <code>ropt</code>, consider the Rosenbrock function, a standard test problem:</p> \\[ f(x,y) = (a - x)^2 + b (y = x^2)^2, \\] <p>which has a global minimum of \\(f(x, y) = 0\\) at \\((x, y) = (a, a^2)\\) .</p> <p>Here's an example optimizing the Rosenbrock function for \\(a = 1\\) and \\(b = 100\\):</p> <pre><code>import numpy as np\nfrom numpy.typing import NDArray\n\nfrom ropt.evaluator import EvaluatorContext, EvaluatorResult\nfrom ropt.optimization import EnsembleOptimizer\n\ndef rosenbrock(\n    variables: NDArray[np.float64],                                   # (1)!\n    context: EvaluatorContext                                         # (2)!\n) -&gt; EvaluatorResult:\n    objectives = np.zeros((variables.shape[0], 1), dtype=np.float64)\n    for idx in range(variables.shape[0]):\n        x, y = variables[idx, :]\n        objectives[idx, 0] = (1.0 - x) ** 2 + 100 * (y - x * x) ** 2\n    return EvaluatorResult(objectives=objectives)                     # (3)!\n\nCONFIG = {                                                            # (4)!\n    \"variables\": {\"initial_values\": [0.5, 2.0]},\n    \"gradient\": {\"perturbation_magnitudes\": 1e-6}                     # (5)!\n}\n\nPLAN = [                                                              # (6)!\n    {\"config\": CONFIG},                                               # (7)!\n    {\"optimizer\": {\"id\": \"opt\"}},                                     # (8)!\n    {\"tracker\": {\"id\": \"optimum\", \"source\": \"opt\"}},                  # (9)!\n]\n\noptimizer = EnsembleOptimizer(rosenbrock)                             # (10)!\noptimum = optimizer.start_optimization(plan=PLAN)                     # (11)!\n\nprint(\n    optimum.evaluations.variables,\n    optimum.functions.weighted_objective,\n)\n</code></pre> <ol> <li>The variables to optimize (\\(x, y\\)) are passes as a single <code>numpy</code> array. It    may receive multiple variable vectors to evaluate, hence the input is a    matrix where the variable vectors are the rows of the matrix.</li> <li>Additional information is passes via an    <code>EvaluatorContext</code> object. It is not    needed in this case.</li> <li>Results are returned via an    <code>EvaluatorResult</code> object. The objectives    result is a matrix since multiple input vectors and multiple objectives may    be evaluated.</li> <li>Create an optimizer configuration with default values except for initial    values and perturbation magnitudes.</li> <li>Set perturbation magnitudes to a small value for accurate gradient estimation.</li> <li>The optimization plan describes the steps used to run the optimization.</li> <li>Set the optimizer configuration.</li> <li>Run the optimizer (named <code>opt</code>).</li> <li>Define a tracker to receive results from the optimizer, identified as    <code>optimum</code> with the source set to <code>opt</code>.</li> <li>Create an <code>EnsembleOptimizer</code> object,     passing the <code>rosenbrock</code> function.</li> <li>Start the optimization using the given plan, returning the results from the     last tracker, a <code>FunctionResults</code> object.</li> </ol> <p>Running this will print the estimated optimal variables and the corresponding function value:</p> <pre><code>[0.99959301 0.99917614] 1.7574715576837572e-07\n</code></pre>"}]}