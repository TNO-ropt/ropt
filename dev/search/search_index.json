{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>ropt</code>: A Python module for robust optimization","text":"<p><code>ropt</code> is a module designed for implementing and executing robust optimization workflows. In classical optimization problems, a deterministic function is optimized. However, in robust optimization, the function is expected to exhibit a stochastic nature and is represented by an ensemble of functions (realizations) for different values of some (possibly unknown) random parameters. The optimal solution is then determined by optimizing the value of a statistic, such as the mean, over the ensemble.</p> <p><code>ropt</code> can be employed to construct optimization workflows directly in Python or as a building block in optimization applications. At a minimum, the user needs to provide additional code to calculate the values for each function realization in the ensemble. This can range from simply calling a Python function that returns the objective values to initiating a long-running simulation on an HPC cluster and reading the results. Furthermore, <code>ropt</code> exposes all intermediate results of the optimization, such as objective and gradient values, but functionality to report or store any of these values must be added by the user. Optional functionality to assist with this is included with <code>ropt</code>.</p> <p><code>ropt</code> provides several features for efficiently solving complex robust optimization problems:</p> <ul> <li>Robust optimization over an ensemble of models, i.e., optimizing the average   of a set of objective functions. Alternative objectives can be implemented   using plugins, for instance, to implement risk-aware optimization, such as   Conditional Value at Risk (CVaR) or standard-deviation-based functions.</li> <li>Support for black-box optimization of arbitrary functions.</li> <li>Support for running complex optimization workflows, such as multiple runs with   different optimization settings or even different optimization methods.</li> <li>Support for nested optimization, allowing sub-sets of the variables to be   optimized by optimization workflows that run as part of the black-box function   to be optimized.</li> <li>An interface for running various continuous and discrete optimization methods.   By default, optimizers from the   <code>scipy.optimize</code>   package are included, but additional optimizers can be added via a plugin   mechanism. The most common options of these optimizers can be configured in a   uniform manner, although algorithm- or package-specific options can still be   passed.</li> <li>Efficient estimation of gradients using a Stochastic Simplex Approximate   Gradient (StoSAG) approach. Additional samplers for generating perturbed   values for gradient estimation can be added via a plugin mechanism.</li> <li>Support for linear and non-linear constraints, if supported by the chosen   optimizer.</li> <li>Flexible configuration of the optimization process using   <code>pydantic</code>.</li> <li>Support for tracking and processing optimization results generated during the   optimization process.</li> <li>Optional support for exporting results as   <code>pandas</code> data frames.</li> </ul>"},{"location":"reference/basic_optimizer/","title":"Basic Optimizer","text":""},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer","title":"ropt.plan.BasicOptimizer","text":"<p>A class for executing single optimization runs.</p> <p>The <code>BasicOptimizer</code> is designed to simplify the process of setting up and executing optimization workflows that consist primarily of a single optimization run. It offers a more streamlined approach compared to directly defining and managing a full <code>Plan</code> object, making it ideal for straightforward optimization tasks.</p> <p>This class provides a user-friendly interface for common optimization operations, including:</p> <ul> <li>Initiating a Single Optimization:  Easily start an optimization   process with a provided configuration and evaluator.</li> <li>Observing Optimization Events: Register observer functions to monitor   and react to various events that occur during the optimization, such as   the start of an evaluation or the availability of new results.</li> <li>Abort Conditions: Define a callback function that can be used to check   for abort conditions during the optimization.</li> <li>Result Reporting: Define a callback function that will be called   whenever new results become available.</li> <li>Accessing Results: After the optimization is complete, the optimal   results, corresponding variables, and the optimization's exit code are   readily accessible.</li> <li>Customizable Steps and Handlers: While designed for single runs, it   allows for the addition of custom steps and handlers to the underlying   <code>Plan</code> for more complex scenarios. It is possible to pass keyword   arguments to the custom steps and handlers.</li> </ul> <p>By encapsulating the core elements of an optimization run, the <code>BasicOptimizer</code> reduces the boilerplate code required for simple optimization tasks, allowing users to focus on defining the optimization problem and analyzing the results.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.results","title":"results  <code>property</code>","text":"<pre><code>results: FunctionResults | None\n</code></pre> <p>Return the optimal result found during the optimization.</p> <p>This property provides access to the best <code>FunctionResults</code> object discovered during the optimization process. It encapsulates the objective function value, constraint values, and other relevant information about the optimal solution.</p> <p>Returns:</p> Type Description <code>FunctionResults | None</code> <p>The optimal result.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.variables","title":"variables  <code>property</code>","text":"<pre><code>variables: NDArray[float64] | None\n</code></pre> <p>Return the optimal variables found during the optimization.</p> <p>This property provides access to the variable values that correspond to the optimal <code>FunctionResults</code> object. These variables represent the solution that yielded the best objective function value found during the optimization process.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>The variables corresponding to the optimal result.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.exit_code","title":"exit_code  <code>property</code>","text":"<pre><code>exit_code: OptimizerExitCode\n</code></pre> <p>Return the exit code of the optimization run.</p> <p>This property provides access to the <code>OptimizerExitCode</code> that indicates the outcome of the optimization process. It can be used to determine whether the optimization completed successfully, was aborted, or encountered an error.</p> <p>Returns:</p> Type Description <code>OptimizerExitCode</code> <p>The exit code of the optimization run.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: dict[str, Any] | EnOptConfig,\n    evaluator: Evaluator,\n    *,\n    transforms: OptModelTransforms | None = None,\n    constraint_tolerance: float = 1e-10,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Initialize a <code>BasicOptimizer</code> object.</p> <p>This constructor sets up the necessary components for a single optimization run. It requires an optimization configuration and an evaluator, which together define the optimization problem and how to evaluate potential solutions. The <code>transforms</code> object can be used to apply transformations to the optimization model, such as scaling or shifting variables. If a constraint value is within the <code>constraint_tolerance</code> of zero, it is considered satisfied. The <code>kwargs</code> may be used to define custom steps, and handlers to modify the behavior of the optimization process.</p> Custom  steps <p>The optional keyword arguments (<code>kwargs</code>) provide a mechanism to inject a custom step into the optimization process. The behavior is as follows:</p> <ol> <li>Custom Step Execution: If a single keyword argument is     provided, the <code>BasicOptimizer</code> checks if a step with the same     name exists. If so, that step is executed immediately, receiving     the key-value pair as a keyword input, together with the     transforms passed via a <code>transforms</code> keyword. Only one custom     step can be executed this way, if other keyword arguments are     present an error is raised. The custom step receives the <code>Plan</code>     object and may install a custom run function to be executed     later, or install custom result handlers.</li> <li>Default Optimization: If no custom step is run, or if the     custom step does not install a custom run function, the default     optimization process is used.</li> <li>Callback Installation and Execution: Finally, any callbacks     added via <code>set_abort_callback</code> or <code>set_results_callback</code> are     installed, and the appropriate run function is executed.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>dict[str, Any] | EnOptConfig</code> <p>The configuration for the optimization.</p> required <code>evaluator</code> <code>Evaluator</code> <p>The evaluator object.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms.</p> <code>None</code> <code>constraint_tolerance</code> <code>float</code> <p>The constraint violation tolerance.</p> <code>1e-10</code> <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments.</p> <code>{}</code>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.run","title":"run","text":"<pre><code>run() -&gt; Self\n</code></pre> <p>Run the optimization process.</p> <p>This method initiates the optimization workflow defined by the <code>BasicOptimizer</code> object. It executes the underlying <code>Plan</code>, which manages the optimization steps, result handling, and event processing. After the optimization is complete, the optimal results, variables, and exit code can be accessed via the corresponding properties.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.set_abort_callback","title":"set_abort_callback","text":"<pre><code>set_abort_callback(callback: Callable[[], bool]) -&gt; Self\n</code></pre> <p>Set a callback to check for abort conditions.</p> <p>The provided callback function will be invoked repeatedly during the optimization process. If the callback returns <code>True</code>, the optimization will be aborted, and the <code>BasicOptimizer</code> will exit with an <code>OptimizerExitCode.USER_ABORT</code>.</p> <p>The callback function should have no arguments and return a boolean value.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[], bool]</code> <p>The callable to check for abort conditions.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.set_results_callback","title":"set_results_callback","text":"<pre><code>set_results_callback(callback: Callable[..., None]) -&gt; Self\n</code></pre> <p>Set a callback to report new results.</p> <p>The provided callback function will be invoked whenever new results become available during the optimization process. This allows for real-time monitoring and analysis of the optimization's progress.</p> <p>The required signature of the callback function should be:</p> <pre><code>def callback(results: tuple[FunctionResults, ...]) -&gt; None:\n    ...\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[..., None]</code> <p>The callable that will be invoked to report new results.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/default_function_estimator_plugin/","title":"Default Function Estimator Plugin","text":""},{"location":"reference/default_function_estimator_plugin/#ropt.plugins.function_estimator.default.DefaultFunctionEstimator","title":"ropt.plugins.function_estimator.default.DefaultFunctionEstimator","text":"<p>               Bases: <code>FunctionEstimator</code></p> <p>The default function estimator plugin.</p> <p>This plugin currently implements two methods:</p> <code>mean</code>: Calculate the combined functions as a weighted mean of the function    values of each realization. Gradients are accordingly calculated as    a weighted sum. <code>stddev</code>: Calculate the combined functions as the standard deviation of function    values of each realization. Gradients are calculated accordingly using    the chain rule. The sign of the result is adjusted such that the standard    deviation is always minimized."},{"location":"reference/default_plan_plugin/","title":"Default Plan Plugin","text":""},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultPlanStepPlugin","title":"ropt.plugins.plan.default.DefaultPlanStepPlugin","text":"<p>               Bases: <code>PlanStepPlugin</code></p> <p>The default plan plugin class.</p> <p>This class provides a number of steps:</p> <code>Steps</code>: <ul> <li>A step that performs a single ensemble evaluation (<code>evaluator</code>).</li> </ul> <ul> <li>A step that runs an optimization (<code>optimizer</code>).</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultPlanHandlerPlugin","title":"ropt.plugins.plan.default.DefaultPlanHandlerPlugin","text":"<p>               Bases: <code>PlanHandlerPlugin</code></p> <p>The default plan plugin class.</p> <p>This class provides a number of result handlers:</p> <code>Result Handlers</code>: <ul> <li>A handler that tracks optimal results (<code>tracker</code>).</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep","title":"ropt.plugins.plan.evaluator.DefaultEvaluatorStep","text":"<p>               Bases: <code>PlanStep</code></p> <p>The default evaluator step.</p> <p>This step performs a single ensemble evaluation, yielding one or more <code>FunctionResults</code> objects. The evaluation can process multiple variable vectors, each of which is evaluated separately, producing an individual results object for each vector.</p> <p>Before executing the evaluator step, a <code>START_EVALUATOR_STEP</code> event is emitted. After the evaluator step finishes, an <code>FINISHED_EVALUATOR_STEP</code> event is emitted. Result handlers should respond to the latter event to process the generated results.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize a default evaluator step.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan that runs this step.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep.run","title":"run","text":"<pre><code>run(\n    config: dict[str, Any] | EnOptConfig,\n    transforms: OptModelTransforms | None = None,\n    variables: ArrayLike | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; OptimizerExitCode\n</code></pre> <p>Run the evaluator step.</p> <p>The <code>DefaultEvaluatorStep</code> requires an optimizer configuration; the <code>variables</code> parameter is optional. The configuration  object must be an <code>EnOptConfig</code> object, or a dictionary that can be parsed into such an object. If no <code>variables</code> are provided, the initial values specified by the optimizer configuration are used. If <code>values</code> is given, it may be a single vector or a two-dimensional array. In the latter case, each row of the matrix is treated as a separate set of values to be evaluated.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any] | EnOptConfig</code> <p>The optimizer configuration.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms object.</p> <code>None</code> <code>variables</code> <code>ArrayLike | None</code> <p>Variables to evaluate.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata to add to events.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep.emit_event","title":"emit_event","text":"<pre><code>emit_event(event: Event) -&gt; None\n</code></pre> <p>Emit an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep","title":"ropt.plugins.plan.optimizer.DefaultOptimizerStep","text":"<p>               Bases: <code>PlanStep</code></p> <p>The default optimizer step.</p> <p>The optimizer step performs an optimization, yielding a sequence of <code>FunctionResults</code> and <code>GradientResults</code> objects. The optimizer is configured using an <code>EnOptConfig</code> object or a dictionary that can be parsed into such an object. While the initial values for optimization are typically specified in the configuration, they can be overridden by providing them directly.</p> <p>The optimizer step emits several signals:</p> <ul> <li><code>START_OPTIMIZER_STEP</code>:   Emitted before the optimization starts.</li> <li><code>FINISHED_OPTIMIZER_STEP</code>:   Emitted after the optimization finishes.</li> <li><code>START_EVALUATION</code>: Emitted   before a function or gradient evaluation.</li> <li><code>FINISHED_EVALUATION</code>: Emitted   after a function or gradient evaluation.</li> </ul> <p>The <code>FINISHED_EVALUATION</code> signal is particularly important as it passes   the generated <code>Results</code> objects. Result handlers   specified in the plan will respond to this signal to process those results.</p> <p>The optimizer step supports nested optimizations, where each function evaluation in the optimization calls a function that should run the nested optimization and produce the result for the function evaluation.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize a default optimizer step.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan that runs this step.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.run","title":"run","text":"<pre><code>run(\n    config: dict[str, Any] | EnOptConfig,\n    transforms: OptModelTransforms | None = None,\n    variables: ArrayLike | None = None,\n    nested_optimization: Plan | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; OptimizerExitCode\n</code></pre> <p>Run the optimizer step.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any] | EnOptConfig</code> <p>The optimizer configuration.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms object.</p> <code>None</code> <code>variables</code> <code>ArrayLike | None</code> <p>Variables to evaluate.</p> <code>None</code> <code>nested_optimization</code> <code>Plan | None</code> <p>Optional nested plan.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata to add to events.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.emit_event","title":"emit_event","text":"<pre><code>emit_event(event: Event) -&gt; None\n</code></pre> <p>Emit an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler","title":"ropt.plugins.plan._tracker.DefaultTrackerHandler","text":"<p>               Bases: <code>PlanHandler</code></p> <p>The default tracker results handler object.</p> <p>This handler tracks the <code>Results</code> objects that it receives and selects one to retain in a variable. Currently it tracks either the last result it receives, or the best result. The best result is defined as the result that has the lowest weighted objective value. Optionally, results may be filtered by checking for violations of constraints, by comparing constraint values to a threshold.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler.__init__","title":"__init__","text":"<pre><code>__init__(\n    plan: Plan,\n    *,\n    what: Literal[\"best\", \"last\"] = \"best\",\n    constraint_tolerance: float | None = None,\n    sources: set[UUID] | None = None,\n    transforms: OptModelTransforms | None = None,\n) -&gt; None\n</code></pre> <p>Initialize a default tracker results handler.</p> <p>This handler monitors <code>Results</code> objects from specified sources and selects a single result to retain based on the specified criteria. It can track either the best result encountered so far or the most recent result. The \"best\" result is determined by the lowest weighted objective value.</p> <p>Results can optionally be filtered based on constraint violations. If a <code>constraint_tolerance</code> is provided, results that violate constraints beyond this tolerance will be discarded and not tracked.</p> <p>The <code>sources</code> parameter allows you to specify which steps' results should be tracked. Only results from steps whose IDs are included in this set will be considered.</p> <p>Tracking of results is based on the results in the optimizer domain, and the tracked results are accessible via the <code>\"results\"</code> key. If the <code>transforms</code> argument is not <code>None</code>, tracking still occurs in the optimizer domain, but the results accessible via the <code>\"results\"</code> key are transformed to the user domain.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan this handler is part of.</p> required <code>what</code> <code>Literal['best', 'last']</code> <p>Specifies whether to track the \"best\" or \"last\" result.</p> <code>'best'</code> <code>constraint_tolerance</code> <code>float | None</code> <p>Constraint tolerance for filtering results.</p> <code>None</code> <code>sources</code> <code>set[UUID] | None</code> <p>A set of UUIDs of steps whose results to track.</p> <code>None</code> <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms to apply to the final results.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler.handle_event","title":"handle_event","text":"<pre><code>handle_event(event: Event) -&gt; None\n</code></pre> <p>Handle an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to handle.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._store.DefaultStoreHandler","title":"ropt.plugins.plan._store.DefaultStoreHandler","text":"<p>               Bases: <code>PlanHandler</code></p> <p>The default store results handler object.</p> <p>This handler tracks the <code>Results</code> objects that it receives and stores them in memory.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._store.DefaultStoreHandler.__init__","title":"__init__","text":"<pre><code>__init__(\n    plan: Plan,\n    *,\n    sources: set[UUID] | None = None,\n    transforms: OptModelTransforms | None = None,\n) -&gt; None\n</code></pre> <p>Initialize a default store results handler object.</p> <p>This handler stores a collection of <code>Results</code> objects from specified sources. It accumulates results from <code>FINISHED_EVALUATION</code> events emitted by the designated sources.</p> <p>The <code>sources</code> parameter determines which steps' results are tracked.</p> <p>The stored results can be accessed via the <code>\"results\"</code> key. The results are stored as a tuple of <code>Results</code> objects.</p> <p>If the <code>transforms</code> argument is not None, these are applied to transform the results from the optimizer domain to the user domain.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan that this handler is part of.</p> required <code>sources</code> <code>set[UUID] | None</code> <p>The IDs of the steps whose results should be tracked.</p> <code>None</code> <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms to apply to the results.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._store.DefaultStoreHandler.handle_event","title":"handle_event","text":"<pre><code>handle_event(event: Event) -&gt; None\n</code></pre> <p>Handle an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to handle.</p> required"},{"location":"reference/default_realization_filter_plugin/","title":"Default Realization Filter Plugin","text":""},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.DefaultRealizationFilter","title":"ropt.plugins.realization_filter.default.DefaultRealizationFilter","text":"<p>               Bases: <code>RealizationFilter</code></p> <p>The default realization filter plugin class.</p> <p>This plugin currently implements four methods:</p> <code>sort-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>SortObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects the set of realizations from a given index range. <code>sort-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>SortConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects the set of    realizations from a given index range. <code>cvar-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>CVaRObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects a percentile of the realizations, applying interpolation whenever    the number of selected realizations is not an integer number. <code>cvar-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>CVaRConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects a    percentile of the realizations, applying interpolation whenever the    number of selected realizations is not an integer number."},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.SortObjectiveOptions","title":"ropt.plugins.realization_filter.default.SortObjectiveOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-objective</code> method.</p> <p>The <code>sort-objective</code> method sorts realizations according to the value of one or multiple objectives, and retains a number of realizations within a given index range in the sorted list. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>list[NonNegativeInt]</code> <p>The indices of the objectives to sort.</p> <code>first</code> <code>NonNegativeInt</code> <p>Index or name of the first realization to use.</p> <code>last</code> <code>NonNegativeInt</code> <p>Index of name of the last realization to use.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.SortConstraintOptions","title":"ropt.plugins.realization_filter.default.SortConstraintOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-constraint</code> method.</p> <p>The <code>sort-constraint</code> method sorts realizations according to the value of a constraint, and retains a number of realizations within a given index range in the sorted list.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>NonNegativeInt</code> <p>The index of the constraint to sort.</p> <code>first</code> <code>NonNegativeInt</code> <p>Index or name of the first realization to use.</p> <code>last</code> <code>NonNegativeInt</code> <p>Index or name of the last realization to use.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.CVaRObjectiveOptions","title":"ropt.plugins.realization_filter.default.CVaRObjectiveOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-objective</code> method.</p> <p>The <code>cvar-objective</code> method finds realizations weights by applying the CVaR method to the objective values. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. \"Worst\" is defined as those realizations having the highest values in case of a minimization and those having the lowest values in case of maximizing.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>list[NonNegativeInt]</code> <p>The indices of the objectives to sort.</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.CVaRConstraintOptions","title":"ropt.plugins.realization_filter.default.CVaRConstraintOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-constraint</code> method.</p> <p>The <code>cvar-constraint</code> method finds realizations weights by applying the CVaR method to the objective values.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. The definition of worst depends on the type of the constraints. After subtracting the right-hand-side value the following applies:</p> <ul> <li>For LE constraints, realizations with the largest values are the worst</li> <li>For GE constraints, realizations with the smallest values are the worst</li> <li>For EQ constraints, realizations with the largest absolute values are the worst</li> </ul> <p>Attributes:</p> Name Type Description <code>sort</code> <code>NonNegativeInt</code> <p>The index of the constraint to sort.</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile.</p>"},{"location":"reference/domain_transforms/","title":"Domain transforms","text":""},{"location":"reference/domain_transforms/#ropt.transforms","title":"ropt.transforms","text":"<p>Domain Transformation Framework.</p> <p>This module provides a flexible framework for transforming optimization variables, objectives, and constraints between user-defined domains and the domains used internally by the optimizer. These transformations are essential for:</p> <ul> <li>Improving Optimizer Performance: Scaling, shifting, and other   transformations can significantly enhance the efficiency, stability, and   convergence of optimization algorithms.</li> <li>Implementing Custom Mappings:  Beyond simple scaling, this framework   supports complex, user-defined mappings between domains, allowing for   tailored problem representations.</li> <li>Handling Diverse Units and Scales: Transformations enable the optimizer   to work with variables and functions that may have vastly different units   or scales, improving numerical stability.</li> </ul> <p>Key Components:</p> <ul> <li>Abstract Base Classes: Transform classes derive from abstract base classes   that define the specific mapping logic between domains.<ul> <li><code>VariableTransform</code>:   Defines the interface for transforming variables between user and   optimizer domains.</li> <li><code>ObjectiveTransform</code>:   Defines the interface for transforming objective values between user   and optimizer domains.</li> <li><code>NonLinearConstraintTransform</code>:   Defines the interface for transforming non-linear constraint values   between user and optimizer domains.</li> </ul> </li> <li><code>OptModelTransforms</code>:   A container class for conveniently grouping and   passing multiple transformation objects (variable, objective, and   nonlinear constraint).</li> </ul> <p>Workflow and Integration:</p> <ol> <li>Configuration: Transformation objects are passed to the     <code>EnOptConfig</code> during configuration     validation, using an     <code>OptModelTransforms</code> instance. This     ensures that the entire optimization process is aware of and configured for     the transformed space.</li> <li>Optimization Plan: The same transformation objects are passed to the     relevant optimization steps within the <code>Plan</code>. (See, for     example, the default implementation of an optimizer step in     <code>DefaultOptimizerStep.run</code>).</li> <li>Evaluation: When the optimizer requests an evaluation of a variable     vector, the following occurs:<ul> <li>Transformation to the User Domain: The variable vector is      transformed from the optimizer       domain back to the user domain using the <code>from_optimizer</code> method of       the <code>VariableTransform</code>.</li> <li>Function Evaluation: Objective and constraint values are calculated       in the user domain.</li> <li>Transformation to the Optimizer Domain: The resulting objective and      constraint values are       transformed to the optimizer domain using the <code>to_optimizer</code> methods       of the <code>ObjectiveTransform</code> and <code>NonLinearConstraintTransform</code>.</li> </ul> </li> <li>Optimization: The optimizer proceeds using the transformed values.</li> <li>Results: The <code>Results</code> objects produced during     optimization hold values in the optimizer domain. To obtain results in the     user domain, the     <code>transform_from_optimizer</code>     method is used to create new <code>Results</code> objects with the transformed values.     For example,     <code>DefaultOptimizerStep.run</code>     emits events that include a dictionary with a <code>\"results\"</code> key That contains     <code>Results</code> objects in the  optimizer domain. To obtain results in the user     domain they must be converted using the     <code>transform_from_optimizer</code>     method.</li> </ol> <p>Classes:</p> Name Description <code>OptModelTransforms</code> <p>A data class for conveniently grouping and passing                 multiple transformation objects.</p> <code>VariableScaler</code> <p>A concrete implementation of <code>VariableTransform</code>                 that performs linear scaling and shifting.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms","title":"ropt.transforms.OptModelTransforms  <code>dataclass</code>","text":"<p>A container for optimization model transformers.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.variables","title":"variables  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>variables: VariableTransform | None = None\n</code></pre> <p>A <code>VariableTransform</code> object that defines the transformation for variables.</p> <p>If <code>None</code>, no transformation is applied to variables.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.objectives","title":"objectives  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>objectives: ObjectiveTransform | None = None\n</code></pre> <p>An <code>ObjectiveTransform</code> object that defines the transformation for objectives.</p> <p>If <code>None</code>, no transformation is applied to objectives.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.nonlinear_constraints","title":"nonlinear_constraints  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>nonlinear_constraints: (\n    NonLinearConstraintTransform | None\n) = None\n</code></pre> <p>A <code>NonLinearConstraintTransform</code> object that defines the transformation for nonlinear constraints.</p> <p>If <code>None</code>, no transformation is applied to nonlinear constraints.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform","title":"ropt.transforms.base.VariableTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for variable transformations.</p> <p>This class defines the interface for transforming variables between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of transformation.</p> <p>When implementing a variable transformation, the following aspects must be considered:</p> <ul> <li>Variable Value Transformation: Mapping variable values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Perturbation Magnitude Transformation: Stochastic gradient-based   algorithms use perturbations with specified magnitudes (see   <code>perturbation_magnitudes</code>). These   magnitudes are typically defined in the user domain and must be   transformed to the optimizer domain using the   <code>magnitudes_to_optimizer</code>   method.</li> <li>Bound Constraint Difference Transformation: To report violations of   variable bounds, the differences between variable values and their   lower/upper bounds must be transformed from the optimizer domain back   to the user domain. This is done using the   <code>bound_constraint_diffs_from_optimizer</code>   method.</li> <li>Linear Constraint Transformation: Linear constraints are generally   defined by coefficients and right-hand-side values in the user domain.   These must be transformed to the optimizer domain using the   <code>linear_constraints_to_optimizer</code>   method.</li> <li>Linear Constraint Difference Transformation: To report violations of   linear constraints, the differences between the linear constraint   values and their right-hand-side values must be transformed back to the   user domain. This is done using the   <code>linear_constraints_diffs_from_optimizer</code>   method.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform values from the user domain to the optimizer domain.</p> <p>This method maps variable values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform values from the optimizer domain to the user domain.</p> <p>This method maps variable values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.magnitudes_to_optimizer","title":"magnitudes_to_optimizer  <code>abstractmethod</code>","text":"<pre><code>magnitudes_to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform perturbation magnitudes to the optimizer domain.</p> <p>This method transforms perturbation magnitudes, typically used in stochastic gradient-based algorithms, from the user-defined domain to the optimizer's internal domain. The transformation ensures that the perturbations are applied correctly in the optimizer's space, which may have different scaling or units than the user domain.</p> <p>For example, if variables are scaled down in the optimizer domain, the perturbation magnitudes should also be scaled down proportionally.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The perturbation magnitudes in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed perturbation magnitudes in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.bound_constraint_diffs_from_optimizer","title":"bound_constraint_diffs_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>bound_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform bound constraint differences to the user domain.</p> <p>This method transforms the differences between variable values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if variables are scaled in the optimizer domain, the differences between the variables and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their lower bounds in the optimizer domain.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their upper bounds in the optimizer domain.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.linear_constraints_to_optimizer","title":"linear_constraints_to_optimizer","text":"<pre><code>linear_constraints_to_optimizer(\n    coefficients: NDArray[float64],\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Transform linear constraints from the user domain to the optimizer domain.</p> <p>This method transforms linear constraints, defined by their coefficients and right-hand-side bounds, from the user-defined domain to the optimizer's internal domain. This is essential to maintain the validity of the constraints after variable transformations.</p> <p>For instance, if variables are scaled or shifted in the optimizer domain, the coefficients and bounds of the linear constraints must be adjusted accordingly to ensure the constraints remain consistent.</p> <p>The linear constraints are defined by the equation <code>A * x = b</code>, where <code>A</code> is the coefficient matrix, <code>x</code> is the variable vector, and <code>b</code> represents the right-hand-side bounds.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>NDArray[float64]</code> <p>The coefficient matrix.</p> required <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed coefficient matrix and bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.linear_constraints_diffs_from_optimizer","title":"linear_constraints_diffs_from_optimizer","text":"<pre><code>linear_constraints_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform linear constraint differences to the user domain.</p> <p>This method transforms the differences between linear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if linear constraints are scaled in the optimizer domain, the differences between the constraint values and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform","title":"ropt.transforms.base.ObjectiveTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for objective transformations.</p> <p>This class defines the interface for transforming objective values between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of objective transformation.</p> <p>When implementing an objective transformation, the following aspects must be considered:</p> <ul> <li>Objective Value Transformation: Mapping objective values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Weighted Objective Transformation: The optimizer works with a   single, weighted objective value. If the transformation affects the   weighted objective, the   <code>weighted_objective_from_optimizer</code>   method should be overridden to handle this.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    objectives: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform objective values to the optimizer domain.</p> <p>This method maps objective values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>objectives</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the objective values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objective values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed objective values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    objectives: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform objective values to the user domain.</p> <p>This method maps objective values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>objectives</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the objective values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objective values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed objective values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.weighted_objective_from_optimizer","title":"weighted_objective_from_optimizer","text":"<pre><code>weighted_objective_from_optimizer(\n    weighted_objective: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform the weighted objective to the user domain.</p> <p>The optimizer uses a single, weighted objective value evaluated in the optimizer domain. This method reverses that transformation, mapping the weighted objective back to the user domain.</p> <p>For example, if the transformation to the optimizer domain involved a sign change to convert a maximization problem into a minimization problem, this method would change the sign back.</p> Note <p>This method may be applied to the weighted objective itself or to its gradient. Therefore, the input may be a scalar or a vector of values.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted objective value(s) to transform.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed weighted objective value(s).</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform","title":"ropt.transforms.base.NonLinearConstraintTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for nonlinear constraint transformations.</p> <p>This class defines the interface for transforming nonlinear constraint values between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of nonlinear constraint transformation.</p> <p>When implementing a nonlinear constraint transformation, the following aspects must be considered:</p> <ul> <li>Constraint Value Transformation: Mapping constraint values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Right-Hand-Side Bound Transformation: Mapping the right-hand-side   bounds of the constraints between the user and optimizer domains. This is   achieved by overriding the   <code>bounds_to_optimizer</code>   method.</li> <li>Constraint Difference Transformation: To report violations of   nonlinear constraints, the differences between constraint values and their   lower/upper bounds must be transformed from the optimizer domain back to   the user domain. This is done using the   <code>nonlinear_constraint_diffs_from_optimizer</code>   method.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    constraints: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform constraint values to the optimizer domain.</p> <p>This method maps nonlinear constraint values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>constraints</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the constraint values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>constraints</code> <code>NDArray[float64]</code> <p>The nonlinear constraint values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed nonlinear constraint values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    constraints: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform constraint values to the user domain.</p> <p>This method maps nonlinear constraint values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>constraints</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the constraint values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>constraints</code> <code>NDArray[float64]</code> <p>The nonlinear constraint values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed nonlinear constraint values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.bounds_to_optimizer","title":"bounds_to_optimizer  <code>abstractmethod</code>","text":"<pre><code>bounds_to_optimizer(\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform the right-hand-side bounds to the optimizer domain.</p> <p>This method transforms the lower and upper bounds of the nonlinear constraints from the user-defined domain to the optimizer's internal domain. This transformation is necessary to ensure that the constraints remain valid after the variables have been transformed.</p> <p>For example, if constraint values are scaled or shifted in the optimizer domain, the bounds must be adjusted accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values in the user domain.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values in the user domain.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.nonlinear_constraint_diffs_from_optimizer","title":"nonlinear_constraint_diffs_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>nonlinear_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform nonlinear constraint differences to the user domain.</p> <p>This method transforms the differences between nonlinear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if constraint values are scaled in the optimizer domain, the differences between the constraint values and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the nonlinear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the nonlinear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler","title":"ropt.transforms.VariableScaler","text":"<p>               Bases: <code>VariableTransform</code></p> <p>Linearly scales and shifts variables between domains.</p> <p>This class implements a linear transformation for variables, allowing for scaling and shifting between the user-defined domain and the optimizer's internal domain. The transformation is defined by a scaling factor and an offset for each variable.</p> <p>The transformation from the user domain to the optimizer domain is given by:</p> \\[x_{opt} = \\frac{(x_{\\textrm{user}} - \\textrm{offset})}{\\textrm{scale}}\\] <p>The transformation from the optimizer domain back to the user domain is:</p> \\[x_{user} = x_{\\textrm{opt}} * {\\textrm{scale}} + {\\textrm{offset}}\\] <p>This transformation can be used to improve the performance of the optimizer by working with variables that are scaled to a more suitable range or centered around a specific value.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.__init__","title":"__init__","text":"<pre><code>__init__(\n    scales: NDArray[float64] | None,\n    offsets: NDArray[float64] | None,\n) -&gt; None\n</code></pre> <p>Initialize the variable scaler.</p> <p>This scaler applies a linear transformation to variables, defined by scaling factors and offset values.</p> <p>If both <code>scales</code> and <code>offsets</code> are provided, they are broadcasted to ensure they have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>scales</code> <code>NDArray[float64] | None</code> <p>The scaling factors for each variable.</p> required <code>offsets</code> <code>NDArray[float64] | None</code> <p>The offset values for each variable.</p> required"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.to_optimizer","title":"to_optimizer","text":"<pre><code>to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform variable values to the optimizer domain.</p> <p>This method applies the linear scaling and offset transformation to variable values, mapping them from the user-defined domain to the optimizer's internal domain.</p> <p>The transformation is defined as: <code>x_opt = (x_user - offset) / scale</code>.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.from_optimizer","title":"from_optimizer","text":"<pre><code>from_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform variable values to the user domain.</p> <p>This method applies the inverse linear scaling and offset transformation to variable values, mapping them from the optimizer's internal domain back to the user-defined domain.</p> <p>The transformation is defined as: <code>x_user = x_opt * scale + offset</code>.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.magnitudes_to_optimizer","title":"magnitudes_to_optimizer","text":"<pre><code>magnitudes_to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform perturbation magnitudes to the optimizer domain.</p> <p>This method transforms perturbation magnitudes, typically used in stochastic gradient-based algorithms, from the user-defined domain to the optimizer's internal domain. The transformation ensures that the perturbations are applied correctly in the optimizer's space, which may have different scaling or units than the user domain.</p> <p>The transformation is defined as: <code>x_opt = x_user / scale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The perturbation magnitudes in the user domain.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed perturbation magnitudes in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.linear_constraints_to_optimizer","title":"linear_constraints_to_optimizer","text":"<pre><code>linear_constraints_to_optimizer(\n    coefficients: NDArray[float64],\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Transform linear constraints to the optimizer domain.</p> <p>This method transforms linear constraints, defined by their coefficients and right-hand-side bounds, from the user-defined domain to the optimizer's internal domain. This transformation accounts for the scaling and shifting applied to the variables and ensures that the constraints remain valid in the optimizer's space.</p> <p>The set of linear constraints can be represented by a matrix equation: \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\).</p> <p>When linearly transforming variables to the optimizer domain, the coefficients (\\(\\mathbf{A}\\)) and right-hand-side values (\\(\\mathbf{b}\\)) must be converted to remain valid (see also the configuration for linear constraints). If the linear transformation of the variables to the optimizer domain is given by:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{S} \\mathbf{x} + \\mathbf{o}\\] <p>then the coefficients and right-hand-side values must be transformed as follows:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A} \\mathbf{S}^{-1} \\\\ \\hat{\\mathbf{b}}     &amp;= \\mathbf{b} + \\mathbf{A}\\mathbf{S}^{-1}\\mathbf{o} \\end{align}\\] <p>where \\(S\\) is a diagonal matrix with scaling factors on the diagonal and \\(o\\) are the offsets.</p> <p>The resulting equations are further scaled by dividing them by maximum of the absolute values of the coefficients in each equation.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>NDArray[float64]</code> <p>The coefficient matrix of the linear constraints.</p> required <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed coefficient matrix and bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.bound_constraint_diffs_from_optimizer","title":"bound_constraint_diffs_from_optimizer","text":"<pre><code>bound_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform bound constraint differences to the user domain.</p> <p>This method transforms the differences between variable values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if variables are scaled in the optimizer domain, the differences between the variables and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>The transformation is defined as: <code>x_user = x_opt * scale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.linear_constraints_diffs_from_optimizer","title":"linear_constraints_diffs_from_optimizer","text":"<pre><code>linear_constraints_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform linear constraint differences to the user domain.</p> <p>This method transforms the differences between linear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>This is implemented by re-scaling the equations with the weights that were determined and stored by the <code>linear_constraints_to_optimizer</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/enopt_config/","title":"Configuration","text":""},{"location":"reference/enopt_config/#ropt.config.enopt","title":"ropt.config.enopt","text":"<p>The <code>ropt.config.enopt</code> module provides configuration classes for optimization workflows.</p> <p>This module defines a set of classes that are used to configure various aspects of an optimization process, including variables, objectives, constraints, realizations, samplers, and more.</p> <p>The central configuration class is <code>EnOptConfig</code>, which encapsulates the complete configuration for a single optimization step. It is designed to be flexible and extensible, allowing users to customize the optimization process to their specific needs.</p> <p>These configuration classes are built using <code>pydantic</code>, which provides robust data validation and parsing capabilities. This ensures that the configuration data is consistent and adheres to the expected structure.</p> <p>Configuration objects are typically created from dictionaries of configuration values using the <code>model_validate</code> method provided by <code>pydantic</code>.</p> <p>Key Features:</p> <ul> <li>Modular Design: The configuration is broken down into smaller, manageable   components, each represented by a dedicated class.</li> <li>Validation: <code>pydantic</code> ensures that the configuration data is valid and   consistent.</li> <li>Extensibility: The modular design allows for easy extension and   customization of the optimization process.</li> <li>Centralized Configuration: The   <code>EnOptConfig</code> class provides a single point   of entry for configuring an optimization step.</li> <li>Domain Transformations:  The optimization process supports domain   transformations, as detailed in the <code>ropt.transforms</code>   module. These transformations map variables, objectives, and constraints   between the user-defined domain and the domain used by the optimizer. This   capability is valuable for operations such as scaling, shifting, or other   adjustments that can enhance the performance and stability of the optimization   algorithm. Domain transformations are implemented through a set of classes   that define the necessary mappings. When creating an <code>EnOptConfig</code> object,   transformation objects can be provided to automatically apply these   transformations during configuration validation.</li> </ul> <p>Parsing and Validation</p> <p>The configuration classes are built using <code>pydantic</code>, which provides robust data validation. The primary configuration class is <code>EnOptConfig</code>, and it contains nested configuration classes for various aspects of the optimization. To parse a configuration from a dictionary, use the <code>model_validate</code> class method:</p> <pre><code>from ropt.config.enopt import EnOptConfig\n\nconfig_dict = {\n    \"variables\": {\n        \"initial_values\": [10.0, 10.0],\n    }\n}\nconfig = EnOptConfig.model_validate(config_dict)\nconfig.variables.initial_values  # [10.0, 10.0]\n</code></pre> <p>Domain transformation objects from the <code>ropt.transforms</code> module can be passed to the <code>model_validate</code> method via the <code>context</code> parameter:</p> <pre><code>from ropt.config.enopt import EnOptConfig\nfrom ropt.transforms import OptModelTransforms, VariableScaler\n\nconfig_dict = {\n    \"variables\": {\n        \"initial_values\": [10.0, 10.0],\n    }\n}\nscaler = VariableScaler([10.0, 5.0], None)\nconfig = EnOptConfig.model_validate(\n    config_dict, context=OptModelTransforms(variables=scaler)\n)\nconfig.variables.initial_values  # [1.0, 2.0]\n</code></pre> <p>Classes:</p> Name Description <code>EnOptConfig</code> <p>The main configuration class for an optimization step.</p> <code>VariablesConfig</code> <p>Configuration for variables.</p> <code>ObjectiveFunctionsConfig</code> <p>Configuration for objective functions.</p> <code>LinearConstraintsConfig</code> <p>Configuration for linear constraints.</p> <code>NonlinearConstraintsConfig</code> <p>Configuration for non-linear constraints.</p> <code>RealizationsConfig</code> <p>Configuration for realizations.</p> <code>OptimizerConfig</code> <p>Configuration for the optimizer.</p> <code>GradientConfig</code> <p>Configuration for gradient calculations.</p> <code>FunctionEstimatorConfig</code> <p>Configuration for function estimators.</p> <code>RealizationFilterConfig</code> <p>Configuration for realization filters.</p> <code>SamplerConfig</code> <p>Configuration for samplers.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.EnOptConfig","title":"EnOptConfig","text":"<p>The primary configuration class for an optimization step.</p> <p><code>EnOptConfig</code> orchestrates the configuration of an entire optimization workflow. It contains nested configuration classes that define specific aspects of the optimization, such as variables, objectives, constraints, realizations, and the optimizer itself.</p> <p><code>realization_filters</code>, <code>function_estimators</code>, and <code>samplers</code> are configured as tuples. Other configuration fields reference these objects by their index within the tuples. For example, <code>GradientConfig</code> uses a <code>samplers</code> field, which is an array of indices specifying the sampler to use for each variable.</p> Info <p>Many nested configuration classes use <code>numpy</code> arrays. These arrays typically have a size determined by a configured property (e.g., the number of variables) or a size of one. In the latter case, the single value is broadcasted to all relevant elements. For example, <code>VariablesConfig</code> defines properties like initial values and bounds as <code>numpy</code> arrays, which must either match the number of variables or have a size of one.</p> <p>Attributes:</p> Name Type Description <code>variables</code> <code>VariablesConfig</code> <p>Configuration for the optimization variables.</p> <code>objectives</code> <code>ObjectiveFunctionsConfig</code> <p>Configuration for the objective functions.</p> <code>linear_constraints</code> <code>LinearConstraintsConfig | None</code> <p>Configuration for linear constraints.</p> <code>nonlinear_constraints</code> <code>NonlinearConstraintsConfig | None</code> <p>Configuration for non-linear constraints.</p> <code>realizations</code> <code>RealizationsConfig</code> <p>Configuration for the realizations.</p> <code>optimizer</code> <code>OptimizerConfig</code> <p>Configuration for the optimization algorithm.</p> <code>gradient</code> <code>GradientConfig</code> <p>Configuration for gradient calculations.</p> <code>realization_filters</code> <code>tuple[RealizationFilterConfig, ...]</code> <p>Configuration for realization filters.</p> <code>function_estimators</code> <code>tuple[FunctionEstimatorConfig, ...]</code> <p>Configuration for function estimators.</p> <code>samplers</code> <code>tuple[SamplerConfig, ...]</code> <p>Configuration for samplers.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.VariablesConfig","title":"VariablesConfig","text":"<p>Configuration class for optimization variables.</p> <p>This class, <code>VariablesConfig</code>, defines the configuration for the optimization variables used in an <code>EnOptConfig</code> object. It specifies the initial values, bounds, types, and an optional mask for the variables.</p> <p>The <code>initial_values</code> field is a required <code>numpy</code> array that sets the starting values for the variables. The number of variables is determined by the length of this array.</p> <p>The <code>lower_bounds</code> and <code>upper_bounds</code> fields define the bounds for each variable. These are also <code>numpy</code> arrays and are broadcasted to match the number of variables. By default, they are set to negative and positive infinity, respectively. <code>numpy.nan</code> values in these arrays indicate unbounded variables and are converted to <code>numpy.inf</code> with the appropriate sign.</p> <p>The optional <code>types</code> field allows assigning a <code>VariableType</code> to each variable. If not provided, all variables are assumed to be continuous real-valued (<code>VariableType.REAL</code>).</p> <p>The optional <code>mask</code> field is a boolean <code>numpy</code> array that indicates which variables are free to change during optimization. <code>True</code> values in the mask indicate that the corresponding variable is free, while <code>False</code> indicates a fixed variable.</p> <p>Attributes:</p> Name Type Description <code>types</code> <code>ArrayEnum | None</code> <p>Optional variable types.</p> <code>initial_values</code> <code>Array1D</code> <p>Initial values for the variables.</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the variables (default: \\(-\\infty\\)).</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the variables (default: \\(+\\infty\\)).</p> <code>mask</code> <code>Array1DBool | None</code> <p>Optional boolean mask indicating free variables.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.ObjectiveFunctionsConfig","title":"ObjectiveFunctionsConfig","text":"<p>Configuration class for objective functions.</p> <p>This class, <code>ObjectiveFunctionsConfig</code>, defines the configuration for objective functions used in an <code>EnOptConfig</code> object.</p> <p><code>ropt</code> supports multi-objective optimization. Multiple objectives are combined into a single value by summing them after weighting. The <code>weights</code> field, a <code>numpy</code> array, determines the weight of each objective function. The length of this array defines the number of objective functions. The weights are automatically normalized to sum to 1 (e.g., <code>[1, 1]</code> becomes <code>[0.5, 0.5]</code>).</p> <p>Objective functions can be processed by realization filters and function estimators. The <code>realization_filters</code> and <code>function_estimators</code> fields contain indices that refer to the corresponding configuration objects in the parent <code>EnOptConfig</code> object.</p> <p>Attributes:</p> Name Type Description <code>weights</code> <code>Array1D</code> <p>Weights for the objective functions (default: 1.0).</p> <code>realization_filters</code> <code>Array1DInt | None</code> <p>Optional indices of realization filters.</p> <code>function_estimators</code> <code>Array1DInt | None</code> <p>Optional indices of function estimators.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.LinearConstraintsConfig","title":"LinearConstraintsConfig","text":"<p>Configuration class for linear constraints.</p> <p>This class, <code>LinearConstraintsConfig</code>, defines linear constraints used in an <code>EnOptConfig</code> object.</p> <p>Linear constraints are defined by a set of linear equations involving the optimization variables. These equations can represent equality or inequality constraints. The <code>coefficients</code> field is a 2D <code>numpy</code> array where each row represents a constraint, and each column corresponds to a variable.</p> <p>The <code>lower_bounds</code> and <code>upper_bounds</code> fields specify the bounds on the right-hand side of each constraint equation. These fields are converted and broadcasted to <code>numpy</code> arrays with a length equal to the number of constraint equations.</p> <p>Less-than and greater-than inequality constraints can be specified by setting the lower bounds to \\(-\\infty\\), or the upper bounds to \\(+\\infty\\), respectively. Equality constraints are specified by setting the lower bounds equal to the upper bounds.</p> <p>Attributes:</p> Name Type Description <code>coefficients</code> <code>Array2D</code> <p>Matrix of coefficients for the linear constraints.</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the right-hand side of the constraint equations.</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the right-hand side of the constraint equations.</p> Linear transformation of variables. <p>The set of linear constraints can be represented by a matrix equation: \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\).</p> <p>When linearly transforming variables to the optimizer domain, the coefficients (\\(\\mathbf{A}\\)) and right-hand-side values (\\(\\mathbf{b}\\)) must be converted to remain valid. If the linear transformation of the variables to the optimizer domain is given by:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{S} \\mathbf{x} + \\mathbf{o}\\] <p>then the coefficients and right-hand-side values must be transformed as follows:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A} \\mathbf{S}^{-1} \\\\ \\hat{\\mathbf{b}}     &amp;= \\mathbf{b} + \\mathbf{A}\\mathbf{S}^{-1}\\mathbf{o} \\end{align}\\]"},{"location":"reference/enopt_config/#ropt.config.enopt.NonlinearConstraintsConfig","title":"NonlinearConstraintsConfig","text":"<p>Configuration class for non-linear constraints.</p> <p>This class, <code>NonlinearConstraintsConfig</code>, defines non-linear constraints used in an <code>EnOptConfig</code> object.</p> <p>Non-linear constraints are defined by comparing a constraint function to a right-hand-side value, allowing for equality or inequality constraints. The <code>lower_bounds</code> and <code>upper_bounds</code> fields, which are <code>numpy</code> arrays, specify the bounds on these right-hand-side values. The length of these arrays determines the number of constraint functions.</p> <p>Less-than and greater-than inequality constraints can be specified by setting the lower bounds to \\(-\\infty\\), or the upper bounds to \\(+\\infty\\), respectively. Equality constraints are specified by setting the lower bounds equal to the upper bounds.</p> <p>Non-linear constraints can be processed by realization filters and function estimators. The <code>realization_filters</code> and <code>function_estimators</code> fields contain indices that refer to the corresponding objects configured in the parent <code>EnOptConfig</code> object.</p> <p>Attributes:</p> Name Type Description <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the right-hand-side values.</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the right-hand-side values.</p> <code>realization_filters</code> <code>Array1DInt | None</code> <p>Optional indices of realization filters.</p> <code>function_estimators</code> <code>Array1DInt | None</code> <p>Optional indices of function estimators.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationsConfig","title":"RealizationsConfig","text":"<p>Configuration class for realizations.</p> <p>This class, <code>RealizationsConfig</code>, defines the configuration for realizations used in an <code>EnOptConfig</code> object.</p> <p>To optimize an ensemble of functions, a set of realizations is defined. When the optimizer requests a function value or a gradient, these are calculated for each realization and then combined into a single value. Typically, this combination is a weighted sum, but other methods are possible.</p> <p>The <code>weights</code> field, a <code>numpy</code> array, determines the weight of each realization. The length of this array defines the number of realizations. The weights are automatically normalized to sum to 1 (e.g., <code>[1, 1]</code> becomes <code>[0.5, 0.5]</code>).</p> <p>If function value calculations for some realizations fail (e.g., due to a simulation error), the total function and gradient values can still be calculated by excluding the missing values. However, a minimum number of successful realizations may be required. The <code>realization_min_success</code> field specifies this minimum. By default, it is set equal to the number of realizations, meaning no missing values are allowed.</p> Note <p>Setting <code>realization_min_success</code> to zero allows the optimization to proceed even if all realizations fail. While some optimizers can handle this, most will treat it as if the value were one, requiring at least one successful realization.</p> <p>Attributes:</p> Name Type Description <code>weights</code> <code>Array1D</code> <p>Weights for the realizations (default: 1.0).</p> <code>realization_min_success</code> <code>NonNegativeInt | None</code> <p>Minimum number of successful realizations (default:                     equal to the number of realizations).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.OptimizerConfig","title":"OptimizerConfig","text":"<p>Configuration class for the optimization algorithm.</p> <p>This class, <code>OptimizerConfig</code>, defines the configuration for the optimization algorithm used in an <code>EnOptConfig</code> object.</p> <p>While optimization methods can have diverse parameters, this class provides a standardized set of settings that are commonly used and forwarded to the optimizer:</p> <ul> <li><code>max_iterations</code>: The maximum number of iterations allowed. The   optimizer may choose to ignore this.</li> <li><code>max_functions</code>: The maximum number of function evaluations allowed.</li> <li><code>max_batches</code>: The maximum number of evaluations batches allowed. The   optimizer callback may ask to evaluate a batch of multiple functions and   gradients at once. This setting will limit the number of those calls.</li> <li><code>tolerance</code>: The convergence tolerance used as a stopping criterion.   The exact definition depends on the optimizer, and it may be ignored.</li> <li><code>speculative</code>: If <code>True</code>, forces early gradient evaluations, even if   not strictly required. This can improve load balancing on HPC clusters but   is only effective if the optimizer supports it. This is disabled if   <code>split_evaluations</code> is <code>True</code>.</li> <li><code>split_evaluations</code>: If <code>True</code>, forces separate function and gradient   evaluations, even if the optimizer requests them together. This is useful   with realization filters that completely disable some realizations, to   potentially reduce the number of evaluations for gradients (see   <code>RealizationFilterConfig</code>).</li> <li><code>parallel</code>: If <code>True</code>, allows the optimizer to use parallelized   function evaluations. This typically applies to gradient-free methods and   may be ignored.</li> <li><code>output_dir</code>: An optional output directory where the optimizer can   store files.</li> <li><code>options</code>: A dictionary or list of strings for generic optimizer   options. The required format and interpretation depend on the specific   optimization method.</li> <li><code>stdout</code>: Redirect optimizer standard output to the given file.</li> <li><code>stderr</code>: Redirect optimizer standard error to the given file.</li> </ul> Differences between <code>max_iterations</code>, <code>max_functions</code>, and <code>max_batches</code> <p>These three parameters provide different ways to limit the duration or computational cost of the optimization process:</p> <ul> <li> <p><code>max_iterations</code>: This limit is passed directly to the backend   optimization algorithm. Many optimizers define an \"iteration\" as a   distinct step in their process, which might involve one or more   function or gradient evaluations. The interpretation of <code>max_iterations</code>   depends on the specific backend optimizer; it typically caps the number   of these internal iterations. Some backends might ignore this setting if   they don't have a clear concept of iterations.</p> </li> <li> <p><code>max_batches</code>: This limit restricts the total number of calls made   to the evaluation function provided to <code>ropt</code>. An optimizer might request   a batch containing multiple function and/or gradient evaluations within   a single call. <code>max_batches</code> limits how many such batch requests are   processed sequentially. This is particularly useful for managing resource   usage when batches are evaluated in parallel (e.g., on an HPC cluster),   as it controls the number of sequential submission steps. The number of   batches does not necessarily correspond directly to the number of   optimizer iterations, especially if function and gradient evaluations   occur in separate batches.</p> </li> <li> <p><code>max_functions</code>: This imposes a hard limit on the total number of   individual objective function evaluations performed across all batches.   Since a single batch evaluation (limited by <code>max_batches</code>) can involve   multiple function evaluations, setting <code>max_functions</code> provides more   granular control over the total computational effort spent on function   calls. It can serve as an alternative stopping criterion if the backend   optimizer doesn't support <code>max_iterations</code> or if you need to strictly   limit the function evaluation count. Note that exceeding this limit might   cause the optimization to terminate mid-batch, potentially earlier than   a corresponding <code>max_batches</code> limit would.</p> </li> </ul> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the optimization method.</p> <code>max_iterations</code> <code>PositiveInt | None</code> <p>Maximum number of iterations (optional).</p> <code>max_functions</code> <code>PositiveInt | None</code> <p>Maximum number of function evaluations (optional).</p> <code>max_batches</code> <code>PositiveInt | None</code> <p>Maximum number of batch evaluations (optional).</p> <code>tolerance</code> <code>NonNegativeFloat | None</code> <p>Convergence tolerance (optional).</p> <code>speculative</code> <code>bool</code> <p>Force early gradient evaluations (default: <code>False</code>).</p> <code>split_evaluations</code> <code>bool</code> <p>Force separate function/gradient evaluations (default: <code>False</code>).</p> <code>parallel</code> <code>bool</code> <p>Allow parallelized function evaluations (default: <code>False</code>).</p> <code>output_dir</code> <code>Path | None</code> <p>Output directory for the optimizer (optional).</p> <code>options</code> <code>dict[str, Any] | list[str] | None</code> <p>Generic options for the optimizer (optional).</p> <code>stdout</code> <code>Path | None</code> <p>File to redirect optimizer standard output (optional).</p> <code>stderr</code> <code>Path | None</code> <p>File to redirect optimizer standard error (optional).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.GradientConfig","title":"GradientConfig","text":"<p>Configuration class for gradient calculations.</p> <p>This class, <code>GradientConfig</code>, defines the configuration for gradient calculations used in an <code>EnOptConfig</code> object.</p> <p>Gradients are estimated using function values calculated from perturbed variables and the unperturbed variables. The <code>number_of_perturbations</code> field determines the number of perturbed variables used, which must be at least one.</p> <p>If function evaluations for some perturbed variables fail, the gradient may still be estimated as long as a minimum number of evaluations succeed. The <code>perturbation_min_success</code> field specifies this minimum. By default, it equals <code>number_of_perturbations</code>.</p> <p>Perturbations are generated by sampler objects configured in the parent <code>EnOptConfig</code> object. The <code>samplers</code> field specifies, for each variable, the index of the sampler to use. A random number generator is created to support samplers that require random numbers.</p> <p>The generated perturbation values are scaled by the <code>perturbation_magnitudes</code> and can be modified based on the <code>perturbation_types</code>. See <code>PerturbationType</code> for details on available perturbation types.</p> <p>Perturbed variables may violate the defined variable bounds. The <code>boundary_types</code> field specifies how to handle such violations. See <code>BoundaryType</code> for details on available boundary handling methods.</p> <p>The <code>perturbation_types</code> and <code>boundary_types</code> fields use values from the <code>PerturbationType</code> and <code>BoundaryType</code> enumerations, respectively.</p> <p>Gradients are calculated for each realization individually and then combined into a total gradient. If <code>number_of_perturbations</code> is low, or even just one, individual gradient calculations may be unreliable. In this case, setting <code>merge_realizations</code> to <code>True</code> directs the optimizer to combine the results of all realizations directly into a single gradient estimate.</p> Seed for Samplers <p>The <code>seed</code> value ensures consistent results across repeated runs with the same configuration. To obtain unique results for each optimization run, modify the seed. A common approach is to use a tuple with a unique ID as the first element, ensuring reproducibility across nested and parallel plan evaluations.</p> <p>Attributes:</p> Name Type Description <code>number_of_perturbations</code> <code>PositiveInt</code> <p>Number of perturbations (default: <code>DEFAULT_NUMBER_OF_PERTURBATIONS</code>).</p> <code>perturbation_min_success</code> <code>PositiveInt | None</code> <p>Minimum number of successful function evaluations for perturbed variables (default: equal to <code>number_of_perturbations</code>).</p> <code>perturbation_magnitudes</code> <code>Array1D</code> <p>Magnitudes of the perturbations for each variable (default: <code>DEFAULT_PERTURBATION_MAGNITUDE</code>).</p> <code>perturbation_types</code> <code>ArrayEnum</code> <p>Type of perturbation for each variable (see <code>PerturbationType</code>, default: <code>DEFAULT_PERTURBATION_TYPE</code>).</p> <code>boundary_types</code> <code>ArrayEnum</code> <p>How to handle perturbations that violate boundary conditions (see <code>BoundaryType</code>, default: <code>DEFAULT_PERTURBATION_BOUNDARY_TYPE</code>).</p> <code>samplers</code> <code>Array1DInt | None</code> <p>Indices of the samplers to use for each variable.</p> <code>seed</code> <code>ItemOrTuple[int]</code> <p>Seed for the random number generator used by the samplers.</p> <code>merge_realizations</code> <code>bool</code> <p>Merge all realizations for the final gradient calculation (default: <code>False</code>).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.FunctionEstimatorConfig","title":"FunctionEstimatorConfig","text":"<p>Configuration class for function estimators.</p> <p>This class, <code>FunctionEstimatorConfig</code>, defines the configuration for function estimators used in an <code>EnOptConfig</code> object. Function estimators are configured as a tuple in the <code>function_estimators</code> field of the <code>EnOptConfig</code>, defining the available estimators for the optimization.</p> <p>By default, objective and constraint functions, as well as their gradients, are calculated from individual realizations using a weighted sum. Function estimators provide a way to modify this default calculation.</p> <p>The <code>method</code> field specifies the function estimator method to use for combining the individual realizations. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the function estimator method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the function estimator.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationFilterConfig","title":"RealizationFilterConfig","text":"<p>Configuration class for realization filters.</p> <p>This class, <code>RealizationFilterConfig</code>, defines the configuration for realization filters used in an <code>EnOptConfig</code> object. Realization filters are configured as a tuple in the <code>realization_filters</code> field of the <code>EnOptConfig</code>, defining the available filters for the optimization.</p> <p>By default, objective and constraint functions, as well as their gradients, are calculated as a weighted function of all realizations. Realization filters provide a way to modify the weights of individual realizations. For example, they can be used to select a subset of realizations for calculating the final objective and constraint functions and their gradients by setting the weights of the other realizations to zero.</p> <p>The <code>method</code> field specifies the realization filter method to use for adjusting the weights. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the realization filter method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the realization filter.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.SamplerConfig","title":"SamplerConfig","text":"<p>Configuration class for samplers.</p> <p>This class, <code>SamplerConfig</code>, defines the configuration for samplers used in an <code>EnOptConfig</code> object. Samplers are configured as a tuple in the <code>samplers</code> field of the <code>EnOptConfig</code>, defining the available samplers for the optimization. The <code>samplers</code> field in the <code>GradientConfig</code> specifies the index of the sampler to use for each variable.</p> <p>Samplers generate perturbations added to variables for gradient calculations. These perturbations can be deterministic or stochastic.</p> <p>The <code>method</code> field specifies the sampler method to use for generating perturbations. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>By default, each realization uses a different set of perturbed variables. Setting the <code>shared</code> flag to <code>True</code> directs the sampler to use the same set of perturbed values for all realizations.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the sampler method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the sampler.</p> <code>shared</code> <code>bool</code> <p>Whether to share perturbation values between realizations (default: <code>False</code>).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants","title":"ropt.config.enopt.constants","text":"<p>Default values used by the configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_SEED","title":"DEFAULT_SEED  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SEED: Final = 1\n</code></pre> <p>Default seed for random number generators.</p> <p>The seed is used as the base value for random number generators within various components of the optimization process, such as samplers. Using a consistent seed ensures reproducibility across multiple runs with the same configuration. To obtain unique results for each optimization run, modify this seed.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_NUMBER_OF_PERTURBATIONS","title":"DEFAULT_NUMBER_OF_PERTURBATIONS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_NUMBER_OF_PERTURBATIONS: Final = 5\n</code></pre> <p>Default number of perturbations for gradient estimation.</p> <p>This value defines the default number of perturbed variables used to estimate gradients. A higher number of perturbations can lead to more accurate gradient estimates but also increases the number of function evaluations required.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_MAGNITUDE","title":"DEFAULT_PERTURBATION_MAGNITUDE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_MAGNITUDE: Final = 0.005\n</code></pre> <p>Default magnitude for variable perturbations.</p> <p>This value specifies the default value of the scaling factor applied to the perturbation values generated by samplers. The magnitude can be interpreted as an absolute value or as a relative value, depending on the selected perturbation type.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_BOUNDARY_TYPE","title":"DEFAULT_PERTURBATION_BOUNDARY_TYPE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_BOUNDARY_TYPE: Final = MIRROR_BOTH\n</code></pre> <p>Default perturbation boundary handling type.</p> <p>This value determines how perturbations that violate the defined variable bounds are handled. The default, <code>BoundaryType.MIRROR_BOTH</code>, mirrors perturbations back into the valid range if they exceed either the lower or upper bound.</p> <p>See also: <code>BoundaryType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_TYPE","title":"DEFAULT_PERTURBATION_TYPE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_TYPE: Final = ABSOLUTE\n</code></pre> <p>Default perturbation type.</p> <p>This value determines how the perturbation magnitude is interpreted. The default, <code>PerturbationType.ABSOLUTE</code>, means that the perturbation magnitude is added directly to the variable value. Other options, such as <code>PerturbationType.RELATIVE</code>, scale the perturbation magnitude based on the variable's bounds.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.options","title":"ropt.config.options","text":"<p>This module defines utilities for validating plugin options.</p> <p>This module provides classes and functions to define and validate options for plugins. It uses Pydantic to create models that represent the schema of plugin options, allowing for structured and type-safe configuration.</p> <p>Classes:</p> Name Description <code>OptionsSchemaModel</code> <p>Represents the overall schema for plugin options.</p> <code>MethodSchemaModel</code> <p>Represents the schema for a specific method within a plugin, including its name and options.</p>"},{"location":"reference/enopt_config/#ropt.config.options.OptionsSchemaModel","title":"OptionsSchemaModel","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the overall schema for plugin options.</p> <p>This class defines the structure for describing the methods and options available for a plugin. The methods are described in a list of [<code>MethodSchemaModel][ropt.config.options.MethodSchemaModel</code>] objects, each describing a method supported by the plugin.</p> <p>Attributes:</p> Name Type Description <code>methods</code> <code>dict[str, MethodSchemaModel[Any]]</code> <p>A list of method schemas.</p> <p>Example: <pre><code>from ropt.config.options import OptionsSchemaModel\n\nschema = OptionsSchemaModel.model_validate(\n    {\n        \"methods\": [\n            {\n                \"options\": {\"a\": float}\n            },\n            {\n                \"options\": {\"b\": int | str},\n            },\n        ]\n    }\n)\n\noptions = schema.get_options_model(\"method\")\nprint(options.model_validate({\"a\": 1.0, \"b\": 1}))  # a=1.0 b=1\n</code></pre></p>"},{"location":"reference/enopt_config/#ropt.config.options.OptionsSchemaModel.get_options_model","title":"get_options_model","text":"<pre><code>get_options_model(method: str) -&gt; type[BaseModel]\n</code></pre> <p>Creates a Pydantic model for validating options of a specific method.</p> <p>This method dynamically generates a Pydantic model tailored to validate the options associated with a given method. It iterates through the defined methods, collecting option schemas from those matching the specified <code>method</code> name. The resulting model can then be used to validate dictionaries of options against the defined schema.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The name of the method for which to create the options model.</p> required <p>Returns:</p> Type Description <code>type[BaseModel]</code> <p>A Pydantic model class capable of validating options for the specified method.</p>"},{"location":"reference/enopt_config/#ropt.config.options.MethodSchemaModel","title":"MethodSchemaModel","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Represents the schema for a specific method within a plugin.</p> <p>This class defines the structure for describing one or more methods supported by a plugin. It contains a dictionary describing an option for this method.</p> <p>Attributes:</p> Name Type Description <code>options</code> <code>dict[str, T]</code> <p>A list of option dictionaries.</p> <code>url</code> <code>HttpUrl | None</code> <p>An optional URL for the plugin.</p>"},{"location":"reference/enopt_config/#ropt.config.options.gen_options_table","title":"gen_options_table","text":"<pre><code>gen_options_table(schema: dict[str, Any]) -&gt; str\n</code></pre> <p>Generates a Markdown table documenting plugin options.</p> <p>This function takes a schema dictionary, validates it against the <code>OptionsSchemaModel</code>, and then generates a Markdown table that summarizes the available methods and their options. Each row in the table represents a method, and the columns list the method's name and its configurable options. If a URL is provided for a method, the method name will be hyperlinked to that URL in the table.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict[str, Any]</code> <p>A dictionary representing the schema of plugin options.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string containing a Markdown table that documents the plugin options.</p>"},{"location":"reference/enums/","title":"Enumerations","text":""},{"location":"reference/enums/#ropt.enums","title":"ropt.enums","text":"<p>Enumerations used within the <code>ropt</code> library.</p>"},{"location":"reference/enums/#ropt.enums.VariableType","title":"VariableType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the variable types.</p> <p>The variable types are configured in the <code>variables</code> section of the optimizer configuration. The optimization backends may make us of this information to modify their behavior accordingly.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.REAL","title":"REAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REAL = 1\n</code></pre> <p>Continuous variables represented by real values.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.INTEGER","title":"INTEGER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTEGER = 2\n</code></pre> <p>Discrete variables represented by integer values.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType","title":"BoundaryType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the ways boundaries should be treated.</p> <p>When variables are perturbed their values may violate boundary constraints. This enumeration lists the ways these values can be modified to fix this.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.NONE","title":"NONE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONE = 1\n</code></pre> <p>Do not modify the value.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.TRUNCATE_BOTH","title":"TRUNCATE_BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TRUNCATE_BOTH = 2\n</code></pre> <p>Truncate the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     l_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     b_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.BoundaryType.MIRROR_BOTH","title":"MIRROR_BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MIRROR_BOTH = 3\n</code></pre> <p>Mirror the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     2l_i - v_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     2b_i - v_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i        &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.PerturbationType","title":"PerturbationType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of perturbations that can be applied.</p> <p>When applying a perturbation to a variable, generally, some value is generated, which is then applied to the unperturbed values (usually by addition). This enumeration lists the ways how this perturbation value can be modified before being added to the unperturbed variable.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.ABSOLUTE","title":"ABSOLUTE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABSOLUTE = 1\n</code></pre> <p>Use the perturbation value as is.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.RELATIVE","title":"RELATIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RELATIVE = 2\n</code></pre> <p>Multiply the perturbation value \\(p_i\\) by the range defined by the bounds of the variables \\(c_i\\): \\(\\hat{p}_i = (c_{i,\\text{max}} - c_{i,\\text{min}}) \\times p_i\\). The bounds will generally be defined in the configuration for the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.EventType","title":"EventType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the events handled by the event broker.</p> <p>During the execution of the optimization plan, events may be emitted and callbacks can be connected to these events . When triggered by an event, the callbacks receive an <code>Event</code> object. This object contains at least the type of the event (a value of this enumeration) and the current configuration of the step that is executing. If the step has a name it is also added to the event. Additionally, depending on the event type, a tuple of result objects, an exit code  may be present. Refer to the documentation of the individual event types for details.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATION","title":"START_EVALUATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_EVALUATION = 1\n</code></pre> <p>Emitted before evaluating new functions.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATION","title":"FINISHED_EVALUATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_EVALUATION = 2\n</code></pre> <p>Emitted after finishing the evaluation.</p> <p>Results may be passed to callback reacting to this event.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_OPTIMIZER_STEP","title":"START_OPTIMIZER_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_OPTIMIZER_STEP = 3\n</code></pre> <p>Emitted just before starting an optimizer step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_OPTIMIZER_STEP","title":"FINISHED_OPTIMIZER_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_OPTIMIZER_STEP = 4\n</code></pre> <p>Emitted immediately after an optimizer step finishes.</p> <p>Results and an exit code may be passed via the event object.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATOR_STEP","title":"START_EVALUATOR_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_EVALUATOR_STEP = 5\n</code></pre> <p>Emitted just before starting an evaluation step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATOR_STEP","title":"FINISHED_EVALUATOR_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_EVALUATOR_STEP = 6\n</code></pre> <p>Emitted immediately after an evaluation step finishes.</p> <p>Results and an exit code may be passed via the event object.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode","title":"OptimizerExitCode","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the reasons for terminating an optimization.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = 0\n</code></pre> <p>Unknown cause of termination.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.TOO_FEW_REALIZATIONS","title":"TOO_FEW_REALIZATIONS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TOO_FEW_REALIZATIONS = 1\n</code></pre> <p>Returned when too few realizations are evaluated successfully.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.MAX_FUNCTIONS_REACHED","title":"MAX_FUNCTIONS_REACHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MAX_FUNCTIONS_REACHED = 2\n</code></pre> <p>Returned when the maximum number of function evaluations is reached.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.MAX_BATCHES_REACHED","title":"MAX_BATCHES_REACHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MAX_BATCHES_REACHED = 3\n</code></pre> <p>Returned when the maximum number of evaluation batches is reached.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.NESTED_OPTIMIZER_FAILED","title":"NESTED_OPTIMIZER_FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NESTED_OPTIMIZER_FAILED = 4\n</code></pre> <p>Returned when a nested optimization fails to find an optimal value.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.USER_ABORT","title":"USER_ABORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>USER_ABORT = 5\n</code></pre> <p>Returned when the optimization is aborted by the user.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.OPTIMIZER_STEP_FINISHED","title":"OPTIMIZER_STEP_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OPTIMIZER_STEP_FINISHED = 6\n</code></pre> <p>Returned when an optimization step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.EVALUATION_STEP_FINISHED","title":"EVALUATION_STEP_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EVALUATION_STEP_FINISHED = 7\n</code></pre> <p>Returned when an evaluation step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis","title":"ResultAxis","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumerates the possible axes in a Results data object.</p> <p>Result objects (see <code>Results</code>) contain multidimensional arrays where the axes represent particular quantities, for instance variables, function objects, or realization numbers. The result objects contain metadata that identify the axes by values of this enumeration. These can be retrieved by the <code>get_axes</code> method of the attributes of a results object. They are used internally when exporting data to determine the type of the array axes, for instance to retrieve the names of the variables from the configuration.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.VARIABLE","title":"VARIABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VARIABLE = 'variable'\n</code></pre> <p>The axis index corresponds to the index of the variable.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.OBJECTIVE","title":"OBJECTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OBJECTIVE = 'objective'\n</code></pre> <p>The axis index corresponds to the index of the objective function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.LINEAR_CONSTRAINT","title":"LINEAR_CONSTRAINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINEAR_CONSTRAINT = 'linear_constraint'\n</code></pre> <p>The axis index corresponds to the index of the linear constraint.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.NONLINEAR_CONSTRAINT","title":"NONLINEAR_CONSTRAINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONLINEAR_CONSTRAINT = 'nonlinear_constraint'\n</code></pre> <p>The axis index corresponds to the index of the constraint function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.REALIZATION","title":"REALIZATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REALIZATION = 'realization'\n</code></pre> <p>The axis index corresponds to the index of the realization.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.PERTURBATION","title":"PERTURBATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PERTURBATION = 'perturbation'\n</code></pre> <p>The axis index corresponds to the index of the perturbation.</p>"},{"location":"reference/evaluator/","title":"Function Evaluations","text":""},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator","title":"ropt.ensemble_evaluator.EnsembleEvaluator","text":"<p>Construct functions and gradients from an ensemble of functions.</p> <p>The <code>EnsembleEvaluator</code> class is responsible for calculating functions and gradients from an ensemble of functions. It leverages the settings defined in an <code>EnOptConfig</code> configuration object to guide the calculations.</p> <p>The core functionality relies on an <code>Evaluator</code> callable, which is used to evaluate the individual functions within the ensemble. The evaluator provides the raw function values, which are then processed by the <code>EnsembleEvaluator</code> to produce the final function and gradient estimates.</p>"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.__init__","title":"__init__","text":"<pre><code>__init__(\n    config: EnOptConfig,\n    transforms: OptModelTransforms | None,\n    evaluator: Evaluator,\n    plugin_manager: PluginManager,\n) -&gt; None\n</code></pre> <p>Initialize the EnsembleEvaluator.</p> <p>This method sets up the <code>EnsembleEvaluator</code> with the necessary configuration, evaluator, and plugins.</p> <p>The <code>config</code> object contains all the settings required for the ensemble evaluation, such as the number of realizations, the function estimators, and the gradient settings. The <code>transforms</code> object can be used to transform the variables, objectives, and constraints before or after the evaluation. The <code>evaluator</code> callable should conform to the <code>Evaluator</code> protocol. The <code>plugin_manager</code> is used to load the realization filters, function estimators, and samplers.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration object.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms object.</p> required <code>evaluator</code> <code>Evaluator</code> <p>The callable for evaluating individual functions.</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>A plugin manager to load required plugins.</p> required"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.calculate","title":"calculate","text":"<pre><code>calculate(\n    variables: NDArray[float64],\n    *,\n    compute_functions: bool,\n    compute_gradients: bool,\n) -&gt; tuple[Results, ...]\n</code></pre> <p>Evaluate the given variable vectors.</p> <p>This method calculates functions, gradients, or both, based on the provided variable vectors and the specified flags.</p> <p>The <code>variables</code> argument can be a single vector or a matrix where each row is a variable vector.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vectors to evaluate.</p> required <code>compute_functions</code> <code>bool</code> <p>Whether to calculate functions.</p> required <code>compute_gradients</code> <code>bool</code> <p>Whether to calculate gradients.</p> required <p>Returns:</p> Type Description <code>tuple[Results, ...]</code> <p>The results for function evaluations and/or gradient evaluations.</p>"},{"location":"reference/evaluator/#ropt.evaluator.Evaluator","title":"ropt.evaluator.Evaluator","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for evaluator objects or callables.</p> <p>The <code>EnsembleEvaluator</code> class requires a function evaluator callback that conforms to the <code>Evaluator</code> signature. This callback accepts one or more variable vectors to evaluate, along with an <code>EvaluatorContext</code> object that provides relevant information for the evaluation. It returns an <code>EvaluatorResult</code> object containing the results.</p>"},{"location":"reference/evaluator/#ropt.evaluator.Evaluator.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64], context: EvaluatorContext\n) -&gt; EvaluatorResult\n</code></pre> <p>Evaluate objective and constraint functions for given variables.</p> <p>This method defines the signature for the function evaluator callback. The evaluator calculates objective and constraint functions for a set of variable vectors, potentially for a subset of realizations and perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate. Each row represents        a variable vector.</p> required <code>context</code> <code>EvaluatorContext</code> <p>The evaluation context, providing additional information        about the evaluation.</p> required <p>Returns:</p> Type Description <code>EvaluatorResult</code> <p>An evaluation results object containing the calculated objective and constraint values, along with any additional metadata.</p> Reusing Objective <p>When defining multiple objectives, there may be a need to reuse the same objective value multiple times. For instance, a total objective could consist of the mean of the objectives for each realization, plus the standard deviation of the same values. This can be implemented by defining two objectives: the first calculated as the mean of the realizations, and the second using a function estimator to compute the standard deviations. The optimizer is unaware that both objectives use the same set of realizations. To prevent redundant calculations, the evaluator should compute the results of the realizations once and return them for both objectives.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext","title":"ropt.evaluator.EvaluatorContext  <code>dataclass</code>","text":"<p>Capture additional details for the function evaluator.</p> <p>Function evaluator callbacks (see <code>Evaluator</code>) primarily receive variable vectors to evaluate objective and constraint functions. However, they may also benefit from additional information to optimize their calculations. This <code>EvaluatorContext</code> object provides that supplementary information.</p> <p>Specifically, it provides:</p> <ul> <li>The configuration object for the current optimization step.</li> <li>The realization index for each variable vector.</li> <li>The perturbation index for each variable vector (if applicable). A value   less than 0 indicates that the vector is not a perturbation.</li> <li>Boolean matrices (<code>active_objectives</code> and <code>active_constraints</code>) indicating   which objective/realization and constraint/realization evaluations are   required by the optimizer.</li> <li>A boolean vector (<code>active</code>) indicating which realizations require   evaluation.</li> </ul> <p>The <code>active_objectives</code> and <code>active_constraints</code> matrices are structured such that each column corresponds to a realization, and each row corresponds to a function or constraint. A <code>True</code> value signifies that the corresponding evaluation is essential for the optimizer.</p> The <code>active</code> property <p>In many cases, evaluators may only be able to compute all objectives and constraints for a given realization or none at all. In these scenarios, the <code>active</code> property provides a simplified view, indicating only the realizations that need to be evaluated. <code>active</code> cannot be set when creating the evaluator context, it is calculated from <code>active_objectives</code> and <code>active_constraints</code>.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>Configuration of the optimizer.</p> required <code>realizations</code> <code>NDArray[intc]</code> <p>Realization numbers for each requested evaluation.</p> required <code>perturbations</code> <code>NDArray[intc] | None</code> <p>Perturbation numbers for each requested evaluation.                 A value less than 0 indicates that the vector is                 not a perturbation.</p> <code>None</code> <code>active_objectives</code> <code>NDArray[bool_] | None</code> <p>Indicates which function/realization evaluations are                 essential for the optimizer.</p> <code>None</code> <code>active_constraints</code> <code>NDArray[bool_] | None</code> <p>Indicates which constraint/realization evaluations                 are essential for the optimizer.</p> <code>None</code>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorResult","title":"ropt.evaluator.EvaluatorResult  <code>dataclass</code>","text":"<p>Store the results of a function evaluation.</p> <p>This class stores the results of evaluating objective and constraint functions for a set of variable vectors.</p> <p>The <code>objectives</code> and <code>constraints</code> are stored as matrices. Each column in these matrices corresponds to a specific objective or constraint, and each row corresponds to a variable vector.</p> <p>When the evaluator is asked to evaluate functions, some variable vectors may be marked as inactive. The results for these inactive vectors should be set to zero. All active variable vectors should be evaluated. If an evaluation fails for any reason, the corresponding values should be set to <code>numpy.nan</code>.</p> <p>A <code>batch_id</code> can be set to identify this specific set of evaluation results.</p> <p>The <code>evaluation_info</code> dictionary can store additional metadata for each evaluation. This information is not used internally by <code>ropt</code> and can have an arbitrary structure, to be interpreted by the application. This can be used, for example, to uniquely identify the results calculated for each variable vector, allowing them to be linked back to their corresponding input vectors.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The calculated objective values.</p> required <code>constraints</code> <code>NDArray[float64] | None</code> <p>Optional calculated constraint values.</p> <code>None</code> <code>batch_id</code> <code>int | None</code> <p>Optional batch ID to identify this set of results.</p> <code>None</code> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional info for each evaluation.</p> <code>dict()</code>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#ropt.exceptions","title":"ropt.exceptions","text":"<p>Exceptions raised within the <code>ropt</code> library.</p>"},{"location":"reference/exceptions/#ropt.exceptions.ConfigError","title":"ConfigError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an configuration error occurs.</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted","title":"OptimizationAborted","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization is aborted.</p> <p>When constructing the exception object an exit code must be passed that indicates the reason for aborting (see <code>OptimizerExitCode</code>).</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted.__init__","title":"__init__","text":"<pre><code>__init__(exit_code: OptimizerExitCode) -&gt; None\n</code></pre> <p>Initialize an exception that aborts the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>exit_code</code> <code>OptimizerExitCode</code> <p>The exit code indicating the reason for the abort.</p> required"},{"location":"reference/exceptions/#ropt.exceptions.PlanAborted","title":"PlanAborted","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization plan is aborted.</p> <p>Steps within a plan may abort a plan by setting its <code>aborted</code> attribute. Any attemps to run steps after this, will raise this exception.</p>"},{"location":"reference/external_optimizer_plugin/","title":"External Optimizer Plugin","text":""},{"location":"reference/external_optimizer_plugin/#ropt.plugins.optimizer.external.ExternalOptimizer","title":"ropt.plugins.optimizer.external.ExternalOptimizer","text":"<p>               Bases: <code>Optimizer</code></p> <p>Plugin class for optimization using an external process.</p> <p>This class enables optimization via an external process, which performs the optimization independently and communicates with this class over pipes to request function evaluations, report optimizer states, and handle any errors.</p> <p>Typically, the optimizer is specified within an <code>OptimizerConfig</code> via the <code>method</code> field, which either provides the algorithm name directly or follows the form <code>plugin-name/method-name</code>. In the first case, <code>ropt</code> searches among all available optimizer plugins to find the specified method. In the second case, it checks if the plugin identified by <code>plugin-name</code> contains <code>method-name</code> and, if so, uses it. Both of these are not supported by the external optimizer class. Instead, it requires that the <code>method</code> field includes both the plugin and method names in the format <code>external/plugin-name/method-name</code> or <code>external/method-name</code>. This ensures the external optimizer can identify and launch the specified optimization method <code>method-name</code> and launch it as an external process.</p>"},{"location":"reference/function_estimator_plugins/","title":"Function estimator Plugins","text":""},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator","title":"ropt.plugins.function_estimator","text":"<p>Provides plugin functionality for adding function estimators.</p> <p>Function estimators are used by the optimization process to combine the results (objective function values and gradients) from a set of realizations into a single representative value. This module allows for the extension of <code>ropt</code> with custom strategies for aggregating ensemble results.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Function estimator plugins must inherit from the   <code>FunctionEstimatorPlugin</code>   base class. This class acts as a factory, defining a <code>create</code> method to   instantiate estimator objects.</li> <li>Estimator Implementation: The actual aggregation logic resides in classes   that inherit from the   <code>FunctionEstimator</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>) and the index   of the specific estimator configuration to use (<code>estimator_index</code>). The core   functionality is provided by the <code>calculate_function</code> and   <code>calculate_gradient</code> methods, which combine the function values and gradients   from multiple realizations, respectively, using realization weights.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>FunctionEstimatorPlugin</code> implementations (typically via entry   points) and uses them to create <code>FunctionEstimator</code> instances as needed   during plan execution.</li> </ul> <p>Built-in Function Estimator Plugins:</p> <p>The default <code>DefaultFunctionEstimator</code> class provides methods for calculating the weighted mean (<code>mean</code>) and standard deviation (<code>stddev</code>) of the realization results.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin","title":"ropt.plugins.function_estimator.base.FunctionEstimatorPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Function Estimator Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>FunctionEstimator</code> instances. These plugins act as factories for specific function estimation strategies.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate function estimator plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>FunctionEstimator</code> object that will perform the aggregation of ensemble results (function values and gradients).</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig, estimator_index: int\n) -&gt; FunctionEstimator\n</code></pre> <p>Factory method to create a concrete FunctionEstimator instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>FunctionEstimator</code> objects. Plugin implementations must override this method to return an instance of their specific <code>FunctionEstimator</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires a function estimator provided by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The main EnOpt configuration object.</p> required <code>estimator_index</code> <code>int</code> <p>Index into <code>enopt_config.function_estimators</code> for              this estimator.</p> required <p>Returns:</p> Type Description <code>FunctionEstimator</code> <p>An initialized FunctionEstimator object ready for use.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator","title":"ropt.plugins.function_estimator.base.FunctionEstimator","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Function Estimator Implementations.</p> <p>This class defines the fundamental interface for all concrete function estimator implementations within the <code>ropt</code> framework. Function estimator plugins provide classes derived from <code>FunctionEstimator</code> that encapsulate the logic for combining the objective function values and gradients from an ensemble of realizations into a single representative value. This aggregated value is then used by the core optimization algorithm.</p> <p>Instances of <code>FunctionEstimator</code> subclasses are created by their corresponding <code>FunctionEstimatorPlugin</code> factories. They are initialized with an <code>EnOptConfig</code> object detailing the optimization setup and the <code>estimator_index</code> identifying the specific estimator configuration to use from the config.</p> <p>The core functionality involves combining results using realization weights, performed by the <code>calculate_function</code> and <code>calculate_gradient</code> methods, which must be implemented by subclasses.</p> <p>Subclasses must implement:</p> <ul> <li><code>__init__</code>: To accept the configuration and index.</li> <li><code>calculate_function</code>: To combine function values from realizations.</li> <li><code>calculate_gradient</code>: To combine gradient values from realizations.</li> </ul>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig, estimator_index: int\n) -&gt; None\n</code></pre> <p>Initialize the function estimator object.</p> <p>The <code>function_estimators</code> field in the <code>enopt_config</code> is a tuple of estimator configurations (<code>FunctionEstimatorConfig</code>). The <code>estimator_index</code> identifies which configuration from this tuple should be used to initialize this specific estimator instance.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>estimator_index</code> <code>int</code> <p>The index of the estimator configuration to use.</p> required"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator.calculate_function","title":"calculate_function  <code>abstractmethod</code>","text":"<pre><code>calculate_function(\n    functions: NDArray[float64], weights: NDArray[float64]\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Combine function values from realizations into an expected value.</p> <p>This method takes the function (objective or constraint) values evaluated for each realization in the ensemble and combines them into a single representative value or vector of values, using the provided realization weights.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The function values for each realization.</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight for each realization.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A scalar or 1D array representing the combined function value(s).</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimator.calculate_gradient","title":"calculate_gradient  <code>abstractmethod</code>","text":"<pre><code>calculate_gradient(\n    functions: NDArray[float64],\n    gradient: NDArray[float64],\n    weights: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Combine gradients from realizations into an expected gradient.</p> <p>This method takes the gradients evaluated for each realization and combines them into a single representative gradient vector or matrix, using the provided realization weights and potentially the function values themselves (e.g., for estimators like standard deviation where the chain rule applies).</p> Interaction with <code>merge_realizations</code> <p>The <code>merge_realizations</code> flag in the <code>GradientConfig</code> determines how the initial gradient estimate(s) are computed by <code>ropt</code> before being passed to this <code>calculate_gradient</code> method.</p> <ul> <li>If <code>False</code> (default): <code>ropt</code> estimates a separate gradient for each   realization that has a non-zero weight. The implementation   must then combine these gradients using the provided <code>weights</code>.</li> <li>If <code>True</code>: <code>ropt</code> computes a single, merged gradient estimate by   treating all perturbations across all realizations collectively.   The implementation must handle this input appropriately. For simple   averaging estimators, this might involve returning the input gradient   unchanged.</li> </ul> <p>The <code>merge_realizations=True</code> option allows gradient estimation even with a low number of perturbations (potentially just one) but is generally only suitable for estimators performing averaging-like operations. Estimator implementations should check this flag during initialization (<code>__init__</code>) and raise a <code>ConfigError</code> if <code>merge_realizations=True</code> is incompatible with the estimator's logic (e.g., standard deviation).</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization.</p> required <code>gradient</code> <code>NDArray[float64]</code> <p>The gradient for each realization.</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected gradients.</p>"},{"location":"reference/optimization/","title":"Optimization","text":""},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer","title":"ropt.optimization.EnsembleOptimizer","text":"<p>Optimizer for ensemble-based optimizations.</p> <p>The <code>EnsembleOptimizer</code> class provides the core functionality for running ensemble-based optimizations. Direct use of this class is generally discouraged. Instead, the <code>Plan</code> or <code>BasicOptimizer</code> classes are recommended for greater flexibility and ease of use.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.is_parallel","title":"is_parallel  <code>property</code>","text":"<pre><code>is_parallel: bool\n</code></pre> <p>Determine if the optimization supports parallel evaluations.</p> <p>The underlying optimization algorithm may request function evaluations via a callback. Parallel optimization, in this context, means that the algorithm may request multiple function evaluations in a single callback.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimization supports parallel evaluations, <code>False</code></p> <code>bool</code> <p>otherwise.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig,\n    ensemble_evaluator: EnsembleEvaluator,\n    plugin_manager: PluginManager,\n    signal_evaluation: SignalEvaluationCallback\n    | None = None,\n    nested_optimizer: NestedOptimizerCallback | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the EnsembleOptimizer.</p> <p>This class orchestrates ensemble-based optimizations. It requires an optimization configuration, an evaluator, and a plugin manager to function.</p> <p>The <code>EnsembleOptimizer</code> needs the following to define a single optimization run:</p> <ol> <li>An <code>EnOptConfig</code> object: This     contains all configuration settings for the optimization.</li> <li>An <code>EnsembleEvaluator</code>     object: This object is responsible for evaluating functions.</li> <li>A <code>PluginManager</code> object: This object     provides access to optimizer plugins.</li> </ol> <p>Additionally, two optional callbacks can be provided to extend the functionality:</p> <ol> <li>A     <code>SignalEvaluationCallback</code>:     This callback is invoked before and after each function evaluation.</li> <li>A     <code>NestedOptimizerCallback</code>:     This callback is invoked at each function evaluation to run a nested     optimization.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The ensemble optimization configuration.</p> required <code>ensemble_evaluator</code> <code>EnsembleEvaluator</code> <p>The evaluator for function evaluations.</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>The plugin manager.</p> required <code>signal_evaluation</code> <code>SignalEvaluationCallback | None</code> <p>Optional callback to signal evaluations.</p> <code>None</code> <code>nested_optimizer</code> <code>NestedOptimizerCallback | None</code> <p>Optional callback for nested optimizations.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.start","title":"start","text":"<pre><code>start(variables: NDArray[float64]) -&gt; OptimizerExitCode\n</code></pre> <p>Start the optimization process.</p> <p>This method initiates the optimization process using the provided initial variables. The optimization will continue until a stopping criterion is met or an error occurs.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The initial variables for the optimization.</p> required <p>Returns:</p> Type Description <code>OptimizerExitCode</code> <p>An <code>OptimizerExitCode</code> indicating</p> <code>OptimizerExitCode</code> <p>the reason for termination.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback","title":"ropt.optimization.SignalEvaluationCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for a callback to signal the start and end of an evaluation.</p> <p>This callback is invoked before and after each evaluation, allowing for custom handling or tracking of evaluation events.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    results: tuple[Results, ...] | None = None,\n) -&gt; None\n</code></pre> <p>Callback protocol for signaling the start and end of evaluations.</p> <p>This callback is invoked by the ensemble optimizer before and after each evaluation. Before the evaluation starts, the callback is called with <code>results</code> set to <code>None</code>. After the evaluation completes, the callback is called again, this time with <code>results</code> containing the output of the evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>tuple[Results, ...] | None</code> <p>The results produced by the evaluation, or <code>None</code> if the      evaluation has not yet started.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback","title":"ropt.optimization.NestedOptimizerCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for functions that start a nested optimization.</p>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64],\n) -&gt; tuple[FunctionResults | None, bool]\n</code></pre> <p>Callback protocol for executing a nested optimization.</p> <p>This function is invoked by the ensemble optimizer during each function evaluation to initiate a nested optimization process. It receives the current variables as input and is expected to perform a nested optimization using these variables as a starting point. The function should return a tuple containing the result of the nested optimization and a boolean indicating whether the nested optimization was aborted by the user. The result of the nested optimization should be a <code>FunctionResults</code> object, or <code>None</code> if no result is available.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variables to use as the starting point.</p> required <p>Returns:</p> Type Description <code>tuple[FunctionResults | None, bool]</code> <p>The result and a boolean indicating if the user aborted.</p>"},{"location":"reference/optimizer_plugins/","title":"Optimizer Plugins","text":""},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer","title":"ropt.plugins.optimizer","text":"<p>Framework and Implementations for Optimizer Plugins.</p> <p>This module provides the necessary components for integrating optimization algorithms into <code>ropt</code> via its plugin system. Optimizer plugins allow <code>ropt</code> to utilize various optimization techniques, either built-in or provided by third-party packages.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Optimizer plugins must inherit from the   <code>OptimizerPlugin</code> base class.   This class acts as a factory, defining a <code>create</code> method to instantiate   optimizer objects.</li> <li>Optimizer Implementation: The actual optimization logic resides in classes   that inherit from the <code>Optimizer</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>) and an   <code>OptimizerCallback</code>. The   callback is used by the optimizer to request function and gradient evaluations   from <code>ropt</code>. The optimization process is initiated by calling the optimizer's   <code>start</code> method.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>OptimizerPlugin</code> implementations (typically via entry points) and   uses them to create <code>Optimizer</code> instances as needed during plan execution.</li> </ul> <p>Utilities:</p> <p>The <code>ropt.plugins.optimizer.utils</code> module offers helper functions for common tasks within optimizer plugins, such as validating constraint support and handling normalized constraints.</p> <p>Built-in Optimizers:</p> <p><code>ropt</code> includes the following optimizers by default:</p> <ul> <li><code>SciPyOptimizer</code>: Provides   access to various algorithms from the <code>scipy.optimize</code> library.</li> <li><code>ExternalOptimizer</code>:   Enables running other optimizer plugins in a separate external process, useful   for isolation or specific execution environments.</li> </ul>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin","title":"ropt.plugins.optimizer.base.OptimizerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Optimizer Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>Optimizer</code> instances. These plugins act as factories for specific optimization algorithms or backends.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate optimizer plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>Optimizer</code> object that will perform the optimization.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    config: EnOptConfig,\n    optimizer_callback: OptimizerCallback,\n) -&gt; Optimizer\n</code></pre> <p>Create an Optimizer instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>Optimizer</code> objects. Plugin implementations must override this method to return an instance of their specific <code>Optimizer</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires an optimizer provided by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The  configuration object containing the                 optimization settings.</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The callback function used by the optimizer to                 request evaluations.</p> required <p>Returns:</p> Type Description <code>Optimizer</code> <p>An initialized instance of an <code>Optimizer</code> subclass.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.validate_options","title":"validate_options  <code>classmethod</code>","text":"<pre><code>validate_options(\n    method: str, options: dict[str, Any] | list[str] | None\n) -&gt; None\n</code></pre> <p>Validate the optimizer-specific options for a given method.</p> <p>This class method is intended to check if the <code>options</code> dictionary, typically provided in the <code>OptimizerConfig</code>, contains valid keys and values for the specified optimization <code>method</code> supported by this plugin.</p> <p>This default implementation performs no validation. Subclasses should override this method to implement validation logic specific to the methods they support, potentially using schema validation tools like Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The specific optimization method name (e.g., \"slsqp\",      \"my_optimizer/variant1\").</p> required <code>options</code> <code>dict[str, Any] | list[str] | None</code> <p>The dictionary or a list of strings of options.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the provided options are invalid for the specified        method.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer","title":"ropt.plugins.optimizer.base.Optimizer","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Optimizer Implementations.</p> <p>This class defines the fundamental interface for all concrete optimizer implementations within the <code>ropt</code> framework. Optimizer plugins provide classes derived from <code>Optimizer</code> that encapsulate the logic of specific optimization algorithms.</p> <p>Instances of <code>Optimizer</code> subclasses are created by their corresponding <code>OptimizerPlugin</code> factories. They are initialized with an <code>EnOptConfig</code> object detailing the optimization setup and an <code>OptimizerCallback</code> function. The callback is crucial as it allows the optimizer to request function and gradient evaluations from the <code>ropt</code> core during its execution.</p> <p>The optimization process itself is initiated by calling the <code>start</code> method, which must be implemented by subclasses.</p> <p>Subclasses must implement: - <code>__init__</code>: To accept the configuration and callback. - <code>start</code>: To contain the main optimization loop.</p> <p>Subclasses can optionally override: - <code>allow_nan</code>:   To indicate if the algorithm can handle NaN function values. - <code>is_parallel</code>: To indicate if the algorithm may perform parallel evaluations.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.allow_nan","title":"allow_nan  <code>property</code>","text":"<pre><code>allow_nan: bool\n</code></pre> <p>Indicate whether the optimizer can handle NaN function values.</p> <p>If an optimizer algorithm can gracefully handle <code>NaN</code> (Not a Number) objective function values, its implementation should override this property to return <code>True</code>.</p> <p>This is particularly relevant in ensemble-based optimization where evaluations might fail for all realizations. When <code>allow_nan</code> is <code>True</code>, setting <code>realization_min_success</code> to zero allows the evaluation process to return <code>NaN</code> instead of raising an error, enabling the optimizer to potentially continue.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimizer supports NaN function values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.is_parallel","title":"is_parallel  <code>property</code>","text":"<pre><code>is_parallel: bool\n</code></pre> <p>Indicate whether the optimizer alows parallel evaluations.</p> <p>If an optimizer algorithm is designed to evaluate multiple variable vectors concurrently, its implementation should override this property to return <code>True</code>.</p> <p>This information can be used by <code>ropt</code> or other components to manage resources or handle parallel execution appropriately.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimizer allows parallel evaluations.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    config: EnOptConfig,\n    optimizer_callback: OptimizerCallback,\n) -&gt; None\n</code></pre> <p>Initialize an optimizer object.</p> <p>The <code>config</code> object provides the desired configuration for the optimization process and should be used to set up the optimizer correctly before starting the optimization. The optimization will be initiated using the <code>start</code> method and will repeatedly require function and gradient evaluations at given variable vectors. The <code>optimizer_callback</code> argument provides the function that should be used to calculate the function and gradient values, which can then be forwarded to the optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used.</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.start","title":"start  <code>abstractmethod</code>","text":"<pre><code>start(initial_values: NDArray[float64]) -&gt; None\n</code></pre> <p>Initiate the optimization process.</p> <p>This abstract method must be implemented by concrete <code>Optimizer</code> subclasses to start the optimization process. It takes the initial set of variable values as input.</p> <p>During execution, the implementation should use the <code>OptimizerCallback</code> (provided during initialization) to request necessary function and gradient evaluations from the <code>ropt</code> core.</p> <p>Parameters:</p> Name Type Description Default <code>initial_values</code> <code>NDArray[float64]</code> <p>A 1D NumPy array representing the starting variable             values for the optimization.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerCallback","title":"ropt.plugins.optimizer.base.OptimizerCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Defines the call signature for the optimizer evaluation callback.</p> <p><code>Optimizer</code> instances, implemented by optimization plugins, are initialized with a callback function conforming to this protocol. The optimizer uses this callback to request function and gradient evaluations from the <code>ropt</code> core during the optimization process.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64],\n    /,\n    *,\n    return_functions: bool,\n    return_gradients: bool,\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Request function and/or gradient evaluations from the <code>ropt</code> core.</p> <p>This method is called by the optimizer implementation to obtain objective function values, constraint values, and their gradients for one or more sets of variable values.</p> <p>The <code>variables</code> argument can be a 1D array (single vector) or a 2D array (matrix where each row is a variable vector). Parallel or batch-based optimizers might provide a matrix, while others typically provide a single vector.</p> <p>The <code>return_functions</code> and <code>return_gradients</code> flags control what is computed and returned. The results are always a tuple <code>(functions, gradients)</code>.</p> <ul> <li> <p>Functions Array: If <code>return_functions</code> is <code>True</code>, this array contains   the objective and non-linear constraint values.     If <code>variables</code> was a vector, it's a 1D array:</p> <pre><code>[objective, constraint1, constraint2, ...]\n</code></pre> <p>If <code>variables</code> was a matrix, it's a 2D array where each row corresponds to a row in the input <code>variables</code>, with the same structure:</p> <pre><code>[\n  [obj_row1, con1_row1, ...],\n  [obj_row2, con2_row2, ...],\n ...\n]\n</code></pre> </li> <li> <p>Gradients Array: If <code>return_gradients</code> is <code>True</code>, this array contains   the gradients of the objective and non-linear constraints. It's always   a 2D array where rows correspond to the objective/constraints and columns   correspond to the variables:</p> <pre><code>[\n  [grad_obj_var1,  grad_obj_var2,  ...],\n  [grad_con1_var1, grad_con1_var2, ...],\n  ...\n]\n</code></pre> </li> </ul> <p>Currently, gradient evaluation is only requested for a single variable   vector at a time.</p> <p>If <code>return_functions</code> and/or <code>return_gradients</code> are <code>False</code>, the corresponding results are empty arrays.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>A 1D or 2D array of variable values to evaluate.</p> required <code>return_functions</code> <code>bool</code> <p>If <code>True</code>, compute and return function/constraint values.</p> required <code>return_gradients</code> <code>bool</code> <p>If <code>True</code>, compute and return gradient values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing two NumPy arrays: (functions_array, gradients_array).</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils","title":"ropt.plugins.optimizer.utils","text":"<p>Utility functions for use by optimizer plugins.</p> <p>This module provides utility functions to validate supported constraints, filter linear constraints, and to retrieve the list of supported optimizers.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints","title":"NormalizedConstraints","text":"<p>Class for handling normalized constraints.</p> <p>This class can be used to normalize non-linear constraints into the form C(x) = 0, C(x) &lt;= 0, or C(x) &gt;= 0. By default this is done by subtracting the right-hand side value, and multiplying with -1, if necessary.</p> <p>The right hand sides are provided by the <code>lower_bounds</code> and <code>upper_bound</code> values. If corresponding entries in these arrays are equeal (within a 1e-15 tolerance), the corresponding constraint is assumed to be a equality constraint. If they are not, they are considered inequality constraints, if one or both values are finite. If the lower bounds are finite, the constraint is added as is, after subtracting of the lower bound. If the upper bound is finite, the same is done, but the constraint is multiplied by -1. If both are finite, both constraints are added, effectively splitting a two-sided constraint into two normalized constraints.</p> <p>By default this normalizes inequality constraints to the form C(x) &lt; 0, by setting <code>flip</code> flag, this can be changed to C(x) &lt; 0.</p> <p>Usage:</p> <ol> <li>Initialize with the lower and upper bounds.</li> <li>Before each new function/gradient evaluation with a new variable     vector, reset the normalized constraints by calling the <code>reset</code>     method.</li> <li>The constraint values are given by the <code>constraints</code> property. Before     accessing it, call the <code>set_constraints</code> with the raw constraints. If     necessary, this will calculate and cache the normalized values. Since     values are cached, calling this method and accessing <code>constraints</code>     multiple times is cheap.</li> <li>Use the same procedure for gradients, using the <code>gradients</code> property     and <code>set_gradients</code>. Raw gradients must be provided as a matrix,     where the rows are the gradients of each constraint.</li> <li>Use the <code>is_eq</code> property to retrieve a vector of boolean flags to     check which constraints are equality constraints.</li> </ol> <p>See the <code>scipy</code> optimization backend in the <code>ropt</code> source code for an example of usage.</p> Parallel evaluation. <p>The raw constraints may be a vector of constraints, or may be a matrix of constraints for multiple variables to support parallel evaluation. In the latter case, the constraints for different variables are given by the columns of the matrix. In this case, the <code>constraints</code> property will have the same structure. Note that this is only supported for the constraint values, not for the gradients. Hence, parallel evaluation of multiple gradients is not supported.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.is_eq","title":"is_eq  <code>property</code>","text":"<pre><code>is_eq: list[bool]\n</code></pre> <p>Return flags indicating which constraints are equality constraints.</p> <p>Returns:</p> Type Description <code>list[bool]</code> <p>A list of booleans, <code>True</code> for constraints that are equality constraints.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.constraints","title":"constraints  <code>property</code>","text":"<pre><code>constraints: NDArray[float64] | None\n</code></pre> <p>Return the cached normalized constraint values.</p> <p>These are the constraint values after applying the normalization logic (subtracting RHS, potential sign flipping) based on the bounds provided during initialization.</p> <p>This property should be accessed after calling <code>set_constraints</code> with the raw constraint values for the current variable vector. Returns <code>None</code> if <code>set_constraints</code> has not been called since the last <code>reset</code>.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>A NumPy array containing the normalized constraint values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.gradients","title":"gradients  <code>property</code>","text":"<pre><code>gradients: NDArray[float64] | None\n</code></pre> <p>Return the cached normalized constraint gradients.</p> <p>These are the gradients of the constraints after applying the normalization logic (potential sign flipping) based on the bounds provided during initialization.</p> <p>This property should be accessed after calling <code>set_gradients</code> with the raw constraint gradients for the current variable vector. Returns <code>None</code> if <code>set_gradients</code> has not been called since the last <code>reset</code>.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>A 2D NumPy array containing the normalized constraint gradients.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.__init__","title":"__init__","text":"<pre><code>__init__(\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n    *,\n    flip: bool = False,\n) -&gt; None\n</code></pre> <p>Initialize the normalization class.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right hand sides.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right hand sides.</p> required <code>flip</code> <code>bool</code> <p>Whether to flip the sign of the constraints.</p> <code>False</code>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset cached normalized constraints and gradients.</p> <p>This should be called before evaluating with a new variable vector to ensure fresh values are calculated upon the next access.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_constraints","title":"set_constraints","text":"<pre><code>set_constraints(values: NDArray[float64]) -&gt; None\n</code></pre> <p>Calculate and cache normalized constraint values.</p> <p>This method takes the raw constraint values (evaluated at the current variable vector) and applies the normalization logic defined during initialization (subtracting RHS, potential sign flipping). The results are stored internally and made available via the <code>constraints</code> property.</p> <p>This supports parallel evaluation: if <code>values</code> is a 2D array, each row is treated as the constraint values for a separate variable vector evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>A 1D or 2D NumPy array of raw constraint values. If 2D,     rows represent different evaluations.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_gradients","title":"set_gradients","text":"<pre><code>set_gradients(values: NDArray[float64]) -&gt; None\n</code></pre> <p>Calculate and cache normalized constraint gradients.</p> <p>This method takes the raw constraint gradients (evaluated at the current variable vector) and applies the normalization logic defined during initialization (potential sign flipping). The results are stored internally and made available via the <code>gradients</code> property.</p> Note <p>Unlike <code>set_constraints</code>, this method does not support parallel evaluation; it expects gradients corresponding to a single variable vector.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>A 2D NumPy array of raw constraint gradients (rows are     gradients of original constraints, columns are variables).</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.validate_supported_constraints","title":"validate_supported_constraints","text":"<pre><code>validate_supported_constraints(\n    config: EnOptConfig,\n    method: str,\n    supported_constraints: dict[str, set[str]],\n    required_constraints: dict[str, set[str]],\n) -&gt; None\n</code></pre> <p>Validate if the configured constraints are supported by the chosen method.</p> <p>This function checks if the constraints defined in the <code>config</code> object (bounds, linear, non-linear) are compatible with the specified optimization <code>method</code>. It uses dictionaries mapping constraint types to sets of methods that support or require them.</p> <p>Constraint types are identified by keys like <code>\"bounds\"</code>, <code>\"linear:eq\"</code>, <code>\"linear:ineq\"</code>, <code>\"nonlinear:eq\"</code>, and <code>\"nonlinear:ineq\"</code>.</p> <p>Example <code>supported_constraints</code> dictionary: <pre><code>{\n    \"bounds\": {\"L-BFGS-B\", \"TNC\", \"SLSQP\"},\n    \"linear:eq\": {\"SLSQP\"},\n    \"linear:ineq\": {\"SLSQP\"},\n    \"nonlinear:eq\": {\"SLSQP\"},\n    \"nonlinear:ineq\": {\"SLSQP\"},\n}\n</code></pre> A similar structure is used for <code>required_constraints</code>.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimization configuration object.</p> required <code>method</code> <code>str</code> <p>The name of the optimization method being used.</p> required <code>supported_constraints</code> <code>dict[str, set[str]]</code> <p>Dict mapping constraint types to sets of methods                    that support them.</p> required <code>required_constraints</code> <code>dict[str, set[str]]</code> <p>Dict mapping constraint types to sets of methods                    that require them.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If a configured constraint is not supported by the                  method, or if a required constraint is missing.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.create_output_path","title":"create_output_path","text":"<pre><code>create_output_path(\n    base_name: str,\n    base_dir: Path | None = None,\n    name: str | None = None,\n    suffix: str | None = None,\n) -&gt; Path\n</code></pre> <p>Construct a unique output path, appending an index if necessary.</p> <p>This function generates a file or directory path based on the provided components. If the resulting path already exists, it automatically appends or increments a numerical suffix (e.g., \"-001\", \"-002\") to ensure uniqueness.</p> <p>Parameters:</p> Name Type Description Default <code>base_name</code> <code>str</code> <p>The core name for the path.</p> required <code>base_dir</code> <code>Path | None</code> <p>Optional parent directory for the path.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Optional identifier (e.g., step name) to include in the path.</p> <code>None</code> <code>suffix</code> <code>str | None</code> <p>Optional file extension or suffix for the path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>A unique <code>pathlib.Path</code> object.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.get_masked_linear_constraints","title":"get_masked_linear_constraints","text":"<pre><code>get_masked_linear_constraints(\n    config: EnOptConfig,\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Adjust linear constraints based on a variable mask.</p> <p>When an optimization problem uses a variable mask (<code>config.variables.mask</code>) to optimize only a subset of variables, the linear constraints need to be adapted. This function performs that adaptation.</p> <p>It removes columns from the constraint coefficient matrix (<code>config.linear_constraints.coefficients</code>) that correspond to the masked (fixed) variables. The contribution of these fixed variables (using their <code>initial_values</code>) is then calculated and subtracted from the original lower and upper bounds (<code>config.linear_constraints.lower_bounds</code>, <code>config.linear_constraints.upper_bounds</code>) to produce adjusted bounds for the optimization involving only the active variables.</p> <p>Additionally, any constraint rows that originally involved only masked variables (i.e., all coefficients for active variables in that row are zero) are removed entirely, as they become trivial constants.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The <code>EnOptConfig</code> object     containing the variable mask and linear constraints.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>The adjusted coefficients and bounds.</p>"},{"location":"reference/plan/","title":"Optimization Plans","text":""},{"location":"reference/plan/#ropt.plan","title":"ropt.plan","text":"<p>Code for executing optimization plans.</p> <p>The <code>Plan</code> class orchestrates optimization workflows by managing steps and result handlers.</p> <p>A plan consists of <code>PlanStep</code> objects, which define individual actions, and <code>PlanHandler</code> objects, which process and store data generated during execution. Both steps and result handlers are implemented using a plugin mechanism, making it easy to extend the range of supported actions and data processing. The <code>ropt</code> library provides default implementations through the default plan handler and default plan step plugins. These provide basic steps and result handlers to support a wide range of optimization workflows.</p> <p>Most optimization plans require shared state across all steps, such as the plugin manager and an evaluator callable for function evaluations. This shared state is managed by the <code>OptimizerContext</code> object, which is provided when creating a plan. The <code>OptimizerContext</code> also handles events produced by plan steps by calling registered callbacks and forwarding them to result handlers.</p> <p>Setting up and executing a <code>Plan</code> object for simple optimization cases can be complex. The <code>BasicOptimizer</code> class simplifies this process by providing a convenient way to build and execute straightforward plans involving a single optimization.</p>"},{"location":"reference/plan/#ropt.plan.Plan","title":"ropt.plan.Plan","text":"<p>Plan class for executing optimization workflows.</p> <p>The <code>Plan</code> object is the core component for executing optimization workflows. It orchestrates the execution of individual steps and the processing of results through handlers.</p> <p>Building a Plan:</p> <p>To construct a plan, individual actions, known as steps, are added using the <code>add_step</code> method. Data processing and storage are managed by handlers, which are added using the <code>add_handler</code> method. The plan stores the step and handler objects internally. Their respective creation functions return unique IDs for identification. The <code>handler_exists</code> and <code>step_exists</code> methods can be used to verify whether a handler or step with a given name is supported.</p> <p>Executing a Plan:</p> <p>Once a plan is assembled, it can be executed in several ways. For fine-grained control, the <code>run_step</code> method can be invoked repeatedly, executing each step individually. This approach allows for the integration of complex logic and custom functions, leveraging the full capabilities of Python. Alternatively, for more structured workflows, a Python function encapsulating a sequence of steps can be defined. This function is added to the plan using the <code>add_function</code> method. The entire workflow defined by this function can then be executed with a single call to <code>run_function</code>, with optional arguments to customize its behavior. The <code>has_function</code> method can be used to check if a function has been added to the plan.</p> <p>Shared State and Events:</p> <p>The plan maintains shared state in an <code>OptimizerContext</code>, which is provided during initialization and can be shared among multiple plans. The <code>optimizer_context</code> property provides access to this context.</p> <p>Steps can communicate events using the <code>emit_event</code> method. Result handlers can respond to these events, enabling actions such as processing optimization results.</p> <p>Nested Plans:</p> <p>Multiple plans can be defined. A step within one plan can trigger the execution of another plan, enabling nested workflows. In nested plans, the <code>set_parent</code> method establishes a parent-child relationship, allowing events to propagate up the hierarchy to the parent plan.</p> <p>Aborting a Plan:</p> <p>A plan's execution can be terminated, either programmatically from within a step or handler, or externally by directly calling the <code>abort</code> method. The <code>aborted</code> property can be used to check if a plan has been aborted.</p> <p>Handler Data:</p> <p>Individual handlers may store values that they accumulate or calculate from the events that they handle. Code outside of the handlers, such as the optimization workflow code that runs the steps, can set and retrieve these values using the <code>get</code> and <code>set</code> methods.</p>"},{"location":"reference/plan/#ropt.plan.Plan.aborted","title":"aborted  <code>property</code>","text":"<pre><code>aborted: bool\n</code></pre> <p>Check if the plan was aborted.</p> <p>Determines whether the plan's execution has been aborted.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the plan was aborted; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.optimizer_context","title":"optimizer_context  <code>property</code>","text":"<pre><code>optimizer_context: OptimizerContext\n</code></pre> <p>Return the optimizer context.</p> <p>Retrieves the <code>OptimizerContext</code> object associated with this plan. The optimizer context provides shared state and functionality for executing the optimization plan.</p> <p>Returns:</p> Name Type Description <code>OptimizerContext</code> <code>OptimizerContext</code> <p>The optimizer context object used by the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.__init__","title":"__init__","text":"<pre><code>__init__(\n    optimizer_context: OptimizerContext,\n    parent: Plan | None = None,\n) -&gt; None\n</code></pre> <p>Initialize a plan object.</p> <p>Constructs a new plan, associating it with an <code>OptimizerContext</code> and an optional parent plan.</p> <p>The plan will operate within the provided <code>optimizer_context</code>. If a <code>parent</code> plan is specified, this plan becomes a child, enabling event propagation up the plan hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer_context</code> <code>OptimizerContext</code> <p>The execution context for the plan.</p> required <code>parent</code> <code>Plan | None</code> <p>An optional parent plan.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.Plan.add_handler","title":"add_handler","text":"<pre><code>add_handler(name: str, **kwargs: Any) -&gt; uuid.UUID\n</code></pre> <p>Add a handler to the plan.</p> <p>Constructs and registers a result handler with the plan. The handler's type is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding handler class. Any additional keyword arguments are passed to the handler's constructor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler to add.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for the handler's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>UUID</code> <p>The unique ID of the newly added handler.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_step","title":"add_step","text":"<pre><code>add_step(name: str, **kwargs: Any) -&gt; uuid.UUID\n</code></pre> <p>Add a step to the plan.</p> <p>Registers a step with the plan. The step's type is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding step class. Any additional keyword arguments are passed to the step's constructor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the step to add.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for the step's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>UUID</code> <p>uuid.UUID: The unique ID of the newly added step.</p>"},{"location":"reference/plan/#ropt.plan.Plan.handler_exists","title":"handler_exists","text":"<pre><code>handler_exists(name: str) -&gt; bool\n</code></pre> <p>Check if a handler exists.</p> <p>Determines whether a handler with the specified name is supported by the plugin system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the handler exists; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.step_exists","title":"step_exists","text":"<pre><code>step_exists(name: str) -&gt; bool\n</code></pre> <p>Check if a step exists.</p> <p>Determines whether a step with the specified name is supported by the plugin system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the step to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the step exists; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.run_step","title":"run_step","text":"<pre><code>run_step(step: UUID, **kwargs: Any) -&gt; Any\n</code></pre> <p>Run a step in the plan.</p> <p>Executes a specific step within the plan. The step's <code>run</code> method is called with the provided keyword arguments. If the plan has been aborted, a <code>PlanAborted</code> exception is raised before the step is executed.</p> <p>The step is executed only once. The value returned by the step's <code>run</code> method is returned by this method.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>UUID</code> <p>The unique ID of the step to run.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments to pass to the step's <code>run</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value returned by the step's <code>run</code> method.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>step</code> ID is not valid.</p> <code>PlanAborted</code> <p>If the plan has been aborted.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_function","title":"add_function","text":"<pre><code>add_function(func: Callable[..., Any]) -&gt; None\n</code></pre> <p>Add a function to the plan.</p> <p>Registers a user-defined function with the plan. This function can encapsulate a sequence of steps or custom logic. It can be executed later using the <code>run_function</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The function to register with the plan.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.has_function","title":"has_function","text":"<pre><code>has_function() -&gt; bool\n</code></pre> <p>Check if a function has been added to the plan.</p> <p>Determines whether a user-defined function has been registered with the plan.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if a function has been added; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.run_function","title":"run_function","text":"<pre><code>run_function(*args: Any, **kwargs: Any) -&gt; Any\n</code></pre> <p>Run a function in the plan.</p> <p>Executes the user-defined function that has been registered with the plan via the <code>add_function</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>Arbitrary positional arguments to pass to the function.</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result returned by the function.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If no function has been added to the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.abort","title":"abort","text":"<pre><code>abort() -&gt; None\n</code></pre> <p>Abort the plan.</p> <p>Prevents further steps in the plan from being executed. This method does not interrupt a currently running step but ensures that no subsequent steps will be initiated. It can be used to halt the plan's execution due to a step failure or external intervention.</p> <p>The <code>aborted</code> property can be used to check if the plan has been aborted.</p>"},{"location":"reference/plan/#ropt.plan.Plan.set_parent","title":"set_parent","text":"<pre><code>set_parent(parent: Plan) -&gt; None\n</code></pre> <p>Set the parent of the plan.</p> <p>Establishes a parent-child relationship between this plan and another plan. This enables event propagation up the plan hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>Plan</code> <p>The parent plan.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.emit_event","title":"emit_event","text":"<pre><code>emit_event(event: Event) -&gt; None\n</code></pre> <p>Emit an event.</p> <p>Emits an event, triggering associated handlers and observers.</p> <p>When this method is called:</p> <ol> <li>All event handlers associated with the plan are invoked.</li> <li>If the plan has no parent, all observer functions registered for the     specified event type are called.</li> <li>If the plan has a parent, the parent plan's <code>emit_event</code> method is     also called, propagating the event up the hierarchy.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event object to emit.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.get","title":"get","text":"<pre><code>get(id_: UUID, /, key: str) -&gt; Any\n</code></pre> <p>Retrieve a value stored in a handler.</p> <p>Retrieves a value stored within a specific result handler. This method uses the <code>[]</code> operator to access the value associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>id_</code> <code>UUID</code> <p>The unique identifier of the handler.</p> required <code>key</code> <code>str</code> <p>The key associated with the value to retrieve.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value associated with the key in the specified handler.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>id_</code> is not a valid handler ID.</p>"},{"location":"reference/plan/#ropt.plan.Plan.set","title":"set","text":"<pre><code>set(id_: UUID, /, key: str, value: Any) -&gt; None\n</code></pre> <p>Set a value in a handler.</p> <p>Stores a value within a specific result handler. This method uses the <code>[]</code> operator to assign the value to the specified key.</p> <p>Parameters:</p> Name Type Description Default <code>id_</code> <code>UUID</code> <p>The unique identifier of the handler.</p> required <code>key</code> <code>str</code> <p>The key to associate with the value.</p> required <code>value</code> <code>Any</code> <p>The value to store.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>id_</code> is not a valid handler ID.</p>"},{"location":"reference/plan/#ropt.plan.OptimizerContext","title":"ropt.plan.OptimizerContext","text":"<p>Manages shared state and resources for an optimization plan.</p> <p>The OptimizerContext acts as a central hub for managing shared resources and state across all steps within an optimization plan. This ensures that different parts of the plan can access and interact with the same information and tools.</p> <p>This context object is responsible for:</p> <ul> <li>Providing a callable <code>Evaluator</code> for evaluating functions, which is   essential for optimization algorithms to assess the quality of solutions.   The evaluator is used to calculate the objective function's value and   potentially constraint values for given variables.</li> <li>Managing a <code>PluginManager</code> to retrieve and utilize plugins, allowing for   extensibility and customization of the optimization workflow. Plugins are   modular pieces of code that extend the functionality of the optimization   framework, such as new <code>PlanStep</code> or <code>PlanHandler</code> implementations.</li> <li>Handling event callbacks that are triggered in response to specific events   during the plan's execution. These callbacks are executed after the plan   has processed the event, allowing for actions to be taken in response to   changes or milestones. This allows you to monitor the optimization, react   to changes, or perform custom actions at specific points in the plan's   execution.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>Evaluator</code> <p>A callable for evaluating functions in the plan.</p> required <code>plugin_manager</code> <code>PluginManager | None</code> <p>A plugin manager; a default is created if not provided.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.__init__","title":"__init__","text":"<pre><code>__init__(\n    evaluator: Evaluator,\n    plugin_manager: PluginManager | None = None,\n) -&gt; None\n</code></pre> <p>Initializes the optimization context.</p> <p>Sets up the shared state and resources required for an optimization plan. This includes a function evaluator and a plugin manager.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>Evaluator</code> <p>A callable for evaluating functions in the plan.</p> required <code>plugin_manager</code> <code>PluginManager | None</code> <p>A plugin manager; a default is created if not provided.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.add_observer","title":"add_observer","text":"<pre><code>add_observer(\n    event: EventType, callback: Callable[[Event], None]\n) -&gt; Self\n</code></pre> <p>Adds an observer function for a specific event type.</p> <p>Observer functions are called when an event of the specified type occurs during optimization. The provided callback function will receive an <code>Event</code> object containing information about the event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>EventType</code> <p>The type of event to observe.</p> required <code>callback</code> <code>Callable[[Event], None]</code> <p>The function to call when the event occurs.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The OptimizerContext instance, allowing for method chaining.</p>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.call_observers","title":"call_observers","text":"<pre><code>call_observers(event: Event) -&gt; None\n</code></pre> <p>Calls all observers for a specific event.</p> <p>This method triggers all observer functions registered for the given event type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit to the observers.</p> required"},{"location":"reference/plan/#ropt.plan.Event","title":"ropt.plan.Event  <code>dataclass</code>","text":"<p>Stores data related to an optimization event.</p> <p>During the execution of an optimization plan, events are triggered to signal specific occurrences. Callbacks can be registered to react to these events and will receive an <code>Event</code> object containing relevant information.</p> <p>The specific data within the <code>Event</code> object varies depending on the event type. See the <code>EventType</code> documentation for details.</p> <p>Attributes:</p> Name Type Description <code>event_type</code> <code>EventType</code> <p>The type of event that occurred.</p> <code>config</code> <code>EnOptConfig</code> <p>The configuration used for the optimization.</p> <code>source</code> <code>UUID</code> <p>The ID of the step that triggered the event.</p> <code>data</code> <code>dict[str, Any]</code> <p>A dictionary containing additional event-specific data.</p>"},{"location":"reference/plan_plugins/","title":"Plan Plugins","text":""},{"location":"reference/plan_plugins/#ropt.plugins.plan","title":"ropt.plugins.plan","text":"<p>Framework and Implementations for Optimization Plan Plugins.</p> <p>This module provides the core components and default implementations for extending <code>ropt</code>'s optimization plan capabilities (<code>Plan</code>) through plugins. It allows users to define custom sequences of operations (steps) and ways to process the results and events generated during plan execution (handlers).</p> <p>Core Concepts:</p> <ul> <li>Plan Steps: Represent individual actions within an optimization plan,     such as running an optimizer or performing evaluations.</li> <li>Plan Handlers: Process events emitted by the plan or its steps, enabling     tasks like result tracking, data storage, or logging.</li> </ul> <p>The implementation of these core concepts relies on classes derived from the following abstract base classes:</p> <ol> <li> <p>Plugin Base Classes:</p> <ul> <li><code>PlanStepPlugin</code>: The base for   plugins that create plan steps. These plugins are discovered by the   <code>PluginManager</code> and used to instantiate   actual <code>PlanStep</code> objects.</li> <li><code>PlanHandlerPlugin</code>: The base   for plugins that create plan result handlers. Similar to step plugins,   these are used by the <code>PluginManager</code> to instantiate <code>PlanHandler</code>   objects.</li> </ul> </li> <li> <p>Component Base Classes:</p> <ul> <li><code>PlanStep</code>: The abstract base class   that all concrete plan step implementations must inherit from. It defines   the <code>run</code> method where the step's   logic resides.</li> <li><code>PlanHandler</code>: The abstract base   class for all result handlers. It defines the   <code>handle_event</code> method   for processing events emitted during plan execution and allows storing   state using dictionary-like access.</li> </ul> </li> </ol> <p>By inheriting from these classes, developers can create custom steps and handlers that integrate seamlessly into the <code>ropt</code> optimization plan execution framework (<code>Plan</code>).</p> <p>Built-in Plan Plugins:</p> <p><code>ropt</code> includes default plugins providing common plan components:</p> <ul> <li>Steps (via     <code>DefaultPlanStepPlugin</code>):<ul> <li><code>evaluator</code>: Performs ensemble evaluations     (<code>DefaultEvaluatorStep</code>).</li> <li><code>optimizer</code>: Runs an optimization algorithm using a configured optimizer     plugin     (<code>DefaultOptimizerStep</code>).</li> </ul> </li> <li>Handlers (via     <code>DefaultPlanHandlerPlugin</code>):<ul> <li><code>tracker</code>: Tracks the 'best' or 'last' valid result based on objective     value and constraints     (<code>DefaultTrackerHandler</code>).</li> <li><code>store</code>: Accumulates all results from specified sources     (<code>DefaultStoreHandler</code>).</li> </ul> </li> </ul> <p>These built-in components allow for the construction of standard optimization workflows out-of-the-box, while the plugin architecture enables customization and extension.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStepPlugin","title":"ropt.plugins.plan.base.PlanStepPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for plugins that create PlanStep instances.</p> <p>This class defines the interface for plugins that act as factories for <code>PlanStep</code> objects.</p> <p>The <code>PluginManager</code> uses the <code>create</code> class method of these plugins to instantiate <code>PlanStep</code> objects when they are added to an optimization <code>Plan</code> via <code>Plan.add_step</code>.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStepPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(name: str, plan: Plan, **kwargs: Any) -&gt; PlanStep\n</code></pre> <p>Create a PlanStep instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>PlanStep</code> objects. Plugin implementations must override this method to return an instance of their specific <code>PlanStep</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when a plan requests a step provided by this plugin via <code>Plan.add_step</code>.</p> <p>The <code>name</code> argument specifies the requested step, potentially in the format <code>\"plugin-name/method-name\"</code> or just <code>\"method-name\"</code>. Implementations can use this <code>name</code> to vary the created step if the plugin supports multiple step types.</p> <p>Any additional keyword arguments (<code>kwargs</code>) passed during the <code>Plan.add_step</code> call are forwarded here, allowing for custom configuration of the step instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The requested step name (potentially plugin-specific).</p> required <code>plan</code> <code>Plan</code> <p>The parent <code>Plan</code> instance.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for custom configuration.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PlanStep</code> <p>An initialized instance of a <code>PlanStep</code> subclass.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandlerPlugin","title":"ropt.plugins.plan.base.PlanHandlerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Plan Handler Plugins.</p> <p>This class defines the interface for plugins responsible for creating <code>PlanHandler</code> instances within an optimization plan (<code>Plan</code>).</p> <p>During plan setup, the <code>PluginManager</code> identifies the appropriate handler plugin based on a requested name and uses its <code>create</code> class method to instantiate the actual <code>PlanHandler</code> object that will process events during plan execution.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandlerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(name: str, plan: Plan, **kwargs: Any) -&gt; PlanHandler\n</code></pre> <p>Create a PlanHandler instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>PlanHandler</code> objects. Plugin implementations must override this method to return an instance of their specific <code>PlanHandler</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when a plan requests a handler provided by this plugin via <code>Plan.add_handler</code>.</p> <p>The <code>name</code> argument specifies the requested handler, potentially in the format <code>\"plugin-name/method-name\"</code> or just <code>\"method-name\"</code>. Implementations can use this <code>name</code> to vary the created handler if the plugin supports multiple handler types.</p> <p>Any additional keyword arguments (<code>kwargs</code>) passed during the <code>Plan.add_handler</code> call are forwarded here, allowing for custom configuration of the handler instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The requested handler name (potentially plugin-specific).</p> required <code>plan</code> <code>Plan</code> <p>The parent <code>Plan</code> instance.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for custom configuration.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PlanHandler</code> <p>An initialized instance of a <code>PlanHandler</code> subclass.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep","title":"ropt.plugins.plan.base.PlanStep","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Optimization Plan Steps.</p> <p>This class defines the fundamental interface for all executable steps within an optimization <code>Plan</code>. Concrete step implementations, which perform specific actions like running an optimizer or evaluating functions, must inherit from this base class.</p> <p><code>PlanStep</code> objects are typically created by corresponding <code>PlanStepPlugin</code> factories, which are managed by the <code>PluginManager</code>. Once instantiated and added to a <code>Plan</code>, their <code>run</code> method is called by the plan during execution.</p> <p>Each <code>PlanStep</code> instance has a unique <code>id</code> and maintains a reference to its parent <code>plan</code>.</p> <p>Subclasses must implement the abstract <code>run</code> method to define the step's specific behavior.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.id","title":"id  <code>property</code>","text":"<pre><code>id: UUID\n</code></pre> <p>Return the unique identifier of the handler.</p> <p>Returns:</p> Type Description <code>UUID</code> <p>A UUID object representing the unique identifier of the handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.plan","title":"plan  <code>property</code>","text":"<pre><code>plan: Plan\n</code></pre> <p>Return the parent plan associated with this step.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The <code>Plan</code> object that owns and executes this step.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize the PlanStep.</p> <p>Associates the step with its parent <code>Plan</code> and assigns a unique ID. The parent plan is accessible via the <code>plan</code> property.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The <code>Plan</code> instance that owns this step.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.run","title":"run  <code>abstractmethod</code>","text":"<pre><code>run(*args: Any, **kwargs: Any) -&gt; Any\n</code></pre> <p>Execute the logic defined by this plan step.</p> <p>This abstract method must be implemented by concrete <code>PlanStep</code> subclasses to define the specific action the step performs within the optimization <code>Plan</code>.</p> <p>The <code>Plan</code> object calls this method during its execution sequence, passing any arguments provided when the step was invoked via <code>Plan.run_step</code>. The return value and type can vary depending on the specific step implementation.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>Positional arguments passed from <code>Plan.run_step</code>.</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Keyword arguments passed from <code>Plan.run_step</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The result of the step's execution, if any.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler","title":"ropt.plugins.plan.base.PlanHandler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Optimization Plan Result Handlers.</p> <p>This class defines the fundamental interface for all result handlers within an optimization <code>Plan</code>. Concrete handler implementations, which process events emitted during plan execution (e.g., tracking results, storing data, logging), must inherit from this base class.</p> <p><code>PlanHandler</code> objects are typically created by corresponding <code>PlanHandlerPlugin</code> factories, managed by the <code>PluginManager</code>. Once instantiated and added to a <code>Plan</code>, their <code>handle_event</code> method is called by the plan whenever an <code>Event</code> is emitted.</p> <p>Handlers can also store state using dictionary-like access (<code>[]</code>), allowing them to accumulate information or make data available to subsequent steps or handlers within the plan.</p> <p>Each <code>PlanHandler</code> instance has a unique <code>id</code> and maintains a reference to its parent <code>plan</code>.</p> <p>Subclasses must implement the abstract <code>handle_event</code> method to define their specific event processing logic.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler.id","title":"id  <code>property</code>","text":"<pre><code>id: UUID\n</code></pre> <p>Return the unique identifier (UUID) of this handler instance.</p> <p>Returns:</p> Type Description <code>UUID</code> <p>The unique UUID object for this handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler.plan","title":"plan  <code>property</code>","text":"<pre><code>plan: Plan\n</code></pre> <p>Return the parent plan associated with this handler.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The <code>Plan</code> object that owns this handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize the PlanHandler.</p> <p>Associates the handler with its parent <code>Plan</code>, assigns a unique ID, and initializes an internal dictionary for storing state. The parent plan is accessible via the <code>plan</code> property.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The <code>Plan</code> instance that owns this handler.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler.handle_event","title":"handle_event  <code>abstractmethod</code>","text":"<pre><code>handle_event(event: Event) -&gt; None\n</code></pre> <p>Process an event emitted by the optimization plan.</p> <p>This abstract method must be implemented by concrete <code>PlanHandler</code> subclasses. It defines the handler's core logic for reacting to <code>Event</code> objects emitted during the execution of the parent <code>Plan</code>.</p> <p>Implementations should inspect the <code>event</code> object (its <code>event_type</code> and <code>data</code>) and perform actions accordingly, such as storing results, logging information, or updating internal state.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The <code>Event</code> object containing details    about what occurred in the plan.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key: str) -&gt; Any\n</code></pre> <p>Retrieve a value from the handler's internal state.</p> <p>This method enables dictionary-like access (<code>handler[key]</code>) to the values stored within the handler's internal state dictionary. This allows handlers to store and retrieve data accumulated during plan execution.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The string key identifying the value to retrieve.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value associated with the specified key.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>key</code> does not exist in the             handler's stored values.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandler.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key: str, value: Any) -&gt; None\n</code></pre> <p>Store or update a value in the handler's internal state.</p> <p>This method enables dictionary-like assignment (<code>handler[key] = value</code>) to store arbitrary data within the handler's internal state dictionary. This allows handlers to accumulate information or make data available to other components of the plan.</p> <p>The key must be a valid Python identifier.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The string key identifying the value to store (must be an identifier).</p> required <code>value</code> <code>Any</code> <p>The value to associate with the key.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>key</code> is not a valid identifier.</p>"},{"location":"reference/plugin_manager/","title":"Plugins","text":""},{"location":"reference/plugin_manager/#ropt.plugins","title":"ropt.plugins","text":"<p>Extending <code>ropt</code> with Plugins.</p> <p>The <code>ropt.plugins</code> module provides the framework for extending <code>ropt</code>'s capabilities through a plugin system. Plugins allow for the integration of custom or third-party components, installed as separate packages.</p> <p><code>ropt</code> supports several types of plugins, each addressing a specific aspect of the optimization workflow:</p> <ul> <li><code>plan</code>: Defines components for constructing and executing   optimization plans   (<code>PlanHandlerPlugin</code> and   <code>PlanStepPlugin</code>).</li> <li><code>optimizer</code>: Implements optimization algorithms.</li> <li><code>sampler</code>: Generates parameter perturbations, which   are used for gradient estimation.</li> <li><code>realization_filter</code>: Selects subsets of   ensemble realizations for calculating objectives or constraints.</li> <li><code>function_estimator</code>: Computes final   objective function values and gradients from individual realization results.</li> </ul> <p>Plugin Management and Discovery</p> <p>The <code>PluginManager</code> class is central to the plugin system. It discovers and manages available plugins. Plugins are typically discovered automatically using Python's standard entry points mechanism.</p> <p>Each plugin type has a corresponding abstract base class that custom plugins must inherit from:</p> <ul> <li>Plan: <code>PlanHandlerPlugin</code> and   <code>PlanStepPlugin</code></li> <li>Optimizer: <code>OptimizerPlugin</code></li> <li>Sampler: <code>SamplerPlugin</code></li> <li>Realization Filter: <code>RealizationFilterPlugin</code></li> <li>Function Estimator: <code>FunctionEstimatorPlugin</code></li> </ul> <p>Using Plugins</p> <p>The <code>PluginManager.get_plugin</code> method is used internally by <code>ropt</code> to retrieve the appropriate plugin implementation based on a specified type and method name. The <code>PluginManager.is_supported</code> method can check if a specific method is available.</p> <p>Plugins can implement multiple named methods. To request a specific method (<code>method-name</code>) from a particular plugin (<code>plugin-name</code>), use the format <code>\"plugin-name/method-name\"</code>. If only a method name is provided, the plugin manager searches through all registered plugins (that allow discovery) for one that supports the method. Using <code>\"plugin-name/default\"</code> typically selects the primary or default method offered by that plugin, although specifying \"default\" without a plugin name is not permitted.</p> <p>Plugins retrieved by the <code>PluginManager.get_plugin</code> method generally implement a <code>create</code> factory method that will be used to instantiate the objects that implement the desired functionality. These objects must inherit from the base class for the corresponding plugin type:</p> <ul> <li>Plan: <code>PlanHandler</code> and   <code>PlanStep</code></li> <li>Optimizer: <code>Optimizer</code></li> <li>Sampler: <code>Sampler</code></li> <li>Realization Filter: <code>RealizationFilter</code></li> <li>Function Estimator: <code>FunctionEstimator</code></li> </ul> <p>Pre-installed Plugins Included with <code>ropt</code></p> <p><code>ropt</code> comes bundled with a set of pre-installed plugins:</p> <ul> <li>Plan: The built-in   <code>default</code> handler and   <code>default</code> step plugins,   providing components for executing complex optimization plans.</li> <li>Optimizer: The <code>scipy</code>   plugin, leveraging algorithms from <code>scipy.optimize</code>, and the   <code>ExternalOptimizer</code>,   which is used to launch optimizers in separate processes.</li> <li>Sampler: The <code>scipy</code> plugin,   using distributions from <code>scipy.stats</code>.</li> <li>Realization Filter: The   <code>default</code>   plugin, offering filters based on ranking and for CVaR optimization.</li> <li>Function Estimator: The   <code>default</code>   plugin, supporting objectives based on mean or standard deviation.</li> </ul>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager","title":"PluginManager","text":"<p>Manages the discovery and retrieval of <code>ropt</code> plugins.</p> <p>The <code>PluginManager</code> is responsible for finding available plugins based on Python's entry points mechanism and providing access to them. It serves as a central registry for different types of plugins used within <code>ropt</code>, such as optimizers, samplers, and plan components.</p> <p>Upon initialization, the manager scans for entry points defined under the <code>ropt.plugins.*</code> groups (e.g., <code>ropt.plugins.optimizer</code>). Plugins found this way are loaded and stored internally, categorized by their type.</p> <p>The primary way to interact with the manager is through the <code>get_plugin</code> method, which retrieves a specific plugin class based on its type and a method name it supports. The <code>is_supported</code> method can be used to check for the availability of a plugin method without retrieving it.</p> <p>Example: Registering a Custom Optimizer Plugin</p> <p>To make a custom optimizer plugin available to <code>ropt</code>, you would typically define an entry point in your package's <code>pyproject.toml</code>:</p> <pre><code>[project.entry-points.\"ropt.plugins.optimizer\"]\nmy_optimizer = \"my_package.my_module:MyOptimizer\"\n</code></pre> <p>When <code>ropt</code> initializes the <code>PluginManager</code>, it will discover and load <code>MyOptimizer</code> from <code>my_package.my_module</code>, making it accessible via <code>plugin_manager.get_plugin(\"optimizer\", \"my_optimizer/some_method\")</code> or potentially <code>plugin_manager.get_plugin(\"optimizer\", \"some_method\")</code> if discovery is allowed and the method is unique.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the plugin manager.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.get_plugin","title":"get_plugin","text":"<pre><code>get_plugin(plugin_type: PluginType, method: str) -&gt; Any\n</code></pre> <p>Retrieve a plugin class by its type and a supported method name.</p> <p>This method finds and returns the class of a plugin that matches the specified <code>plugin_type</code> and supports the given <code>method</code>.</p> <p>The <code>method</code> argument can be specified in two ways:</p> <ol> <li>Explicit Plugin: Use the format <code>\"plugin-name/method-name\"</code>.     This directly requests the <code>method-name</code> from the plugin named     <code>plugin-name</code>.</li> <li>Implicit Plugin: Provide only the <code>method-name</code>. The manager     will search through all registered plugins of the specified     <code>plugin_type</code> that allow discovery (see     <code>Plugin.allows_discovery</code>).     It returns the first plugin found that supports the <code>method-name</code>.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The category of the plugin (e.g., \"optimizer\", \"sampler\").</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin must support, potentially          prefixed with the plugin name and a slash (<code>/</code>).</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The plugin class that matches the criteria.</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If no matching plugin is found for the given type and          method, or if \"default\" is used as a method name without          specifying a plugin name.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.is_supported","title":"is_supported","text":"<pre><code>is_supported(plugin_type: PluginType, method: str) -&gt; bool\n</code></pre> <p>Check if a specific plugin method is available.</p> <p>Verifies whether a plugin of the specified <code>plugin_type</code> supports the given <code>method</code>. This is useful for checking availability before attempting to retrieve a plugin with <code>get_plugin</code>.</p> <p>The <code>method</code> argument can be specified in two ways:</p> <ol> <li>Explicit Plugin: <code>\"plugin-name/method-name\"</code> checks if the specific     plugin named <code>plugin-name</code> supports <code>method-name</code>.</li> <li>Implicit Plugin: <code>\"method-name\"</code> searches through all discoverable     plugins of the given <code>plugin_type</code> to see if any support <code>method-name</code>.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The category of the plugin (e.g., \"optimizer\", \"sampler\").</p> required <code>method</code> <code>str</code> <p>The name of the method to check, potentially prefixed          with the plugin name and a slash (<code>/</code>).</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if a matching plugin supports the specified method.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginType","title":"PluginType  <code>module-attribute</code>","text":"<pre><code>PluginType = Literal[\n    \"optimizer\",\n    \"sampler\",\n    \"realization_filter\",\n    \"function_estimator\",\n    \"plan_handler\",\n    \"plan_step\",\n]\n</code></pre> <p>Represents the valid types of plugins supported by <code>ropt</code>.</p> <p>This type alias defines the string identifiers used to categorize different plugins within the <code>ropt</code> framework. Each identifier corresponds to a specific role in the optimization process:</p> <ul> <li><code>\"optimizer\"</code>: Plugins implementing optimization algorithms   (<code>OptimizerPlugin</code>).</li> <li><code>\"sampler\"</code>: Plugins for generating parameter samples   (<code>SamplerPlugin</code>).</li> <li><code>\"realization_filter\"</code>: Plugins for filtering ensemble realizations   (<code>RealizationFilterPlugin</code>).</li> <li><code>\"function_estimator\"</code>: Plugins for estimating objective functions and gradients   (<code>FunctionEstimatorPlugin</code>).</li> <li><code>\"plan_handler\"</code>: Plugins that create handlers for processing plan results   (<code>PlanHandlerPlugin</code>).</li> <li><code>\"plan_step\"</code>: Plugins that define executable steps within an optimization plan   (<code>PlanStepPlugin</code>).</li> </ul>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin","title":"Plugin","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all <code>ropt</code> plugins.</p> <p>This class serves as the fundamental building block for all plugins within the <code>ropt</code> framework. Any class intended to function as a plugin (e.g., an optimizer, sampler, plan step, or plan handler) must inherit from this base class.</p> <p>It defines the core interface that all plugins must adhere to, ensuring consistency and enabling the <code>PluginManager</code> to discover and manage them effectively.</p> <p>Subclasses must implement the <code>is_supported</code> class method to indicate which named methods (functionalities) they provide. They can optionally override the <code>allows_discovery</code> class method if they should not be automatically selected by the plugin manager when a method name is provided without an explicit plugin name.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.is_supported","title":"is_supported  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>is_supported(method: str) -&gt; bool\n</code></pre> <p>Verify if this plugin supports a specific named method.</p> <p>This class method is used by the <code>PluginManager</code> (specifically its <code>is_supported</code> method) to determine if this plugin class provides the functionality associated with the given <code>method</code> name.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The string identifier of the method to check for support.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the plugin supports the specified method, <code>False</code> otherwise.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.allows_discovery","title":"allows_discovery  <code>classmethod</code>","text":"<pre><code>allows_discovery() -&gt; bool\n</code></pre> <p>Determine if the plugin allows implicit discovery by method name.</p> <p>By default (<code>True</code>), plugins can be found by the <code>PluginManager</code> when a user provides only a method name (without specifying the plugin, e.g., <code>\"method-name\"</code>).</p> <p>If a plugin should only be used when explicitly named (e.g., <code>\"plugin-name/method-name\"</code>), it must override this class method to return <code>False</code>.</p> <p>For instance, the <code>external</code> optimizer plugin acts as a wrapper for other optimizers run in separate processes. It doesn't provide methods directly and must always be explicitly requested, so it overrides this method to return <code>False</code>.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the plugin can be discovered implicitly by method name.</p>"},{"location":"reference/realization_filter_plugins/","title":"Realization Filter Plugins","text":""},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter","title":"ropt.plugins.realization_filter","text":"<p>Provides plugin functionality for adding realization filters.</p> <p>Realization filters are used by the optimization process to determine how the results from a set of realizations should be weighted when evaluating the overall objective and constraint functions. This module allows for the extension of <code>ropt</code> with custom realization filtering strategies.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Realization filter plugins must inherit from the   <code>RealizationFilterPlugin</code>   base class. This class acts as a factory, defining a <code>create</code> method to   instantiate filter objects.</li> <li>Filter Implementation: The actual filtering logic resides in classes that   inherit from the   <code>RealizationFilter</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>) and the index   of the specific filter configuration to use (<code>filter_index</code>). The core   functionality is provided by the <code>get_realization_weights</code> method, which   calculates and returns weights for each realization based on their objective   and constraint values.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>RealizationFilterPlugin</code> implementations (typically via entry   points) and uses them to create <code>RealizationFilter</code> instances as needed during   plan execution.</li> </ul> <p>Built-in Realization Filter Plugins:</p> <p>The default <code>DefaultRealizationFilter</code> class provides several filtering methods, including sorting by objective/constraint values and Conditional Value-at-Risk (CVaR) based weighting.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin","title":"ropt.plugins.realization_filter.base.RealizationFilterPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Realization Filter Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>RealizationFilter</code> instances. These plugins act as factories for specific realization filtering strategies.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate realization filter plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>RealizationFilter</code> object that will calculate the realization weights.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig, filter_index: int\n) -&gt; RealizationFilter\n</code></pre> <p>Factory method to create a concrete RealizationFilter instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>RealizationFilter</code> objects. Plugin implementations must override this method to return an instance of their specific <code>RealizationFilter</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires realization weights calculated by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The main EnOpt configuration object.</p> required <code>filter_index</code> <code>int</code> <p>Index into <code>enopt_config.realization_filters</code> for           this filter.</p> required <p>Returns:</p> Type Description <code>RealizationFilter</code> <p>An initialized RealizationFilter object ready for use.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter","title":"ropt.plugins.realization_filter.base.RealizationFilter","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for realization filter classes.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig, filter_index: int\n) -&gt; None\n</code></pre> <p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>filter_index</code> <code>int</code> <p>The index of the filter to use.</p> required"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter.get_realization_weights","title":"get_realization_weights  <code>abstractmethod</code>","text":"<pre><code>get_realization_weights(\n    objectives: NDArray[float64],\n    constraints: NDArray[float64] | None,\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Return the updated weights of the realizations.</p> <p>This method is called by the optimizer with the current values of the objectives and constraints. Based on these values it must decide how much weight each realization should be given, and return those as a vector.</p> <p>The objectives and the constraints are passed as matrices, where the columns contain the values of the objectives or constraints. The index along the row axis corresponds to the number of the realization.</p> Normalization <p>The weights will be normalized to a sum of one by the optimizer before use, hence any non-negative weight value is permissable.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objectives of all realizations.</p> required <code>constraints</code> <code>NDArray[float64] | None</code> <p>The constraints for all realizations.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A vector of weights of the realizations.</p>"},{"location":"reference/results/","title":"Optimization Results","text":""},{"location":"reference/results/#ropt.results","title":"ropt.results","text":"<p>Data classes for storing intermediate optimization results.</p> <p>During the optimization process, the calculation of functions and gradients generates data that needs to be reported. To facilitate this, new results are passed to callbacks as a sequence of <code>Results</code> objects. These objects can be instances of either the <code>FunctionResults</code> or <code>GradientResults</code> classes, which store the results of function and gradient evaluations, respectively.</p> <p>Much of the data within these result objects is multi-dimensional. For example, the <code>objectives</code> field, which is part of the nested <code>evaluations</code> object within <code>FunctionResults</code>, is a two-dimensional <code>numpy</code> array. In this array, each column represents a different objective, and each row corresponds to a specific realization number.</p> <p>To simplify exporting and reporting, the identity of the axes in these multi-dimensional arrays is stored as metadata associated with each field. These fields are derived from the <code>ResultField</code> class, which provides a <code>get_axes</code> class method for retrieving the axes. For instance, for the <code>objectives</code> field, this method would return:</p> <p><pre><code>&gt;&gt;&gt; from ropt.results import FunctionEvaluations\n&gt;&gt;&gt; FunctionEvaluations.get_axes(\"objectives\")\n(&lt;ResultAxis.REALIZATION: 'realization'&gt;, &lt;ResultAxis.OBJECTIVE: 'objective'&gt;)\n</code></pre> Given that the first axis denotes realizations and the second axis denotes objectives, each row in the array represents the set of objective values for a specific realization. This metadata provides the necessary context for exporting and reporting code to associate each element in the result matrix with its corresponding realization and objective, as specified in the optimizer configuration. The pandas exporting code, for example, utilizes this information to construct a multi-index for the output DataFrame and to transform the multi-dimensional data into multiple columns.</p>"},{"location":"reference/results/#ropt.results.Results","title":"ropt.results.Results  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for storing optimization results.</p> <p>The <code>Results</code> class serves as a foundation for storing various types of optimization results. It is not intended to be instantiated directly but rather serves as a base for derived classes like <code>FunctionResults</code> and <code>GradientResults</code>, which hold the actual data.</p> <p>This class provides storage for the following generic information:</p> <ul> <li>Batch ID: An optional identifier, potentially generated by the     function evaluator, that uniquely identifies a group of function     evaluations passed to the evaluator by teh optimizer.</li> <li>Metadata: A dictionary for storing additional information generated     during optimization. This metadata can include various primitive values     that are not directly interpreted by the optimization code but are     useful for reporting and analysis.</li> </ul> <p>The derived classes, <code>FunctionResults</code> and <code>GradientResults</code>, extend this base class with specific attributes for storing function evaluation results and gradient evaluation results, respectively. These derived classes also provide methods for exporting the stored data.</p> <p>One key method provided by the <code>Results</code> class is <code>to_dataframe</code>, which allows exporting the contents of a specific field, or a subset of its sub-fields, to a <code>pandas</code> DataFrame for further data analysis and reporting.</p> <p>Attributes:</p> Name Type Description <code>batch_id</code> <code>int | None</code> <p>The ID of the evaluation batch.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>A dictionary of metadata.</p>"},{"location":"reference/results/#ropt.results.Results.transform_from_optimizer","title":"transform_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>transform_from_optimizer(\n    transforms: OptModelTransforms,\n) -&gt; Results\n</code></pre> <p>Transform results from the optimizer domain to the user domain.</p> <p>During optimization, variables, objectives, and constraints are often transformed to a different domain (the optimizer domain) to enhance the performance and stability of the optimization algorithm. The <code>Results</code> objects produced during optimization are initially in the optimizer domain. This method reverses these transformations, mapping the results back to the user-defined domain. The transformations between the user and optimizer domains are defined by the classes in the <code>ropt.transforms</code> module.</p> <p>For instance, variables might have been scaled and shifted to a range more suitable for the optimizer. This method, using the provided <code>OptModelTransforms</code> object, applies the inverse scaling and shifting to restore the variables to their original scale and offset. Similarly, objectives and constraints are transformed back to the user domain.</p> <p>These transformations are defined and managed by the <code>OptModelTransforms</code> object, which encapsulates the specific transformations for variables, objectives, and nonlinear constraints.</p> <p>Parameters:</p> Name Type Description Default <code>transforms</code> <code>OptModelTransforms</code> <p>The <code>OptModelTransforms</code> object containing the domain transformations to apply.</p> required <p>Returns:</p> Type Description <code>Results</code> <p>A new <code>FunctionResults</code> object with all relevant data transformed</p> <code>Results</code> <p>back to the user domain.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe(\n    field_name: str,\n    select: Iterable[str],\n    unstack: Iterable[ResultAxis] | None = None,\n    names: dict[str, Sequence[str | int] | None]\n    | None = None,\n) -&gt; pd.DataFrame\n</code></pre> <p>Export a field to a pandas DataFrame.</p> <p>Exports the values of a single field to a <code>pandas</code> DataFrame. The field to export is selected by the <code>field_name</code> argument. Typically, such a field contains multiple sub-fields. By default, all sub-fields are exported as columns in the DataFrame, but a subset can be selected using the <code>select</code> argument.</p> <p>Sub-fields may be multi-dimensional arrays, which are exported in a stacked manner. Using the axis types found in the metadata, the exporter constructs a multi-index labeled with the corresponding names provided via the <code>names</code> argument. If <code>names</code> is <code>None</code>, numerical indices are used. These multi-indices can optionally be unstacked into multiple columns by providing the axis types to unstack via the <code>unstack</code> argument.</p> The DataFrame Index <p>The index of the resulting DataFrame may be a multi-index constructed from axis indices or labels. In addition, the <code>batch_id</code> (if not <code>None</code>) is prepended to the index.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field to export.</p> required <code>select</code> <code>Iterable[str]</code> <p>Select the sub-fields to export. By default, all         sub-fields are exported.</p> required <code>unstack</code> <code>Iterable[ResultAxis] | None</code> <p>Select axes to unstack. By default, no axes are         unstacked.</p> <code>None</code> <code>names</code> <code>dict[str, Sequence[str | int] | None] | None</code> <p>A dictionary mapping axis types to names.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>pandas</code> module is not installed.</p> <code>ValueError</code> <p>If the field name is incorrect.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas</code> DataFrame containing the results.</p> Warning <p>This function requires the <code>pandas</code> module to be installed.</p>"},{"location":"reference/results/#ropt.results.ResultField","title":"ropt.results.ResultField  <code>dataclass</code>","text":"<p>Base class for fields within <code>Results</code> objects.</p> <p>The <code>ResultField</code> class serves as a foundation for defining the various data fields that can be stored within <code>Results</code> objects. These fields typically hold multi-dimensional numerical data, such as objective values, constraint values, or gradients.</p> <p>This class provides a standardized way to:</p> <ul> <li>Store metadata about the axes of multi-dimensional arrays.</li> <li>Retrieve the axes associated with a specific field.</li> </ul> <p>Derived classes, such as <code>FunctionEvaluations</code> or <code>Gradients</code>, extend this base class to define specific data structures for different types of optimization results.</p>"},{"location":"reference/results/#ropt.results.ResultField.get_axes","title":"get_axes  <code>classmethod</code>","text":"<pre><code>get_axes(name: str) -&gt; tuple[ResultAxis, ...]\n</code></pre> <p>Retrieve the axes associated with a specific field.</p> <p>Fields within a <code>ResultField</code> object that store multi-dimensional <code>numpy</code> arrays, contain metadata that describes the meaning of each dimension in the array. This method retrieves the axes of a field within a ResultField object from that meta-data, returning a tuple of <code>ResultAxis</code>][ropt.enums.ResultAxis] enums.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the field (sub-field) within the   <code>ResultField</code> instance or class.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided field name is not recognized.</p> <p>Returns:</p> Type Description <code>tuple[ResultAxis, ...]</code> <p>A tuple of <code>ResultAxis</code> enums, representing the axes of the field.</p>"},{"location":"reference/results/#ropt.results.FunctionResults","title":"ropt.results.FunctionResults  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>Stores results related to function evaluations.</p> <p>The <code>FunctionResults</code> class extends the base <code>Results</code> class to store data specific to function evaluations. This includes:</p> <ul> <li>Evaluations: The results of the function evaluations, including the   variable values, objective values, and constraint values for each   realization. See   <code>FunctionEvaluations</code>.</li> <li>Realizations: Information about the realizations, such as weights for   objectives and constraints, and whether each realization was successful.   See <code>Realizations</code>.</li> <li>Functions: The calculated objective and constraint function values,   typically aggregated across realizations. See   <code>Functions</code>.</li> <li>Constraint Info: Details about constraint differences and violations.   See <code>ConstraintInfo</code>.</li> </ul> <p>Attributes:</p> Name Type Description <code>evaluations</code> <code>FunctionEvaluations</code> <p>Results of the function evaluations.</p> <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations.</p> <code>functions</code> <code>Functions | None</code> <p>The calculated functions.</p> <code>constraint_info</code> <code>ConstraintInfo | None</code> <p>Information on constraint differences and violations.</p>"},{"location":"reference/results/#ropt.results.GradientResults","title":"ropt.results.GradientResults  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>Stores results related to gradient evaluations.</p> <p>The <code>GradientResults</code> class extends the base <code>Results</code> class to store data specific to gradient evaluations. This includes:</p> <ul> <li>Evaluations: The results of the function evaluations for perturbed   variables, including the perturbed variable values, objective values, and   constraint values for each realization and perturbation. See   <code>GradientEvaluations</code>.</li> <li>Realizations: Information about the realizations, such as weights for   objectives and constraints, and whether each realization was successful.   See <code>Realizations</code>.</li> <li>Gradients: The calculated gradients of the objectives and constraints.   See <code>Gradients</code>.</li> </ul> <p>Attributes:</p> Name Type Description <code>evaluations</code> <code>GradientEvaluations</code> <p>Results of the function evaluations for perturbed           variables.</p> <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations.</p> <code>gradients</code> <code>Gradients | None</code> <p>The calculated gradients.</p>"},{"location":"reference/results/#ropt.results.Functions","title":"ropt.results.Functions  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the calculated objective and constraint function values.</p> <p>The <code>Functions</code> class stores the calculated values of the objective and constraint functions. These values are typically derived from the evaluations performed across all realizations, often through a process like averaging. The optimizer may handle multiple objectives and constraints. Multiple objectives are combined into a single weighted sum, which is stored in the <code>weighted_objective</code> field. Multiple constraints are handled individually by the optimizer.</p> <p>Attributes:</p> Name Type Description <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective values.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each individual objective.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The value of each individual constraint.</p>"},{"location":"reference/results/#ropt.results.Gradients","title":"ropt.results.Gradients  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the calculated objective and constraint gradients.</p> <p>The <code>Gradients</code> class stores the calculated gradients of the objective and constraint functions. These gradients are typically derived from function evaluations across all realizations, often through a process like averaging. The optimizer may handle multiple objectives and constraints. Multiple objective gradients are combined into a single weighted sum, which is stored in the <code>weighted_objective</code> field. Multiple constraint gradients are handled individually by the optimizer.</p> <p>Attributes:</p> Name Type Description <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective gradients.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The gradient of each individual objective.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The gradient of each individual constraint.</p>"},{"location":"reference/results/#ropt.results.FunctionEvaluations","title":"ropt.results.FunctionEvaluations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the results of function evaluations.</p> <p>The <code>FunctionEvaluations</code> class stores the results of evaluating the objective and constraint functions for a set of variables. It includes the following information:</p> <ul> <li>Variables: The vector of variable values at which the functions were   evaluated.</li> <li>Objectives: The calculated objective function values for each   realization. This is a two-dimensional array where each row corresponds to   a realization and each column corresponds to an objective.</li> <li>Constraints: The calculated constraint function values for each   realization. This is a two-dimensional array where each row corresponds to   a realization and each column corresponds to a constraint.</li> <li>Evaluation Info: Optional metadata associated with each realization,   potentially provided by the evaluator. If provided, each value in the info   dictionary must be a one-dimensional array with a length equal to the   number of realizations.</li> </ul> <p>Attributes:</p> Name Type Description <code>variables</code> <code>NDArray[float64]</code> <p>The variable vector.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The objective function values for each realization.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The constraint function values for each realization.</p> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional metadata for each evaluated realization.</p>"},{"location":"reference/results/#ropt.results.GradientEvaluations","title":"ropt.results.GradientEvaluations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the results of evaluations for gradient calculations.</p> <p>The <code>GradientEvaluations</code> class stores the results of evaluating the objective and constraint functions for perturbed variables, which is necessary for gradient calculations. It contains the following information:</p> <ul> <li>Variables: The vector of unperturbed variable values.</li> <li>Perturbed Variables: A three-dimensional array of perturbed variable   values. The axes represent (in order): realization, perturbation, and   variable.</li> <li>Perturbed Objectives: The calculated objective function values for   each realization and perturbation. This is a three-dimensional array where   the axes represent (in order): realization, perturbation, and objective.</li> <li>Perturbed Constraints: The calculated constraint function values for   each realization and perturbation. This is a three-dimensional array where   the axes represent (in order): realization, perturbation, and constraint.</li> <li>Evaluation Info: Optional metadata associated with each realization   and perturbation, potentially provided by the evaluator. If provided, each   value in the <code>evaluation_info</code> dictionary must be a two-dimensional array   where the rows correspond to perturbations and the second columns   correspond to realizations.</li> </ul> <p>Attributes:</p> Name Type Description <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> <code>perturbed_variables</code> <code>NDArray[float64]</code> <p>The perturbed variable values for each                    realization and perturbation.</p> <code>perturbed_objectives</code> <code>NDArray[float64]</code> <p>The objective function values for each                    realization and perturbation.</p> <code>perturbed_constraints</code> <code>NDArray[float64] | None</code> <p>The constraint function values for each                    realization and perturbation.</p> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional metadata for each evaluated                    realization and perturbation.</p>"},{"location":"reference/results/#ropt.results.Realizations","title":"ropt.results.Realizations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores information about the realizations.</p> <p>The <code>Realizations</code> class stores data related to the individual realizations used in the optimization process. This includes:</p> <ul> <li>Failed Realizations: A boolean array indicating whether each   realization's evaluation was successful. <code>True</code> indicates a failed   realization, while <code>False</code> indicates a successful one.</li> <li>Objective Weights: A two-dimensional array of weights used for each   objective in each realization. The first axis corresponds to the   objectives, and the second axis corresponds to the realizations. These   weights may change during optimization, depending on the type of objective   calculation.</li> <li>Constraint Weights: A two-dimensional array of weights used for each   constraint in each realization. The first axis corresponds to the   constraints, and the second axis corresponds to the realizations. These   weights may change during optimization, depending on the type of   constraint calculation.</li> </ul> <p>Attributes:</p> Name Type Description <code>failed_realizations</code> <code>NDArray[bool_]</code> <p>Boolean array indicating failed realizations.</p> <code>objective_weights</code> <code>NDArray[float64] | None</code> <p>Weights for each objective in each realization.</p> <code>constraint_weights</code> <code>NDArray[float64] | None</code> <p>Weights for each constraint in each realization.</p>"},{"location":"reference/results/#ropt.results.ConstraintInfo","title":"ropt.results.ConstraintInfo  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores information about constraint differences and violations.</p> <p>The <code>ConstraintInfo</code> class stores the differences between variable or  constraint values and their respective bounds. It also calculates and  stores constraint violations. This information is useful for assessing  how well the optimization process is satisfying the imposed constraints.</p> <p>The class stores the following information:</p> <ul> <li> <p>Bound Differences: The differences between the variable values and    their lower and upper bounds.</p> <ul> <li><code>bound_lower</code>: The difference between the variable values and their   lower bounds. A negative value indicates that the variable is below its   lower bound.</li> <li><code>bound_upper</code>: The difference between the variable values and their   upper bounds. A positive value indicates that the variable is above its   upper bound.</li> </ul> </li> <li> <p>Linear Constraint Differences: The differences between the linear    constraint values and their lower and upper bounds.</p> <ul> <li><code>linear_lower</code>: The difference between the linear constraint values   and their lower bounds. A negative value indicates that the constraint   is below its lower bound.</li> <li><code>linear_upper</code>: The difference between the linear constraint values and   their upper bounds. A positive value indicates that the constraint is   above its upper bound.</li> </ul> </li> <li> <p>Nonlinear Constraint Differences: The differences between the    nonlinear constraint values and their lower and upper bounds.</p> <ul> <li><code>nonlinear_lower</code>: The difference between the nonlinear constraint   values and their lower bounds. A negative value indicates that the   constraint is below its lower bound.</li> <li><code>nonlinear_upper</code>: The difference between the nonlinear constraint   values and their upper bounds. A positive value indicates that the   constraint is above its upper bound.</li> </ul> </li> <li> <p>Constraint Violations: The magnitude of the constraint violations.</p> <ul> <li><code>bound_violation</code>: The magnitude of the violation of the variable   bounds.</li> <li><code>linear_violation</code>: The magnitude of the violation of the linear    constraints.</li> <li><code>nonlinear_violation</code>: The magnitude of the violation of the nonlinear   constraints.</li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>bound_lower</code> <code>NDArray[float64] | None</code> <p>Difference between variables and their lower bounds.</p> <code>bound_upper</code> <code>NDArray[float64] | None</code> <p>Difference between variables and their upper bounds.</p> <code>linear_lower</code> <code>NDArray[float64] | None</code> <p>Difference between linear constraints and their lower                 bounds.</p> <code>linear_upper</code> <code>NDArray[float64] | None</code> <p>Difference between linear constraints and their upper                 bounds.</p> <code>nonlinear_lower</code> <code>NDArray[float64] | None</code> <p>Difference between nonlinear constraints and their                 lower bounds.</p> <code>nonlinear_upper</code> <code>NDArray[float64] | None</code> <p>Difference between nonlinear constraints and their                 upper bounds.</p> <code>bound_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the variable bounds.</p> <code>linear_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the linear constraints.</p> <code>nonlinear_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the nonlinear constraints.</p>"},{"location":"reference/results/#ropt.results.results_to_dataframe","title":"ropt.results.results_to_dataframe","text":"<pre><code>results_to_dataframe(\n    results: Sequence[Results],\n    fields: set[str],\n    result_type: Literal[\"functions\", \"gradients\"],\n    names: dict[str, Sequence[str | int] | None]\n    | None = None,\n) -&gt; pd.DataFrame\n</code></pre> <p>Combine a sequence of results into a single pandas DataFrame.</p> <p>This function aggregates results from multiple <code>FunctionResults</code> or <code>GradientResults</code> objects into a single <code>pandas</code> DataFrame. It is designed to be used with observers that produce results during the optimization process.</p> <p>The <code>fields</code> argument determines which data fields to include in the DataFrame. These fields can be any of the attributes defined within <code>FunctionResults</code> or <code>GradientResults</code>. Nested fields are specified using dot notation (e.g., <code>evaluations.variables</code> to include the <code>variables</code> field within the <code>evaluations</code> object).</p> <p>The <code>evaluation_info</code> sub-fields, found within the <code>evaluations</code> fields of <code>functions</code> and <code>gradient</code> results, respectively, are dictionaries. To include specific keys from these dictionaries, use the format <code>evaluations.evaluation_info.key</code>, where <code>key</code> is the name of the desired key.</p> <p>Many fields may result in multiple columns in the DataFrame. For example, <code>evaluations.variables</code> will generate a separate column for each variable. If available, variable names will be used as column labels. Multi-dimensional fields, such as those with named realizations and objectives, will have column names that are tuples of the corresponding names.</p> <p>The <code>result_type</code> argument specifies whether to include function evaluation results (<code>functions</code>) or gradient results (<code>gradients</code>).</p> <p>The <code>names</code> argument is an optional dictionary that maps axis types to names. These names are used to label the multi-index columns in the resulting DataFrame. If not provided, numerical indices are used.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Sequence[Results]</code> <p>A sequence of <code>Results</code> objects          to combine.</p> required <code>fields</code> <code>set[str]</code> <p>The names of the fields to include in the DataFrame.</p> required <code>result_type</code> <code>Literal['functions', 'gradients']</code> <p>The type of results to include (\"functions\" or          \"gradients\").</p> required <code>names</code> <code>dict[str, Sequence[str | int] | None] | None</code> <p>A dictionary mapping axis types to names.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas</code> DataFrame containing the combined results.</p>"},{"location":"reference/sampler_plugins/","title":"Sampler Plugins","text":""},{"location":"reference/sampler_plugins/#ropt.plugins.sampler","title":"ropt.plugins.sampler","text":"<p>Provides plugin functionality for adding sampler plugins.</p> <p>Samplers are used by the optimization process to generate perturbed variable vectors. This module allows for the extension of <code>ropt</code> with custom samplers.</p> <p>Core Concepts:</p> <ul> <li>Plugin Interface: Sampler plugins must inherit from the   <code>SamplerPlugin</code> base class.   This class acts as a factory, defining a <code>create</code> method to instantiate   sampler objects.</li> <li>Sampler Implementation: The actual sampling logic resides in classes   that inherit from the <code>Sampler</code>   abstract base class. These classes are initialized with the optimization   configuration (<code>EnOptConfig</code>), the index   of the specific sampler configuration to use (<code>sampler_index</code>), an optional   variable mask (<code>mask</code>), and a random number generator (<code>rng</code>). Samples are   generated by calling the sampler's <code>generate_samples</code> method.</li> <li>Discovery: The <code>PluginManager</code> discovers   available <code>SamplerPlugin</code> implementations (typically via entry points) and   uses them to create <code>Sampler</code> instances as needed during plan execution.</li> </ul> <p>Built-in Sampler Plugins:</p> <p>By default, the <code>SciPySampler</code> sampler is installed, which provides several sampling methods based on the <code>scipy.stats</code> and <code>scipy.stats.qmc</code> packages.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin","title":"ropt.plugins.sampler.base.SamplerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract Base Class for Sampler Plugins (Factories).</p> <p>This class defines the interface for plugins responsible for creating <code>Sampler</code> instances. These plugins act as factories for specific sampling algorithms or strategies.</p> <p>During plan execution, the <code>PluginManager</code> identifies the appropriate sampler plugin based on the configuration and uses its <code>create</code> class method to instantiate the actual <code>Sampler</code> object that will generate the perturbation samples.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig,\n    sampler_index: int,\n    mask: NDArray[bool_] | None,\n    rng: Generator,\n) -&gt; Sampler\n</code></pre> <p>Factory method to create a concrete Sampler instance.</p> <p>This abstract class method serves as a factory for creating concrete <code>Sampler</code> objects. Plugin implementations must override this method to return an instance of their specific <code>Sampler</code> subclass.</p> <p>The <code>PluginManager</code> calls this method when an optimization step requires samples generated by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The main EnOpt configuration object.</p> required <code>sampler_index</code> <code>int</code> <p>Index into <code>enopt_config.samplers</code> for this sampler.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>Optional boolean mask for variable subset sampling.</p> required <code>rng</code> <code>Generator</code> <p>NumPy random number generator instance.</p> required <p>Returns:</p> Type Description <code>Sampler</code> <p>An initialized Sampler object ready for use.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler","title":"ropt.plugins.sampler.base.Sampler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Sampler Implementations.</p> <p>This class defines the fundamental interface for all concrete sampler implementations within the <code>ropt</code> framework. Sampler plugins provide classes derived from <code>Sampler</code> that encapsulate the logic of specific sampling algorithms or strategies used to generate perturbed variable vectors for the optimization process.</p> <p>Instances of <code>Sampler</code> subclasses are created by their corresponding <code>SamplerPlugin</code> factories. They are initialized with an <code>EnOptConfig</code> object detailing the optimization setup, the <code>sampler_index</code> identifying the specific sampler configuration to use from the config, an optional variable <code>mask</code> indicating which variables this sampler instance handles, and a NumPy random number generator (<code>rng</code>) for stochastic methods.</p> <p>The core functionality, generating samples, is performed by the <code>generate_samples</code> method, which must be implemented by subclasses.</p> <p>Subclasses must implement:</p> <ul> <li><code>__init__</code>: To accept the configuration, index, mask, and RNG.</li> <li><code>generate_samples</code>: To contain the sample generation logic.</li> </ul>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig,\n    sampler_index: int,\n    mask: NDArray[bool_] | None,\n    rng: Generator,\n) -&gt; None\n</code></pre> <p>Initialize the sampler object.</p> <p>The <code>samplers</code> field in the <code>enopt_config</code> is a tuple of sampler configurations (<code>SamplerConfig</code>). The <code>sampler_index</code> identifies which configuration from this tuple should be used to initialize this specific sampler instance.</p> <p>If a boolean <code>mask</code> array is provided, it indicates that this sampler instance is responsible for generating samples only for the subset of variables where the mask is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler configuration to use.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>Optional mask indicating variables handled by this sampler.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for stochastic methods.</p> required"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler.generate_samples","title":"generate_samples  <code>abstractmethod</code>","text":"<pre><code>generate_samples() -&gt; NDArray[np.float64]\n</code></pre> <p>Generate and return an array of sampled perturbation values.</p> <p>This method must return a three-dimensional NumPy array containing the generated perturbation samples. The shape of the array should be <code>(n_realizations, n_perturbations, n_variables)</code>, where:</p> <ul> <li><code>n_realizations</code> is the number of realizations in the ensemble.</li> <li><code>n_perturbations</code> is the number of perturbations requested.</li> <li><code>n_variables</code> is the total number of optimization variables.</li> </ul> <p>If the <code>shared</code> flag is <code>True</code> in the associated <code>SamplerConfig</code>, the first dimension (realizations) should have a size of 1. The framework will broadcast these shared samples across all realizations.</p> <p>If a boolean <code>mask</code> was provided during initialization, this sampler instance is responsible only for a subset of variables (where the mask is <code>True</code>). The returned array must still have the full <code>n_variables</code> size along the last axis. However, values corresponding to variables not handled by this sampler (where the mask is <code>False</code>) must be zero.</p> Sample Scaling and Perturbation Magnitudes <p>The generated samples represent unscaled perturbations. During the gradient estimation process, these samples will be multiplied element-wise by the <code>perturbation_magnitudes</code> defined in the <code>GradientConfig</code>.</p> <p>Therefore, it is generally recommended that sampler implementations produce samples with a characteristic scale of approximately one (e.g., drawn from a distribution with a standard deviation of 1, or uniformly distributed within <code>[-1, 1]</code>). This allows the <code>perturbation_magnitudes</code> to directly control the effective size of the perturbations applied to the variables.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A 3D NumPy array of sampled perturbation values.</p>"},{"location":"reference/scipy_optimizer_plugin/","title":"SciPy Optimizer Plugin","text":""},{"location":"reference/scipy_optimizer_plugin/#ropt.plugins.optimizer.scipy.SciPyOptimizer","title":"ropt.plugins.optimizer.scipy.SciPyOptimizer","text":"<p>               Bases: <code>Optimizer</code></p> <p>SciPy optimization backend for ropt.</p> <p>This class provides an interface to several optimization algorithms from SciPy's <code>scipy.optimize</code> module, enabling their use within <code>ropt</code>.</p> <p>To select an optimizer, set the <code>method</code> field within the <code>optimizer</code> section of the <code>EnOptConfig</code> configuration object to the desired algorithm's name. Most methods support the general options defined in the <code>EnOptConfig</code> object. For algorithm-specific options, use the <code>options</code> dictionary within the <code>optimizer</code> section.</p> <p>The table below lists the included methods together with the method-specific options that are supported. Click on the method name to consult the corresponding <code>scipy.optimize</code> documentation:</p> Method Method Options Nelder-Mead disp, maxiter, maxfev, xatol, fatol, adaptive Powell disp, maxiter, maxfev, xtol, ftol CG disp, maxiter, gtol, norm, eps, finite_diff_rel_step, c1, c2 BFGS disp, maxiter, gtol, norm, eps, finite_diff_rel_step, xrtol, c1, c2 Newton-CG disp, maxiter, xtol, eps, c1, c2 L-BFGS-B disp, maxiter, maxcor, ftol, gtol, eps, maxfun, iprint, maxls, finite_diff_rel_step TNC disp, maxfun, eps, scale, offset, maxCGit, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, finite_diff_rel_step COBYLA disp, maxiter, rhobeg, tol, catol SLSQP disp, maxiter, ftol, eps, finite_diff_rel_step differential_evolution disp, maxiter, strategy, popsize, tol, mutation, recombination, seed, polish, init, atol, updating"},{"location":"reference/scipy_sampler_plugin/","title":"SciPy Sampler Plugin","text":""},{"location":"reference/scipy_sampler_plugin/#ropt.plugins.sampler.scipy.SciPySampler","title":"ropt.plugins.sampler.scipy.SciPySampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Plugin class for producing sampling values via SciPy.</p> <p>This plugin implements the following sampling methods using the corresponding methods from the SciPy stats module:</p> <ul> <li> <p>Sampling from probability   distributions:</p> <code>uniform</code> Uniform distribution with a default range of [-1, 1]. <code>norm</code> Normal distribution with mean zero and standard deviation 1. <code>truncnorm</code> Truncated normal distribution with mean zero and standard   deviation 1 truncated a the range [-1, 1]. </li> <li> <p>Sampling using methods from the Quasi-Monte Carlo   submodule:</p> <code>sobol</code> Using Sobol sequences, scaled to -1 and 1. <code>halton</code> Using Halton sequences, scaled to -1 and 1. <code>lhs</code> Using Latin Hypercube sampling, scaled to -1 and 1. </li> </ul> <p>Specific options that are normally passed as arguments in the SciPy functions can be provided via the options dictionary in the configuration object. Consult the <code>scipy.stats</code> manual for details on these options.</p>"},{"location":"reference/utilities/","title":"Utilities","text":""},{"location":"reference/utilities/#ropt.config.utils","title":"ropt.config.utils","text":"<p>Utilities for checking configuration values.</p> <p>These utilities are intended to be used in the model validation code of Pydantic models.</p>"},{"location":"reference/utilities/#ropt.config.utils.ImmutableBaseModel","title":"ImmutableBaseModel","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for immutable classes.</p> <p>This model serves as an alternative to frozen Pydantic classes. It is particularly useful when post-initialization validators are required, as these validators may not function properly with frozen Pydantic classes.</p>"},{"location":"reference/utilities/#ropt.config.utils.ImmutableBaseModel.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name: str, value: Any) -&gt; None\n</code></pre> <p>Attribute setter method.</p> <p>This method sets an attribute if the object is not immutable.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the attribute to set.</p> required <code>value</code> <code>Any</code> <p>The value to assign to the attribute.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>Raised if the object is immutable and cannot be modified.</p>"},{"location":"reference/utilities/#ropt.config.utils.normalize","title":"normalize","text":"<pre><code>normalize(array: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Normalize a vector.</p> <p>Normalize the sum of the values to one.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[float64]</code> <p>The input array.</p> required <p>Returns:</p> Name Type Description <code>ValueError</code> <code>NDArray[float64]</code> <p>The normalized array</p>"},{"location":"reference/utilities/#ropt.config.utils.immutable_array","title":"immutable_array","text":"<pre><code>immutable_array(\n    array_like: ArrayLike, **kwargs: Any\n) -&gt; NDArray[Any]\n</code></pre> <p>Make an immutable array.</p> <p>Converts the input to an array and makes it immutable.`</p> <p>Parameters:</p> Name Type Description Default <code>array_like</code> <code>ArrayLike</code> <p>The input.</p> required <code>kwargs</code> <code> </code> <p>Additional keyword arguments for array conversion.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>The immutable array.</p>"},{"location":"reference/utilities/#ropt.config.utils.broadcast_arrays","title":"broadcast_arrays","text":"<pre><code>broadcast_arrays(*args: Any) -&gt; tuple[NDArray[Any], ...]\n</code></pre> <p>Broadcast a set of arrays to a common dimensionality and makes them immutable.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>The input arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>tuple[NDArray[Any], ...]</code> <p>The broadcasted immutable arrays.</p>"},{"location":"reference/utilities/#ropt.config.utils.broadcast_1d_array","title":"broadcast_1d_array","text":"<pre><code>broadcast_1d_array(\n    array: NDArray[Any], name: str, size: int\n) -&gt; NDArray[Any]\n</code></pre> <p>Broadcast the input array to an 1D array of given size.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[Any]</code> <p>The input array.</p> required <code>name</code> <code>str</code> <p>The name of the array, used in an error message.</p> required <code>size</code> <code>int</code> <p>The size of the result.</p> required <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>An 1D array of the requested size.</p>"},{"location":"reference/utilities/#ropt.config.utils.check_enum_values","title":"check_enum_values","text":"<pre><code>check_enum_values(\n    value: NDArray[ubyte], enum_type: Type[IntEnum]\n) -&gt; None\n</code></pre> <p>Check if an enum value is valid.</p> <p>Given an array of byte integers, check of the values are within the range of values of the given enum.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NDArray[ubyte]</code> <p>The enum values.</p> required <code>enum_type</code> <code>Type[IntEnum]</code> <p>The type to check.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array contains an invalid value.</p>"},{"location":"reference/utilities/#ropt.config.validated_types","title":"ropt.config.validated_types","text":"<p>Annotated types for use with Pydantic models.</p> <p>These types can be used to convert input values to a desired type and guarantee certain properties. They include types that convert inputs to immutable NumPy arrays of specified dimension and type:</p> <ul> <li><code>Array1D</code>: For converting sequences to   immutable one-dimensional floating-point arrays.</li> <li><code>Array2D</code>: For converting sequences to   immutable two-dimensional floating-point arrays.</li> <li><code>ArrayEnum</code>: For converting   sequences to values of numerical enumerations of any dimension.</li> <li><code>Array1DInt</code>: For converting   sequences to immutable one-dimensional integer arrays.</li> <li><code>Array1DBool</code>: For converting   sequences to immutable one-dimensional boolean arrays.</li> </ul> <p>Additionally, the following convenience types create sets or tuples, ensuring that single values are embedded in a set or tuple, respectively:</p> <ul> <li><code>ItemOrSet[T]</code>: Create a set of type <code>T</code>.</li> <li><code>ItemOrTuple[T]</code>: Create a tuple of type <code>T</code>.</li> </ul>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1D","title":"Array1D  <code>module-attribute</code>","text":"<pre><code>Array1D = Annotated[\n    NDArray[float64], BeforeValidator(_convert_1d_array)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of floating point values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array2D","title":"Array2D  <code>module-attribute</code>","text":"<pre><code>Array2D = Annotated[\n    NDArray[float64], BeforeValidator(_convert_2d_array)\n]\n</code></pre> <p>Convert to an immutable 2D numpy array of floating point values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ArrayEnum","title":"ArrayEnum  <code>module-attribute</code>","text":"<pre><code>ArrayEnum = Annotated[\n    NDArray[ubyte], BeforeValidator(_convert_enum_array)\n]\n</code></pre> <p>Convert to an immutable numpy array of numerical enumeration values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1DInt","title":"Array1DInt  <code>module-attribute</code>","text":"<pre><code>Array1DInt = Annotated[\n    NDArray[intc], BeforeValidator(_convert_1d_array_intc)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of integer values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1DBool","title":"Array1DBool  <code>module-attribute</code>","text":"<pre><code>Array1DBool = Annotated[\n    NDArray[bool_], BeforeValidator(_convert_1d_array_bool)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of boolean values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ItemOrSet","title":"ItemOrSet  <code>module-attribute</code>","text":"<pre><code>ItemOrSet = Annotated[set[T], BeforeValidator(_convert_set)]\n</code></pre> <p>Convert to single value to a set containing that value, passes sets unchanged.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ItemOrTuple","title":"ItemOrTuple  <code>module-attribute</code>","text":"<pre><code>ItemOrTuple = Annotated[\n    tuple[T, ...], BeforeValidator(_convert_tuple)\n]\n</code></pre> <p>Convert to single value to a tuple containing that value, passes sets unchanged.</p>"},{"location":"usage/robust_optimization/","title":"Introduction: Ensemble-based robust optimization","text":"<p>Constraint optimization is the process of optimizing an objective function \\(f(\\mathbf{x})\\) with respect to a vector of variables \\(\\mathbf{x}\\) in the presence of one or more inequality constraints \\(g_j(\\mathbf{x})\\) and/or equality constraints \\(h_k(\\mathbf{x})\\).</p> \\[ \\begin{align} \\textrm{minimize} \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{subject to} \\quad &amp; g_j(\\mathbf{x}) \\le 0, \\quad j=1, \\ldots, J \\\\ &amp; h_k(\\mathbf{x}) = 0, \\quad k=1, \\ldots, K \\\\ &amp; \\mathbf{x}^L \\le \\mathbf{x} \\le \\mathbf{x}^U \\end{align} \\] <p>In this context, the function \\(f(\\mathbf{x})\\) is assumed to have a deterministic nature, meaning it is well-defined for given parameters. However, in realistic scenarios, \\(f(\\mathbf{x})\\) may be part of a larger set of functions, especially if it depends on uncertain parameters drawn from some, possibly unknown, probability distribution.</p> <p>Ensemble-based robust optimization aims to optimize an ensemble of functions \\(f_i(\\mathbf{x})\\) with respect to \\(\\mathbf{x}\\). The set of realizations \\(f_i\\) captures the uncertainty that may exist in the model, which can be, for instance, constructed by varying some parameters according to a given probability distribution. When given a set of realizations, ensemble-based optimization proceeds by combining the functions \\(f_i(\\mathbf{x})\\) into a single objective function. For example, using a weighted sum, the problem becomes (ignoring constraints):</p> \\[ \\textrm{minimize} \\quad \\sum_i w_i f_i(\\mathbf{x}), \\] <p>where \\(w_i\\) represents the weights assigned to the different realizations. In more complex settings, the realizations may also be combined in different ways, and the set of realizations may be modified during optimization. For instance, risk-aware objectives may be constructed by minimizing the standard deviation of the functions or by selecting some of the worst-performing realizations at each iteration.</p> <p>In practice, the optimization task often becomes complex due to additional factors. The evaluation of functions might be computationally expensive, and calculating their gradients analytically can be challenging or even impossible. For example, the functions may involve lengthy simulations of a physical process with numerous variables, utilizing numerical calculations that preclude straightforward analytical differentiation.</p> <p><code>ropt</code> leverages standard optimization algorithms, such as those available in the SciPy package. These methods typically follow an iterative approach, necessitating repeated assessments of the objective function and, in many cases, its gradient. Currently, it is assumed that the functions are not easily differentiated analytically. One of the core functions of <code>ropt</code> is to calculate gradients efficiently using stochastic methods.</p> <p><code>ropt</code> is responsible for configuring and executing the optimization algorithm, building the overall function and gradient values from individual realizations, and monitoring both intermediate and final optimization results. It delegates the actual calculations of functions to external code that is provided by the user.</p> <p>While many optimization scenarios involve a single run of a particular method, there are cases where it proves beneficial to conduct multiple runs using the same or different algorithms. For example, when dealing with a mix of continuous and discrete variables, it might be advantageous to employ different methods for each variable type. <code>ropt</code> facilitates this by offering a mechanism to run a workflow containing multiple optimizers, potentially of different types, in an alternating or nested fashion.</p>"},{"location":"usage/running/","title":"Running a basic optimization script","text":"<p>Consider the Rosenbrock function, a standard test problem:</p> \\[ f(x,y) = (a - x)^2 + b (y - x^2)^2, \\] <p>which has a global minimum of \\(f(x, y) = 0\\) at \\((x, y) = (a, a^2)\\) .</p> <p>Here's an example optimizing the Rosenbrock function for \\(a = 1\\) and \\(b = 100\\):</p> <pre><code>import numpy as np\nfrom numpy.typing import NDArray\n\nfrom ropt.evaluator import EvaluatorContext, EvaluatorResult\nfrom ropt.plan import BasicOptimizer\n\n\ndef rosenbrock(\n    variables: NDArray[np.float64],                                   # (1)!\n    context: EvaluatorContext                                         # (2)!\n) -&gt; EvaluatorResult:\n    objectives = np.zeros((variables.shape[0], 1), dtype=np.float64)\n    for idx in range(variables.shape[0]):\n        x, y = variables[idx, :]\n        objectives[idx, 0] = (1.0 - x) ** 2 + 100 * (y - x * x) ** 2\n    return EvaluatorResult(objectives=objectives)                     # (3)!\n\nCONFIG = {                                                            # (4)!\n    \"variables\": {\"initial_values\": [0.5, 2.0]},\n    \"gradient\": {\"perturbation_magnitudes\": 1e-5}                     # (5)!\n}\n\noptimum = BasicOptimizer(CONFIG, rosenbrock).run().results            # (6)!\n\nprint(optimum.evaluations.variables, optimum.functions.weighted_objective)\n</code></pre> <ol> <li>The variables to optimize (\\(x, y\\)) are passes as a single <code>numpy</code> array. The    function may receive multiple variable vectors to evaluate, hence the input    is a matrix where the variable vectors are the rows of the matrix.</li> <li>Additional information is passes via an    <code>EvaluatorContext</code> object. It is not    needed in this case.</li> <li>Results are returned via an    <code>EvaluatorResult</code> object. The objectives    result is a matrix since multiple input vectors and multiple objectives may    be evaluated.</li> <li>Create an optimizer configuration with default values except for initial    values and perturbation magnitudes.</li> <li>Set perturbation magnitudes to a small value for accurate gradient    estimation.</li> <li>Make an <code>BasicOptimizer</code> plan, run it, and    retrieve the results.</li> </ol> <p>Running this will print the estimated optimal variables and the corresponding function value:</p> <pre><code>[1.00117794 1.0023715 ] 1.4078103983185034e-06\n</code></pre> <p>This example uses the BasicOptimizer class which provides a simplified interface for running optimizations. More complex optimization workflows can be implemented using the plan functionality.</p>"}]}