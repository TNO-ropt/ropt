{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>ropt</code>: A Python module for robust optimization","text":"<p><code>ropt</code> is a module designed for implementing and executing robust optimization workflows. In classical optimization problems, a deterministic function is optimized. However, in robust optimization, the function is expected to exhibit a stochastic nature and is represented by an ensemble of functions (realizations) for different values of some (possibly unknown) random parameters. The optimal solution is then determined by optimizing the value of a statistic, such as the mean, over the ensemble.</p> <p><code>ropt</code> can be employed to construct optimization workflows directly in Python or as a building block in optimization applications. At a minimum, the user needs to provide additional code to calculate the values for each function realization in the ensemble. This can range from simply calling a Python function that returns the objective values to initiating a long-running simulation on an HPC cluster and reading the results. Furthermore, <code>ropt</code> exposes all intermediate results of the optimization, such as objective and gradient values, but functionality to report or store any of these values must be added by the user. Optional functionality to assist with this is included with <code>ropt</code>.</p> <p><code>ropt</code> provides several features for efficiently solving complex robust optimization problems:</p> <ul> <li>Robust optimization over an ensemble of models, i.e., optimizing the average   of a set of objective functions. Alternative objectives can be implemented   using plugins, for instance, to implement risk-aware optimization, such as   Conditional Value at Risk (CVaR) or standard-deviation-based functions.</li> <li>Support for black-box optimization of arbitrary functions.</li> <li>Support for running complex optimization workflows, such as multiple runs with   different optimization settings or even different optimization methods.</li> <li>Support for nested optimization, allowing sub-sets of the variables to be   optimized by optimization workflows that run as part of the black-box function   to be optimized.</li> <li>An interface for running various continuous and discrete optimization methods.   By default, optimizers from the   <code>scipy.optimize</code>   package are included, but additional optimizers can be added via a plugin   mechanism. The most common options of these optimizers can be configured in a   uniform manner, although algorithm- or package-specific options can still be   passed.</li> <li>Efficient estimation of gradients using a Stochastic Simplex Approximate   Gradient (StoSAG) approach. Additional samplers for generating perturbed   values for gradient estimation can be added via a plugin mechanism.</li> <li>Support for linear and non-linear constraints, if supported by the chosen   optimizer.</li> <li>Flexible configuration of the optimization process using   <code>pydantic</code>.</li> <li>Support for tracking and processing optimization results generated during the   optimization process.</li> <li>Support for generating formatted tables of the results.</li> <li>Optional support for exporting results as   <code>pandas</code> data frames.</li> </ul>"},{"location":"reference/basic_optimizer/","title":"Basic Optimizer","text":""},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer","title":"ropt.plan.BasicOptimizer","text":"<p>A class for executing single optimization runs.</p> <p>The <code>BasicOptimizer</code> is designed to simplify the process of setting up and executing optimization workflows that consist primarily of a single optimization run. It offers a more streamlined approach compared to directly defining and managing a full <code>Plan</code> object, making it ideal for straightforward optimization tasks.</p> <p>This class provides a user-friendly interface for common optimization operations, including:</p> <ul> <li>Initiating a Single Optimization:  Easily start an optimization   process with a provided configuration and evaluator.</li> <li>Observing Optimization Events: Register observer functions to monitor   and react to various events that occur during the optimization, such as   the start of an evaluation or the availability of new results.</li> <li>Abort Conditions: Define a callback function that can be used to check   for abort conditions during the optimization.</li> <li>Result Reporting: Define a callback function that will be called   whenever new results become available.</li> <li>Accessing Results: After the optimization is complete, the optimal   results, corresponding variables, and the optimization's exit code are   readily accessible.</li> <li>Customizable Steps and Handlers: While designed for single runs, it   allows for the addition of custom steps and handlers to the underlying   <code>Plan</code> for more complex scenarios. It is possible to pass keyword   arguments to the custom steps and handlers.</li> </ul> <p>By encapsulating the core elements of an optimization run, the <code>BasicOptimizer</code> reduces the boilerplate code required for simple optimization tasks, allowing users to focus on defining the optimization problem and analyzing the results.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.results","title":"results  <code>property</code>","text":"<pre><code>results: FunctionResults | None\n</code></pre> <p>Return the optimal result found during the optimization.</p> <p>This property provides access to the best <code>FunctionResults</code> object discovered during the optimization process. It encapsulates the objective function value, constraint values, and other relevant information about the optimal solution.</p> <p>Returns:</p> Type Description <code>FunctionResults | None</code> <p>The optimal result.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.variables","title":"variables  <code>property</code>","text":"<pre><code>variables: NDArray[float64] | None\n</code></pre> <p>Return the optimal variables found during the optimization.</p> <p>This property provides access to the variable values that correspond to the optimal <code>FunctionResults</code> object. These variables represent the solution that yielded the best objective function value found during the optimization process.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>The variables corresponding to the optimal result.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.exit_code","title":"exit_code  <code>property</code>","text":"<pre><code>exit_code: OptimizerExitCode\n</code></pre> <p>Return the exit code of the optimization run.</p> <p>This property provides access to the <code>OptimizerExitCode</code> that indicates the outcome of the optimization process. It can be used to determine whether the optimization completed successfully, was aborted, or encountered an error.</p> <p>Returns:</p> Type Description <code>OptimizerExitCode</code> <p>The exit code of the optimization run.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: dict[str, Any] | EnOptConfig,\n    evaluator: Evaluator,\n    *,\n    transforms: OptModelTransforms | None = None,\n    constraint_tolerance: float = 1e-10,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Initialize a <code>BasicOptimizer</code> object.</p> <p>This constructor sets up the necessary components for a single optimization run. It requires an optimization configuration and an evaluator, which together define the optimization problem and how to evaluate potential solutions. The <code>transforms</code> object can be used to apply transformations to the optimization model, such as scaling or shifting variables. If a constraint value is within the <code>constraint_tolerance</code> of zero, it is considered satisfied. The <code>kwargs</code> may be used to define custom steps, and handlers to modify the behavior of the optimization process.</p> Custom handlers and steps <p>The optional keyword arguments (<code>kwargs</code>) provide a mechanism to inject custom steps or handlers into the optimization process. The behavior is as follows:</p> <ol> <li>Custom Step Execution: If a single keyword argument is     provided, the <code>BasicOptimizer</code> checks if a step with the same     name exists. If so, that step is executed immediately, receiving     the key-value pair as input. Only one custom step can be     executed this way, if other keyword arguments are present an     error is raised. The custom step receives the <code>Plan</code> object and     may install a custom run function to be executed later.</li> <li>Default Optimization and Custom Handlers: If no custom step     is run, or if the custom step does not install a custom run     function, the default optimization process is used. In this     case, multiple keyword arguments are allowed. Each keyword is     checked to see if a handler with the same name exists. If so,     the handler is installed.</li> <li>Callback Installation and Execution: Finally, any callbacks     added via <code>set_abort_callback</code> or <code>set_results_callback</code> are     installed, and the appropriate run function is executed.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>dict[str, Any] | EnOptConfig</code> <p>The configuration for the optimization.</p> required <code>evaluator</code> <code>Evaluator</code> <p>The evaluator object.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms.</p> <code>None</code> <code>constraint_tolerance</code> <code>float</code> <p>The constraint violation tolerance.</p> <code>1e-10</code> <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments.</p> <code>{}</code>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.run","title":"run","text":"<pre><code>run() -&gt; Self\n</code></pre> <p>Run the optimization process.</p> <p>This method initiates the optimization workflow defined by the <code>BasicOptimizer</code> object. It executes the underlying <code>Plan</code>, which manages the optimization steps, result handling, and event processing. After the optimization is complete, the optimal results, variables, and exit code can be accessed via the corresponding properties.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.set_abort_callback","title":"set_abort_callback","text":"<pre><code>set_abort_callback(callback: Callable[[], bool]) -&gt; Self\n</code></pre> <p>Set a callback to check for abort conditions.</p> <p>The provided callback function will be invoked repeatedly during the optimization process. If the callback returns <code>True</code>, the optimization will be aborted, and the <code>BasicOptimizer</code> will exit with an <code>OptimizerExitCode.USER_ABORT</code>.</p> <p>The callback function should have no arguments and return a boolean value.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[], bool]</code> <p>The callable to check for abort conditions.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/basic_optimizer/#ropt.plan.BasicOptimizer.set_results_callback","title":"set_results_callback","text":"<pre><code>set_results_callback(\n    callback: Callable[..., None],\n    *,\n    transformed: bool = False,\n) -&gt; Self\n</code></pre> <p>Set a callback to report new results.</p> <p>The provided callback function will be invoked whenever new results become available during the optimization process. This allows for real-time monitoring and analysis of the optimization's progress.</p> <p>The required signature of the callback function depends on the <code>transformed</code> parameter:</p> <ul> <li> <p>If <code>transformed</code> is <code>False</code> (default), the callback should accept a     single argument: a tuple of     <code>FunctionResults</code> objects. The     signature should be:</p> <pre><code>def callback(results: tuple[FunctionResults, ...]) -&gt; None:\n    ...\n</code></pre> </li> <li> <p>If <code>transformed</code> is <code>True</code>, the callback should accept two     arguments: a tuple of the original     <code>FunctionResults</code> objects and a     tuple of the transformed     <code>FunctionResults</code> objects. The     signature should be:</p> <pre><code>def callback(\n    results: tuple[FunctionResults, ...],\n    transformed_results: tuple[FunctionResults, ...],\n) -&gt; None:\n    ...\n</code></pre> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[..., None]</code> <p>The callable that will be invoked to report new results.</p> required <code>transformed</code> <code>bool</code> <p>If <code>True</code>, also pass the transformed results to the callback.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The <code>BasicOptimizer</code> instance, allowing for method chaining.</p>"},{"location":"reference/default_function_estimator_plugin/","title":"Default Function Estimator Plugin","text":""},{"location":"reference/default_function_estimator_plugin/#ropt.plugins.function_estimator.default.DefaultFunctionEstimator","title":"ropt.plugins.function_estimator.default.DefaultFunctionEstimator","text":"<p>               Bases: <code>FunctionEstimatorPlugin</code></p> <p>The default function estimator plugin.</p> <p>This plugin currently implements two methods:</p> <code>mean</code>: Calculate the combined functions as a weighted mean of the function    values of each realization. Gradients are accordingly calculated as    a weighted sum. <code>stddev</code>: Calculate the combined functions as the standard deviation of function    values of each realization. Gradients are calculated accordingly using    the chain rule. The sign of the result is adjusted such that the standard    deviation is always minimized."},{"location":"reference/default_plan_plugin/","title":"Default Plan Plugin","text":""},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultPlanStepPlugin","title":"ropt.plugins.plan.default.DefaultPlanStepPlugin","text":"<p>               Bases: <code>PlanStepPlugin</code></p> <p>The default plan plugin class.</p> <p>This class provides a number of steps:</p> <code>Steps</code>: <ul> <li>A step that performs a single ensemble evaluation (<code>evaluator</code>).</li> </ul> <ul> <li>A step that runs an optimization (<code>optimizer</code>).</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.default.DefaultPlanHandlerPlugin","title":"ropt.plugins.plan.default.DefaultPlanHandlerPlugin","text":"<p>               Bases: <code>PlanHandlerPlugin</code></p> <p>The default plan plugin class.</p> <p>This class provides a number of result handlers:</p> <code>Result Handlers</code>: <ul> <li>A handler that tracks optimal results (<code>tracker</code>).</li> </ul>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep","title":"ropt.plugins.plan.evaluator.DefaultEvaluatorStep","text":"<p>               Bases: <code>PlanStep</code></p> <p>The default evaluator step.</p> <p>This step performs a single ensemble evaluation, yielding one or more <code>FunctionResults</code> objects. The evaluation can process multiple variable vectors, each of which is evaluated separately, producing an individual results object for each vector.</p> <p>Before executing the evaluator step, a <code>START_EVALUATOR_STEP</code> event is emitted. After the evaluator step finishes, an <code>FINISHED_EVALUATOR_STEP</code> event is emitted. Result handlers should respond to the latter event to process the generated results.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize a default evaluator step.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan that runs this step.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep.run","title":"run","text":"<pre><code>run(\n    config: Any,\n    transforms: OptModelTransforms | None = None,\n    variables: ArrayLike | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; OptimizerExitCode\n</code></pre> <p>Run the evaluator step.</p> <p>The <code>DefaultEvaluatorStep</code> requires an optimizer configuration; the <code>variables</code> parameter is optional. The configuration  object must be an <code>EnOptConfig</code> object, or a dictionary that can be parsed into such an object. If no <code>variables</code> are provided, the initial values specified by the optimizer configuration are used. If <code>values</code> is given, it may be a single vector or a two-dimensional array. In the latter case, each row of the matrix is treated as a separate set of values to be evaluated.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>The optimizer configuration.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms object.</p> <code>None</code> <code>variables</code> <code>ArrayLike | None</code> <p>Variables to evaluate.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata to add to events.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.evaluator.DefaultEvaluatorStep.emit_event","title":"emit_event","text":"<pre><code>emit_event(event: Event) -&gt; None\n</code></pre> <p>Emit an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep","title":"ropt.plugins.plan.optimizer.DefaultOptimizerStep","text":"<p>               Bases: <code>PlanStep</code></p> <p>The default optimizer step.</p> <p>The optimizer step performs an optimization, yielding a sequence of <code>FunctionResults</code> and <code>GradientResults</code> objects. The optimizer is configured using an <code>EnOptConfig</code> object or a dictionary that can be parsed into such an object. While the initial values for optimization are typically specified in the configuration, they can be overridden by providing them directly.</p> <p>The optimizer step emits several signals:</p> <ul> <li><code>START_OPTIMIZER_STEP</code>:   Emitted before the optimization starts.</li> <li><code>FINISHED_OPTIMIZER_STEP</code>:   Emitted after the optimization finishes.</li> <li><code>START_EVALUATION</code>: Emitted   before a function or gradient evaluation.</li> <li><code>FINISHED_EVALUATION</code>: Emitted   after a function or gradient evaluation.</li> </ul> <p>The <code>FINISHED_EVALUATION</code> signal is particularly important as it passes   the generated <code>Results</code> objects. Result handlers   specified in the plan will respond to this signal to process those results.</p> <p>The optimizer step supports nested optimizations, where each function evaluation in the optimization calls a function that should run the nested optimization and produce the result for the function evaluation.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize a default optimizer step.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan that runs this step.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.run","title":"run","text":"<pre><code>run(\n    config: dict[str, Any] | EnOptConfig,\n    transforms: OptModelTransforms | None = None,\n    variables: ArrayLike | None = None,\n    nested_optimization: Plan | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; OptimizerExitCode\n</code></pre> <p>Run the optimizer step.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any] | EnOptConfig</code> <p>The optimizer configuration.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms object.</p> <code>None</code> <code>variables</code> <code>ArrayLike | None</code> <p>Variables to evaluate.</p> <code>None</code> <code>nested_optimization</code> <code>Plan | None</code> <p>Optional nested plan.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata to add to events.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan.optimizer.DefaultOptimizerStep.emit_event","title":"emit_event","text":"<pre><code>emit_event(event: Event) -&gt; None\n</code></pre> <p>Emit an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit.</p> required"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler","title":"ropt.plugins.plan._tracker.DefaultTrackerHandler","text":"<p>               Bases: <code>ResultHandler</code></p> <p>The default tracker results handler object.</p> <p>This handler tracks the <code>Results</code> objects that it receives and selects one to retain in a variable. Currently it tracks either the last result it receives, or the best result. The best result is defined as the result that has the lowest weighted objective value. Optionally, results may be filtered by checking for violations of constraints, by comparing constraint values to a threshold.</p>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler.__init__","title":"__init__","text":"<pre><code>__init__(\n    plan: Plan,\n    *,\n    what: Literal[\"best\", \"last\"] = \"best\",\n    constraint_tolerance: float | None = None,\n    sources: set[UUID] | None = None,\n) -&gt; None\n</code></pre> <p>Initialize a default tracker results handler.</p> <p>This handler monitors <code>Results</code> objects from specified sources and selects a single result to retain based on the specified criteria. It can track either the best result encountered so far or the most recent result. The \"best\" result is determined by the lowest weighted objective value.</p> <p>Results can optionally be filtered based on constraint violations. If a <code>constraint_tolerance</code> is provided, results that violate constraints beyond this tolerance will be discarded and not tracked.</p> <p>The <code>sources</code> parameter allows you to specify which steps' results should be tracked. Only results from steps whose IDs are included in this set will be considered.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The plan this handler is part of.</p> required <code>what</code> <code>Literal['best', 'last']</code> <p>Specifies whether to track the \"best\" or \"last\" result.</p> <code>'best'</code> <code>constraint_tolerance</code> <code>float | None</code> <p>Constraint tolerance for filtering results.</p> <code>None</code> <code>sources</code> <code>set[UUID] | None</code> <p>A set of UUIDs of steps whose results to track.</p> <code>None</code>"},{"location":"reference/default_plan_plugin/#ropt.plugins.plan._tracker.DefaultTrackerHandler.handle_event","title":"handle_event","text":"<pre><code>handle_event(event: Event) -&gt; None\n</code></pre> <p>Handle an event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to handle.</p> required"},{"location":"reference/default_realization_filter_plugin/","title":"Default Realization Filter Plugin","text":""},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.DefaultRealizationFilter","title":"ropt.plugins.realization_filter.default.DefaultRealizationFilter","text":"<p>               Bases: <code>RealizationFilterPlugin</code></p> <p>The default realization filter plugin class.</p> <p>This plugin currently implements four methods:</p> <code>sort-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>SortObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects the set of realizations from a given index range. <code>sort-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>SortConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects the set of    realizations from a given index range. <code>cvar-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>CVaRObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects a percentile of the realizations, applying interpolation whenever    the number of selected realizations is not an integer number. <code>cvar-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>CVaRConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects a    percentile of the realizations, applying interpolation whenever the    number of selected realizations is not an integer number."},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.SortObjectiveOptions","title":"ropt.plugins.realization_filter.default.SortObjectiveOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-objective</code> method.</p> <p>The <code>sort-objective</code> method sorts realizations according to the value of one or multiple objectives, and retains a number of realizations within a given index range in the sorted list. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>list[NonNegativeInt]</code> <p>The indices of the objectives to sort.</p> <code>first</code> <code>NonNegativeInt</code> <p>Index or name of the first realization to use.</p> <code>last</code> <code>NonNegativeInt</code> <p>Index of name of the last realization to use.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.SortConstraintOptions","title":"ropt.plugins.realization_filter.default.SortConstraintOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-constraint</code> method.</p> <p>The <code>sort-constraint</code> method sorts realizations according to the value of a constraint, and retains a number of realizations within a given index range in the sorted list.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>NonNegativeInt</code> <p>The index of the constraint to sort.</p> <code>first</code> <code>NonNegativeInt</code> <p>Index or name of the first realization to use.</p> <code>last</code> <code>NonNegativeInt</code> <p>Index or name of the last realization to use.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.CVaRObjectiveOptions","title":"ropt.plugins.realization_filter.default.CVaRObjectiveOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-objective</code> method.</p> <p>The <code>cvar-objective</code> method finds realizations weights by applying the CVaR method to the objective values. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. \"Worst\" is defined as those realizations having the highest values in case of a minimization and those having the lowest values in case of maximizing.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>list[NonNegativeInt]</code> <p>The indices of the objectives to sort.</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile.</p>"},{"location":"reference/default_realization_filter_plugin/#ropt.plugins.realization_filter.default.CVaRConstraintOptions","title":"ropt.plugins.realization_filter.default.CVaRConstraintOptions","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-constraint</code> method.</p> <p>The <code>cvar-constraint</code> method finds realizations weights by applying the CVaR method to the objective values.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. The definition of worst depends on the type of the constraints. After subtracting the right-hand-side value the following applies:</p> <ul> <li>For LE constraints, realizations with the largest values are the worst</li> <li>For GE constraints, realizations with the smallest values are the worst</li> <li>For EQ constraints, realizations with the largest absolute values are the worst</li> </ul> <p>Attributes:</p> Name Type Description <code>sort</code> <code>NonNegativeInt</code> <p>The index of the constraint to sort.</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile.</p>"},{"location":"reference/domain_transforms/","title":"Domain transforms","text":""},{"location":"reference/domain_transforms/#ropt.transforms","title":"ropt.transforms","text":"<p>Domain Transformation Framework.</p> <p>This module provides a flexible framework for transforming optimization variables, objectives, and constraints between user-defined domains and the domains used internally by the optimizer. These transformations are essential for:</p> <ul> <li>Improving Optimizer Performance: Scaling, shifting, and other   transformations can significantly enhance the efficiency, stability, and   convergence of optimization algorithms.</li> <li>Implementing Custom Mappings:  Beyond simple scaling, this framework   supports complex, user-defined mappings between domains, allowing for   tailored problem representations.</li> <li>Handling Diverse Units and Scales: Transformations enable the optimizer   to work with variables and functions that may have vastly different units   or scales, improving numerical stability.</li> </ul> <p>Key Components:</p> <ul> <li>Abstract Base Classes: Transform classes derive from abstract base classes   that define the specific mapping logic between domains.<ul> <li><code>VariableTransform</code>:   Defines the interface for transforming variables between user and   optimizer domains.</li> <li><code>ObjectiveTransform</code>:   Defines the interface for transforming objective values between user   and optimizer domains.</li> <li><code>NonLinearConstraintTransform</code>:   Defines the interface for transforming non-linear constraint values   between user and optimizer domains.</li> </ul> </li> <li><code>OptModelTransforms</code>:   A container class for conveniently grouping and   passing multiple transformation objects (variable, objective, and   nonlinear constraint).</li> </ul> <p>Workflow and Integration:</p> <ol> <li>Configuration: Transformation objects are passed to the     <code>EnOptConfig</code> during configuration     validation, using an     <code>OptModelTransforms</code> instance. This     ensures that the entire optimization process is aware of and configured for     the transformed space.</li> <li>Optimization Plan: The same transformation objects are passed to the     relevant optimization steps within the <code>Plan</code>. (See, for     example, the default implementation of an optimizer step in     <code>DefaultOptimizerStep.run</code>).</li> <li>Evaluation: When the optimizer requests an evaluation of a variable     vector, the following occurs:<ul> <li>Transformation to the User Domain: The variable vector is      transformed from the optimizer       domain back to the user domain using the <code>from_optimizer</code> method of       the <code>VariableTransform</code>.</li> <li>Function Evaluation: Objective and constraint values are calculated       in the user domain.</li> <li>Transformation to the Optimizer Domain: The resulting objective and      constraint values are       transformed to the optimizer domain using the <code>to_optimizer</code> methods       of the <code>ObjectiveTransform</code> and <code>NonLinearConstraintTransform</code>.</li> </ul> </li> <li>Optimization: The optimizer proceeds using the transformed values.</li> <li>Results: The <code>Results</code> objects produced during     optimization hold values in the optimizer domain. To obtain results in the     user domain, the     <code>transform_from_optimizer</code>     method is used to create new <code>Results</code> objects with the transformed values.     For example,     <code>DefaultOptimizerStep.run</code>     emits events that include a dictionary with <code>\"results\"</code> and     <code>\"transformed_results\"</code> keys. The <code>\"results\"</code> key contains <code>Results</code> objects     in the user domain, while <code>\"transformed_results\"</code> contains the original     <code>Results</code> objects in the optimizer domain.</li> </ol> <p>Provided Classes:</p> <ul> <li><code>OptModelTransforms</code>: A data   class for conveniently grouping and passing multiple transformation   objects.</li> <li><code>VariableScaler</code>: A concrete   implementation of <code>VariableTransform</code> that performs linear scaling and   shifting.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms","title":"ropt.transforms.OptModelTransforms  <code>dataclass</code>","text":"<p>A container for optimization model transformers.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.variables","title":"variables  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>variables: VariableTransform | None = None\n</code></pre> <p>A <code>VariableTransform</code> object that defines the transformation for variables.</p> <p>If <code>None</code>, no transformation is applied to variables.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.objectives","title":"objectives  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>objectives: ObjectiveTransform | None = None\n</code></pre> <p>An <code>ObjectiveTransform</code> object that defines the transformation for objectives.</p> <p>If <code>None</code>, no transformation is applied to objectives.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.OptModelTransforms.nonlinear_constraints","title":"nonlinear_constraints  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>nonlinear_constraints: (\n    NonLinearConstraintTransform | None\n) = None\n</code></pre> <p>A <code>NonLinearConstraintTransform</code> object that defines the transformation for nonlinear constraints.</p> <p>If <code>None</code>, no transformation is applied to nonlinear constraints.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform","title":"ropt.transforms.base.VariableTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for variable transformations.</p> <p>This class defines the interface for transforming variables between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of transformation.</p> <p>When implementing a variable transformation, the following aspects must be considered:</p> <ul> <li>Variable Value Transformation: Mapping variable values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Perturbation Magnitude Transformation: Stochastic gradient-based   algorithms use perturbations with specified magnitudes (see   <code>perturbation_magnitudes</code>). These   magnitudes are typically defined in the user domain and must be   transformed to the optimizer domain using the   <code>magnitudes_to_optimizer</code>   method.</li> <li>Bound Constraint Difference Transformation: To report violations of   variable bounds, the differences between variable values and their   lower/upper bounds must be transformed from the optimizer domain back   to the user domain. This is done using the   <code>bound_constraint_diffs_from_optimizer</code>   method.</li> <li>Linear Constraint Transformation: Linear constraints are generally   defined by coefficients and right-hand-side values in the user domain.   These must be transformed to the optimizer domain using the   <code>linear_constraints_to_optimizer</code>   method.</li> <li>Linear Constraint Difference Transformation: To report violations of   linear constraints, the differences between the linear constraint   values and their right-hand-side values must be transformed back to the   user domain. This is done using the   <code>linear_constraints_diffs_from_optimizer</code>   method.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform values from the user domain to the optimizer domain.</p> <p>This method maps variable values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform values from the optimizer domain to the user domain.</p> <p>This method maps variable values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.magnitudes_to_optimizer","title":"magnitudes_to_optimizer  <code>abstractmethod</code>","text":"<pre><code>magnitudes_to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform perturbation magnitudes to the optimizer domain.</p> <p>This method transforms perturbation magnitudes, typically used in stochastic gradient-based algorithms, from the user-defined domain to the optimizer's internal domain. The transformation ensures that the perturbations are applied correctly in the optimizer's space, which may have different scaling or units than the user domain.</p> <p>For example, if variables are scaled down in the optimizer domain, the perturbation magnitudes should also be scaled down proportionally.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The perturbation magnitudes in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed perturbation magnitudes in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.bound_constraint_diffs_from_optimizer","title":"bound_constraint_diffs_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>bound_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform bound constraint differences to the user domain.</p> <p>This method transforms the differences between variable values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if variables are scaled in the optimizer domain, the differences between the variables and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their lower bounds in the optimizer domain.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their upper bounds in the optimizer domain.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.linear_constraints_to_optimizer","title":"linear_constraints_to_optimizer","text":"<pre><code>linear_constraints_to_optimizer(\n    coefficients: NDArray[float64],\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Transform linear constraints from the user domain to the optimizer domain.</p> <p>This method transforms linear constraints, defined by their coefficients and right-hand-side bounds, from the user-defined domain to the optimizer's internal domain. This is essential to maintain the validity of the constraints after variable transformations.</p> <p>For instance, if variables are scaled or shifted in the optimizer domain, the coefficients and bounds of the linear constraints must be adjusted accordingly to ensure the constraints remain consistent.</p> <p>The linear constraints are defined by the equation <code>A * x = b</code>, where <code>A</code> is the coefficient matrix, <code>x</code> is the variable vector, and <code>b</code> represents the right-hand-side bounds.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>NDArray[float64]</code> <p>The coefficient matrix.</p> required <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed coefficient matrix and bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.VariableTransform.linear_constraints_diffs_from_optimizer","title":"linear_constraints_diffs_from_optimizer","text":"<pre><code>linear_constraints_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform linear constraint differences to the user domain.</p> <p>This method transforms the differences between linear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if linear constraints are scaled in the optimizer domain, the differences between the constraint values and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform","title":"ropt.transforms.base.ObjectiveTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for objective transformations.</p> <p>This class defines the interface for transforming objective values between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of objective transformation.</p> <p>When implementing an objective transformation, the following aspects must be considered:</p> <ul> <li>Objective Value Transformation: Mapping objective values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Weighted Objective Transformation: The optimizer works with a   single, weighted objective value. If the transformation affects the   weighted objective, the   <code>weighted_objective_from_optimizer</code>   method should be overridden to handle this.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    objectives: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform objective values to the optimizer domain.</p> <p>This method maps objective values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>objectives</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the objective values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objective values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed objective values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    objectives: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform objective values to the user domain.</p> <p>This method maps objective values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>objectives</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the objective values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objective values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed objective values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.ObjectiveTransform.weighted_objective_from_optimizer","title":"weighted_objective_from_optimizer","text":"<pre><code>weighted_objective_from_optimizer(\n    weighted_objective: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform the weighted objective to the user domain.</p> <p>The optimizer uses a single, weighted objective value evaluated in the optimizer domain. This method reverses that transformation, mapping the weighted objective back to the user domain.</p> <p>For example, if the transformation to the optimizer domain involved a sign change to convert a maximization problem into a minimization problem, this method would change the sign back.</p> Note <p>This method may be applied to the weighted objective itself or to its gradient. Therefore, the input may be a scalar or a vector of values.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted objective value(s) to transform.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed weighted objective value(s).</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform","title":"ropt.transforms.base.NonLinearConstraintTransform","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for nonlinear constraint transformations.</p> <p>This class defines the interface for transforming nonlinear constraint values between the user-defined domain and the optimizer's internal domain. Concrete implementations of this class handle the specific logic for each type of nonlinear constraint transformation.</p> <p>When implementing a nonlinear constraint transformation, the following aspects must be considered:</p> <ul> <li>Constraint Value Transformation: Mapping constraint values between the   user and optimizer domains. This is achieved by overriding the   <code>to_optimizer</code>   and   <code>from_optimizer</code>   methods.</li> <li>Right-Hand-Side Bound Transformation: Mapping the right-hand-side   bounds of the constraints between the user and optimizer domains. This is   achieved by overriding the   <code>bounds_to_optimizer</code>   method.</li> <li>Constraint Difference Transformation: To report violations of   nonlinear constraints, the differences between constraint values and their   lower/upper bounds must be transformed from the optimizer domain back to   the user domain. This is done using the   <code>nonlinear_constraint_diffs_from_optimizer</code>   method.</li> </ul>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.to_optimizer","title":"to_optimizer  <code>abstractmethod</code>","text":"<pre><code>to_optimizer(\n    constraints: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform constraint values to the optimizer domain.</p> <p>This method maps nonlinear constraint values from the user-defined domain to the optimizer's internal domain. This transformation might involve scaling, shifting, or other operations to improve the optimizer's performance.</p> <p>The input <code>constraints</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the constraint values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>constraints</code> <code>NDArray[float64]</code> <p>The nonlinear constraint values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed nonlinear constraint values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.from_optimizer","title":"from_optimizer  <code>abstractmethod</code>","text":"<pre><code>from_optimizer(\n    constraints: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform constraint values to the user domain.</p> <p>This method maps nonlinear constraint values from the optimizer's internal domain back to the user-defined domain. This transformation reverses any scaling, shifting, or other operations that were applied to improve the optimizer's performance.</p> <p>The input <code>constraints</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the constraint values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>constraints</code> <code>NDArray[float64]</code> <p>The nonlinear constraint values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed nonlinear constraint values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.bounds_to_optimizer","title":"bounds_to_optimizer  <code>abstractmethod</code>","text":"<pre><code>bounds_to_optimizer(\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform the right-hand-side bounds to the optimizer domain.</p> <p>This method transforms the lower and upper bounds of the nonlinear constraints from the user-defined domain to the optimizer's internal domain. This transformation is necessary to ensure that the constraints remain valid after the variables have been transformed.</p> <p>For example, if constraint values are scaled or shifted in the optimizer domain, the bounds must be adjusted accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values in the user domain.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values in the user domain.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.base.NonLinearConstraintTransform.nonlinear_constraint_diffs_from_optimizer","title":"nonlinear_constraint_diffs_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>nonlinear_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform nonlinear constraint differences to the user domain.</p> <p>This method transforms the differences between nonlinear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if constraint values are scaled in the optimizer domain, the differences between the constraint values and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the nonlinear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the nonlinear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler","title":"ropt.transforms.VariableScaler","text":"<p>               Bases: <code>VariableTransform</code></p> <p>Linearly scales and shifts variables between domains.</p> <p>This class implements a linear transformation for variables, allowing for scaling and shifting between the user-defined domain and the optimizer's internal domain. The transformation is defined by a scaling factor and an offset for each variable.</p> <p>The transformation from the user domain to the optimizer domain is given by:</p> \\[x_{opt} = \\frac{(x_{\\textrm{user}} - \\textrm{offset})}{\\textrm{scale}}\\] <p>The transformation from the optimizer domain back to the user domain is:</p> \\[x_{user} = x_{\\textrm{opt}} * {\\textrm{scale}} + {\\textrm{offset}}\\] <p>This transformation can be used to improve the performance of the optimizer by working with variables that are scaled to a more suitable range or centered around a specific value.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.__init__","title":"__init__","text":"<pre><code>__init__(\n    scales: NDArray[float64] | None,\n    offsets: NDArray[float64] | None,\n) -&gt; None\n</code></pre> <p>Initialize the variable scaler.</p> <p>This scaler applies a linear transformation to variables, defined by scaling factors and offset values.</p> <p>If both <code>scales</code> and <code>offsets</code> are provided, they are broadcasted to ensure they have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>scales</code> <code>NDArray[float64] | None</code> <p>The scaling factors for each variable.</p> required <code>offsets</code> <code>NDArray[float64] | None</code> <p>The offset values for each variable.</p> required"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.to_optimizer","title":"to_optimizer","text":"<pre><code>to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform variable values to the optimizer domain.</p> <p>This method applies the linear scaling and offset transformation to variable values, mapping them from the user-defined domain to the optimizer's internal domain.</p> <p>The transformation is defined as: <code>x_opt = (x_user - offset) / scale</code>.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the user domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.from_optimizer","title":"from_optimizer","text":"<pre><code>from_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform variable values to the user domain.</p> <p>This method applies the inverse linear scaling and offset transformation to variable values, mapping them from the optimizer's internal domain back to the user-defined domain.</p> <p>The transformation is defined as: <code>x_user = x_opt * scale + offset</code>.</p> <p>The input <code>values</code> may be a multi-dimensional array. It is assumed that the last axis of the array represents the variable values. If this is not the case, you must adjust the order of the axes before and after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The variable values in the optimizer domain to be transformed.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed variable values in the user domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.magnitudes_to_optimizer","title":"magnitudes_to_optimizer","text":"<pre><code>magnitudes_to_optimizer(\n    values: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Transform perturbation magnitudes to the optimizer domain.</p> <p>This method transforms perturbation magnitudes, typically used in stochastic gradient-based algorithms, from the user-defined domain to the optimizer's internal domain. The transformation ensures that the perturbations are applied correctly in the optimizer's space, which may have different scaling or units than the user domain.</p> <p>The transformation is defined as: <code>x_opt = x_user / scale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The perturbation magnitudes in the user domain.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The transformed perturbation magnitudes in the optimizer domain.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.linear_constraints_to_optimizer","title":"linear_constraints_to_optimizer","text":"<pre><code>linear_constraints_to_optimizer(\n    coefficients: NDArray[float64],\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Transform linear constraints to the optimizer domain.</p> <p>This method transforms linear constraints, defined by their coefficients and right-hand-side bounds, from the user-defined domain to the optimizer's internal domain. This transformation accounts for the scaling and shifting applied to the variables and ensures that the constraints remain valid in the optimizer's space.</p> <p>The set of linear constraints can be represented by a matrix equation: \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\).</p> <p>When linearly transforming variables to the optimizer domain, the coefficients (\\(\\mathbf{A}\\)) and right-hand-side values (\\(\\mathbf{b}\\)) must be converted to remain valid. If the linear transformation of the variables to the optimizer domain is given by:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{S} \\mathbf{x} + \\mathbf{o}\\] <p>then the coefficients and right-hand-side values must be transformed as follows:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A} \\mathbf{S}^{-1} \\\\ \\hat{\\mathbf{b}}     &amp;= \\mathbf{b} + \\mathbf{A}\\mathbf{S}^{-1}\\mathbf{o} \\end{align}\\] <p>where \\(S\\) is a diagonal matrix with scaling factors on the diagonal and \\(o\\) are the offsets.</p> <p>The resulting equations are further scaled by dividing them by maximum of the absolute values of the coefficients in each equation.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>NDArray[float64]</code> <p>The coefficient matrix of the linear constraints.</p> required <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right-hand-side values.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right-hand-side values.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed coefficient matrix and bounds.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.bound_constraint_diffs_from_optimizer","title":"bound_constraint_diffs_from_optimizer","text":"<pre><code>bound_constraint_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform bound constraint differences to the user domain.</p> <p>This method transforms the differences between variable values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>For example, if variables are scaled in the optimizer domain, the differences between the variables and their bounds must be scaled back to the user domain to accurately reflect the constraint violations in the user's original units.</p> <p>The transformation is defined as: <code>x_user = x_opt * scale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the variable values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/domain_transforms/#ropt.transforms.VariableScaler.linear_constraints_diffs_from_optimizer","title":"linear_constraints_diffs_from_optimizer","text":"<pre><code>linear_constraints_diffs_from_optimizer(\n    lower_diffs: NDArray[float64],\n    upper_diffs: NDArray[float64],\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>Transform linear constraint differences to the user domain.</p> <p>This method transforms the differences between linear constraint values and their lower/upper bounds from the optimizer's internal domain back to the user-defined domain. These differences are used to report constraint violations.</p> <p>This is implemented by re-scaling the equations with the weights that were determined and stored by the <code>linear_constraints_to_optimizer</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>lower_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their lower bounds.</p> required <code>upper_diffs</code> <code>NDArray[float64]</code> <p>The differences between the linear constraint values and their upper bounds.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple containing the transformed lower and upper differences.</p>"},{"location":"reference/enopt_config/","title":"Configuration","text":""},{"location":"reference/enopt_config/#ropt.config.enopt","title":"ropt.config.enopt","text":"<p>The <code>ropt.config.enopt</code> module provides configuration classes for optimization workflows.</p> <p>This module defines a set of classes that are used to configure various aspects of an optimization process, including variables, objectives, constraints, realizations, samplers, and more.</p> <p>The central configuration class is <code>EnOptConfig</code>, which encapsulates the complete configuration for a single optimization step. It is designed to be flexible and extensible, allowing users to customize the optimization process to their specific needs.</p> <p>These configuration classes are built using <code>pydantic</code>, which provides robust data validation and parsing capabilities. This ensures that the configuration data is consistent and adheres to the expected structure.</p> <p>Configuration objects are typically created from dictionaries of configuration values using the <code>model_validate</code> method provided by <code>pydantic</code>.</p> <p>Key Features:</p> <ul> <li>Modular Design: The configuration is broken down into smaller, manageable   components, each represented by a dedicated class.</li> <li>Validation: <code>pydantic</code> ensures that the configuration data is valid and   consistent.</li> <li>Extensibility: The modular design allows for easy extension and   customization of the optimization process.</li> <li>Centralized Configuration: The   <code>EnOptConfig</code> class provides a single point   of entry for configuring an optimization step.</li> <li>Domain Transformations:  The optimization process supports domain   transformations, as detailed in the <code>ropt.transforms</code>   module. These transformations map variables, objectives, and constraints   between the user-defined domain and the domain used by the optimizer. This   capability is valuable for operations such as scaling, shifting, or other   adjustments that can enhance the performance and stability of the optimization   algorithm. Domain transformations are implemented through a set of classes   that define the necessary mappings. When creating an <code>EnOptConfig</code> object,   transformation objects can be provided to automatically apply these   transformations during configuration validation.</li> </ul> <p>Parsing and Validation</p> <p>The configuration classes are built using <code>pydantic</code>, which provides robust data validation. The primary configuration class is <code>EnOptConfig</code>, and it contains nested configuration classes for various aspects of the optimization. To parse a configuration from a dictionary, use the <code>model_validate</code> class method:</p> <pre><code>from ropt.config.enopt import EnOptConfig\n\nconfig_dict = {\n    \"variables\": {\n        \"initial_values\": [10.0, 10.0],\n    }\n}\nconfig = EnOptConfig.model_validate(config_dict)\nconfig.variables.initial_values  # [10.0, 10.0]\n</code></pre> <p>Domain transformation objects from the <code>ropt.transforms</code> module can be passed to the <code>model_validate</code> method via the <code>context</code> parameter:</p> <pre><code>from ropt.config.enopt import EnOptConfig\nfrom ropt.transforms import OptModelTransforms, VariableScaler\n\nconfig_dict = {\n    \"variables\": {\n        \"initial_values\": [10.0, 10.0],\n    }\n}\nscaler = VariableScaler([10.0, 5.0], None)\nconfig = EnOptConfig.model_validate(\n    config_dict, context=OptModelTransforms(variables=scaler)\n)\nconfig.variables.initial_values  # [1.0, 2.0]\n</code></pre> <p>Classes:</p> <ul> <li><code>EnOptConfig</code>: The main configuration class   for an optimization step.</li> <li><code>VariablesConfig</code>: Configuration for   variables.</li> <li><code>ObjectiveFunctionsConfig</code>:   Configuration for objective functions.</li> <li><code>LinearConstraintsConfig</code>:   Configuration for linear constraints.</li> <li><code>NonlinearConstraintsConfig</code>:   Configuration for non-linear constraints.</li> <li><code>RealizationsConfig</code>: Configuration   for realizations.</li> <li><code>OptimizerConfig</code>: Configuration for the   optimizer.</li> <li><code>GradientConfig</code>: Configuration for   gradient calculations.</li> <li><code>FunctionEstimatorConfig</code>:   Configuration for function estimators.</li> <li><code>RealizationFilterConfig</code>:   Configuration for realization filters.</li> <li><code>SamplerConfig</code>: Configuration for   samplers.</li> </ul>"},{"location":"reference/enopt_config/#ropt.config.enopt.EnOptConfig","title":"EnOptConfig","text":"<p>The primary configuration class for an optimization step.</p> <p><code>EnOptConfig</code> orchestrates the configuration of an entire optimization workflow. It contains nested configuration classes that define specific aspects of the optimization, such as variables, objectives, constraints, realizations, and the optimizer itself.</p> <p><code>realization_filters</code>, <code>function_estimators</code>, and <code>samplers</code> are configured as tuples. Other configuration fields reference these objects by their index within the tuples. For example, <code>GradientConfig</code> uses a <code>samplers</code> field, which is an array of indices specifying the sampler to use for each variable.</p> Info <p>Many nested configuration classes use <code>numpy</code> arrays. These arrays typically have a size determined by a configured property (e.g., the number of variables) or a size of one. In the latter case, the single value is broadcasted to all relevant elements. For example, <code>VariablesConfig</code> defines properties like initial values and bounds as <code>numpy</code> arrays, which must either match the number of variables or have a size of one.</p> <p>Attributes:</p> Name Type Description <code>variables</code> <code>VariablesConfig</code> <p>Configuration for the optimization variables.</p> <code>objectives</code> <code>ObjectiveFunctionsConfig</code> <p>Configuration for the objective functions.</p> <code>linear_constraints</code> <code>LinearConstraintsConfig | None</code> <p>Configuration for linear constraints.</p> <code>nonlinear_constraints</code> <code>NonlinearConstraintsConfig | None</code> <p>Configuration for non-linear constraints.</p> <code>realizations</code> <code>RealizationsConfig</code> <p>Configuration for the realizations.</p> <code>optimizer</code> <code>OptimizerConfig</code> <p>Configuration for the optimization algorithm.</p> <code>gradient</code> <code>GradientConfig</code> <p>Configuration for gradient calculations.</p> <code>realization_filters</code> <code>tuple[RealizationFilterConfig, ...]</code> <p>Configuration for realization filters.</p> <code>function_estimators</code> <code>tuple[FunctionEstimatorConfig, ...]</code> <p>Configuration for function estimators.</p> <code>samplers</code> <code>tuple[SamplerConfig, ...]</code> <p>Configuration for samplers.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.VariablesConfig","title":"VariablesConfig","text":"<p>Configuration class for optimization variables.</p> <p>This class, <code>VariablesConfig</code>, defines the configuration for the optimization variables used in an <code>EnOptConfig</code> object. It specifies the initial values, bounds, types, and an optional mask for the variables.</p> <p>The <code>initial_values</code> field is a required <code>numpy</code> array that sets the starting values for the variables. The number of variables is determined by the length of this array.</p> <p>The <code>lower_bounds</code> and <code>upper_bounds</code> fields define the bounds for each variable. These are also <code>numpy</code> arrays and are broadcasted to match the number of variables. By default, they are set to negative and positive infinity, respectively. <code>numpy.nan</code> values in these arrays indicate unbounded variables and are converted to <code>numpy.inf</code> with the appropriate sign.</p> <p>The optional <code>types</code> field allows assigning a <code>VariableType</code> to each variable. If not provided, all variables are assumed to be continuous real-valued (<code>VariableType.REAL</code>).</p> <p>The optional <code>mask</code> field is a boolean <code>numpy</code> array that indicates which variables are free to change during optimization. <code>True</code> values in the mask indicate that the corresponding variable is free, while <code>False</code> indicates a fixed variable.</p> <p>Attributes:</p> Name Type Description <code>types</code> <code>ArrayEnum | None</code> <p>Optional variable types.</p> <code>initial_values</code> <code>Array1D</code> <p>Initial values for the variables.</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the variables (default: \\(-\\infty\\)).</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the variables (default: \\(+\\infty\\)).</p> <code>mask</code> <code>Array1DBool | None</code> <p>Optional boolean mask indicating free variables.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.ObjectiveFunctionsConfig","title":"ObjectiveFunctionsConfig","text":"<p>Configuration class for objective functions.</p> <p>This class, <code>ObjectiveFunctionsConfig</code>, defines the configuration for objective functions used in an <code>EnOptConfig</code> object.</p> <p><code>ropt</code> supports multi-objective optimization. Multiple objectives are combined into a single value by summing them after weighting. The <code>weights</code> field, a <code>numpy</code> array, determines the weight of each objective function. The length of this array defines the number of objective functions. The weights are automatically normalized to sum to 1 (e.g., <code>[1, 1]</code> becomes <code>[0.5, 0.5]</code>).</p> <p>Objective functions can be processed by realization filters and function estimators. The <code>realization_filters</code> and <code>function_estimators</code> fields contain indices that refer to the corresponding configuration objects in the parent <code>EnOptConfig</code> object.</p> <p>Attributes:</p> Name Type Description <code>weights</code> <code>Array1D</code> <p>Weights for the objective functions (default: 1.0).</p> <code>realization_filters</code> <code>Array1DInt | None</code> <p>Optional indices of realization filters.</p> <code>function_estimators</code> <code>Array1DInt | None</code> <p>Optional indices of function estimators.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.LinearConstraintsConfig","title":"LinearConstraintsConfig","text":"<p>Configuration class for linear constraints.</p> <p>This class, <code>LinearConstraintsConfig</code>, defines linear constraints used in an <code>EnOptConfig</code> object.</p> <p>Linear constraints are defined by a set of linear equations involving the optimization variables. These equations can represent equality or inequality constraints. The <code>coefficients</code> field is a 2D <code>numpy</code> array where each row represents a constraint, and each column corresponds to a variable.</p> <p>The <code>lower_bounds</code> and <code>upper_bounds</code> fields specify the bounds on the right-hand side of each constraint equation. These fields are converted and broadcasted to <code>numpy</code> arrays with a length equal to the number of constraint equations.</p> <p>Less-than and greater-than inequality constraints can be specified by setting the lower bounds to \\(-\\infty\\), or the upper bounds to \\(+\\infty\\), respectively. Equality constraints are specified by setting the lower bounds equal to the upper bounds.</p> <p>Attributes:</p> Name Type Description <code>coefficients</code> <code>Array2D</code> <p>Matrix of coefficients for the linear constraints.</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the right-hand side of the constraint equations.</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the right-hand side of the constraint equations.</p> Linear transformation of variables. <p>The set of linear constraints can be represented by a matrix equation: \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\).</p> <p>When linearly transforming variables to the optimizer domain, the coefficients (\\(\\mathbf{A}\\)) and right-hand-side values (\\(\\mathbf{b}\\)) must be converted to remain valid. If the linear transformation of the variables to the optimizer domain is given by:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{S} \\mathbf{x} + \\mathbf{o}\\] <p>then the coefficients and right-hand-side values must be transformed as follows:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A} \\mathbf{S}^{-1} \\\\ \\hat{\\mathbf{b}}     &amp;= \\mathbf{b} + \\mathbf{A}\\mathbf{S}^{-1}\\mathbf{o} \\end{align}\\]"},{"location":"reference/enopt_config/#ropt.config.enopt.NonlinearConstraintsConfig","title":"NonlinearConstraintsConfig","text":"<p>Configuration class for non-linear constraints.</p> <p>This class, <code>NonlinearConstraintsConfig</code>, defines non-linear constraints used in an <code>EnOptConfig</code> object.</p> <p>Non-linear constraints are defined by comparing a constraint function to a right-hand-side value, allowing for equality or inequality constraints. The <code>lower_bounds</code> and <code>upper_bounds</code> fields, which are <code>numpy</code> arrays, specify the bounds on these right-hand-side values. The length of these arrays determines the number of constraint functions.</p> <p>Less-than and greater-than inequality constraints can be specified by setting the lower bounds to \\(-\\infty\\), or the upper bounds to \\(+\\infty\\), respectively. Equality constraints are specified by setting the lower bounds equal to the upper bounds.</p> <p>Non-linear constraints can be processed by realization filters and function estimators. The <code>realization_filters</code> and <code>function_estimators</code> fields contain indices that refer to the corresponding objects configured in the parent <code>EnOptConfig</code> object.</p> <p>Attributes:</p> Name Type Description <code>lower_bounds</code> <code>Array1D</code> <p>Lower bounds for the right-hand-side values.</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bounds for the right-hand-side values.</p> <code>realization_filters</code> <code>Array1DInt | None</code> <p>Optional indices of realization filters.</p> <code>function_estimators</code> <code>Array1DInt | None</code> <p>Optional indices of function estimators.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationsConfig","title":"RealizationsConfig","text":"<p>Configuration class for realizations.</p> <p>This class, <code>RealizationsConfig</code>, defines the configuration for realizations used in an <code>EnOptConfig</code> object.</p> <p>To optimize an ensemble of functions, a set of realizations is defined. When the optimizer requests a function value or a gradient, these are calculated for each realization and then combined into a single value. Typically, this combination is a weighted sum, but other methods are possible.</p> <p>The <code>weights</code> field, a <code>numpy</code> array, determines the weight of each realization. The length of this array defines the number of realizations. The weights are automatically normalized to sum to 1 (e.g., <code>[1, 1]</code> becomes <code>[0.5, 0.5]</code>).</p> <p>If function value calculations for some realizations fail (e.g., due to a simulation error), the total function and gradient values can still be calculated by excluding the missing values. However, a minimum number of successful realizations may be required. The <code>realization_min_success</code> field specifies this minimum. By default, it is set equal to the number of realizations, meaning no missing values are allowed.</p> Note <p>Setting <code>realization_min_success</code> to zero allows the optimization to proceed even if all realizations fail. While some optimizers can handle this, most will treat it as if the value were one, requiring at least one successful realization.</p> <p>Attributes:</p> Name Type Description <code>weights</code> <code>Array1D</code> <p>Weights for the realizations (default: 1.0).</p> <code>realization_min_success</code> <code>NonNegativeInt | None</code> <p>Minimum number of successful realizations (default:                     equal to the number of realizations).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.OptimizerConfig","title":"OptimizerConfig","text":"<p>Configuration class for the optimization algorithm.</p> <p>This class, <code>OptimizerConfig</code>, defines the configuration for the optimization algorithm used in an <code>EnOptConfig</code> object.</p> <p>While optimization methods can have diverse parameters, this class provides a standardized set of settings that are commonly used and forwarded to the optimizer:</p> <ul> <li><code>max_iterations</code>: The maximum number of iterations allowed. The   optimizer may choose to ignore this.</li> <li><code>max_functions</code>: The maximum number of function evaluations allowed.</li> <li><code>tolerance</code>: The convergence tolerance used as a stopping criterion.   The exact definition depends on the optimizer, and it may be ignored.</li> <li><code>speculative</code>: If <code>True</code>, forces early gradient evaluations, even if   not strictly required. This can improve load balancing on HPC clusters but   is only effective if the optimizer supports it. This is disabled if   <code>split_evaluations</code> is <code>True</code>.</li> <li><code>split_evaluations</code>: If <code>True</code>, forces separate function and gradient   evaluations, even if the optimizer requests them together. This is useful   with realization filters that completerly disable some realizations, to   potentially reduce the number of evaluations for gradients (see   <code>RealizationFilterConfig</code>).</li> <li><code>parallel</code>: If <code>True</code>, allows the optimizer to use parallelized   function evaluations. This typically applies to gradient-free methods and   may be ignored.</li> <li><code>output_dir</code>: An optional output directory where the optimizer can   store files.</li> <li><code>options</code>: A dictionary or list of strings for generic optimizer   options. The required format and interpretation depend on the specific   optimization method.</li> <li><code>stdout</code>: Redirect optimizer standard output to the given file.</li> <li><code>stderr</code>: Redirect optimizer standard error to the given file.</li> </ul> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the optimization method.</p> <code>max_iterations</code> <code>PositiveInt | None</code> <p>Maximum number of iterations (optional).</p> <code>max_functions</code> <code>PositiveInt | None</code> <p>Maximum number of function evaluations (optional).</p> <code>tolerance</code> <code>NonNegativeFloat | None</code> <p>Convergence tolerance (optional).</p> <code>speculative</code> <code>bool</code> <p>Force early gradient evaluations (default: <code>False</code>).</p> <code>split_evaluations</code> <code>bool</code> <p>Force separate function/gradient evaluations (default: <code>False</code>).</p> <code>parallel</code> <code>bool</code> <p>Allow parallelized function evaluations (default: <code>False</code>).</p> <code>output_dir</code> <code>Path | None</code> <p>Output directory for the optimizer (optional).</p> <code>options</code> <code>dict[str, Any] | list[str] | None</code> <p>Generic options for the optimizer (optional).</p> <code>stdout</code> <code>Path | None</code> <p>File to redirect optimizer standard output (optional).</p> <code>stderr</code> <code>Path | None</code> <p>File to redirect optimizer standard error (optional).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.GradientConfig","title":"GradientConfig","text":"<p>Configuration class for gradient calculations.</p> <p>This class, <code>GradientConfig</code>, defines the configuration for gradient calculations used in an <code>EnOptConfig</code> object.</p> <p>Gradients are estimated using function values calculated from perturbed variables and the unperturbed variables. The <code>number_of_perturbations</code> field determines the number of perturbed variables used, which must be at least one.</p> <p>If function evaluations for some perturbed variables fail, the gradient may still be estimated as long as a minimum number of evaluations succeed. The <code>perturbation_min_success</code> field specifies this minimum. By default, it equals <code>number_of_perturbations</code>.</p> <p>Perturbations are generated by sampler objects configured in the parent <code>EnOptConfig</code> object. The <code>samplers</code> field specifies, for each variable, the index of the sampler to use. A random number generator is created to support samplers that require random numbers.</p> <p>The generated perturbation values are scaled by the <code>perturbation_magnitudes</code> and can be modified based on the <code>perturbation_types</code>. See <code>PerturbationType</code> for details on available perturbation types.</p> <p>Perturbed variables may violate the defined variable bounds. The <code>boundary_types</code> field specifies how to handle such violations. See <code>BoundaryType</code> for details on available boundary handling methods.</p> <p>The <code>perturbation_types</code> and <code>boundary_types</code> fields use values from the <code>PerturbationType</code> and <code>BoundaryType</code> enumerations, respectively.</p> <p>Gradients are calculated for each realization individually and then combined into a total gradient. If <code>number_of_perturbations</code> is low, or even just one, individual gradient calculations may be unreliable. In this case, setting <code>merge_realizations</code> to <code>True</code> directs the optimizer to combine the results of all realizations directly into a single gradient estimate.</p> Seed for Samplers <p>The <code>seed</code> value ensures consistent results across repeated runs with the same configuration. To obtain unique results for each optimization run, modify the seed. A common approach is to use a tuple with a unique ID as the first element, ensuring reproducibility across nested and parallel plan evaluations.</p> <p>Attributes:</p> Name Type Description <code>number_of_perturbations</code> <code>PositiveInt</code> <p>Number of perturbations (default: <code>DEFAULT_NUMBER_OF_PERTURBATIONS</code>).</p> <code>perturbation_min_success</code> <code>PositiveInt | None</code> <p>Minimum number of successful function evaluations for perturbed variables (default: equal to <code>number_of_perturbations</code>).</p> <code>perturbation_magnitudes</code> <code>Array1D</code> <p>Magnitudes of the perturbations for each variable (default: <code>DEFAULT_PERTURBATION_MAGNITUDE</code>).</p> <code>perturbation_types</code> <code>ArrayEnum</code> <p>Type of perturbation for each variable (see <code>PerturbationType</code>, default: <code>DEFAULT_PERTURBATION_TYPE</code>).</p> <code>boundary_types</code> <code>ArrayEnum</code> <p>How to handle perturbations that violate boundary conditions (see <code>BoundaryType</code>, default: <code>DEFAULT_PERTURBATION_BOUNDARY_TYPE</code>).</p> <code>samplers</code> <code>Array1DInt | None</code> <p>Indices of the samplers to use for each variable.</p> <code>seed</code> <code>ItemOrTuple[int]</code> <p>Seed for the random number generator used by the samplers.</p> <code>merge_realizations</code> <code>bool</code> <p>Merge all realizations for the final gradient calculation (default: <code>False</code>).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.FunctionEstimatorConfig","title":"FunctionEstimatorConfig","text":"<p>Configuration class for function estimators.</p> <p>This class, <code>FunctionEstimatorConfig</code>, defines the configuration for function estimators used in an <code>EnOptConfig</code> object. Function estimators are configured as a tuple in the <code>function_estimators</code> field of the <code>EnOptConfig</code>, defining the available estimators for the optimization.</p> <p>By default, objective and constraint functions, as well as their gradients, are calculated from individual realizations using a weighted sum. Function estimators provide a way to modify this default calculation.</p> <p>The <code>method</code> field specifies the function estimator method to use for combining the individual realizations. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the function estimator method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the function estimator.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationFilterConfig","title":"RealizationFilterConfig","text":"<p>Configuration class for realization filters.</p> <p>This class, <code>RealizationFilterConfig</code>, defines the configuration for realization filters used in an <code>EnOptConfig</code> object. Realization filters are configured as a tuple in the <code>realization_filters</code> field of the <code>EnOptConfig</code>, defining the available filters for the optimization.</p> <p>By default, objective and constraint functions, as well as their gradients, are calculated as a weighted function of all realizations. Realization filters provide a way to modify the weights of individual realizations. For example, they can be used to select a subset of realizations for calculating the final objective and constraint functions and their gradients by setting the weights of the other realizations to zero.</p> <p>The <code>method</code> field specifies the realization filter method to use for adjusting the weights. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the realization filter method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the realization filter.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.SamplerConfig","title":"SamplerConfig","text":"<p>Configuration class for samplers.</p> <p>This class, <code>SamplerConfig</code>, defines the configuration for samplers used in an <code>EnOptConfig</code> object. Samplers are configured as a tuple in the <code>samplers</code> field of the <code>EnOptConfig</code>, defining the available samplers for the optimization. The <code>samplers</code> field in the <code>GradientConfig</code> specifies the index of the sampler to use for each variable.</p> <p>Samplers generate perturbations added to variables for gradient calculations. These perturbations can be deterministic or stochastic.</p> <p>The <code>method</code> field specifies the sampler method to use for generating perturbations. The <code>options</code> field allows passing a dictionary of key-value pairs to further configure the chosen method. The interpretation of these options depends on the selected method.</p> <p>By default, each realization uses a different set of perturbed variables. Setting the <code>shared</code> flag to <code>True</code> directs the sampler to use the same set of perturbed values for all realizations.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the sampler method.</p> <code>options</code> <code>dict[str, Any]</code> <p>Dictionary of options for the sampler.</p> <code>shared</code> <code>bool</code> <p>Whether to share perturbation values between realizations (default: <code>False</code>).</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants","title":"ropt.config.enopt.constants","text":"<p>Default values used by the configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_SEED","title":"DEFAULT_SEED  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SEED: Final = 1\n</code></pre> <p>Default seed for random number generators.</p> <p>The seed is used as the base value for random number generators within various components of the optimization process, such as samplers. Using a consistent seed ensures reproducibility across multiple runs with the same configuration. To obtain unique results for each optimization run, modify this seed.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_NUMBER_OF_PERTURBATIONS","title":"DEFAULT_NUMBER_OF_PERTURBATIONS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_NUMBER_OF_PERTURBATIONS: Final = 5\n</code></pre> <p>Default number of perturbations for gradient estimation.</p> <p>This value defines the default number of perturbed variables used to estimate gradients. A higher number of perturbations can lead to more accurate gradient estimates but also increases the number of function evaluations required.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_MAGNITUDE","title":"DEFAULT_PERTURBATION_MAGNITUDE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_MAGNITUDE: Final = 0.005\n</code></pre> <p>Default magnitude for variable perturbations.</p> <p>This value specifies the default value of the scaling factor applied to the perturbation values generated by samplers. The magnitude can be interpreted as an absolute value or as a relative value, depending on the selected perturbation type.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_BOUNDARY_TYPE","title":"DEFAULT_PERTURBATION_BOUNDARY_TYPE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_BOUNDARY_TYPE: Final = MIRROR_BOTH\n</code></pre> <p>Default perturbation boundary handling type.</p> <p>This value determines how perturbations that violate the defined variable bounds are handled. The default, <code>BoundaryType.MIRROR_BOTH</code>, mirrors perturbations back into the valid range if they exceed either the lower or upper bound.</p> <p>See also: <code>BoundaryType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_TYPE","title":"DEFAULT_PERTURBATION_TYPE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PERTURBATION_TYPE: Final = ABSOLUTE\n</code></pre> <p>Default perturbation type.</p> <p>This value determines how the perturbation magnitude is interpreted. The default, <code>PerturbationType.ABSOLUTE</code>, means that the perturbation magnitude is added directly to the variable value. Other options, such as <code>PerturbationType.RELATIVE</code>, scale the perturbation magnitude based on the variable's bounds.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enums/","title":"Enumerations","text":""},{"location":"reference/enums/#ropt.enums","title":"ropt.enums","text":"<p>Enumerations used within the <code>ropt</code> library.</p>"},{"location":"reference/enums/#ropt.enums.VariableType","title":"VariableType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the variable types.</p> <p>The variable types are configured in the <code>variables</code> section of the optimizer configuration. The optimization backends may make us of this information to modify their behavior accordingly.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.REAL","title":"REAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REAL = 1\n</code></pre> <p>Continuous variables represented by real values.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.INTEGER","title":"INTEGER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTEGER = 2\n</code></pre> <p>Discrete variables represented by integer values.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType","title":"BoundaryType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the ways boundaries should be treated.</p> <p>When variables are perturbed their values may violate boundary constraints. This enumeration lists the ways these values can be modified to fix this.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.NONE","title":"NONE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONE = 1\n</code></pre> <p>Do not modify the value.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.TRUNCATE_BOTH","title":"TRUNCATE_BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TRUNCATE_BOTH = 2\n</code></pre> <p>Truncate the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     l_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     b_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.BoundaryType.MIRROR_BOTH","title":"MIRROR_BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MIRROR_BOTH = 3\n</code></pre> <p>Mirror the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     2l_i - v_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     2b_i - v_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i        &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.PerturbationType","title":"PerturbationType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of perturbations that can be applied.</p> <p>When applying a perturbation to a variable, generally, some value is generated, which is then applied to the unperturbed values (usually by addition). This enumeration lists the ways how this perturbation value can be modified before being added to the unperturbed variable.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.ABSOLUTE","title":"ABSOLUTE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABSOLUTE = 1\n</code></pre> <p>Use the perturbation value as is.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.RELATIVE","title":"RELATIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RELATIVE = 2\n</code></pre> <p>Multiply the perturbation value \\(p_i\\) by the range defined by the bounds of the variables \\(c_i\\): \\(\\hat{p}_i = (c_{i,\\text{max}} - c_{i,\\text{min}}) \\times p_i\\). The bounds will generally be defined in the configuration for the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.EventType","title":"EventType","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the events handled by the event broker.</p> <p>During the execution of the optimization plan, events may be emitted and callbacks can be connected to these events . When triggered by an event, the callbacks receive an <code>Event</code> object. This object contains at least the type of the event (a value of this enumeration) and the current configuration of the step that is executing. If the step has a name it is also added to the event. Additionally, depending on the event type, a tuple of result objects, an exit code  may be present. Refer to the documentation of the individual event types for details.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATION","title":"START_EVALUATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_EVALUATION = 1\n</code></pre> <p>Emitted before evaluating new functions.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATION","title":"FINISHED_EVALUATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_EVALUATION = 2\n</code></pre> <p>Emitted after finishing the evaluation.</p> <p>Results may be passed to callback reacting to this event.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_OPTIMIZER_STEP","title":"START_OPTIMIZER_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_OPTIMIZER_STEP = 3\n</code></pre> <p>Emitted just before starting an optimizer step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_OPTIMIZER_STEP","title":"FINISHED_OPTIMIZER_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_OPTIMIZER_STEP = 4\n</code></pre> <p>Emitted immediately after an optimizer step finishes.</p> <p>Results and an exit code may be passed via the event object.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATOR_STEP","title":"START_EVALUATOR_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>START_EVALUATOR_STEP = 5\n</code></pre> <p>Emitted just before starting an evaluation step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATOR_STEP","title":"FINISHED_EVALUATOR_STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED_EVALUATOR_STEP = 6\n</code></pre> <p>Emitted immediately after an evaluation step finishes.</p> <p>Results and an exit code may be passed via the event object.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode","title":"OptimizerExitCode","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the reasons for terminating an optimization.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = 0\n</code></pre> <p>Unknown cause of termination.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.TOO_FEW_REALIZATIONS","title":"TOO_FEW_REALIZATIONS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TOO_FEW_REALIZATIONS = 1\n</code></pre> <p>Returned when too few realizations are evaluated successfully.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.MAX_FUNCTIONS_REACHED","title":"MAX_FUNCTIONS_REACHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MAX_FUNCTIONS_REACHED = 2\n</code></pre> <p>Returned when the maximum number of function evaluations is reached.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.NESTED_OPTIMIZER_FAILED","title":"NESTED_OPTIMIZER_FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NESTED_OPTIMIZER_FAILED = 3\n</code></pre> <p>Returned when a nested optimization fails to find an optimal value.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.USER_ABORT","title":"USER_ABORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>USER_ABORT = 4\n</code></pre> <p>Returned when the optimization is aborted by the user.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.OPTIMIZER_STEP_FINISHED","title":"OPTIMIZER_STEP_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OPTIMIZER_STEP_FINISHED = 5\n</code></pre> <p>Returned when an optimization step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.EVALUATION_STEP_FINISHED","title":"EVALUATION_STEP_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EVALUATION_STEP_FINISHED = 6\n</code></pre> <p>Returned when an evaluation step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis","title":"ResultAxis","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumerates the possible axes in a Results data object.</p> <p>Result objects (see <code>Results</code>) contain multidimensional arrays where the axes represent particular quantities, for instance variables, function objects, or realization numbers. The result objects contain metadata that identify the axes by values of this enumeration. These can be retrieved by the <code>get_axes</code> method of the attributes of a results object. They are used internally when exporting data to determine the type of the array axes, for instance to retrieve the names of the variables from the configuration.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.VARIABLE","title":"VARIABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VARIABLE = 'variable'\n</code></pre> <p>The axis index corresponds to the index of the variable.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.OBJECTIVE","title":"OBJECTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OBJECTIVE = 'objective'\n</code></pre> <p>The axis index corresponds to the index of the objective function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.LINEAR_CONSTRAINT","title":"LINEAR_CONSTRAINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINEAR_CONSTRAINT = 'linear_constraint'\n</code></pre> <p>The axis index corresponds to the index of the linear constraint.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.NONLINEAR_CONSTRAINT","title":"NONLINEAR_CONSTRAINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONLINEAR_CONSTRAINT = 'nonlinear_constraint'\n</code></pre> <p>The axis index corresponds to the index of the constraint function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.REALIZATION","title":"REALIZATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REALIZATION = 'realization'\n</code></pre> <p>The axis index corresponds to the index of the realization.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxis.PERTURBATION","title":"PERTURBATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PERTURBATION = 'perturbation'\n</code></pre> <p>The axis index corresponds to the index of the perturbation.</p>"},{"location":"reference/evaluator/","title":"Function Evaluations","text":""},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator","title":"ropt.ensemble_evaluator.EnsembleEvaluator","text":"<p>Construct functions and gradients from an ensemble of functions.</p> <p>The <code>EnsembleEvaluator</code> class is responsible for calculating functions and gradients from an ensemble of functions. It leverages the settings defined in an <code>EnOptConfig</code> configuration object to guide the calculations.</p> <p>The core functionality relies on an <code>Evaluator</code> callable, which is used to evaluate the individual functions within the ensemble. The evaluator provides the raw function values, which are then processed by the <code>EnsembleEvaluator</code> to produce the final function and gradient estimates.</p>"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.__init__","title":"__init__","text":"<pre><code>__init__(\n    config: EnOptConfig,\n    transforms: OptModelTransforms | None,\n    evaluator: Evaluator,\n    plugin_manager: PluginManager,\n) -&gt; None\n</code></pre> <p>Initialize the EnsembleEvaluator.</p> <p>This method sets up the <code>EnsembleEvaluator</code> with the necessary configuration, evaluator, and plugins.</p> <p>The <code>config</code> object contains all the settings required for the ensemble evaluation, such as the number of realizations, the function estimators, and the gradient settings. The <code>transforms</code> object can be used to transform the variables, objectives, and constraints before or after the evaluation. The <code>evaluator</code> callable should conform to the <code>Evaluator</code> protocol. The <code>plugin_manager</code> is used to load the realization filters, function estimators, and samplers.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration object.</p> required <code>transforms</code> <code>OptModelTransforms | None</code> <p>Optional transforms object.</p> required <code>evaluator</code> <code>Evaluator</code> <p>The callable for evaluating individual functions.</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>A plugin manager to load required plugins.</p> required"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.calculate","title":"calculate","text":"<pre><code>calculate(\n    variables: NDArray[float64],\n    *,\n    compute_functions: bool,\n    compute_gradients: bool,\n) -&gt; tuple[Results, ...]\n</code></pre> <p>Evaluate the given variable vectors.</p> <p>This method calculates functions, gradients, or both, based on the provided variable vectors and the specified flags.</p> <p>The <code>variables</code> argument can be a single vector or a matrix where each row is a variable vector.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vectors to evaluate.</p> required <code>compute_functions</code> <code>bool</code> <p>Whether to calculate functions.</p> required <code>compute_gradients</code> <code>bool</code> <p>Whether to calculate gradients.</p> required <p>Returns:</p> Type Description <code>tuple[Results, ...]</code> <p>The results for function evaluations and/or gradient evaluations.</p>"},{"location":"reference/evaluator/#ropt.evaluator.Evaluator","title":"ropt.evaluator.Evaluator","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for evaluator objects or callables.</p> <p>The <code>EnsembleEvaluator</code> class requires a function evaluator callback that conforms to the <code>Evaluator</code> signature. This callback accepts one or more variable vectors to evaluate, along with an <code>EvaluatorContext</code> object that provides relevant information for the evaluation. It returns an <code>EvaluatorResult</code> object containing the results.</p>"},{"location":"reference/evaluator/#ropt.evaluator.Evaluator.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64], context: EvaluatorContext\n) -&gt; EvaluatorResult\n</code></pre> <p>Evaluate objective and constraint functions for given variables.</p> <p>This method defines the signature for the function evaluator callback. The evaluator calculates objective and constraint functions for a set of variable vectors, potentially for a subset of realizations and perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate. Each row represents        a variable vector.</p> required <code>context</code> <code>EvaluatorContext</code> <p>The evaluation context, providing additional information        about the evaluation.</p> required <p>Returns:</p> Type Description <code>EvaluatorResult</code> <p>An evaluation results object containing the calculated objective and constraint values, along with any additional metadata.</p> Reusing Objective <p>When defining multiple objectives, there may be a need to reuse the same objective value multiple times. For instance, a total objective could consist of the mean of the objectives for each realization, plus the standard deviation of the same values. This can be implemented by defining two objectives: the first calculated as the mean of the realizations, and the second using a function estimator to compute the standard deviations. The optimizer is unaware that both objectives use the same set of realizations. To prevent redundant calculations, the evaluator should compute the results of the realizations once and return them for both objectives.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext","title":"ropt.evaluator.EvaluatorContext  <code>dataclass</code>","text":"<p>Capture additional details for the function evaluator.</p> <p>Function evaluator callbacks (see <code>Evaluator</code>) primarily receive variable vectors to evaluate objective and constraint functions. However, they may also benefit from additional information to optimize their calculations. This <code>EvaluatorContext</code> object provides that supplementary information.</p> <p>Specifically, it provides:</p> <ul> <li>The configuration object for the current optimization step.</li> <li>The realization index for each variable vector.</li> <li>The perturbation index for each variable vector (if applicable). A value   less than 0 indicates that the vector is not a perturbation.</li> <li>Boolean matrices (<code>active_objectives</code> and <code>active_constraints</code>) indicating   which objective/realization and constraint/realization evaluations are   required by the optimizer.</li> <li>A boolean vector (<code>active</code>) indicating which realizations require   evaluation.</li> </ul> <p>The <code>active_objectives</code> and <code>active_constraints</code> matrices are structured such that each column corresponds to a realization, and each row corresponds to a function or constraint. A <code>True</code> value signifies that the corresponding evaluation is essential for the optimizer.</p> The <code>active</code> property <p>In many cases, evaluators may only be able to compute all objectives and constraints for a given realization or none at all. In these scenarios, the <code>active</code> property provides a simplified view, indicating only the realizations that need to be evaluated. <code>active</code> cannot be set when creating the evaluator context, it is calculated from <code>active_objectives</code> and <code>active_constraints</code>.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>Configuration of the optimizer.</p> required <code>realizations</code> <code>NDArray[intc]</code> <p>Realization numbers for each requested evaluation.</p> required <code>perturbations</code> <code>NDArray[intc] | None</code> <p>Perturbation numbers for each requested evaluation.                 A value less than 0 indicates that the vector is                 not a perturbation.</p> <code>None</code> <code>active_objectives</code> <code>NDArray[bool_] | None</code> <p>Indicates which function/realization evaluations are                 essential for the optimizer.</p> <code>None</code> <code>active_constraints</code> <code>NDArray[bool_] | None</code> <p>Indicates which constraint/realization evaluations                 are essential for the optimizer.</p> <code>None</code>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorResult","title":"ropt.evaluator.EvaluatorResult  <code>dataclass</code>","text":"<p>Store the results of a function evaluation.</p> <p>This class stores the results of evaluating objective and constraint functions for a set of variable vectors.</p> <p>The <code>objectives</code> and <code>constraints</code> are stored as matrices. Each column in these matrices corresponds to a specific objective or constraint, and each row corresponds to a variable vector.</p> <p>When the evaluator is asked to evaluate functions, some variable vectors may be marked as inactive. The results for these inactive vectors should be set to zero. All active variable vectors should be evaluated. If an evaluation fails for any reason, the corresponding values should be set to <code>numpy.nan</code>.</p> <p>A <code>batch_id</code> can be set to identify this specific set of evaluation results.</p> <p>The <code>evaluation_info</code> dictionary can store additional metadata for each evaluation. This information is not used internally by <code>ropt</code> and can have an arbitrary structure, to be interpreted by the application. This can be used, for example, to uniquely identify the results calculated for each variable vector, allowing them to be linked back to their corresponding input vectors.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The calculated objective values.</p> required <code>constraints</code> <code>NDArray[float64] | None</code> <p>Optional calculated constraint values.</p> <code>None</code> <code>batch_id</code> <code>int | None</code> <p>Optional batch ID to identify this set of results.</p> <code>None</code> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional info for each evaluation.</p> <code>dict()</code>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#ropt.exceptions","title":"ropt.exceptions","text":"<p>Exceptions raised within the <code>ropt</code> library.</p>"},{"location":"reference/exceptions/#ropt.exceptions.ConfigError","title":"ConfigError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an configuration error occurs.</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted","title":"OptimizationAborted","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization is aborted.</p> <p>When constructing the exception object an exit code must be passed that indicates the reason for aborting (see <code>OptimizerExitCode</code>).</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted.__init__","title":"__init__","text":"<pre><code>__init__(exit_code: OptimizerExitCode) -&gt; None\n</code></pre> <p>Initialize an exception that aborts the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>exit_code</code> <code>OptimizerExitCode</code> <p>The exit code indicating the reason for the abort.</p> required"},{"location":"reference/exceptions/#ropt.exceptions.PlanAborted","title":"PlanAborted","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization plan is aborted.</p> <p>Steps within a plan may abort a plan by setting its <code>aborted</code> attribute. Any attemps to run steps after this, will raise this exception.</p>"},{"location":"reference/external_optimizer_plugin/","title":"External Optimizer Plugin","text":""},{"location":"reference/external_optimizer_plugin/#ropt.plugins.optimizer.external.ExternalOptimizer","title":"ropt.plugins.optimizer.external.ExternalOptimizer","text":"<p>               Bases: <code>OptimizerPlugin</code></p> <p>Plugin class for optimization using an external process.</p> <p>This class enables optimization via an external process, which performs the optimization independently and communicates with this class over pipes to request function evaluations, report optimizer states, and handle any errors.</p> <p>Typically, the optimizer is specified within an <code>OptimizerConfig</code> via the <code>method</code> field, which either provides the algorithm name directly or follows the form <code>plugin-name/method-name</code>. In the first case, <code>ropt</code> searches among all available optimizer plugins to find the specified method. In the second case, it checks if the plugin identified by <code>plugin-name</code> contains <code>method-name</code> and, if so, uses it. Both of these are not supported by the external optimizer class. Instead, it requires that the <code>method</code> field includes both the plugin and method names in the format <code>external/plugin-name/method-name</code> or <code>external/method-name</code>. This ensures the external optimizer can identify and launch the specified optimization method <code>method-name</code> and launch it as an external process.</p>"},{"location":"reference/function_estimator_plugins/","title":"Function estimator Plugins","text":""},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator","title":"ropt.plugins.function_estimator","text":"<p>Plugin functionality for adding function estimators.</p> <p>This package contains the abstract base classes for function estimator plugins, and the default function estimators that are part of <code>ropt</code>.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base","title":"ropt.plugins.function_estimator.base","text":"<p>This module defines the abstract base classes for function estimators.</p> <p>Function estimators can be added via the plugin mechanism to implement additional ways to functions and gradient ensembles. Any object that adheres to the <code>FunctionEstimatorPlugin</code> base class may be installed as a plugin.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin","title":"FunctionEstimatorPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for function estimators.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig, estimator_index: int\n) -&gt; None\n</code></pre> <p>Initialize the function estimator object.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>estimator_index</code> <code>int</code> <p>The index of the estimator to use.</p> required"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin.calculate_function","title":"calculate_function  <code>abstractmethod</code>","text":"<pre><code>calculate_function(\n    functions: NDArray[float64], weights: NDArray[float64]\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Combine functions from realizations into an expected function.</p> Calculation from merged realizations <p>Normally the gradient is calculated for each realization separately and then combined into an overall gradient with <code>calculate_gradient</code> method. The <code>merge_realizations</code> flag in the ensemble optimizer configuration directs the optimizer to calculate the overall gradient from all realizations directly. This yields a reasonable estimation if the function estimator is an averaging operation, but may not be appropriate in other cases.</p> <p>At initialization, the <code>merge_realizations</code> flag should be checked, and if necessary a <code>ConfigError</code> with an appropriate message should be raised.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization.</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected function values.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin.calculate_gradient","title":"calculate_gradient  <code>abstractmethod</code>","text":"<pre><code>calculate_gradient(\n    functions: NDArray[float64],\n    gradient: NDArray[float64],\n    weights: NDArray[float64],\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Combine gradients from realizations into an expected gradient.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization.</p> required <code>gradient</code> <code>NDArray[float64]</code> <p>The gradient for each realization.</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected gradients.</p>"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.base.FunctionEstimatorPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig, estimator_index: int\n) -&gt; FunctionEstimatorPlugin\n</code></pre> <p>Initialize the function estimator object.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>estimator_index</code> <code>int</code> <p>The index of the estimator to use.</p> required"},{"location":"reference/function_estimator_plugins/#ropt.plugins.function_estimator.default","title":"ropt.plugins.function_estimator.default","text":"<p>This module implements the default function estimator plugin.</p>"},{"location":"reference/optimization/","title":"Optimization","text":""},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer","title":"ropt.optimization.EnsembleOptimizer","text":"<p>Optimizer for ensemble-based optimizations.</p> <p>The <code>EnsembleOptimizer</code> class provides the core functionality for running ensemble-based optimizations. Direct use of this class is generally discouraged. Instead, the <code>Plan</code> or <code>BasicOptimizer</code> classes are recommended for greater flexibility and ease of use.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.is_parallel","title":"is_parallel  <code>property</code>","text":"<pre><code>is_parallel: bool\n</code></pre> <p>Determine if the optimization supports parallel evaluations.</p> <p>The underlying optimization algorithm may request function evaluations via a callback. Parallel optimization, in this context, means that the algorithm may request multiple function evaluations in a single callback.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the optimization supports parallel evaluations, <code>False</code></p> <code>bool</code> <p>otherwise.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig,\n    ensemble_evaluator: EnsembleEvaluator,\n    plugin_manager: PluginManager,\n    signal_evaluation: SignalEvaluationCallback\n    | None = None,\n    nested_optimizer: NestedOptimizerCallback | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the EnsembleOptimizer.</p> <p>This class orchestrates ensemble-based optimizations. It requires an optimization configuration, an evaluator, and a plugin manager to function.</p> <p>The <code>EnsembleOptimizer</code> needs the following to define a single optimization run:</p> <ol> <li>An <code>EnOptConfig</code> object: This     contains all configuration settings for the optimization.</li> <li>An <code>EnsembleEvaluator</code>     object: This object is responsible for evaluating functions.</li> <li>A <code>PluginManager</code> object: This object     provides access to optimizer plugins.</li> </ol> <p>Additionally, two optional callbacks can be provided to extend the functionality:</p> <ol> <li>A     <code>SignalEvaluationCallback</code>:     This callback is invoked before and after each function evaluation.</li> <li>A     <code>NestedOptimizerCallback</code>:     This callback is invoked at each function evaluation to run a nested     optimization.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The ensemble optimization configuration.</p> required <code>ensemble_evaluator</code> <code>EnsembleEvaluator</code> <p>The evaluator for function evaluations.</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>The plugin manager.</p> required <code>signal_evaluation</code> <code>SignalEvaluationCallback | None</code> <p>Optional callback to signal evaluations.</p> <code>None</code> <code>nested_optimizer</code> <code>NestedOptimizerCallback | None</code> <p>Optional callback for nested optimizations.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.start","title":"start","text":"<pre><code>start(variables: NDArray[float64]) -&gt; OptimizerExitCode\n</code></pre> <p>Start the optimization process.</p> <p>This method initiates the optimization process using the provided initial variables. The optimization will continue until a stopping criterion is met or an error occurs.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The initial variables for the optimization.</p> required <p>Returns:</p> Type Description <code>OptimizerExitCode</code> <p>An <code>OptimizerExitCode</code> indicating</p> <code>OptimizerExitCode</code> <p>the reason for termination.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback","title":"ropt.optimization.SignalEvaluationCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for a callback to signal the start and end of an evaluation.</p> <p>This callback is invoked before and after each evaluation, allowing for custom handling or tracking of evaluation events.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    results: tuple[Results, ...] | None = None,\n) -&gt; None\n</code></pre> <p>Callback protocol for signaling the start and end of evaluations.</p> <p>This callback is invoked by the ensemble optimizer before and after each evaluation. Before the evaluation starts, the callback is called with <code>results</code> set to <code>None</code>. After the evaluation completes, the callback is called again, this time with <code>results</code> containing the output of the evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>tuple[Results, ...] | None</code> <p>The results produced by the evaluation, or <code>None</code> if the      evaluation has not yet started.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback","title":"ropt.optimization.NestedOptimizerCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for functions that start a nested optimization.</p>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64],\n) -&gt; tuple[FunctionResults | None, bool]\n</code></pre> <p>Callback protocol for executing a nested optimization.</p> <p>This function is invoked by the ensemble optimizer during each function evaluation to initiate a nested optimization process. It receives the current variables as input and is expected to perform a nested optimization using these variables as a starting point. The function should return a tuple containing the result of the nested optimization and a boolean indicating whether the nested optimization was aborted by the user. The result of the nested optimization should be a <code>FunctionResults</code> object, or <code>None</code> if no result is available.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variables to use as the starting point.</p> required <p>Returns:</p> Type Description <code>tuple[FunctionResults | None, bool]</code> <p>The result and a boolean indicating if the user aborted.</p>"},{"location":"reference/optimizer_plugins/","title":"Optimizer Plugins","text":""},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer","title":"ropt.plugins.optimizer","text":"<p>Plugin functionality for adding optimization plugins.</p> <p>Optimization plugins are managed by a <code>PluginManager</code> object, which returns classes or factory functions to create objects that implement one or more optimization methods. These objects must adhere to the <code>OptimizerPlugin</code> abstract base class. This abstract base class allows <code>ropt</code> to provide the optimizer with the callback used for evaluating functions and gradients and allows it to be started from an optimizer step in the optimization plan.</p> <p>To support the implementation of the optimizer classes, the <code>ropt.plugins.optimizer.utils</code> module provides some utilities.</p> <p>By default the <code>SciPyOptimizerPlugin</code> plugin is installed which provides a number of methods from the <code>scipy.optimize</code> package.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base","title":"ropt.plugins.optimizer.base","text":"<p>This module defines base classes and protocols for optimization plugins.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin","title":"OptimizerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base for optimizer classes.</p> <p>Optimizers provided by optimizer plugins should derive from the <code>Optimizer</code> abstract base class, which specifies the requirements for the class constructor (<code>__init__</code>) and also includes a <code>start</code> method used to initiate the optimization process.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.allow_nan","title":"allow_nan  <code>property</code>","text":"<pre><code>allow_nan: bool\n</code></pre> <p>Return <code>True</code> if a <code>NaN</code> is a valid function value.</p> <p>If the optimizer can handle <code>NaN</code> function values, it may implement this method to return <code>True</code>. This enables handling cases where all function evaluations in an ensemble fail. By setting the <code>realization_min_success</code> configuration parameter to zero, the ensemble optimization plan can then be allowed to return a <code>NaN</code> value instead of raising an error.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>NaN</code> is allowed.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.is_parallel","title":"is_parallel  <code>property</code>","text":"<pre><code>is_parallel: bool\n</code></pre> <p>Whether the current method uses parallel evaluations.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if optimization is parallelized.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.__init__","title":"__init__","text":"<pre><code>__init__(\n    config: EnOptConfig,\n    optimizer_callback: OptimizerCallback,\n) -&gt; None\n</code></pre> <p>Initialize an optimizer object.</p> <p>The <code>config</code> object provides the desired configuration for the optimization process and should be used to set up the optimizer correctly before starting the optimization. The optimization will be initiated using the <code>start</code> method and will repeatedly require function and gradient evaluations at given variable vectors. The <code>optimizer_callback</code> argument provides the function that should be used to calculate the function and gradient values, which can then be forwarded to the optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used.</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.start","title":"start  <code>abstractmethod</code>","text":"<pre><code>start(initial_values: NDArray[float64]) -&gt; None\n</code></pre> <p>Start the optimization.</p> <p>This method must be implemented to run the optimization using the provided initial values, collecting function and gradient evaluations as needed by calling the callback passed via the <code>optimizer_callback</code> argument during initialization.</p> <p>Parameters:</p> Name Type Description Default <code>initial_values</code> <code>NDArray[float64]</code> <p>Vector of variables to start the optimization with.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    config: EnOptConfig,\n    optimizer_callback: OptimizerCallback,\n) -&gt; OptimizerPlugin\n</code></pre> <p>Create an optimizer.</p> <p>This is a factory function for instantiating optimizer objects implemented in the plugin.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used.</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerCallback","title":"OptimizerCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the optimizer callback.</p> <p>Optimization plugins implement optimizer classes derived from the <code>OptimizerPlugin</code> abstract base class. Objects of these classes are initialized with a callback function that follows the call signature defined here. This callback should be used to request the function and gradient evaluations that the optimizer needs.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    variables: NDArray[float64],\n    /,\n    *,\n    return_functions: bool,\n    return_gradients: bool,\n) -&gt; tuple[NDArray[np.float64], NDArray[np.float64]]\n</code></pre> <p>The signature of the optimizer callback.</p> <p>The optimizer callback expects a vector or matrix with variables to evaluate. Discrete optimizers may request function evaluations for multiple variable vectors, passed as the rows of a matrix. Gradient-based methods may currently only pass a single variable vector at a time.</p> <p>The <code>return_functions</code> and <code>return_gradients</code> flags determine whether functions and/or gradients are to be evaluated. The results are returned as a tuple of arrays, one for functions and constraints, the other for gradients. If one of <code>return_functions</code> or <code>return_gradients</code> is <code>False</code>, the corresponding result is an empty array.</p> <p>Multiple function evaluations are returned as a matrix where the rows are the result vectors for each evaluation. The first element of a result vector is the value of the objective value, and the remaining elements are the values of the non-linear constraints.</p> <p>The gradients of the objective function and the non-linear constraints are returned as a matrix. The first row contains the gradient of the objective function, while the remaining rows contain the gradients of the non-linear constraints. Gradient-based methods currently support only a single evaluation, hence there is also only a single result.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vector or matrix to evaluate.</p> required <code>return_functions</code> <code>bool</code> <p>If <code>True</code>, evaluate and return functions.</p> required <code>return_gradients</code> <code>bool</code> <p>If <code>True</code>, evaluate and return gradients.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple with function and gradient values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils","title":"ropt.plugins.optimizer.utils","text":"<p>Utility functions for use by optimizer plugins.</p> <p>This module provides utility functions to validate supported constraints, filter linear constraints, and to retrieve the list of supported optimizers.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints","title":"NormalizedConstraints","text":"<p>Class for handling normalized constraints.</p> <p>This class can be used to normalize non-linear constraints into the form C(x) = 0, C(x) &lt;= 0, or C(x) &gt;= 0. By default this is done by subtracting the right-hand side value, and multiplying with -1, if necessary.</p> <p>The right hand sides are provided by the <code>lower_bounds</code> and <code>upper_bound</code> values. If corresponding entries in these arrays are equeal (within a 1e-15 tolerance), the corresponding constraint is assumed to be a equality constraint. If they are not, they are considered inequality constraints, if one or both values are finite. If the lower bounds are finite, the constraint is added as is, after subtracting of the lower bound. If the upper bound is finite, the same is done, but the constraint is multiplied by -1. If both are finite, both constraints are added, effectively splitting a two-sided constraint into two normalized constraints.</p> <p>By default this normalizes inequality constraints to the form C(x) &lt; 0, by setting <code>flip</code> flag, this can be changed to C(x) &gt; 0.</p> Usage <ol> <li>Initialize with the lower and upper bounds.</li> <li>Before each new function/gradient evaluation with a new variable    vector, reset the normalized constraints by calling the <code>reset</code>    method.</li> <li>The constraint values are given by the <code>constraints</code> property. Before    accessing it, call the <code>set_constraints</code> with the raw constraints. If    necessary, this will calculate and cache the normalized values. Since    values are cached, calling this method and accessing <code>constraints</code>    multiple times is cheap.</li> <li>Use the same procedure for gradients, using the <code>gradients</code> property    and <code>set_gradients</code>. Raw gradients must be provided as a matrix,    where the rows are the gradients of each constraint.</li> <li>Use the <code>is_eq</code> property to retrieve a vector of boolean flags to    check which constraints are equality constraints.</li> </ol> <p>See the <code>scipy</code> optimization backend in the <code>ropt</code> source code for an example of usage.</p> Parallel evaluation. <p>The raw constraints may be a vector of constraints, or may be a matrix of constraints for multiple variables to support parallel evaluation. In the latter case, the constraints for different variables are given by the columns of the matrix. In this case, the <code>constraints</code> property will have the same structure. Note that this is only supported for the constraint values, not for the gradients. Hence, parallel evaluation of multiple gradients is not supported.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.is_eq","title":"is_eq  <code>property</code>","text":"<pre><code>is_eq: list[bool]\n</code></pre> <p>Return the flags that indicate equality transforms.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.constraints","title":"constraints  <code>property</code>","text":"<pre><code>constraints: NDArray[float64] | None\n</code></pre> <p>Return the normalized constraints.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>The normalized constraints.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.gradients","title":"gradients  <code>property</code>","text":"<pre><code>gradients: NDArray[float64] | None\n</code></pre> <p>Return the normalized constraint gradients.</p> <p>Returns:</p> Type Description <code>NDArray[float64] | None</code> <p>The normalized constraint gradients.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.__init__","title":"__init__","text":"<pre><code>__init__(\n    lower_bounds: NDArray[float64],\n    upper_bounds: NDArray[float64],\n    *,\n    flip: bool = False,\n) -&gt; None\n</code></pre> <p>Initialize the normalization class.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bounds</code> <code>NDArray[float64]</code> <p>The lower bounds on the right hand sides.</p> required <code>upper_bounds</code> <code>NDArray[float64]</code> <p>The upper bounds on the right hand sides.</p> required <code>flip</code> <code>bool</code> <p>Whether to flip the sign of the constraints.</p> <code>False</code>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the constraints and its gradients.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_constraints","title":"set_constraints","text":"<pre><code>set_constraints(values: NDArray[float64]) -&gt; None\n</code></pre> <p>Set the constraints property.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The raw constraint values.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.NormalizedConstraints.set_gradients","title":"set_gradients","text":"<pre><code>set_gradients(values: NDArray[float64]) -&gt; None\n</code></pre> <p>Set the normalized and gradients.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[float64]</code> <p>The raw gradient values.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.validate_supported_constraints","title":"validate_supported_constraints","text":"<pre><code>validate_supported_constraints(\n    config: EnOptConfig,\n    method: str,\n    supported_constraints: dict[str, set[str]],\n    required_constraints: dict[str, set[str]],\n) -&gt; None\n</code></pre> <p>Check if the requested optimization features are supported or required.</p> <p>The keys of the supported_constraints and required_constraints dicts specify the type of the constraint as shown in the example below. The values are sets of method names that support or require the type of constraint specified by the key.</p> <p>For example: {     \"bounds\": {\"L-BFGS-B\", \"TNC\", \"SLSQP\"},     \"linear:eq\": {\"SLSQP\"},     \"linear:ineq\": {\"SLSQP\"},     \"nonlinear:eq\": {\"SLSQP\"},     \"nonlinear:ineq\": {\"SLSQP\"}, }</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object.</p> required <code>method</code> <code>str</code> <p>The method to check.</p> required <code>supported_constraints</code> <code>dict[str, set[str]]</code> <p>Specify the supported constraints.</p> required <code>required_constraints</code> <code>dict[str, set[str]]</code> <p>Specify the required constraints.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.create_output_path","title":"create_output_path","text":"<pre><code>create_output_path(\n    base_name: str,\n    base_dir: Path | None = None,\n    name: str | None = None,\n    suffix: str | None = None,\n) -&gt; Path\n</code></pre> <p>Create an output path name.</p> <p>If the path already exists, an index is appended to it.</p> <p>Parameters:</p> Name Type Description Default <code>base_name</code> <code>str</code> <p>Base name of the path.</p> required <code>base_dir</code> <code>Path | None</code> <p>Optional directory to base the path in.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Optional optimization step name to include in the name.</p> <code>None</code> <code>suffix</code> <code>str | None</code> <p>Optional suffix for the resulting path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>The constructed path</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.get_masked_linear_constraints","title":"get_masked_linear_constraints","text":"<pre><code>get_masked_linear_constraints(\n    config: EnOptConfig,\n) -&gt; tuple[\n    NDArray[np.float64],\n    NDArray[np.float64],\n    NDArray[np.float64],\n]\n</code></pre> <p>Get masked coefficients and bounds for linear constraints.</p> <p>If a mask is defined on the variables that defines a sub-set of variables to optimize, any linear constraints must be adapted accordingly. This function does this by removing masked variables from the coefficients, and absorbing the fixed variables in the lower and upper bounds.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimization configuration.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float64], NDArray[float64], NDArray[float64]]</code> <p>The corrected linear constraints.</p>"},{"location":"reference/plan/","title":"Optimization Plans","text":""},{"location":"reference/plan/#ropt.plan","title":"ropt.plan","text":"<p>Code for executing optimization plans.</p> <p>The <code>Plan</code> class orchestrates optimization workflows by managing steps and result handlers.</p> <p>A plan consists of <code>PlanStep</code> objects, which define individual actions, and <code>ResultHandler</code> objects, which process and store data generated during execution. Both steps and result handlers are implemented using a plugin mechanism, making it easy to extend the range of supported actions and data processing. The <code>ropt</code> library provides default implementations through the default plan handler and default plan step plugins. These provide basic steps and result handlers to support a wide range of optimization workflows.</p> <p>Most optimization plans require shared state across all steps, such as the plugin manager and an evaluator callable for function evaluations. This shared state is managed by the <code>OptimizerContext</code> object, which is provided when creating a plan. The <code>OptimizerContext</code> also handles events produced by plan steps by calling registered callbacks and forwarding them to result handlers.</p> <p>Setting up and executing a <code>Plan</code> object for simple optimization cases can be complex. The <code>BasicOptimizer</code> class simplifies this process by providing a convenient way to build and execute straightforward plans involving a single optimization.</p>"},{"location":"reference/plan/#ropt.plan.Plan","title":"ropt.plan.Plan","text":"<p>Plan class for executing optimization workflows.</p> <p>The <code>Plan</code> object is the core component for executing optimization workflows. It orchestrates the execution of individual steps and the processing of results through handlers.</p> <p>Building a Plan:</p> <p>To construct a plan, individual actions, known as steps, are added using the <code>add_step</code> method. Data processing and storage are managed by handlers, which are added using the <code>add_handler</code> method. The plan stores the step and handler objects internally. Their respective creation functions return unique IDs for identification. The <code>handler_exists</code> and <code>step_exists</code> methods can be used to verify whether a handler or step with a given name is supported.</p> <p>Executing a Plan:</p> <p>Once a plan is assembled, it can be executed in several ways. For fine-grained control, the <code>run_step</code> method can be invoked repeatedly, executing each step individually. This approach allows for the integration of complex logic and custom functions, leveraging the full capabilities of Python. Alternatively, for more structured workflows, a Python function encapsulating a sequence of steps can be defined. This function is added to the plan using the <code>add_function</code> method. The entire workflow defined by this function can then be executed with a single call to <code>run_function</code>, with optional arguments to customize its behavior. The <code>has_function</code> method can be used to check if a function has been added to the plan.</p> <p>Shared State and Events:</p> <p>The plan maintains shared state in an <code>OptimizerContext</code>, which is provided during initialization and can be shared among multiple plans. The <code>optimizer_context</code> property provides access to this context.</p> <p>Steps can communicate events using the <code>emit_event</code> method. Result handlers can respond to these events, enabling actions such as processing optimization results.</p> <p>Nested Plans:</p> <p>Multiple plans can be defined. A step within one plan can trigger the execution of another plan, enabling nested workflows. In nested plans, the <code>set_parent</code> method establishes a parent-child relationship, allowing events to propagate up the hierarchy to the parent plan.</p> <p>Aborting a Plan:</p> <p>A plan's execution can be terminated, either programmatically from within a step or handler, or externally by directly calling the <code>abort</code> method. The <code>aborted</code> property can be used to check if a plan has been aborted.</p> <p>Handler Data:</p> <p>Individual handlers may store values that they accumulate or calculate from the events that they handle. Code outside of the handlers, such as the optimization workflow code that runs the steps, can set and retrieve these values using the <code>get</code> and <code>set</code> methods.</p>"},{"location":"reference/plan/#ropt.plan.Plan.aborted","title":"aborted  <code>property</code>","text":"<pre><code>aborted: bool\n</code></pre> <p>Check if the plan was aborted.</p> <p>Determines whether the plan's execution has been aborted.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the plan was aborted; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.optimizer_context","title":"optimizer_context  <code>property</code>","text":"<pre><code>optimizer_context: OptimizerContext\n</code></pre> <p>Return the optimizer context.</p> <p>Retrieves the <code>OptimizerContext</code> object associated with this plan. The optimizer context provides shared state and functionality for executing the optimization plan.</p> <p>Returns:</p> Name Type Description <code>OptimizerContext</code> <code>OptimizerContext</code> <p>The optimizer context object used by the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.__init__","title":"__init__","text":"<pre><code>__init__(\n    optimizer_context: OptimizerContext,\n    parent: Plan | None = None,\n) -&gt; None\n</code></pre> <p>Initialize a plan object.</p> <p>Constructs a new plan, associating it with an <code>OptimizerContext</code> and an optional parent plan.</p> <p>The plan will operate within the provided <code>optimizer_context</code>. If a <code>parent</code> plan is specified, this plan becomes a child, enabling event propagation up the plan hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer_context</code> <code>OptimizerContext</code> <p>The execution context for the plan.</p> required <code>parent</code> <code>Plan | None</code> <p>An optional parent plan.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.Plan.add_handler","title":"add_handler","text":"<pre><code>add_handler(name: str, **kwargs: Any) -&gt; uuid.UUID\n</code></pre> <p>Add a handler to the plan.</p> <p>Constructs and registers a result handler with the plan. The handler's type is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding handler class. Any additional keyword arguments are passed to the handler's constructor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler to add.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for the handler's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>UUID</code> <p>The unique ID of the newly added handler.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_step","title":"add_step","text":"<pre><code>add_step(name: str, **kwargs: Any) -&gt; uuid.UUID\n</code></pre> <p>Add a step to the plan.</p> <p>Registers a step with the plan. The step's type is determined by the provided <code>name</code>, which the plugin system uses to locate the corresponding step class. Any additional keyword arguments are passed to the step's constructor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the step to add.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for the step's constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>UUID</code> <p>uuid.UUID: The unique ID of the newly added step.</p>"},{"location":"reference/plan/#ropt.plan.Plan.handler_exists","title":"handler_exists","text":"<pre><code>handler_exists(name: str) -&gt; bool\n</code></pre> <p>Check if a handler exists.</p> <p>Determines whether a handler with the specified name is supported by the plugin system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the handler exists; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.step_exists","title":"step_exists","text":"<pre><code>step_exists(name: str) -&gt; bool\n</code></pre> <p>Check if a step exists.</p> <p>Determines whether a step with the specified name is supported by the plugin system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the step to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the step exists; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.run_step","title":"run_step","text":"<pre><code>run_step(step: UUID, **kwargs: Any) -&gt; Any\n</code></pre> <p>Run a step in the plan.</p> <p>Executes a specific step within the plan. The step's <code>run</code> method is called with the provided keyword arguments. If the plan has been aborted, a <code>PlanAborted</code> exception is raised before the step is executed.</p> <p>The step is executed only once. The value returned by the step's <code>run</code> method is returned by this method.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>UUID</code> <p>The unique ID of the step to run.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments to pass to the step's <code>run</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value returned by the step's <code>run</code> method.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>step</code> ID is not valid.</p> <code>PlanAborted</code> <p>If the plan has been aborted.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_function","title":"add_function","text":"<pre><code>add_function(func: Callable[..., Any]) -&gt; None\n</code></pre> <p>Add a function to the plan.</p> <p>Registers a user-defined function with the plan. This function can encapsulate a sequence of steps or custom logic. It can be executed later using the <code>run_function</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any]</code> <p>The function to register with the plan.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.has_function","title":"has_function","text":"<pre><code>has_function() -&gt; bool\n</code></pre> <p>Check if a function has been added to the plan.</p> <p>Determines whether a user-defined function has been registered with the plan.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if a function has been added; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.run_function","title":"run_function","text":"<pre><code>run_function(*args: Any, **kwargs: Any) -&gt; Any\n</code></pre> <p>Run a function in the plan.</p> <p>Executes the user-defined function that has been registered with the plan via the <code>add_function</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>Arbitrary positional arguments to pass to the function.</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result returned by the function.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If no function has been added to the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.abort","title":"abort","text":"<pre><code>abort() -&gt; None\n</code></pre> <p>Abort the plan.</p> <p>Prevents further steps in the plan from being executed. This method does not interrupt a currently running step but ensures that no subsequent steps will be initiated. It can be used to halt the plan's execution due to a step failure or external intervention.</p> <p>The <code>aborted</code> property can be used to check if the plan has been aborted.</p>"},{"location":"reference/plan/#ropt.plan.Plan.set_parent","title":"set_parent","text":"<pre><code>set_parent(parent: Plan) -&gt; None\n</code></pre> <p>Set the parent of the plan.</p> <p>Establishes a parent-child relationship between this plan and another plan. This enables event propagation up the plan hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>Plan</code> <p>The parent plan.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.emit_event","title":"emit_event","text":"<pre><code>emit_event(event: Event) -&gt; None\n</code></pre> <p>Emit an event.</p> <p>Emits an event, triggering associated handlers and observers.</p> <p>When this method is called:</p> <ol> <li>All event handlers associated with the plan are invoked.</li> <li>If the plan has no parent, all observer functions registered for the     specified event type are called.</li> <li>If the plan has a parent, the parent plan's <code>emit_event</code> method is     also called, propagating the event up the hierarchy.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event object to emit.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.get","title":"get","text":"<pre><code>get(id_: UUID, /, key: str) -&gt; Any\n</code></pre> <p>Retrieve a value stored in a handler.</p> <p>Retrieves a value stored within a specific result handler. This method uses the <code>[]</code> operator to access the value associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>id_</code> <code>UUID</code> <p>The unique identifier of the handler.</p> required <code>key</code> <code>str</code> <p>The key associated with the value to retrieve.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value associated with the key in the specified handler.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>id_</code> is not a valid handler ID.</p>"},{"location":"reference/plan/#ropt.plan.Plan.set","title":"set","text":"<pre><code>set(id_: UUID, /, key: str, value: Any) -&gt; None\n</code></pre> <p>Set a value in a handler.</p> <p>Stores a value within a specific result handler. This method uses the <code>[]</code> operator to assign the value to the specified key.</p> <p>Parameters:</p> Name Type Description Default <code>id_</code> <code>UUID</code> <p>The unique identifier of the handler.</p> required <code>key</code> <code>str</code> <p>The key to associate with the value.</p> required <code>value</code> <code>Any</code> <p>The value to store.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the provided <code>id_</code> is not a valid handler ID.</p>"},{"location":"reference/plan/#ropt.plan.OptimizerContext","title":"ropt.plan.OptimizerContext","text":"<p>Manages shared state and resources for an optimization plan.</p> <p>The OptimizerContext acts as a central hub for managing shared resources and state across all steps within an optimization plan. This ensures that different parts of the plan can access and interact with the same information and tools.</p> <p>This context object is responsible for:</p> <ul> <li>Providing a callable <code>Evaluator</code> for evaluating functions, which is   essential for optimization algorithms to assess the quality of solutions.   The evaluator is used to calculate the objective function's value and   potentially constraint values for given variables.</li> <li>Managing a <code>PluginManager</code> to retrieve and utilize plugins, allowing for   extensibility and customization of the optimization workflow. Plugins are   modular pieces of code that extend the functionality of the optimization   framework, such as new <code>PlanStep</code> or <code>ResultHandler</code> implementations.</li> <li>Handling event callbacks that are triggered in response to specific events   during the plan's execution. These callbacks are executed after the plan   has processed the event, allowing for actions to be taken in response to   changes or milestones. This allows you to monitor the optimization, react   to changes, or perform custom actions at specific points in the plan's   execution.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>Evaluator</code> <p>A callable for evaluating functions in the plan.</p> required <code>plugin_manager</code> <code>PluginManager | None</code> <p>A plugin manager; a default is created if not provided.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.__init__","title":"__init__","text":"<pre><code>__init__(\n    evaluator: Evaluator,\n    plugin_manager: PluginManager | None = None,\n) -&gt; None\n</code></pre> <p>Initializes the optimization context.</p> <p>Sets up the shared state and resources required for an optimization plan. This includes a function evaluator and a plugin manager.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>Evaluator</code> <p>A callable for evaluating functions in the plan.</p> required <code>plugin_manager</code> <code>PluginManager | None</code> <p>A plugin manager; a default is created if not provided.</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.add_observer","title":"add_observer","text":"<pre><code>add_observer(\n    event: EventType, callback: Callable[[Event], None]\n) -&gt; Self\n</code></pre> <p>Adds an observer function for a specific event type.</p> <p>Observer functions are called when an event of the specified type occurs during optimization. The provided callback function will receive an <code>Event</code> object containing information about the event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>EventType</code> <p>The type of event to observe.</p> required <code>callback</code> <code>Callable[[Event], None]</code> <p>The function to call when the event occurs.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The OptimizerContext instance, allowing for method chaining.</p>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.call_observers","title":"call_observers","text":"<pre><code>call_observers(event: Event) -&gt; None\n</code></pre> <p>Calls all observers for a specific event.</p> <p>This method triggers all observer functions registered for the given event type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit to the observers.</p> required"},{"location":"reference/plan/#ropt.plan.Event","title":"ropt.plan.Event  <code>dataclass</code>","text":"<p>Stores data related to an optimization event.</p> <p>During the execution of an optimization plan, events are triggered to signal specific occurrences. Callbacks can be registered to react to these events and will receive an <code>Event</code> object containing relevant information.</p> <p>The specific data within the <code>Event</code> object varies depending on the event type. See the <code>EventType</code> documentation for details.</p> <p>Attributes:</p> Name Type Description <code>event_type</code> <code>EventType</code> <p>The type of event that occurred.</p> <code>config</code> <code>EnOptConfig</code> <p>The configuration used for the optimization.</p> <code>source</code> <code>UUID</code> <p>The ID of the step that triggered the event.</p> <code>data</code> <code>dict[str, Any]</code> <p>A dictionary containing additional event-specific data.</p>"},{"location":"reference/plan_plugins/","title":"Plan Plugins","text":""},{"location":"reference/plan_plugins/#ropt.plugins.plan","title":"ropt.plugins.plan","text":"<p>Plugin functionality for adding plan objects.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base","title":"ropt.plugins.plan.base","text":"<p>This module defines the base classes for optimization plan plugins.</p> <p>Optimization plan steps and result handlers can be added via the plugin mechanism to implement additional functionality. This is done by creating plugin classes that derive from the <code>PlanHandlerPlugin</code> and <code>PlanStepPlugin</code> classes.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep","title":"PlanStep","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for steps.</p> <p>steps loaded and created by the plugin manager must inherit from this abstract base class. It defines a <code>run</code> method that must be overridden to implement the specific functionality of each step.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.id","title":"id  <code>property</code>","text":"<pre><code>id: UUID\n</code></pre> <p>Return the unique identifier of the handler.</p> <p>Each handler instance is assigned a unique ID upon creation. This ID can be used to distinguish between different handler instances.</p> <p>Returns:</p> Type Description <code>UUID</code> <p>A UUID object representing the unique identifier of the handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.plan","title":"plan  <code>property</code>","text":"<pre><code>plan: Plan\n</code></pre> <p>Return the plan that executes the step.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The plan object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize the step.</p> <p>The <code>plan</code> argument is accessible as the <code>plan</code> property.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The parent plan that manages this step.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.run","title":"run  <code>abstractmethod</code>","text":"<pre><code>run(*args: Any, **kwargs: Any) -&gt; None\n</code></pre> <p>Execute the step object.</p> <p>This method must be overloaded to implement the functionality of the step.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>Optional positional arguments.</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments.</p> <code>{}</code>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler","title":"ResultHandler","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for result handler objects.</p> <p>Result handlers loaded and created by the plugin manager must inherit from this abstract base class. It defines a <code>handle_event</code> method that must be overridden to implement specific functionality.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.id","title":"id  <code>property</code>","text":"<pre><code>id: UUID\n</code></pre> <p>Return the unique identifier of the handler.</p> <p>Each handler instance is assigned a unique ID upon creation. This ID can be used to distinguish between different handler instances.</p> <p>Returns:</p> Type Description <code>UUID</code> <p>A UUID object representing the unique identifier of the handler.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.plan","title":"plan  <code>property</code>","text":"<pre><code>plan: Plan\n</code></pre> <p>Return the associated plan that executes the handler.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The plan object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.__init__","title":"__init__","text":"<pre><code>__init__(plan: Plan) -&gt; None\n</code></pre> <p>Initialize a results handler.</p> <p>The <code>plan</code> argument is accessible as the <code>plan</code> property.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>Plan</code> <p>The parent plan that contains the object.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.handle_event","title":"handle_event  <code>abstractmethod</code>","text":"<pre><code>handle_event(event: Event) -&gt; None\n</code></pre> <p>Handle and propagate an event.</p> <p>This method must be overloaded to implement the functionality of the handler, based on the information passed via the event object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key: str) -&gt; Any\n</code></pre> <p>Get the value of a plan variable.</p> <p>This method implements the <code>[]</code> operator on the handler object to retrieve the value associated with a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to retrieve.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value corresponding to the key.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key: str, value: Any) -&gt; None\n</code></pre> <p>Set a plan variable to the given value.</p> <p>This method implements the <code>[]</code> operator on the handler object to store arbitrary values.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set.</p> required <code>value</code> <code>Any</code> <p>The value to store.</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandlerPlugin","title":"PlanHandlerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for plan handler plugins.</p> <p>This base class serves as the foundation for handler plugins used in an optimization plan. Any plugin derived from this class can be built-in, installed via a plugin mechanism, or dynamically loaded. During the execution of an optimization plan, the required plugin is located through the <code>PluginManager</code>, which then uses the plugin's <code>create_*</code> functions to instantiate  a <code>ResultHandler</code>.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanHandlerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    name: str, plan: Plan, **kwargs: Any\n) -&gt; ResultHandler\n</code></pre> <p>Create a result handler.</p> <p>This factory function instantiates result handler object based on the provided configuration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the handler.</p> required <code>plan</code> <code>Plan</code> <p>The plan in which the handler operates.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments to pass to the handler.</p> <code>{}</code>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStepPlugin","title":"PlanStepPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for plan step plugins.</p> <p>This base class serves as the foundation for step plugins used in an optimization plan. Any plugin derived from this class can be built-in, installed via a plugin mechanism, or dynamically loaded. During the execution of an optimization plan, the required plugin is located through the <code>PluginManager</code>, which then uses the plugin's <code>create_*</code> functions to instantiate a <code>PlanStep</code>.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStepPlugin.create","title":"create  <code>abstractmethod</code>","text":"<pre><code>create(name: str, plan: Plan, **kwargs: Any) -&gt; PlanStep\n</code></pre> <p>Create a result handler.</p> <p>This factory function instantiates result handler object based on the provided configuration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the step.</p> required <code>plan</code> <code>Plan</code> <p>The plan in which the step operates.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments to pass to the step.</p> <code>{}</code>"},{"location":"reference/plugin_manager/","title":"Plugins","text":""},{"location":"reference/plugin_manager/#ropt.plugins","title":"ropt.plugins","text":"<p>The <code>plugins</code> module facilitates the integration of <code>ropt</code> plugins.</p> <p>The core functionality of <code>ropt</code> can be extended through plugins, which can either be builtin, separately installed, or dynamically added at runtime. Currently, <code>ropt</code> supports the following plugin types to implement specific types of functionality:</p> <code>optimizer</code>: Plugins that implement specific optimization methods. The builtin   <code>scipy</code> plugin utilizes the   <code>scipy.optimize</code> module to implement various optimization algorithms. <code>sampler</code>: Plugins responsible for generating perturbations for estimating gradients.   The builtin <code>scipy</code> plugin is based   on <code>scipy.stats</code>,   providing various sampling methods. <code>realization_filter</code>: These plugins implement filters for selecting a sub-set of realizations used   in calculating objective or constraint functions and their gradients. The   included   <code>default</code>   plugin provides filters based on ranking and for CVaR optimization. <code>function_estimator</code>: These plugins calculate the final objective and gradient from sets of   objectives or constraints and their gradients for individual realizations. The   included   <code>default</code>   plugin supports objectives defined by the mean or standard deviation of these   values. <code>plan</code>: Plan plugins implement the objects that execute an optimization plan.   The built-in <code>default</code>   handler and <code>default</code> step   plugins offer a full set of optimization plan objects for executing complex   optimization plans. <p>Plugins are managed by the <code>PluginManager</code> class. This class is used to retrieve plugin objects that derive from an abstract base class defining the required functionality for each plugin type:</p> <ol> <li><code>OptimizerPlugin</code>:     Abstract base class for optimizer plugins.</li> <li><code>SamplerPlugin</code>:     Abstract base class for sampler plugins.</li> <li><code>RealizationFilterPlugin</code>:     Abstract base class for realization filter plugins.</li> <li><code>FunctionEstimatorPlugin</code>:     Abstract base class for function estimator plugins.</li> <li><code>PlanHandlerPlugin</code>:     Abstract base class for optimization plan object plugins.</li> <li><code>PlanStepPlugin</code>:     Abstract base class for optimization plan object plugins.</li> </ol> <p>Plugins can be built-in, installed separately using the standard entry points mechanism, or added dynamically using the <code>add_plugin</code> method.</p> <p>The plugin manager object provides the <code>get_plugin</code> method, which <code>ropt</code> uses to retrieve the necessary plugin based on its type and name. Given the plugin's type and name, this method returns a callable (either a class or a factory function) that <code>ropt</code> uses to instantiate the plugin when needed.</p> Plugin and method names <p>Plugins are registered by name by plugin manager objects. Plugins may implement multiple methods, each of which should also be identified by a name. <code>PluginManager.get_plugin</code> and <code>PluginManager.is_supported</code> accept method names and will search through the available plugins to find the correct plugin code. To refer to a method method-name of a given plugin plugin-name, a string in the form \"plugin-name/method-name\" can be used instead. In this case, the plugin manager will not search through all plugins for the requested method but will only inquire with the plugin plugin-name. By convention, using \"default\" for the method name in such a string will select the default method of the plugin.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager","title":"PluginManager","text":"<p>The plugin manager.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the plugin manager.</p> <p>The plugin manager object is initialized via the entry points mechanism (see <code>importlib.metadata</code>).</p> <p>For instance, to install an additional optimizer plugin, implemented in an independent package, and assuming installation via a <code>pyproject.toml</code> file, add the following:</p> <p><pre><code>[project.entry-points.\"ropt.plugins.optimizer\"]\nmy_optimizer = \"my_optimizer_pkg.my_plugin:MyOptimizer\"\n</code></pre> This will make the <code>MyOptimizer</code> class from the <code>my_optimizer_pkg</code> package available under the name <code>my_optimizer</code>. The <code>MyOptimizer</code> class will be used to create <code>OptimizerPlugin</code> objects.</p> <p>Plugins can also be added dynamically using the <code>add_plugin</code> method.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.add_plugin","title":"add_plugin","text":"<pre><code>add_plugin(\n    plugin_type: PluginType,\n    name: str,\n    plugin: type[Plugin],\n    *,\n    prioritize: bool = False,\n) -&gt; None\n</code></pre> <p>Add a plugin at runtime.</p> <p>This method adds a plugins of a specific type to the plugin manager. Normally it will be added at the end of the internal list of plugins that may be searched for a method. However, if the <code>prioritize</code> keyword is set, it will be added at the beginning of the list.</p> <p>The plugin names are case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>Type of the plugin.</p> required <code>name</code> <code>str</code> <p>The name of the plugin.</p> required <code>plugin</code> <code>type[Plugin]</code> <p>The plugin object.</p> required <code>prioritize</code> <code>bool</code> <p>If <code>True</code>, the plugin will be added to the beginning of list.</p> <code>False</code>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.get_plugin","title":"get_plugin","text":"<pre><code>get_plugin(plugin_type: PluginType, method: str) -&gt; Any\n</code></pre> <p>Retrieve a plugin by type and method name.</p> <p>If the method name is of the form \"plugin-name/method-name\", the method method-name will be retrieved from the given plugin plugin-name.</p> <p>If the given method name does not contain a slash (/), the plugin manager will search through all plugins and return the first plugin that supports the requested method. Searching occurs in the order that plugins were added to the manager, which normally will be one of the plugins loaded via entry points, but plugins added dynamically can be prioritized.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of the plugin to retrieve.</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin should provide.</p> required"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.is_supported","title":"is_supported","text":"<pre><code>is_supported(plugin_type: PluginType, method: str) -&gt; bool\n</code></pre> <p>Check if a method is supported.</p> <p>If the given method name does not contain a slash (/), the plugin manager will search through all plugins and return <code>True</code> if a plugin is found that supports the requested method. If the method name is of the form \"plugin-name/method-name\", <code>True</code> will be returned if the method method-name is supported by the given plugin plugin-name.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of the plugin to retrieve.</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin should provide.</p> required"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.plugins","title":"plugins","text":"<pre><code>plugins(\n    plugin_type: PluginType,\n) -&gt; Generator[tuple[str, type[Plugin]], None, None]\n</code></pre> <p>Generate a sequence of all plugins of a specified type.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of plugins to return.</p> required <p>Yields:</p> Type Description <code>tuple[str, type[Plugin]]</code> <p>A tuple of the plugin name and object.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginType","title":"PluginType  <code>module-attribute</code>","text":"<pre><code>PluginType = Literal[\n    \"optimizer\",\n    \"sampler\",\n    \"realization_filter\",\n    \"function_estimator\",\n    \"plan_handler\",\n    \"plan_step\",\n]\n</code></pre> <p>Plugin Types Supported by <code>ropt</code></p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin","title":"Plugin","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for plugins.</p> <p><code>ropt</code>  plugins should derive from this base class, which specifies an <code>is_supported</code> method.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.is_supported","title":"is_supported  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>is_supported(method: str) -&gt; bool\n</code></pre> <p>Check whether a given method is supported.</p> <p>This method is called by the <code>is_supported</code> method of <code>PluginManager</code> objects to verify if a specific method is supported by this plugin.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The name of the method to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the method is supported; otherwise, False.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.allows_discovery","title":"allows_discovery  <code>classmethod</code>","text":"<pre><code>allows_discovery() -&gt; bool\n</code></pre> <p>Check if the plugin can be discovered automatically.</p> <p>Normally, plugins may be discovered automatically by the plugin manager by checking if they support a specific method. However, some plugins may not support this behavior and should be explicitly requested. These should override this property to return <code>False</code>.</p> <p>For example, the <code>external</code> optimizer plugin does not define its own methods but launches methods from other plugins as an external process. Therefore, the <code>external</code> optimizer plugin must always be specified explicitly, and this method is overloaded to return False.</p>"},{"location":"reference/realization_filter_plugins/","title":"Realization Filter Plugins","text":""},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter","title":"ropt.plugins.realization_filter","text":"<p>Plugin functionality for adding realization filters.</p> <p>This package contains the abstract base class for realization filter plugins, and the default realization filters that are part of <code>ropt</code>.</p> <p>Realization filters are used by the optimizer to determine how a set of realizations should be used to calculate objective and constraint function values. They do this by calculating the weights that should be used for each realization when calculating the values of a given set of objectives and constraints.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base","title":"ropt.plugins.realization_filter.base","text":"<p>This module defines the abstract base class for realization filters.</p> <p>Realization filters can be added via the plugin mechanism to implement additional ways to filter the realizations that are used to calculate functions and gradients. Any object that derives from the <code>RealizationFilterPlugin</code> abstract base class may be installed as a plugin.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin","title":"RealizationFilterPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for realization filter classes.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig, filter_index: int\n) -&gt; None\n</code></pre> <p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>filter_index</code> <code>int</code> <p>The index of the filter to use.</p> required"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin.get_realization_weights","title":"get_realization_weights  <code>abstractmethod</code>","text":"<pre><code>get_realization_weights(\n    objectives: NDArray[float64],\n    constraints: NDArray[float64] | None,\n) -&gt; NDArray[np.float64]\n</code></pre> <p>Return the updated weights of the realizations.</p> <p>This method is called by the optimizer with the current values of the objectives and constraints. Based on these values it must decide how much weight each realization should be given, and return those as a vector.</p> <p>The objectives and the constraints are passed as matrices, where the columns contain the values of the objectives or constraints. The index along the row axis corresponds to the number of the realization.</p> Normalization <p>The weights will be normalized to a sum of one by the optimizer before use, hence any non-negative weight value is permissable.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objectives of all realizations.</p> required <code>constraints</code> <code>NDArray[float64] | None</code> <p>The constraints for all realizations.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A vector of weights of the realizations.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig, filter_index: int\n) -&gt; RealizationFilterPlugin\n</code></pre> <p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>filter_index</code> <code>int</code> <p>The index of the filter to use.</p> required"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.default","title":"ropt.plugins.realization_filter.default","text":"<p>This plugin contains realization filters that are installed by default.</p>"},{"location":"reference/results/","title":"Optimization Results","text":""},{"location":"reference/results/#ropt.results","title":"ropt.results","text":"<p>Data classes for storing intermediate optimization results.</p> <p>During the optimization process, the calculation of functions and gradients generates data that needs to be reported. To facilitate this, new results are passed to callbacks as a sequence of <code>Results</code> objects. These objects can be instances of either the <code>FunctionResults</code> or <code>GradientResults</code> classes, which store the results of function and gradient evaluations, respectively.</p> <p>Much of the data within these result objects is multi-dimensional. For example, the <code>objectives</code> field, which is part of the nested <code>evaluations</code> object within <code>FunctionResults</code>, is a two-dimensional <code>numpy</code> array. In this array, each column represents a different objective, and each row corresponds to a specific realization number.</p> <p>To simplify exporting and reporting, the identity of the axes in these multi-dimensional arrays is stored as metadata associated with each field. These fields are derived from the <code>ResultField</code> class, which provides a <code>get_axes</code> class method for retrieving the axes. For instance, for the <code>objectives</code> field, this method would return:</p> <p><pre><code>&gt;&gt;&gt; from ropt.results import FunctionEvaluations\n&gt;&gt;&gt; FunctionEvaluations.get_axes(\"objectives\")\n(&lt;ResultAxis.REALIZATION: 'realization'&gt;, &lt;ResultAxis.OBJECTIVE: 'objective'&gt;)\n</code></pre> Given that the first axis denotes realizations and the second axis denotes objectives, each row in the array represents the set of objective values for a specific realization. This metadata provides the necessary context for exporting and reporting code to associate each element in the result matrix with its corresponding realization and objective, as specified in the optimizer configuration. The pandas exporting code, for example, utilizes this information to construct a multi-index for the output DataFrame and to transform the multi-dimensional data into multiple columns.</p>"},{"location":"reference/results/#ropt.results.Results","title":"ropt.results.Results  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for storing optimization results.</p> <p>The <code>Results</code> class serves as a foundation for storing various types of optimization results. It is not intended to be instantiated directly but rather serves as a base for derived classes like <code>FunctionResults</code> and <code>GradientResults</code>, which hold the actual data.</p> <p>This class provides storage for the following generic information:</p> <ul> <li>Batch ID: An optional identifier, potentially generated by the     function evaluator, that uniquely identifies a group of function     evaluations passed to the evaluator by teh optimizer.</li> <li>Metadata: A dictionary for storing additional information generated     during optimization. This metadata can include various primitive values     that are not directly interpreted by the optimization code but are     useful for reporting and analysis.</li> </ul> <p>The derived classes, <code>FunctionResults</code> and <code>GradientResults</code>, extend this base class with specific attributes for storing function evaluation results and gradient evaluation results, respectively. These derived classes also provide methods for exporting the stored data.</p> <p>One key method provided by the <code>Results</code> class is <code>to_dataframe</code>, which allows exporting the contents of a specific field, or a subset of its sub-fields, to a <code>pandas</code> DataFrame for further data analysis and reporting.</p> <p>Attributes:</p> Name Type Description <code>batch_id</code> <code>int | None</code> <p>The ID of the evaluation batch.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>A dictionary of metadata.</p>"},{"location":"reference/results/#ropt.results.Results.transform_from_optimizer","title":"transform_from_optimizer  <code>abstractmethod</code>","text":"<pre><code>transform_from_optimizer(\n    transforms: OptModelTransforms,\n) -&gt; Results\n</code></pre> <p>Transform results from the optimizer domain to the user domain.</p> <p>During optimization, variables, objectives, and constraints are often transformed to a different domain (the optimizer domain) to enhance the performance and stability of the optimization algorithm. The <code>Results</code> objects produced during optimization are initially in the optimizer domain. This method reverses these transformations, mapping the results back to the user-defined domain. The transformations between the user and optimizer domains are defined by the classes in the <code>ropt.transforms</code> module.</p> <p>For instance, variables might have been scaled and shifted to a range more suitable for the optimizer. This method, using the provided <code>OptModelTransforms</code> object, applies the inverse scaling and shifting to restore the variables to their original scale and offset. Similarly, objectives and constraints are transformed back to the user domain.</p> <p>These transformations are defined and managed by the <code>OptModelTransforms</code> object, which encapsulates the specific transformations for variables, objectives, and nonlinear constraints.</p> <p>Parameters:</p> Name Type Description Default <code>transforms</code> <code>OptModelTransforms</code> <p>The <code>OptModelTransforms</code> object containing the domain transformations to apply.</p> required <p>Returns:</p> Type Description <code>Results</code> <p>A new <code>FunctionResults</code> object with all relevant data transformed</p> <code>Results</code> <p>back to the user domain.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe(\n    field_name: str,\n    select: Iterable[str],\n    unstack: Iterable[ResultAxis] | None = None,\n    names: dict[str, Sequence[str | int] | None]\n    | None = None,\n) -&gt; pd.DataFrame\n</code></pre> <p>Export a field to a pandas DataFrame.</p> <p>Exports the values of a single field to a <code>pandas</code> DataFrame. The field to export is selected by the <code>field_name</code> argument. Typically, such a field contains multiple sub-fields. By default, all sub-fields are exported as columns in the DataFrame, but a subset can be selected using the <code>select</code> argument.</p> <p>Sub-fields may be multi-dimensional arrays, which are exported in a stacked manner. Using the axis types found in the metadata, the exporter constructs a multi-index labeled with the corresponding names provided via the <code>names</code> argument. If <code>names</code> is <code>None</code>, numerical indices are used. These multi-indices can optionally be unstacked into multiple columns by providing the axis types to unstack via the <code>unstack</code> argument.</p> The DataFrame Index <p>The index of the resulting DataFrame may be a multi-index constructed from axis indices or labels. In addition, the <code>batch_id</code> (if not <code>None</code>) is prepended to the index.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field to export.</p> required <code>select</code> <code>Iterable[str]</code> <p>Select the sub-fields to export. By default, all         sub-fields are exported.</p> required <code>unstack</code> <code>Iterable[ResultAxis] | None</code> <p>Select axes to unstack. By default, no axes are         unstacked.</p> <code>None</code> <code>names</code> <code>dict[str, Sequence[str | int] | None] | None</code> <p>A dictionary mapping axis types to names.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>pandas</code> module is not installed.</p> <code>ValueError</code> <p>If the field name is incorrect.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas</code> DataFrame containing the results.</p> Warning <p>This function requires the <code>pandas</code> module to be installed.</p>"},{"location":"reference/results/#ropt.results.ResultField","title":"ropt.results.ResultField  <code>dataclass</code>","text":"<p>Base class for fields within <code>Results</code> objects.</p> <p>The <code>ResultField</code> class serves as a foundation for defining the various data fields that can be stored within <code>Results</code> objects. These fields typically hold multi-dimensional numerical data, such as objective values, constraint values, or gradients.</p> <p>This class provides a standardized way to:</p> <ul> <li>Store metadata about the axes of multi-dimensional arrays.</li> <li>Retrieve the axes associated with a specific field.</li> </ul> <p>Derived classes, such as <code>FunctionEvaluations</code> or <code>Gradients</code>, extend this base class to define specific data structures for different types of optimization results.</p>"},{"location":"reference/results/#ropt.results.ResultField.get_axes","title":"get_axes  <code>classmethod</code>","text":"<pre><code>get_axes(name: str) -&gt; tuple[ResultAxis, ...]\n</code></pre> <p>Retrieve the axes associated with a specific field.</p> <p>Fields within a <code>ResultField</code> object that store multi-dimensional <code>numpy</code> arrays, contain metadata that describes the meaning of each dimension in the array. This method retrieves the axes of a field within a ResultField object from that meta-data, returning a tuple of <code>ResultAxis</code>][ropt.enums.ResultAxis] enums.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the field (sub-field) within the   <code>ResultField</code> instance or class.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided field name is not recognized.</p> <p>Returns:</p> Type Description <code>tuple[ResultAxis, ...]</code> <p>A tuple of <code>ResultAxis</code> enums, representing the axes of the field.</p>"},{"location":"reference/results/#ropt.results.FunctionResults","title":"ropt.results.FunctionResults  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>Stores results related to function evaluations.</p> <p>The <code>FunctionResults</code> class extends the base <code>Results</code> class to store data specific to function evaluations. This includes:</p> <ul> <li>Evaluations: The results of the function evaluations, including the   variable values, objective values, and constraint values for each   realization. See   <code>FunctionEvaluations</code>.</li> <li>Realizations: Information about the realizations, such as weights for   objectives and constraints, and whether each realization was successful.   See <code>Realizations</code>.</li> <li>Functions: The calculated objective and constraint function values,   typically aggregated across realizations. See   <code>Functions</code>.</li> <li>Constraint Info: Details about constraint differences and violations.   See <code>ConstraintInfo</code>.</li> </ul> <p>Attributes:</p> Name Type Description <code>evaluations</code> <code>FunctionEvaluations</code> <p>Results of the function evaluations.</p> <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations.</p> <code>functions</code> <code>Functions | None</code> <p>The calculated functions.</p> <code>constraint_info</code> <code>ConstraintInfo | None</code> <p>Information on constraint differences and violations.</p>"},{"location":"reference/results/#ropt.results.GradientResults","title":"ropt.results.GradientResults  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>Stores results related to gradient evaluations.</p> <p>The <code>GradientResults</code> class extends the base <code>Results</code> class to store data specific to gradient evaluations. This includes:</p> <ul> <li>Evaluations: The results of the function evaluations for perturbed   variables, including the perturbed variable values, objective values, and   constraint values for each realization and perturbation. See   <code>GradientEvaluations</code>.</li> <li>Realizations: Information about the realizations, such as weights for   objectives and constraints, and whether each realization was successful.   See <code>Realizations</code>.</li> <li>Gradients: The calculated gradients of the objectives and constraints.   See <code>Gradients</code>.</li> </ul> <p>Attributes:</p> Name Type Description <code>evaluations</code> <code>GradientEvaluations</code> <p>Results of the function evaluations for perturbed           variables.</p> <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations.</p> <code>gradients</code> <code>Gradients | None</code> <p>The calculated gradients.</p>"},{"location":"reference/results/#ropt.results.Functions","title":"ropt.results.Functions  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the calculated objective and constraint function values.</p> <p>The <code>Functions</code> class stores the calculated values of the objective and constraint functions. These values are typically derived from the evaluations performed across all realizations, often through a process like averaging. The optimizer may handle multiple objectives and constraints. Multiple objectives are combined into a single weighted sum, which is stored in the <code>weighted_objective</code> field. Multiple constraints are handled individually by the optimizer.</p> <p>Attributes:</p> Name Type Description <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective values.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each individual objective.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The value of each individual constraint.</p>"},{"location":"reference/results/#ropt.results.Gradients","title":"ropt.results.Gradients  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the calculated objective and constraint gradients.</p> <p>The <code>Gradients</code> class stores the calculated gradients of the objective and constraint functions. These gradients are typically derived from function evaluations across all realizations, often through a process like averaging. The optimizer may handle multiple objectives and constraints. Multiple objective gradients are combined into a single weighted sum, which is stored in the <code>weighted_objective</code> field. Multiple constraint gradients are handled individually by the optimizer.</p> <p>Attributes:</p> Name Type Description <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective gradients.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The gradient of each individual objective.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The gradient of each individual constraint.</p>"},{"location":"reference/results/#ropt.results.FunctionEvaluations","title":"ropt.results.FunctionEvaluations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the results of function evaluations.</p> <p>The <code>FunctionEvaluations</code> class stores the results of evaluating the objective and constraint functions for a set of variables. It includes the following information:</p> <ul> <li>Variables: The vector of variable values at which the functions were   evaluated.</li> <li>Objectives: The calculated objective function values for each   realization. This is a two-dimensional array where each row corresponds to   a realization and each column corresponds to an objective.</li> <li>Constraints: The calculated constraint function values for each   realization. This is a two-dimensional array where each row corresponds to   a realization and each column corresponds to a constraint.</li> <li>Evaluation Info: Optional metadata associated with each realization,   potentially provided by the evaluator. If provided, each value in the info   dictionary must be a one-dimensional array with a length equal to the   number of realizations.</li> </ul> <p>Attributes:</p> Name Type Description <code>variables</code> <code>NDArray[float64]</code> <p>The variable vector.</p> <code>objectives</code> <code>NDArray[float64]</code> <p>The objective function values for each realization.</p> <code>constraints</code> <code>NDArray[float64] | None</code> <p>The constraint function values for each realization.</p> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional metadata for each evaluated realization.</p>"},{"location":"reference/results/#ropt.results.GradientEvaluations","title":"ropt.results.GradientEvaluations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores the results of evaluations for gradient calculations.</p> <p>The <code>GradientEvaluations</code> class stores the results of evaluating the objective and constraint functions for perturbed variables, which is necessary for gradient calculations. It contains the following information:</p> <ul> <li>Variables: The vector of unperturbed variable values.</li> <li>Perturbed Variables: A three-dimensional array of perturbed variable   values. The axes represent (in order): realization, perturbation, and   variable.</li> <li>Perturbed Objectives: The calculated objective function values for   each realization and perturbation. This is a three-dimensional array where   the axes represent (in order): realization, perturbation, and objective.</li> <li>Perturbed Constraints: The calculated constraint function values for   each realization and perturbation. This is a three-dimensional array where   the axes represent (in order): realization, perturbation, and constraint.</li> <li>Evaluation Info: Optional metadata associated with each realization   and perturbation, potentially provided by the evaluator. If provided, each   value in the <code>evaluation_info</code> dictionary must be a two-dimensional array   where the rows correspond to perturbations and the second columns   correspond to realizations.</li> </ul> <p>Attributes:</p> Name Type Description <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> <code>perturbed_variables</code> <code>NDArray[float64]</code> <p>The perturbed variable values for each                    realization and perturbation.</p> <code>perturbed_objectives</code> <code>NDArray[float64]</code> <p>The objective function values for each                    realization and perturbation.</p> <code>perturbed_constraints</code> <code>NDArray[float64] | None</code> <p>The constraint function values for each                    realization and perturbation.</p> <code>evaluation_info</code> <code>dict[str, NDArray[Any]]</code> <p>Optional metadata for each evaluated                    realization and perturbation.</p>"},{"location":"reference/results/#ropt.results.Realizations","title":"ropt.results.Realizations  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores information about the realizations.</p> <p>The <code>Realizations</code> class stores data related to the individual realizations used in the optimization process. This includes:</p> <ul> <li>Failed Realizations: A boolean array indicating whether each   realization's evaluation was successful. <code>True</code> indicates a failed   realization, while <code>False</code> indicates a successful one.</li> <li>Objective Weights: A two-dimensional array of weights used for each   objective in each realization. The first axis corresponds to the   objectives, and the second axis corresponds to the realizations. These   weights may change during optimization, depending on the type of objective   calculation.</li> <li>Constraint Weights: A two-dimensional array of weights used for each   constraint in each realization. The first axis corresponds to the   constraints, and the second axis corresponds to the realizations. These   weights may change during optimization, depending on the type of   constraint calculation.</li> </ul> <p>Attributes:</p> Name Type Description <code>failed_realizations</code> <code>NDArray[bool_]</code> <p>Boolean array indicating failed realizations.</p> <code>objective_weights</code> <code>NDArray[float64] | None</code> <p>Weights for each objective in each realization.</p> <code>constraint_weights</code> <code>NDArray[float64] | None</code> <p>Weights for each constraint in each realization.</p>"},{"location":"reference/results/#ropt.results.ConstraintInfo","title":"ropt.results.ConstraintInfo  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Stores information about constraint differences and violations.</p> <p>The <code>ConstraintInfo</code> class stores the differences between variable or  constraint values and their respective bounds. It also calculates and  stores constraint violations. This information is useful for assessing  how well the optimization process is satisfying the imposed constraints.</p> <p>The class stores the following information:</p> <ul> <li> <p>Bound Differences: The differences between the variable values and    their lower and upper bounds.</p> <ul> <li><code>bound_lower</code>: The difference between the variable values and their   lower bounds. A negative value indicates that the variable is below its   lower bound.</li> <li><code>bound_upper</code>: The difference between the variable values and their   upper bounds. A positive value indicates that the variable is above its   upper bound.</li> </ul> </li> <li> <p>Linear Constraint Differences: The differences between the linear    constraint values and their lower and upper bounds.</p> <ul> <li><code>linear_lower</code>: The difference between the linear constraint values   and their lower bounds. A negative value indicates that the constraint   is below its lower bound.</li> <li><code>linear_upper</code>: The difference between the linear constraint values and   their upper bounds. A positive value indicates that the constraint is   above its upper bound.</li> </ul> </li> <li> <p>Nonlinear Constraint Differences: The differences between the    nonlinear constraint values and their lower and upper bounds.</p> <ul> <li><code>nonlinear_lower</code>: The difference between the nonlinear constraint   values and their lower bounds. A negative value indicates that the   constraint is below its lower bound.</li> <li><code>nonlinear_upper</code>: The difference between the nonlinear constraint   values and their upper bounds. A positive value indicates that the   constraint is above its upper bound.</li> </ul> </li> <li> <p>Constraint Violations: The magnitude of the constraint violations.</p> <ul> <li><code>bound_violation</code>: The magnitude of the violation of the variable   bounds.</li> <li><code>linear_violation</code>: The magnitude of the violation of the linear    constraints.</li> <li><code>nonlinear_violation</code>: The magnitude of the violation of the nonlinear   constraints.</li> </ul> </li> </ul> <p>Attributes:</p> Name Type Description <code>bound_lower</code> <code>NDArray[float64] | None</code> <p>Difference between variables and their lower bounds.</p> <code>bound_upper</code> <code>NDArray[float64] | None</code> <p>Difference between variables and their upper bounds.</p> <code>linear_lower</code> <code>NDArray[float64] | None</code> <p>Difference between linear constraints and their lower                 bounds.</p> <code>linear_upper</code> <code>NDArray[float64] | None</code> <p>Difference between linear constraints and their upper                 bounds.</p> <code>nonlinear_lower</code> <code>NDArray[float64] | None</code> <p>Difference between nonlinear constraints and their                 lower bounds.</p> <code>nonlinear_upper</code> <code>NDArray[float64] | None</code> <p>Difference between nonlinear constraints and their                 upper bounds.</p> <code>bound_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the variable bounds.</p> <code>linear_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the linear constraints.</p> <code>nonlinear_violation</code> <code>NDArray[float64] | None</code> <p>Magnitude of the violation of the nonlinear constraints.</p>"},{"location":"reference/results/#ropt.results.results_to_dataframe","title":"ropt.results.results_to_dataframe","text":"<pre><code>results_to_dataframe(\n    results: Sequence[Results],\n    fields: set[str],\n    result_type: Literal[\"functions\", \"gradients\"],\n    names: dict[str, Sequence[str | int] | None]\n    | None = None,\n) -&gt; pd.DataFrame\n</code></pre> <p>Combine a sequence of results into a single pandas DataFrame.</p> <p>This function aggregates results from multiple <code>FunctionResults</code> or <code>GradientResults</code> objects into a single <code>pandas</code> DataFrame. It is designed to be used with observers that produce results during the optimization process.</p> <p>The <code>fields</code> argument determines which data fields to include in the DataFrame. These fields can be any of the attributes defined within <code>FunctionResults</code> or <code>GradientResults</code>. Nested fields are specified using dot notation (e.g., <code>evaluations.variables</code> to include the <code>variables</code> field within the <code>evaluations</code> object).</p> <p>The <code>evaluation_info</code> sub-fields, found within the <code>evaluations</code> fields of <code>functions</code> and <code>gradient</code> results, respectively, are dictionaries. To include specific keys from these dictionaries, use the format <code>evaluations.evaluation_info.key</code>, where <code>key</code> is the name of the desired key.</p> <p>Many fields may result in multiple columns in the DataFrame. For example, <code>evaluations.variables</code> will generate a separate column for each variable. If available, variable names will be used as column labels. Multi-dimensional fields, such as those with named realizations and objectives, will have column names that are tuples of the corresponding names.</p> <p>The <code>result_type</code> argument specifies whether to include function evaluation results (<code>functions</code>) or gradient results (<code>gradients</code>).</p> <p>The <code>names</code> argument is an optional dictionary that maps axis types to names. These names are used to label the multi-index columns in the resulting DataFrame. If not provided, numerical indices are used.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Sequence[Results]</code> <p>A sequence of <code>Results</code> objects          to combine.</p> required <code>fields</code> <code>set[str]</code> <p>The names of the fields to include in the DataFrame.</p> required <code>result_type</code> <code>Literal['functions', 'gradients']</code> <p>The type of results to include (\"functions\" or          \"gradients\").</p> required <code>names</code> <code>dict[str, Sequence[str | int] | None] | None</code> <p>A dictionary mapping axis types to names.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas</code> DataFrame containing the combined results.</p>"},{"location":"reference/sampler_plugins/","title":"SamplerPlugin Plugins","text":""},{"location":"reference/sampler_plugins/#ropt.plugins.sampler","title":"ropt.plugins.sampler","text":"<p>Plugin functionality for adding sampler plugins.</p> <p>SamplerPlugin plugins are managed by a <code>PluginManager</code> object, which returns classes or factory functions to create objects that implement one or more sampling methods to produce perturbations. These objects must adhere to the <code>SamplerPlugin</code> abstract base class.</p> <p>Samplers can be added via the plugin manager, by default the <code>SciPySamplerPlugin</code> plugin is installed which provides a number of methods from the <code>scipy.stats</code> package.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base","title":"ropt.plugins.sampler.base","text":"<p>This module defines the abstract base class for samplers.</p> <p>Samplers can be added via the plugin mechanism to implement additional ways to generate perturbed variables. Any object that follows the <code>SamplerPlugin</code> abstract base class may be installed as a plugin.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin","title":"SamplerPlugin","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for sampler classes.</p> <p><code>ropt</code> employs plugins to implement samplers that are called during an optimization plan to generate perturbed variable vectors. Samplers should derive from the <code>SamplerPlugin</code> base class, which specifies the requirements for the class constructor (<code>__init__</code>) and also includes a <code>generate_samples</code> method used to generate samples used to create perturbed values.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin.__init__","title":"__init__","text":"<pre><code>__init__(\n    enopt_config: EnOptConfig,\n    sampler_index: int,\n    mask: NDArray[bool_] | None,\n    rng: Generator,\n) -&gt; None\n</code></pre> <p>Initialize the sampler object.</p> <p>The <code>samplers</code> field in the <code>enopt_config</code> configuration used by the optimization is a tuple of sampler configurations (see <code>SamplerConfig</code>). The <code>sampler_index</code> field is used to identify the configuration to use to initialize this sampler.</p> <p>The sampler may be used for a subset of the variables. The boolean <code>mask</code> array indicates the variables that are handled by this sampler.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler to use.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>The mask of the variables to sample.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for use by stochastic samplers.</p> required"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin.generate_samples","title":"generate_samples  <code>abstractmethod</code>","text":"<pre><code>generate_samples() -&gt; NDArray[np.float64]\n</code></pre> <p>Return an array containing sampled values.</p> <p>The result should be a three-dimensional array of perturbation values. The variable values are stored along the last axis, for each realization and perturbation. The first axis indexes the realization, and the second axis indexes the perturbation.</p> <p>If the <code>shared</code> flag is set in the <code>SamplerConfig</code> configuration, the first dimension should have a length equal to one, since all realizations will use the same set of perturbations.</p> <p>The sampler may handle only a subset of the variables, as specified by the <code>variable_indices</code> argument of the constructor. In this case, only the corresponding values along the variables axis (the last axis) should be set, while other values should be zero.</p> Sample scaling <p>Samples will be multiplied by the values given by the <code>perturbation_magnitudes</code> field in the <code>gradients</code> section of the optimizer configuration. It makes therefore sense to generate samples that have an order of magnitude around one. For instance, by generating them on a <code>[-1, 1]</code> range, or with a unit standard deviation.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The sampled values.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin.create","title":"create  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>create(\n    enopt_config: EnOptConfig,\n    sampler_index: int,\n    mask: NDArray[bool_] | None,\n    rng: Generator,\n) -&gt; SamplerPlugin\n</code></pre> <p>Create a sampler.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler to use.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>The indices of the variables to sample.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for use by stochastic samplers.</p> required"},{"location":"reference/scipy_optimizer_plugin/","title":"SciPy Optimizer Plugin","text":""},{"location":"reference/scipy_optimizer_plugin/#ropt.plugins.optimizer.scipy.SciPyOptimizerPlugin","title":"ropt.plugins.optimizer.scipy.SciPyOptimizerPlugin","text":"<p>               Bases: <code>OptimizerPlugin</code></p> <p>Plugin class for optimization via SciPy.</p> <p>This class implements several optimizers provided by SciPy in the <code>scipy.optimize</code> package:</p> <ul> <li>Nelder-Mead</li> <li>Powell</li> <li>CG</li> <li>BFGS</li> <li>Newton-CG</li> <li>L-BFGS-B</li> <li>TNC</li> <li>COBYLA</li> <li>SLSQP</li> <li>differential_evolution</li> </ul> <p>The optimizer to use is selected by setting the <code>method</code> field in the <code>optimizer</code> field of <code>EnOptConfig</code> to the name of the algorithm. Most of these methods support the general options set in the <code>EnOptConfig</code> object. However, specific options that are normally passed as arguments in the SciPy functions can be provided via the <code>options</code> dictionary in the configuration object. Consult the <code>scipy.optimize</code> manual for details on these options.</p> <p>Not all constraints are supported by all optimizers:</p> <ul> <li>Bound constraints: Nelder-Mead, L-BFGS-B, SLSQP, TNC,   differential_evolution</li> <li>Linear constraints: SLSQP, differential_evolution</li> <li>Nonlinear constraints: COBYLA (only inequality), SLSQP,   differential_evolution</li> </ul> Info <ul> <li>The Nelder-Mead algorithm only supports bound constraints if SciPy   version &gt;= 1.7.</li> <li>Some SciPy algorithms that require a Hessian or a Hessian-vector   product are not supported. These include dogleg, trust-ncg,   trust-exact, and trust-krylov.</li> </ul>"},{"location":"reference/scipy_sampler_plugin/","title":"SciPy SamplerPlugin Plugin","text":""},{"location":"reference/scipy_sampler_plugin/#ropt.plugins.sampler.scipy.SciPySamplerPlugin","title":"ropt.plugins.sampler.scipy.SciPySamplerPlugin","text":"<p>               Bases: <code>SamplerPlugin</code></p> <p>Plugin class for producing sampling values via SciPy.</p> <p>This plugin implements the following sampling methods using the corresponding methods from the SciPy stats module:</p> <ul> <li> <p>Sampling from probability   distributions:</p> <code>uniform</code> Uniform distribution with a default range of [-1, 1]. <code>norm</code> Normal distribution with mean zero and standard deviation 1. <code>truncnorm</code> Truncated normal distribution with mean zero and standard   deviation 1 truncated a the range [-1, 1]. </li> <li> <p>Sampling using methods from the Quasi-Monte Carlo   submodule:</p> <code>sobol</code> Using Sobol sequences, scaled to -1 and 1. <code>halton</code> Using Halton sequences, scaled to -1 and 1. <code>lhs</code> Using Latin Hypercube sampling, scaled to -1 and 1. </li> </ul> <p>Specific options that are normally passed as arguments in the SciPy functions can be provided via the options dictionary in the configuration object. Consult the <code>scipy.stats</code> manual for details on these options.</p>"},{"location":"reference/utilities/","title":"Utilities","text":""},{"location":"reference/utilities/#ropt.config.utils","title":"ropt.config.utils","text":"<p>Utilities for checking configuration values.</p> <p>These utilities are intended to be used in the model validation code of Pydantic models.</p>"},{"location":"reference/utilities/#ropt.config.utils.ImmutableBaseModel","title":"ImmutableBaseModel","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for immutable classes.</p> <p>This model serves as an alternative to frozen Pydantic classes. It is particularly useful when post-initialization validators are required, as these validators may not function properly with frozen Pydantic classes.</p>"},{"location":"reference/utilities/#ropt.config.utils.ImmutableBaseModel.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name: str, value: Any) -&gt; None\n</code></pre> <p>Attribute setter method.</p> <p>This method sets an attribute if the object is not immutable.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the attribute to set.</p> required <code>value</code> <code>Any</code> <p>The value to assign to the attribute.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>Raised if the object is immutable and cannot be modified.</p>"},{"location":"reference/utilities/#ropt.config.utils.normalize","title":"normalize","text":"<pre><code>normalize(array: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Normalize a vector.</p> <p>Normalize the sum of the values to one.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[float64]</code> <p>The input array.</p> required <p>Returns:</p> Name Type Description <code>ValueError</code> <code>NDArray[float64]</code> <p>The normalized array</p>"},{"location":"reference/utilities/#ropt.config.utils.immutable_array","title":"immutable_array","text":"<pre><code>immutable_array(\n    array_like: ArrayLike, **kwargs: Any\n) -&gt; NDArray[Any]\n</code></pre> <p>Make an immutable array.</p> <p>Converts the input to an array and makes it immutable.`</p> <p>Parameters:</p> Name Type Description Default <code>array_like</code> <code>ArrayLike</code> <p>The input.</p> required <code>kwargs</code> <code> </code> <p>Additional keyword arguments for array conversion.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>The immutable array.</p>"},{"location":"reference/utilities/#ropt.config.utils.broadcast_arrays","title":"broadcast_arrays","text":"<pre><code>broadcast_arrays(*args: Any) -&gt; tuple[NDArray[Any], ...]\n</code></pre> <p>Broadcast a set of arrays to a common dimensionality and makes them immutable.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Any</code> <p>The input arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>tuple[NDArray[Any], ...]</code> <p>The broadcasted immutable arrays.</p>"},{"location":"reference/utilities/#ropt.config.utils.broadcast_1d_array","title":"broadcast_1d_array","text":"<pre><code>broadcast_1d_array(\n    array: NDArray[Any], name: str, size: int\n) -&gt; NDArray[Any]\n</code></pre> <p>Broadcast the input array to an 1D array of given size.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[Any]</code> <p>The input array.</p> required <code>name</code> <code>str</code> <p>The name of the array, used in an error message.</p> required <code>size</code> <code>int</code> <p>The size of the result.</p> required <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>An 1D array of the requested size.</p>"},{"location":"reference/utilities/#ropt.config.utils.check_enum_values","title":"check_enum_values","text":"<pre><code>check_enum_values(\n    value: NDArray[ubyte], enum_type: Type[IntEnum]\n) -&gt; None\n</code></pre> <p>Check if an enum value is valid.</p> <p>Given an array of byte integers, check of the values are within the range of values of the given enum.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>NDArray[ubyte]</code> <p>The enum values.</p> required <code>enum_type</code> <code>Type[IntEnum]</code> <p>The type to check.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array contains an invalid value.</p>"},{"location":"reference/utilities/#ropt.config.validated_types","title":"ropt.config.validated_types","text":"<p>Annotated types for use with Pydantic models.</p> <p>These types can be used to convert input values to a desired type and guarantee certain properties. They include types that convert inputs to immutable NumPy arrays of specified dimension and type:</p> <ul> <li><code>Array1D</code>: For converting sequences to   immutable one-dimensional floating-point arrays.</li> <li><code>Array2D</code>: For converting sequences to   immutable two-dimensional floating-point arrays.</li> <li><code>ArrayEnum</code>: For converting   sequences to values of numerical enumerations of any dimension.</li> <li><code>Array1DInt</code>: For converting   sequences to immutable one-dimensional integer arrays.</li> <li><code>Array1DBool</code>: For converting   sequences to immutable one-dimensional boolean arrays.</li> </ul> <p>Additionally, the following convenience types create sets or tuples, ensuring that single values are embedded in a set or tuple, respectively:</p> <ul> <li><code>ItemOrSet[T]</code>: Create a set of type <code>T</code>.</li> <li><code>ItemOrTuple[T]</code>: Create a tuple of type <code>T</code>.</li> </ul>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1D","title":"Array1D  <code>module-attribute</code>","text":"<pre><code>Array1D = Annotated[\n    NDArray[float64], BeforeValidator(_convert_1d_array)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of floating point values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array2D","title":"Array2D  <code>module-attribute</code>","text":"<pre><code>Array2D = Annotated[\n    NDArray[float64], BeforeValidator(_convert_2d_array)\n]\n</code></pre> <p>Convert to an immutable 2D numpy array of floating point values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ArrayEnum","title":"ArrayEnum  <code>module-attribute</code>","text":"<pre><code>ArrayEnum = Annotated[\n    NDArray[ubyte], BeforeValidator(_convert_enum_array)\n]\n</code></pre> <p>Convert to an immutable numpy array of numerical enumeration values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1DInt","title":"Array1DInt  <code>module-attribute</code>","text":"<pre><code>Array1DInt = Annotated[\n    NDArray[intc], BeforeValidator(_convert_1d_array_intc)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of integer values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.Array1DBool","title":"Array1DBool  <code>module-attribute</code>","text":"<pre><code>Array1DBool = Annotated[\n    NDArray[bool_], BeforeValidator(_convert_1d_array_bool)\n]\n</code></pre> <p>Convert to an immutable 1D numpy array of boolean values.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ItemOrSet","title":"ItemOrSet  <code>module-attribute</code>","text":"<pre><code>ItemOrSet = Annotated[set[T], BeforeValidator(_convert_set)]\n</code></pre> <p>Convert to single value to a set containing that value, passes sets unchanged.</p>"},{"location":"reference/utilities/#ropt.config.validated_types.ItemOrTuple","title":"ItemOrTuple  <code>module-attribute</code>","text":"<pre><code>ItemOrTuple = Annotated[\n    tuple[T, ...], BeforeValidator(_convert_tuple)\n]\n</code></pre> <p>Convert to single value to a tuple containing that value, passes sets unchanged.</p>"},{"location":"usage/robust_optimization/","title":"Introduction: Ensemble-based robust optimization","text":"<p>Constraint optimization is the process of optimizing an objective function \\(f(\\mathbf{x})\\) with respect to a vector of variables \\(\\mathbf{x}\\) in the presence of one or more inequality constraints \\(g_j(\\mathbf{x})\\) and/or equality constraints \\(h_k(\\mathbf{x})\\).</p> \\[ \\begin{align} \\textrm{minimize} \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{subject to} \\quad &amp; g_j(\\mathbf{x}) \\le 0, \\quad j=1, \\ldots, J \\\\ &amp; h_k(\\mathbf{x}) = 0, \\quad k=1, \\ldots, K \\\\ &amp; \\mathbf{x}^L \\le \\mathbf{x} \\le \\mathbf{x}^U \\end{align} \\] <p>In this context, the function \\(f(\\mathbf{x})\\) is assumed to have a deterministic nature, meaning it is well-defined for given parameters. However, in realistic scenarios, \\(f(\\mathbf{x})\\) may be part of a larger set of functions, especially if it depends on uncertain parameters drawn from some, possibly unknown, probability distribution.</p> <p>Ensemble-based robust optimization aims to optimize an ensemble of functions \\(f_i(\\mathbf{x})\\) with respect to \\(\\mathbf{x}\\). The set of realizations \\(f_i\\) captures the uncertainty that may exist in the model, which can be, for instance, constructed by varying some parameters according to a given probability distribution. When given a set of realizations, ensemble-based optimization proceeds by combining the functions \\(f_i(\\mathbf{x})\\) into a single objective function. For example, using a weighted sum, the problem becomes (ignoring constraints):</p> \\[ \\textrm{minimize} \\quad \\sum_i w_i f_i(\\mathbf{x}), \\] <p>where \\(w_i\\) represents the weights assigned to the different realizations. In more complex settings, the realizations may also be combined in different ways, and the set of realizations may be modified during optimization. For instance, risk-aware objectives may be constructed by minimizing the standard deviation of the functions or by selecting some of the worst-performing realizations at each iteration.</p> <p>In practice, the optimization task often becomes complex due to additional factors. The evaluation of functions might be computationally expensive, and calculating their gradients analytically can be challenging or even impossible. For example, the functions may involve lengthy simulations of a physical process with numerous variables, utilizing numerical calculations that preclude straightforward analytical differentiation.</p> <p><code>ropt</code> leverages standard optimization algorithms, such as those available in the SciPy package. These methods typically follow an iterative approach, necessitating repeated assessments of the objective function and, in many cases, its gradient. Currently, it is assumed that the functions are not easily differentiated analytically. One of the core functions of <code>ropt</code> is to calculate gradients efficiently using stochastic methods.</p> <p><code>ropt</code> is responsible for configuring and executing the optimization algorithm, building the overall function and gradient values from individual realizations, and monitoring both intermediate and final optimization results. It delegates the actual calculations of functions to external code that is provided by the user.</p> <p>While many optimization scenarios involve a single run of a particular method, there are cases where it proves beneficial to conduct multiple runs using the same or different algorithms. For example, when dealing with a mix of continuous and discrete variables, it might be advantageous to employ different methods for each variable type. <code>ropt</code> facilitates this by offering a mechanism to run a workflow containing multiple optimizers, potentially of different types, in an alternating or nested fashion.</p>"},{"location":"usage/running/","title":"Running a basic optimization script","text":"<p>Consider the Rosenbrock function, a standard test problem:</p> \\[ f(x,y) = (a - x)^2 + b (y - x^2)^2, \\] <p>which has a global minimum of \\(f(x, y) = 0\\) at \\((x, y) = (a, a^2)\\) .</p> <p>Here's an example optimizing the Rosenbrock function for \\(a = 1\\) and \\(b = 100\\):</p> <pre><code>import numpy as np\nfrom numpy.typing import NDArray\n\nfrom ropt.evaluator import EvaluatorContext, EvaluatorResult\nfrom ropt.plan import BasicOptimizer\n\n\ndef rosenbrock(\n    variables: NDArray[np.float64],                                   # (1)!\n    context: EvaluatorContext                                         # (2)!\n) -&gt; EvaluatorResult:\n    objectives = np.zeros((variables.shape[0], 1), dtype=np.float64)\n    for idx in range(variables.shape[0]):\n        x, y = variables[idx, :]\n        objectives[idx, 0] = (1.0 - x) ** 2 + 100 * (y - x * x) ** 2\n    return EvaluatorResult(objectives=objectives)                     # (3)!\n\nCONFIG = {                                                            # (4)!\n    \"variables\": {\"initial_values\": [0.5, 2.0]},\n    \"gradient\": {\"perturbation_magnitudes\": 1e-5}                     # (5)!\n}\n\noptimum = BasicOptimizer(CONFIG, rosenbrock).run().results            # (6)!\n\nprint(optimum.evaluations.variables, optimum.functions.weighted_objective)\n</code></pre> <ol> <li>The variables to optimize (\\(x, y\\)) are passes as a single <code>numpy</code> array. The    function may receive multiple variable vectors to evaluate, hence the input    is a matrix where the variable vectors are the rows of the matrix.</li> <li>Additional information is passes via an    <code>EvaluatorContext</code> object. It is not    needed in this case.</li> <li>Results are returned via an    <code>EvaluatorResult</code> object. The objectives    result is a matrix since multiple input vectors and multiple objectives may    be evaluated.</li> <li>Create an optimizer configuration with default values except for initial    values and perturbation magnitudes.</li> <li>Set perturbation magnitudes to a small value for accurate gradient    estimation.</li> <li>Make an <code>BasicOptimizer</code> plan, run it, and    retrieve the results.</li> </ol> <p>Running this will print the estimated optimal variables and the corresponding function value:</p> <pre><code>[1.00117794 1.0023715 ] 1.4078103983185034e-06\n</code></pre> <p>This example uses the BasicOptimizer class which provides a simplified interface for running optimizations. More complex optimization workflows can be implemented using the plan functionality.</p>"}]}