{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>ropt</code>: A Python module for robust optimization","text":"<p><code>ropt</code> is a module designed for implementing and executing robust optimization workflows. In classical optimization problems, a deterministic function is optimized. However, in robust optimization, the function is expected to exhibit a stochastic nature and is represented by an ensemble of functions (realizations) for different values of some (possibly unknown) random parameters. The optimal solution is then determined by optimizing the value of a statistic, such as the mean, over the ensemble.</p> <p><code>ropt</code> can be employed to construct optimization workflows directly in Python or as a building block in optimization applications. At a minimum, the user needs to provide additional code to calculate the values for each function realization in the ensemble. This can range from simply calling a Python function that returns the objective values to initiating a long-running simulation on an HPC cluster and reading the results. Furthermore, <code>ropt</code> exposes all intermediate results of the optimization, such as objective and gradient values, but functionality to report or store any of these values must be added by the user. Optional functionality to assist with this is included with <code>ropt</code>.</p> <p><code>ropt</code> provides several features for efficiently solving complex robust optimization problems:</p> <ul> <li>Robust optimization over an ensemble of models, i.e., optimizing the average   of a set of objective functions. Alternative objectives can be implemented   using plugins, for instance, to implement risk-aware optimization, such as   Conditional Value at Risk (CVaR) or standard-deviation-based functions.</li> <li>Support for black-box optimization of arbitrary functions.</li> <li>Support for running complex optimization workflows, such as multiple runs with   different optimization settings or even different optimization methods.</li> <li>Support for nested optimization, allowing sub-sets of the variables to be   optimized by optimization workflows that run as part of the black-box function   to be optimized.</li> <li>An interface for running various continuous and discrete optimization methods.   By default, optimizers from the   <code>scipy.optimize</code>   package are included, but additional optimizers can be added via a plugin   mechanism. The most common options of these optimizers can be configured in a   uniform manner, although algorithm- or package-specific options can still be   passed.</li> <li>Efficient estimation of gradients using a Stochastic Simplex Approximate   Gradient (StoSAG) approach. Additional samplers for generating perturbed   values for gradient estimation can be added via a plugin mechanism.</li> <li>Support for linear and non-linear constraints, if supported by the chosen   optimizer.</li> <li>Flexible configuration of the optimization process using   <code>pydantic</code>.</li> <li>Support for tracking and processing optimization results generated during the   optimization process.</li> <li>Support for generating formatted tables of the results.</li> <li>Optional support for exporting results as   <code>pandas</code> data frames or   <code>xarray</code> data sets, and saving in the <code>netCDF</code> format   using the <code>netCDF4</code> module.</li> <li>Optional support for running function evaluations on distributed resources,   such as HPC clusters, via the <code>Parsl</code> library   for parallel scripting.</li> </ul>"},{"location":"reference/default_function_transforms/","title":"Default Function Transforms","text":""},{"location":"reference/default_function_transforms/#ropt.plugins.function_transform.default.DefaultFunctionTransform","title":"<code>ropt.plugins.function_transform.default.DefaultFunctionTransform</code>","text":"<p>               Bases: <code>FunctionTransform</code></p> <p>The default function transform plugin.</p> <p>This plugin currently implements two methods:</p> <code>mean</code>: Calculate the combined functions as a weighted mean of the function    values of each realization. Gradients are accordingly calculated as    a weighted sum. <code>stddev</code>: Calculate the combined functions as the standard deviation of function    values of each realization. Gradients are calculated accordingly using    the chain rule. The sign of the result is adjusted such that the standard    deviation is always minimized."},{"location":"reference/default_plan_objects/","title":"Default Plan Objects","text":""},{"location":"reference/default_plan_objects/#ropt.plugins.plan.default.DefaultPlanPlugin","title":"<code>ropt.plugins.plan.default.DefaultPlanPlugin</code>","text":"<p>               Bases: <code>PlanPlugin</code></p> <p>Default plan plugin class.</p>"},{"location":"reference/default_realization_filters/","title":"Default Realization Filters","text":""},{"location":"reference/default_realization_filters/#ropt.plugins.realization_filter.default.DefaultRealizationFilter","title":"<code>ropt.plugins.realization_filter.default.DefaultRealizationFilter</code>","text":"<p>               Bases: <code>RealizationFilter</code></p> <p>The default realization filter plugin class.</p> <p>This plugin currently implements four methods:</p> <code>sort-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>SortObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects the set of realizations from a given index range. <code>sort-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>SortConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects the set of    realizations from a given index range. <code>cvar-objective</code>: Filter realizations by selecting a range of objective values. This filter    requires additional configuration using an options dict that can be    parsed into a    <code>CVaRObjectiveOptions</code>    class. This method sorts realizations according to the weighted sum of    the values of objective functions specified in the options. It then    selects a percentile of the realizations, applying interpolation whenever    the number of selected realizations is not an integer number. <code>cvar-constraint</code>: Filter realizations by selecting a range of constraint values. This    filter requires additional configuration using an options dict that can    be parsed into a    <code>CVaRConstraintOptions</code>    class. This method sorts realizations according to the values of    constraint functions specified in the options. It then selects a    percentile of the realizations, applying interpolation whenever the    number of selected realizations is not an integer number."},{"location":"reference/default_realization_filters/#ropt.plugins.realization_filter.default.SortObjectiveOptions","title":"<code>ropt.plugins.realization_filter.default.SortObjectiveOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-objective</code> method.</p> <p>The <code>sort-objective</code> method sorts realizations according to the value of one or multiple objectives, and retains a number of realizations within a given index range in the sorted list. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>List[Union[StrictStr, NonNegativeInt]]</code> <p>The indices of the objectives to sort</p> <code>first</code> <code>NonNegativeInt</code> <p>Index of the first realization to use</p> <code>last</code> <code>NonNegativeInt</code> <p>Index of the last realization to use</p>"},{"location":"reference/default_realization_filters/#ropt.plugins.realization_filter.default.SortConstraintOptions","title":"<code>ropt.plugins.realization_filter.default.SortConstraintOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>sort-constraint</code> method.</p> <p>The <code>sort-constraint</code> method sorts realizations according to the value of a constraint, and retains a number of realizations within a given index range in the sorted list.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>Union[StrictStr, NonNegativeInt]</code> <p>The index of the constraint to sort</p> <code>first</code> <code>NonNegativeInt</code> <p>Index of the first realization to use</p> <code>last</code> <code>NonNegativeInt</code> <p>Index of the last realization to use</p>"},{"location":"reference/default_realization_filters/#ropt.plugins.realization_filter.default.CVaRObjectiveOptions","title":"<code>ropt.plugins.realization_filter.default.CVaRObjectiveOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-objective</code> method.</p> <p>The <code>cvar-objective</code> method finds realizations weights by applying the CVaR method to the objective values. If more than one objective index is given, a weighted sum of these objectives is used, using the weights given in the configuration of the optimizer.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. \"Worst\" is defined as those realizations having the highest values in case of a minimization and those having the lowest values in case of maximizing.</p> <p>Attributes:</p> Name Type Description <code>sort</code> <code>List[Union[StrictStr, NonNegativeInt]]</code> <p>The indices of the objectives to sort</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile</p>"},{"location":"reference/default_realization_filters/#ropt.plugins.realization_filter.default.CVaRConstraintOptions","title":"<code>ropt.plugins.realization_filter.default.CVaRConstraintOptions</code>","text":"<p>               Bases: <code>_ConfigBaseModel</code></p> <p>Configuration settings for the <code>cvar-constraint</code> method.</p> <p>The <code>cvar-constraint</code> method finds realizations weights by applying the CVaR method to the objective values.</p> <p>The percentile argument defines the contribution of the \"worst\" performing realizations in the distribution that is used to calculate the ensemble value. The definition of worst depends on the type of the constraints. After subtracting the right-hand-side value the following applies:</p> <ul> <li>For LE constraints, realizations with the largest values are the worst</li> <li>For GE constraints, realizations with the smallest values are the worst</li> <li>For EQ constraints, realizations with the largest absolute values are the worst</li> </ul> <p>Attributes:</p> Name Type Description <code>sort</code> <code>Union[StrictStr, NonNegativeInt]</code> <p>The index of the constraint to sort</p> <code>percentile</code> <code>Annotated[float, Field(gt=0.0, le=1.0)]</code> <p>The CVaR percentile</p>"},{"location":"reference/enopt_config/","title":"Optimizer configuration","text":""},{"location":"reference/enopt_config/#ropt.config.enopt","title":"<code>ropt.config.enopt</code>","text":"<p>The <code>ropt.config.enopt</code> module contains optimization configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.EnOptConfig","title":"<code>EnOptConfig</code>","text":"<p>The primary configuration class for a single optimization step.</p> <p>The fields of the <code>EnOptConfig</code> class are nested configuration classes that specify specific aspects of a single optimization run.</p> <p>Upon initialization and validation of an <code>EnOptConfig</code> object, the contents of some of these fields may be modified, depending on the content of other fields. A good example is the scaling of variables: The <code>offsets</code> and <code>scales</code> field in the <code>variables</code> field of an <code>EnOptConfig</code> object define a linear transformation of the variables. Upon initialization, values of the <code>linear_constraints</code> field will be transformed accordingly so that the constraints remain valid for the transformed variables.</p> <p>The <code>realization_filters</code>, <code>function_transforms</code>, and <code>samplers</code> fields are defined as tuples of configurations for realization filter, function transform, and sampler objects, respectively. Other configuration fields will refer to these objects by their index into these tuples. For example, the <code>gradient</code> field is implemented by the <code>GradientConfig</code> class, which contains a <code>samplers</code> field that is an array of indices, indicating for each variable which sampler should be used.</p> <p>The original values of all fields used to create the object will be stored internally and are available via the <code>original_inputs</code> field.</p> Info <p>Many of these nested classes contain fields that are <code>numpy</code> arrays of values. In general, these arrays must have a given size defined by the configured property or a size of one. For instance, the <code>variables</code> field must be an object of the <code>VariablesConfig</code> class, which contains information about the variables to be optimized. This includes such properties as initial values, bounds, and so on, which are defined as <code>numpy</code> arrays. The size of these arrays must be either equal to the number of variables or equal to one, in which case that single value is used for all variables.</p> <p>Attributes:</p> Name Type Description <code>variables</code> <code>VariablesConfig</code> <p>Configuration of the variables</p> <code>objective_functions</code> <code>ObjectiveFunctionsConfig</code> <p>Configuration of the objective functions</p> <code>linear_constraints</code> <code>Optional[LinearConstraintsConfig]</code> <p>Configuration of linear constraints</p> <code>nonlinear_constraints</code> <code>Optional[NonlinearConstraintsConfig]</code> <p>Configuration of non-linear constraints</p> <code>realizations</code> <code>RealizationsConfig</code> <p>Configuration of the realizations</p> <code>optimizer</code> <code>OptimizerConfig</code> <p>Configuration of the optimizer</p> <code>gradient</code> <code>GradientConfig</code> <p>Configuration for gradient calculations</p> <code>realization_filters</code> <code>Tuple[RealizationFilterConfig, ...]</code> <p>Configuration of realization filters</p> <code>function_transforms</code> <code>Tuple[FunctionTransformConfig, ...]</code> <p>Configuration of function transforms</p> <code>samplers</code> <code>Tuple[SamplerConfig, ...]</code> <p>Configuration of samplers</p> <code>original_inputs</code> <code>Optional[Dict[str, Any]]</code> <p>The original input to the constructor</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.VariablesConfig","title":"<code>VariablesConfig</code>","text":"<p>The configuration class for variables.</p> <p>This configuration class, configured by the <code>variables</code> field in an <code>EnOptConfig</code> object defines essential aspects of the variables: the initial values and the bounds. These are given by the <code>initial_values</code>, <code>lower_bounds</code>, and <code>upper_bounds</code> fields, which are <code>numpy</code> arrays. Initial values must be provided, while bounds are set to \\(-\\infty\\) and \\(+\\infty\\) by default. The <code>lower_bounds</code> and <code>upper_bounds</code> fields may contain <code>numpy.nan</code> values, indicating that corresponding variables have no lower or upper bounds, respectively. These values are converted to <code>numpy.inf</code> values with an appropriate sign.</p> <p>The <code>names</code> field is optional since variable names are not strictly needed by the optimizer. However, if the <code>names</code> field is given, it determines the number of variables, and the <code>initial_values</code>, <code>lower_bounds</code>, and <code>upper_bounds</code> fields are broadcasted accordingly. If <code>names</code> is not provided, these fields are broadcasted to each other, and their final size determines the number of variables.</p> Variable Names <p><code>ropt</code> does not use the names itself, and names can be of arbitrary type, as long as they are unique. However, some optimizers or external code might need a string representation of each name, which can be obtained using the <code>get_formatted_names</code> method. The <code>delimiters</code> attribute is used by this method to convert the special case of names consisting of tuples of strings.</p> <p>The optional <code>types</code> field can be used to assign types to each variable, according to the <code>VariableType</code> enumeration. The values can be used to configure the optimizer accordingly. If not provided, all variables are assumed to be continuous and of real data type (corresponding to <code>VariableType.REAL</code>)</p> <p>The <code>offsets</code> and <code>scales</code> fields are optional: if given, they are broadcasted to the number of variables and used for scaling. The elements \\(x_i\\) of <code>initial_values</code>, <code>lower_bounds</code>, and <code>upper_bounds</code> fields are rescaled by the elements \\(o_i\\) and \\(s_i\\) of <code>offsets</code> and <code>scales</code>: \\((x_i - o_i) / s_i\\).</p> Transformation of Linear Constraints <p>Any linear constraints defined in the <code>EnOptConfig</code> object via its <code>linear_constraints</code> field will also be transformed using any offsets and scales passed via the <code>VariablesConfig</code> object. See: <code>LinearConstraintsConfig</code>.</p> <p>The optional <code>indices</code> field contains the indices of the variables considered to be free to change. During optimization, only these variables should change while others remain fixed.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>Optional names of the variables</p> <code>types</code> <code>Optional[ArrayEnum]</code> <p>The type of the variables (optional).</p> <code>initial_values</code> <code>Array1D</code> <p>The initial values of the variables</p> <code>lower_bounds</code> <code>Array1D</code> <p>Lower bound of the variables (default: \\(-\\infty\\))</p> <code>upper_bounds</code> <code>Array1D</code> <p>Upper bound of the variables (default: \\(+\\infty\\))</p> <code>offsets</code> <code>Optional[Array1D]</code> <p>Optional offsets, used for scaling the variables</p> <code>scales</code> <code>Optional[Array1D]</code> <p>Optional scales, used for scaling the variables</p> <code>indices</code> <code>Optional[ArrayIndices]</code> <p>Optional indices of variables to optimize.</p> <code>delimiters</code> <code>str</code> <p>Delimiters used to construct names from tuples</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.VariablesConfig.get_formatted_names","title":"<code>get_formatted_names()</code>","text":"<p>Return string representations of the variable names.</p> <p>This method converts the variable names to a tuple of strings. Each name is converted using its string representation unless the name is a tuple. In that case, the tuple items are converted to strings and joined using the delimiters taken from the <code>delimiter</code> field in the <code>Variables</code> object. This field is a string that may consist of multiple delimiters used in turn. If it contains fewer items than needed, the last one is used for the missing ones. By default, the <code>:</code> character is used as the delimiter.</p> <p>Returns:</p> Type Description <code>Optional[Tuple[str, ...]]</code> <p>A tuple of formatted variable names.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.ObjectiveFunctionsConfig","title":"<code>ObjectiveFunctionsConfig</code>","text":"<p>The configuration class for objective functions.</p> <p>This configuration class defines objective functions configured by the <code>objective_functions</code> field in an <code>EnOptConfig</code> object.</p> <p><code>ropt</code> supports optimization over multiple objectives, which are summed after weighting with values passed via the <code>weights</code> field. This field is a <code>numpy</code> array, with a length equal to the number of objective functions. Its values will be normalized to have a sum equal to 1. For example, when <code>weights</code> is set to <code>[1, 1]</code>, the stored values will be <code>[0.5, 0.5]</code>.</p> <p>The <code>names</code> field is optional. If given, the number of objective functions is set equal to its length. The <code>weights</code> array will then be broadcasted to the number of objective values. For example, if <code>names = [\"f1\", \"f2\"]</code> and <code>weights = 1.0</code>, the optimizer assumes two objective functions weighted by <code>[0.5, 0.5]</code>. If <code>names</code> is not set, the number of objectives is determined by the length of <code>weights</code>.</p> <p>The <code>scales</code> field contains scaling values for the objectives. These values are used to scale the objective function values to a desired order of magnitude. Each time new objective function values are obtained during optimization, they are divided by these values. The <code>auto_scale</code> field can be used to direct the optimizer to obtain an additional scaling by multiplying the values of <code>scales</code> by the values of the objective functions at the start of the optimization. Both the <code>scales</code> and <code>auto_scale</code> arrays will be broadcasted to have a size equal to the number of objective functions.</p> Info <p>Both the <code>scales</code> values and the values obtained by auto-scaling will be applied. Thus, if <code>scales</code> is not supplied, auto-scaling will scale the objectives such that their initial values will be equal to one. Setting <code>scales</code> also allows for scaling to different initial values.</p> <p>The objective functions may be subject to realization filters and function transforms. The <code>realization_filters</code> and <code>function_transforms</code> fields contain indices to the realization filter or function transform objects to use. The objects referred to are configured in the parent <code>EnOptConfig</code> object.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>Optional names of the objective functions</p> <code>weights</code> <code>Array1D</code> <p>Objective functions weights (default: 1.0)</p> <code>scales</code> <code>Array1D</code> <p>The scaling factors (default: 1.0)</p> <code>auto_scale</code> <code>Array1DBool</code> <p>Enable/disable auto-scaling (default: <code>False</code>)</p> <code>realization_filters</code> <code>Optional[Array1DInt]</code> <p>Optional realization filter indices</p> <code>function_transforms</code> <code>Optional[Array1DInt]</code> <p>Optional function transform indices</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.LinearConstraintsConfig","title":"<code>LinearConstraintsConfig</code>","text":"<p>The configuration class for linear constraints.</p> <p>This class defines linear constraints configured by the <code>linear_constraints</code> field in an <code>EnOptConfig</code> object.</p> <p>Linear constraints can be described by a set of linear equations on the variables, including equality or non-equality constraints. The <code>coefficients</code> field is a 2D <code>numpy</code> array where the number of rows equals the number of constraints, and the number of columns equals the number of variables.</p> <p>The right-hand sides of the equations are given in the <code>rhs_values</code> field, which will be converted and broadcasted to a <code>numpy</code> array with a length equal to the number of equations.</p> <p>The <code>types</code> field determines the type of each equation: equality (\\(=\\)) or inequality (\\(\\leq\\) or \\(\\geq\\)), and it is broadcasted to a length equal to the number of equations. The <code>types</code> field is defined as an integer array, but its values are limited to those of the <code>ConstraintType</code> enumeration.</p> <p>Attributes:</p> Name Type Description <code>coefficients</code> <code>Array2D</code> <p>The matrix of coefficients</p> <code>rhs_values</code> <code>Array1D</code> <p>The right-hand-sides of the constraint equations</p> <code>types</code> <code>ArrayEnum</code> <p>The type of each equation           (see <code>ConstraintType</code>)</p> Rescaled variables <p>If a <code>LinearConstraintsConfig</code> object is part of an <code>EnOptConfig</code> object, it may be modified during initialization. If the <code>EnOptConfig</code> object defines a rescaling of the variables, the linear coefficients (\\(\\mathbf{A}\\)) and offsets (\\(\\mathbf{b}\\)) are converted to remain valid for the scaled variables:</p> \\[ \\begin{align}     \\hat{\\mathbf{A}} &amp;= \\mathbf{A}\\mathbf{S} \\\\     \\hat{\\mathbf{b}} &amp;= \\mathbf{b} - \\mathbf{A}\\mathbf{o} \\end{align} \\] <p>where \\(\\mathbf{S}\\) is a diagonal matrix containing the variable scales, and \\(\\mathbf{o}\\) is a vector containing the variable offsets.</p> <p>It is important to realize that this does not mean that the constraints themselves are scaled. The equations and right-hand values are transformed, ensuring they yield the same results with scaled variables as the original equations and right-hand side values would with unscaled variables. This should be taken into account when comparing the difference between the equations and right-hand side to a tolerance.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.NonlinearConstraintsConfig","title":"<code>NonlinearConstraintsConfig</code>","text":"<p>The configuration class for non-linear constraints.</p> <p>This class defines non-linear constraints configured by the <code>nonlinear_constraints</code> field in an <code>EnOptConfig</code> object.</p> <p>Non-linear constraints require that some constraint function is compared to a right-hand-side value, either for equality or inequality. The <code>rhs_values</code> field, which is a <code>numpy</code> array with a length equal to the number of constraint functions, provides the right-hand-side values.</p> <p>The <code>names</code> field is optional. If given, the number of constraint functions is set equal to its length. The <code>rhs_values</code> array will then be broadcasted to the number of constraint functions. For example, if <code>names = [\"c1\", \"c2\"]</code> and <code>rhs_values = 0.0</code>, the optimizer assumes two constraint functions and stores <code>rhs_values = [0.0, 0.0]</code>. If <code>names</code> is not set, the number of constraints is determined by the length of <code>rhs_values</code>.</p> <p>The <code>scales</code> field contains scaling values for the constraints. These values scale the constraint function values to a desired order of magnitude. Each time new constraint function values are obtained during optimization, they are divided by these values. The <code>auto_scale</code> field can be used to direct the optimizer to obtain additional scaling by multiplying the values of <code>scales</code> by the values of the constraint functions at the start of the optimization. Both the <code>scales</code> and <code>auto_scale</code> arrays will be broadcasted to have a size equal to the number of constraint functions.</p> Info <p>Both the <code>scales</code> values and the values obtained by auto-scaling will be applied. If <code>scales</code> is not supplied, auto-scaling will scale the constraints such that their initial values will be equal to one. Setting <code>scales</code> additionally allows for scaling to different initial values.</p> <p>The <code>types</code> field determines the type of each constraint: equality (\\(=\\)) or inequality (\\(\\le\\) or \\(\\ge\\)), and is broadcasted to a length equal to the number of constraints. The <code>types</code> field is defined as an integer array, but its values are limited to those of the <code>ConstraintType</code> enumeration.</p> <p>The non-linear constraints may be subject to realization filters and function transforms. The <code>realization_filters</code> and <code>function_transform</code> fields contain indices to the realization filter or function transform objects to use. These objects are configured in the parent <code>EnOptConfig</code> object.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>The names of the constraint functions (optional)</p> <code>rhs_values</code> <code>Array1D</code> <p>The right-hand-side values</p> <code>scales</code> <code>Array1D</code> <p>The scaling factors (default: 1.0)</p> <code>auto_scale</code> <code>Array1DBool</code> <p>Enable/disable auto-scaling (default: <code>False</code>)</p> <code>types</code> <code>ArrayEnum</code> <p>The type of each non-linear constraint                  (<code>ConstraintType</code>)</p> <code>realization_filters</code> <code>Optional[Array1DInt]</code> <p>Optional realization filter indices</p> <code>function_transforms</code> <code>Optional[Array1DInt]</code> <p>Optional function transform indices</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationsConfig","title":"<code>RealizationsConfig</code>","text":"<p>The configuration class for realizations.</p> <p>This class defines realizations configured by the <code>realizations</code> field in an <code>EnOptConfig</code> object.</p> <p>To optimize an ensemble of functions, a set of realizations is defined. When the optimizer requests a function value or a gradient, the functions and gradients are calculated for each realization and combined into a single function or gradient. Usually, this will be a (weighted) sum, but other ways of combining realizations are possible.</p> <p>The <code>weights</code> field is a <code>numpy</code> array, with a length equal to the number of realizations. Its values will be normalized to have a sum equal to 1. For example, when <code>weights</code> is set to <code>[1, 1]</code>, the stored values will be <code>[0.5, 0.5]</code>.</p> <p>The <code>names</code> field is optional. If given, the number of realizations is set equal to its length. The <code>weights</code> array will then be broadcasted to the number of objective values. For example, if <code>names = [\"r1\", \"r2\"]</code> and <code>weights = 1.0</code>, the optimizer assumes two realizations weighted by <code>[0.5, 0.5]</code>. If <code>names</code> is not set, the number of realizations is determined by the length of <code>weights</code>.</p> <p>If during the calculation of the function values for each realization one or more values are missing, for instance due to failure of a complex simulation, the total function and gradient values can still be calculated by leaving the missing values out. However, this may be undesirable, or there may be a hard minimum to the amount of values that is needed. The <code>realization_min_success</code> field can be set to the minimum number of successful realizations. By default, it is set equal to the number of realizations, i.e., there are no missing values allowed by default.</p> Note <p>The value of <code>realization_min_success</code> can be set to zero. Some optimizers can handle this and will proceed with the optimization even if all realizations fail. However, most optimizers cannot handle this and will behave as if the value is set to one.</p> <p>Attributes:</p> Name Type Description <code>names</code> <code>Optional[UniqueNames]</code> <p>Optional names of the realizations</p> <code>weights</code> <code>Array1D</code> <p>The weights of the realizations (default: 1)</p> <code>realization_min_success</code> <code>Optional[NonNegativeInt]</code> <p>The minimum number of successful realizations                      (default: equal to the number of realizations)</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.OptimizerConfig","title":"<code>OptimizerConfig</code>","text":"<p>The configuration class for optimizers used in the optimization.</p> <p>This class defines the configuration for optimizers, configured by the <code>optimizer</code> field in an <code>EnOptConfig</code> object.</p> <p>Although there may be significant differences in the parameters that can be used for different optimization methods, there are a few standard settings defined in this configuration object, which are forwarded to the optimizer:</p> <ul> <li>The maximum number of iterations allowed before the optimization should be   aborted by this optimizer. The optimizer may choose to ignore this option.</li> <li>The maximum number of function evaluations allowed before the optimization   is aborted.</li> <li>The convergence tolerance used as a stopping criterion. The exact   definition of the criterion depends on the optimizer. The optimizer may   choose to ignore this option.</li> <li>Whether gradients should be evaluated early, even if the optimizer does   not strictly need it yet. When evaluating on a distributed HPC cluster,   this may lead to better load-balancing for some methods. This option is   only applied if the optimization algorithm knows how to make use of it.</li> <li>Whether calculations for functions and gradients should be done   separately, even if the optimizer requests them to be evaluated together.   This option is useful when a filter is specified that deactivates some   realizations (see   <code>RealizationFilterConfig</code>).   In this case, after evaluation of the functions, it may be possible to   reduce the number of evaluations for a following gradient calculation.</li> <li>Whether the optimizer may use parallelized function evaluations. This   option currently only applies to gradient-free methods and may be ignored   by the optimizer.</li> <li>An optional location of an output directory, where the optimizer may store   files.</li> <li>Generic optimizer options that may be passed as an arbitrary dictionary,   or as a list of strings. It depends on the method what form is required   and how it is interpreted.</li> </ul> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Name of the optimization method used</p> <code>max_iterations</code> <code>Optional[PositiveInt]</code> <p>Optional maximum number of iterations</p> <code>max_functions</code> <code>Optional[PositiveInt]</code> <p>Optional maximum number of function evaluations</p> <code>tolerance</code> <code>Optional[NonNegativeFloat]</code> <p>Optional tolerance for convergence</p> <code>speculative</code> <code>bool</code> <p>Force gradient evaluations; disabled if                split_evaluations is True (default <code>False</code>)</p> <code>split_evaluations</code> <code>bool</code> <p>Evaluate function and gradient separately                (default: <code>False</code>)</p> <code>parallel</code> <code>bool</code> <p>Allow for parallelized evaluation (default: <code>False</code>)</p> <code>output_dir</code> <code>Optional[Path]</code> <p>Optional output directory for use by the optimizer</p> <code>options</code> <code>Optional[Union[Dict[str, Any], List[str]]]</code> <p>Optional generic options for use by the optimizer</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.GradientConfig","title":"<code>GradientConfig</code>","text":"<p>The configuration class for gradient calculations.</p> <p>This class defines the configuration for gradient calculations, configured by the <code>gradients</code> field in an <code>EnOptConfig</code> object.</p> <p>If the optimizer requires gradient information, it is estimated from a set of function values calculated from perturbed variables and from the unperturbed variables. The number of perturbations is determined by the <code>number_of_perturbations</code> field, which should be at least one and may be larger than the number of variables.</p> <p>Some function evaluations for the perturbed variables may fail, for instance due to an error in a long-running simulation. As long as not too many evaluations fail, the gradient may still be estimated. The <code>perturbation_min_success</code> field determines how many perturbed variables should be successfully evaluated. By default, this parameter is set equal to the number of perturbations.</p> <p>Perturbations are generally produced by sampler objects configured in the parent <code>EnOptConfig</code> object. The <code>samplers</code> field contains, for each variable, an index into the tuple of these configured samplers, indicating which sampler should be used to generate perturbation values for that variable.</p> <p>The generated perturbation values are added to the unperturbed variables after multiplication with the perturbation magnitudes given by the <code>perturbation_magnitudes</code> field. The perturbation values may be used directly or first modified in various ways. The <code>perturbation_types</code> field determines if and how this is done for each variable (see the <code>PerturbationType</code> enumeration for details).</p> <p>The perturbed variables can occasionally violate the bound constraints defined for the variables. This may be undesirable, for instance if the function evaluation may fail for variables that violate these constraints. The <code>boundary_types</code> array determines what action is taken to rectify such a situation (see the <code>BoundaryType</code> enumeration for more details).</p> <p>Both the <code>perturbation_types</code> and <code>boundary_types</code> fields are defined as integer arrays, but their values are limited to the values of the <code>PerturbationType</code> and <code>BoundaryType</code> enumerations, respectively.</p> <p>The gradient is calculated for each realization individually, and the resulting gradients are afterwards combined into a total gradient. If the number of perturbations is low, the calculation of the individual gradients may be unreliable. In particular, in the case of a single perturbation, the result is likely inaccurate. In such a case, the <code>merge_realizations</code> flag can be set to direct the optimizer to use a different calculation to combine the results of all realizations directly into an estimation of the total gradient.</p> <p>Attributes:</p> Name Type Description <code>number_of_perturbations</code> <code>PositiveInt</code> <p>The number of perturbations (default: <code>DEFAULT_NUMBER_OF_PERTURBATIONS</code>)</p> <code>perturbation_min_success</code> <code>Optional[PositiveInt]</code> <p>The minimum number of successful function                       evaluations for perturbed variables (default:                       equal to the number of perturbations)</p> <code>perturbation_magnitudes</code> <code>Array1D</code> <p>The magnitudes of the perturbations for each variable                       (default: <code>DEFAULT_PERTURBATION_MAGNITUDE</code>)</p> <code>perturbation_types</code> <code>ArrayEnum</code> <p>The type of perturbation for each variable                       (<code>PerturbationType</code>,                       default: <code>DEFAULT_PERTURBATION_TYPE</code>)</p> <code>boundary_types</code> <code>ArrayEnum</code> <p>How perturbations that violate boundary conditions                       are treated (see <code>BoundaryType</code>),                       default: <code>DEFAULT_PERTURBATION_BOUNDARY_TYPE</code>).</p> <code>samplers</code> <code>Optional[Array1DInt]</code> <p>The index of the sampler to use for each variable</p> <code>merge_realizations</code> <code>bool</code> <p>If all realizations should be merged for the final                       gradient calculation (default: <code>False</code>)</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.FunctionTransformConfig","title":"<code>FunctionTransformConfig</code>","text":"<p>Configuration class for function transforms.</p> <p>This class defines the configuration for function transforms, which are configured by the <code>function_transforms</code> field in an <code>EnOptConfig</code> object. That field contains a tuple of configuration objects that define which function transforms are available during the optimization.</p> <p>By default, the final objective and constraint functions and their gradients are calculated from the individual realizations by a weighted sum. Function transforms are optionally used to modify this calculation.</p> <p>The <code>method</code> field determines which method will be used to implement the calculation of the final function or gradient from the individual realizations. To further specify how such a method should function, the <code>options</code> field can be used to pass a dictionary of key-value pairs. The interpretation of these options depends on the chosen method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The function transform method</p> <code>options</code> <code>Dict[str, Any]</code> <p>Options to be passed to the transform</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.RealizationFilterConfig","title":"<code>RealizationFilterConfig</code>","text":"<p>The configuration class for realization filters.</p> <p>This class defines the configuration for realization filters, which are configured by the <code>realization_filters</code> field in an <code>EnOptConfig</code> object. This field contains a tuple of configuration objects that define which realization filters are available during optimization.</p> <p>By default, the final objective and constraint functions and their gradients are calculated as a weighted function from all realizations. Realization filters are optionally used to change the weights of the individual realizations. For instance, this can be used to determine which subset of realizations should be used in calculating the final objective and constraint functions and their gradients by setting some weights to zero.</p> <p>The <code>method</code> field determines which method will be used to adjust the weights of the individual realizations. To further specify how such a method should function, the <code>options</code> field can be used to pass a dictionary of key-value pairs. The interpretation of these options depends on the| chosen method.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The realization filter method</p> <code>options</code> <code>Dict[str, Any]</code> <p>Options to be passed to the filter</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.SamplerConfig","title":"<code>SamplerConfig</code>","text":"<p>The sampler configuration class.</p> <p>This class defines the configuration for samplers, which are configured by the <code>samplers</code> field in an <code>EnOptConfig</code> object. That field contains a tuple of configuration objects that define which samplers are available during the optimization. The <code>samplers</code> field in the gradient configuration (<code>GradientConfig</code>) is used to specify the index of the sampler for each variable.</p> <p>Gradients are calculated from a set of perturbed variables, which may be deterministic or stochastic in nature. These perturbations are generally produced by sampler objects that produce perturbation values to add to the unperturbed variables.</p> <p>Perturbation values are produced by a sampler, which provides the methods that can be used. The <code>method</code> field determines which sampler method will be used. To further specify how such a method should function, the <code>options</code> field can be used to pass a dictionary of key-value pairs. The interpretation of these options depends on the chosen method.</p> <p>By default, a different set of perturbed variables is generated for each realization. By setting the <code>shared</code> flag to <code>True</code>, the sampler can be directed to use the same set of perturbed values for each realization.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The sampler method</p> <code>options</code> <code>Dict[str, Any]</code> <p>Options to be passed to the sampler</p> <code>shared</code> <code>bool</code> <p>Whether perturbation values should be shared between realizations      (default: <code>False</code>)</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants","title":"<code>ropt.config.enopt.constants</code>","text":"<p>Default values used by the configuration classes.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_SEED","title":"<code>DEFAULT_SEED: Final = 1</code>  <code>module-attribute</code>","text":"<p>Default random generator seed.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_NUMBER_OF_PERTURBATIONS","title":"<code>DEFAULT_NUMBER_OF_PERTURBATIONS: Final = 5</code>  <code>module-attribute</code>","text":"<p>Default number of perturbations.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_MAGNITUDE","title":"<code>DEFAULT_PERTURBATION_MAGNITUDE: Final = 0.005</code>  <code>module-attribute</code>","text":"<p>Default perturbation magnitude.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_BOUNDARY_TYPE","title":"<code>DEFAULT_PERTURBATION_BOUNDARY_TYPE: Final = BoundaryType.MIRROR_BOTH</code>  <code>module-attribute</code>","text":"<p>Default perturbation boundary handling type.</p> <p>See also: <code>BoundaryType</code>.</p>"},{"location":"reference/enopt_config/#ropt.config.enopt.constants.DEFAULT_PERTURBATION_TYPE","title":"<code>DEFAULT_PERTURBATION_TYPE: Final = PerturbationType.ABSOLUTE</code>  <code>module-attribute</code>","text":"<p>Default perturbation type.</p> <p>See also: <code>PerturbationType</code>.</p>"},{"location":"reference/enums/","title":"Enumerations","text":""},{"location":"reference/enums/#ropt.enums","title":"<code>ropt.enums</code>","text":"<p>Enumerations used within the <code>ropt</code> library.</p>"},{"location":"reference/enums/#ropt.enums.VariableType","title":"<code>VariableType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the variable types.</p> <p>The variable types are configured in the <code>variables</code> section of the optimizer configuration. The optimization backends may make us of this information to modify their behavior accordingly.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.REAL","title":"<code>REAL = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Continuous variables represented by real values.</p>"},{"location":"reference/enums/#ropt.enums.VariableType.INTEGER","title":"<code>INTEGER = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Discrete variables represented by integer values.</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType","title":"<code>ConstraintType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of linear or non-linear constraints.</p> <p>Both linear and non-linear constraints may be less or equal (\\(\\le\\)), greater or equal (\\(\\ge\\)), or equal (\\(=\\)). Internally, \\(\\le\\) or \\(\\ge\\) constraints may be converted to an opposite constraint, depending on the optimizer backend.</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType.LE","title":"<code>LE = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Less or equal constraint (\\(\\le\\)).</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType.GE","title":"<code>GE = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Greater or equal constraint (\\(\\ge\\)).</p>"},{"location":"reference/enums/#ropt.enums.ConstraintType.EQ","title":"<code>EQ = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Equality constraint (\\(=\\)).</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType","title":"<code>BoundaryType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the ways boundaries should be treated.</p> <p>When variables are perturbed their values may violate boundary constraints. This enumeration lists the ways these values can be modified to fix this.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.NONE","title":"<code>NONE = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Do not modify the value.</p>"},{"location":"reference/enums/#ropt.enums.BoundaryType.TRUNCATE_BOTH","title":"<code>TRUNCATE_BOTH = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Truncate the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     l_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     b_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.BoundaryType.MIRROR_BOTH","title":"<code>MIRROR_BOTH = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Mirror the value \\(v_i\\) at the lower or upper boundary (\\(l_i\\), \\(u_i\\)):</p> \\[ \\hat{v_i} = \\begin{cases}     2l_i - v_i &amp; \\text{if $v_i &lt; l_i$}, \\\\     2b_i - v_i &amp; \\text{if $v_i &gt; b_i$}, \\\\     v_i        &amp; \\text{otherwise} \\end{cases} \\]"},{"location":"reference/enums/#ropt.enums.PerturbationType","title":"<code>PerturbationType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the types of perturbations that can be applied.</p> <p>When applying a perturbation to a variable, generally, some value is generated, which is then applied to the unperturbed values (usually by addition). This enumeration lists the ways how this perturbation value can be modified before being added to the unperturbed variable.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.ABSOLUTE","title":"<code>ABSOLUTE = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the perturbation value as is.</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.RELATIVE","title":"<code>RELATIVE = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Multiply the perturbation value \\(p_i\\) by the range defined by the bounds of the variables \\(c_i\\): \\(\\hat{p}_i = (c_{i,\\text{max}} - c_{i,\\text{min}}) \\times p_i\\). The bounds will generally be defined in the configuration for the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.PerturbationType.SCALED","title":"<code>SCALED = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Scale each perturbation \\(p_i\\) according to the scales (\\(s_i\\)) for each variable: \\(\\hat{p}_i = p_i/s_i\\). The scales \\(s_i\\) will generally be defined in the configuration of the variables (see <code>VariablesConfig</code>).</p>"},{"location":"reference/enums/#ropt.enums.EventType","title":"<code>EventType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the events handled by the event broker.</p> <p>During the execution of the optimization plan, events may be emitted and callbacks can be connected to these events . When triggered by an event, the callbacks receive an <code>Event</code> object. This object contains at least the type of the event (a value of this enumeration) and the current configuration of the step that is executing. If the step has a name it is also added to the event. Additionally, depending on the event type, a tuple of result objects, an exit code  may be present. Refer to the documentation of the individual event types for details.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATION","title":"<code>START_EVALUATION = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted before evaluating new functions.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATION","title":"<code>FINISHED_EVALUATION = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted after finishing the evaluation.</p> <p>Results may be passed to callback reacting to this event.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_OPTIMIZER_STEP","title":"<code>START_OPTIMIZER_STEP = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted just before starting an optimizer step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_OPTIMIZER_STEP","title":"<code>FINISHED_OPTIMIZER_STEP = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted immediately after an optimizer step finishes.</p> <p>Results and an exit code may be passed via the event object.</p>"},{"location":"reference/enums/#ropt.enums.EventType.START_EVALUATOR_STEP","title":"<code>START_EVALUATOR_STEP = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted just before starting an evaluation step.</p>"},{"location":"reference/enums/#ropt.enums.EventType.FINISHED_EVALUATOR_STEP","title":"<code>FINISHED_EVALUATOR_STEP = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Emitted immediately after an evaluation step finishes.</p> <p>Results and an exit code may be passed via the event object.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode","title":"<code>OptimizerExitCode</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumerates the reasons for terminating an optimization.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.UNKNOWN","title":"<code>UNKNOWN = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Unknown cause of termination.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.TOO_FEW_REALIZATIONS","title":"<code>TOO_FEW_REALIZATIONS = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when too few realizations are evaluated successfully.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.MAX_FUNCTIONS_REACHED","title":"<code>MAX_FUNCTIONS_REACHED = 2</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when the maximum number of function evaluations is reached.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.NESTED_OPTIMIZER_FAILED","title":"<code>NESTED_OPTIMIZER_FAILED = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when a nested optimization fails to find an optimal value.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.USER_ABORT","title":"<code>USER_ABORT = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when the optimization is aborted by the user.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.OPTIMIZER_STEP_FINISHED","title":"<code>OPTIMIZER_STEP_FINISHED = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when an optimization step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.OptimizerExitCode.EVALUATION_STEP_FINISHED","title":"<code>EVALUATION_STEP_FINISHED = 6</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Returned when an evaluation step terminates normally.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName","title":"<code>ResultAxisName</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumerates the possible axis names in a Results data object.</p> <p>Result objects (see <code>Results</code>) contain multidimensional arrays where the axes represent particular quantities, for instance variables, function objects, or realization numbers. The result objects contain metadata that identify the axes by values of this enumeration. These can be retrieved by the <code>get_axis_names</code> method of the attributes of a results object. They are used internally when exporting data to determine the type of the array axes, for instance to retrieve the names of the variables from the configuration.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.VARIABLE","title":"<code>VARIABLE = 'variable'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the variable.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.OBJECTIVE","title":"<code>OBJECTIVE = 'objective'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the objective function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.LINEAR_CONSTRAINT","title":"<code>LINEAR_CONSTRAINT = 'linear_constraint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the linear constraint.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.NONLINEAR_CONSTRAINT","title":"<code>NONLINEAR_CONSTRAINT = 'nonlinear_constraint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the constraint function.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.REALIZATION","title":"<code>REALIZATION = 'realization'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the realization.</p>"},{"location":"reference/enums/#ropt.enums.ResultAxisName.PERTURBATION","title":"<code>PERTURBATION = 'perturbation'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The axis index corresponds to the index of the perturbation.</p>"},{"location":"reference/evaluator/","title":"Function evaluations","text":""},{"location":"reference/evaluator/#ensemble-evaluator","title":"Ensemble evaluator","text":""},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator","title":"<code>ropt.ensemble_evaluator.EnsembleEvaluator</code>","text":"<p>A class for constructing functions and gradients from an ensemble of functions.</p> <p>This class implements the calculation of functions and gradients from an ensemble of functions, according to the settings defined in an <code>EnOptConfig</code> configuration object, given an <code>Evaluator</code> callable that is used to evaluate the individual functions.</p>"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.constraint_auto_scales","title":"<code>constraint_auto_scales: Optional[NDArray[np.float64]]</code>  <code>property</code>","text":"<p>Return optional auto-calculated scales for constraints.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The calculate scales, or <code>None</code>.</p>"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.__init__","title":"<code>__init__(config, evaluator, result_id_iter, rng, plugin_manager)</code>","text":"<p>Initialize the ensemble evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration object</p> required <code>evaluator</code> <code>Evaluator</code> <p>The callable for evaluation individual functions</p> required <code>result_id_iter</code> <code>Iterator[int]</code> <p>An iterator that generates ID's for generated results</p> required <code>rng</code> <code>Generator</code> <p>A random number generator used for stochastic gradient estimation</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>A plugin manager to load required plugins</p> required"},{"location":"reference/evaluator/#ropt.ensemble_evaluator.EnsembleEvaluator.calculate","title":"<code>calculate(variables, *, compute_functions, compute_gradients)</code>","text":"<p>Evaluate the given variable vectors.</p> <p>The <code>variables</code> argument may be a single vector of variables, or a set of variable vectors represented as row-vectors in a matrix. The <code>compute_functions</code> and <code>compute_gradient</code> flags determine with results are returned: functions, gradients, or both.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vectors to evaluate</p> required <code>compute_functions</code> <code>bool</code> <p>Whether to calculate functions</p> required <code>compute_gradients</code> <code>bool</code> <p>Whether to calculate gradients</p> required <p>Returns:</p> Type Description <code>Tuple[Results, ...]</code> <p>The results, representing single function or gradient evaluations.</p>"},{"location":"reference/evaluator/#evaluator-callbacks","title":"Evaluator callbacks","text":""},{"location":"reference/evaluator/#ropt.evaluator.Evaluator","title":"<code>ropt.evaluator.Evaluator</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for evaluator objects or callables.</p> <p>The optimizers require a callback that follows this protocol.</p>"},{"location":"reference/evaluator/#ropt.evaluator.Evaluator.__call__","title":"<code>__call__(variables, context)</code>","text":"<p>The function evaluator callback signature.</p> <p>The first argument of the function should be a matrix where each column is a variable vector. Depending on the information passed by the second argument, all objective and constraint functions for all vectors or for a subset are to be calculated.</p> <p>The second argument is an <code>EvaluatorContext</code> object, providing supplementary information to the evaluation function.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate</p> required <code>context</code> <code>EvaluatorContext</code> <p>The evaluation context</p> required <p>Returns:</p> Type Description <code>EvaluatorResult</code> <p>An evaluation results object.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext","title":"<code>ropt.evaluator.EvaluatorContext</code>  <code>dataclass</code>","text":"<p>Capture additional details for the function evaluator.</p> <p>Function evaluator callbacks (see <code>Evaluator</code>) mainly require variable vectors to evaluate objective and constraint functions. However, depending on their implementation, evaluators may benefit from additional information. To accommodate this, function evaluators receive a <code>EvaluatorContext</code> object with the following details:</p> <ul> <li>The configuration object for the ongoing optimization step.</li> <li>Indices indicating the realization to which each variable vector belongs.</li> <li>A matrix indicating, for each function and realization, whether it is   active and needs computation.</li> <li>A matrix indicating, for each constraint and realization, whether it is   active and requires computation.</li> </ul> <p>The <code>active_objectives</code> and <code>active_constraints</code> fields are boolean matrices, where each column represents one realization, and each row signifies a function or a constraint. Entries marked as <code>True</code> are essential for the optimizer, while other combinations do not necessitate evaluation.</p> <p>In practical scenarios, these matrices may prove overly detailed for function evaluators. Typically, evaluators may only be capable of calculating all objective and constraint functions for a given realization or none at all. In such cases, it suffices to examine the <code>active</code> property, indicating the realizations requiring evaluation.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>EnOptConfig</code> <p>Configuration of the optimizer.</p> <code>realizations</code> <code>NDArray[intc]</code> <p>Realization numbers for each requested evaluation.</p> <code>active_objectives</code> <code>Optional[NDArray[bool_]]</code> <p>Signifies which function/realization evaluations are                 essential for the optimizer.</p> <code>active_constraints</code> <code>Optional[NDArray[bool_]]</code> <p>Signifies which constraint/realization evaluations are                 essential for the optimizer.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorContext.active","title":"<code>active: Optional[NDArray[np.bool_]]</code>  <code>cached</code> <code>property</code>","text":"<p>Return the set of active variable vectors.</p> <p>This property is useful for determining the realizations for which the objective and constraint functions need to be calculated. The index of each entry corresponds to the realization number and indicates whether the functions should be calculated.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[bool_]]</code> <p>A boolean array.</p>"},{"location":"reference/evaluator/#ropt.evaluator.EvaluatorResult","title":"<code>ropt.evaluator.EvaluatorResult</code>  <code>dataclass</code>","text":"<p>Store the results of a function evaluation.</p> <p>The objectives and constraint values are stored as a matrix, where the columns correspond to the index of the objective or constraint, and the rows correspond to the index of the variable vector for which they were calculated. Depending on context information passed to the evaluation function, not all results may have been calculated, in which case the corresponding entries should contain zeros. Entries may also contain <code>numpy.nan</code> values to signify that a calculation failed.</p> <p>Optionally, a batch ID can be returned to identify the batch of calculations. This can be useful for tracking or managing evaluations performed together.</p> <p>Additionally, evaluation IDs are provided as an option. These IDs can be used to uniquely identify the results calculated for each variable vector, offering a way to link specific evaluations back to their corresponding input vectors.</p> <p>Attributes:</p> Name Type Description <code>objectives</code> <code>NDArray[float64]</code> <p>The calculated objective values.</p> <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional calculated constraint values.</p> <code>batch_id</code> <code>Optional[int]</code> <p>Optional batch ID.</p> <code>evaluation_ids</code> <code>Optional[NDArray[intc]]</code> <p>Optional ID for each evaluation.</p>"},{"location":"reference/evaluator/#optional-evaluator-implementations","title":"Optional evaluator implementations","text":""},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator","title":"<code>ropt.evaluator.ConcurrentEvaluator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for implementing a concurrent evaluator.</p> <p>This abstract base class provides the framework for implementing an evaluator that uses a concurrent executor.</p> <p>The <code>launch</code> method must be implemented to start an evaluation for one vector of variables, and return a future-like object, compatible with the <code>concurrent.futures</code> module of Python, implementing at least the <code>done()</code>, <code>exception()</code>, and <code>result()</code> methods. The <code>monitor</code> method can be overloaded to implement specific monitoring functionality, the default implementation does nothing.</p> <p>The class implements an optional caching mechanism to prevent repeated evaluation of functions. When enabled, all evaluation results are cached in memory and reused when requested. This is in particular useful in optimization plans with multiple or nested optimizations where often restarts occur from points that already have been evaluated before.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator.__init__","title":"<code>__init__(*, enable_cache=True, polling=0.1, max_submit=500)</code>","text":"<p>Initialize a concurrent evaluator object.</p> <p>Some general properties of the evaluator are fixed at initialization time:</p> <ul> <li>The cache may be enabled or disabled using the <code>enable_cache</code> parameter.</li> <li>While evaluations are running concurrently the evaluator will   regularly poll them to check their status. The <code>polling</code> parameter   determine the delay between polling events.</li> <li>When a very large number of jobs is submitted this may overwhelm the   evaluator, depending on the implementation. To prevent this, the jobs   may be submitted in smaller portions, the size of which are defined by   the <code>max_submit</code> argument.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>enable_cache</code> <code>bool</code> <p>Enable the caching mechanism</p> <code>True</code> <code>polling</code> <code>float</code> <p>Time in seconds between checking job status</p> <code>0.1</code> <code>max_submit</code> <code>int</code> <p>Maximum number of variables to submit simultaneously</p> <code>500</code>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator.launch","title":"<code>launch(batch_id, job_id, variables, context)</code>  <code>abstractmethod</code>","text":"<p>Launch an evaluation return a future for each job.</p> <p>This method must implement the process of launching a a single function evaluation for a variable vector passed via the <code>variables</code> parameter. A unique batch ID is passed via the <code>batch_id</code>, which can be optionally used by the evaluator to identify the current batch of functions.</p> <p>This method should return a dictionary mapping the indices of the jobs to the tasks that will contain the result. The tasks are objects deriving from the <code>ConcurrentTask</code> class, containing the future object representing the launched task and its result. Under the hood, other tasks may be launched, but only those that contain results should be returned.</p> <p>This method is called by the <code>__call__</code> method, which implements the <code>Evaluator</code> callback signature.</p> <p>The <code>context</code> argument with optional information is passed from the <code>__call__</code> method unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>batch_id</code> <code>Any</code> <p>The ID of the batch of evaluations to run.</p> required <code>job_id</code> <code>int</code> <p>The ID of the job launched for the variables</p> required <code>variables</code> <code>NDArray[float64]</code> <p>The matrix of variables to evaluate.</p> required <code>context</code> <code>EvaluatorContext</code> <p>Evaluator context.</p> required <p>Returns:</p> Type Description <code>Optional[ConcurrentTask]</code> <p>The last future or <code>None</code> if no tasks were launched.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentEvaluator.monitor","title":"<code>monitor()</code>","text":"<p>Monitor the states of the running evaluations.</p> <p>This method is called regularly in the polling loop that checks the futures until all results are collected. If the status of the evaluations should be monitored, this method should be overridden.</p> <p>The time in seconds between calls in the polling loop can be modified by setting the <code>polling</code> attribute upon object initialization.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentTask","title":"<code>ropt.evaluator.ConcurrentTask</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract data class for tasks in a concurrent evaluator.</p> <p>These task objects should contain the future that represents the task and return the results of the evaluation.</p> <p>It should implement two methods to retrieve the objective function values and optionally the constraint values.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentTask.get_objectives","title":"<code>get_objectives()</code>  <code>abstractmethod</code>","text":"<p>Return the objectives calculated by the task.</p> <p>This method will only be called after the future is done, and if no exception was raised during the execution of the task.</p> Info <p>The return value might be None, as derived evaluator classes might also employ tasks that do not return results.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The calculated objectives.</p>"},{"location":"reference/evaluator/#ropt.evaluator.ConcurrentTask.get_constraints","title":"<code>get_constraints()</code>","text":"<p>Return the constraints calculated by the task, if available.</p> <p>This method will only be called after the future is done, and if no exception was raised during the execution of the task.</p> <p>This has a default implementation that returns <code>None</code>, which is only usable when it is certain that there are no non-linear constraints. If there are non-linear constraints, this method should be overridden.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The calculated constraints or <code>None</code>.</p>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#ropt.exceptions","title":"<code>ropt.exceptions</code>","text":"<p>Exceptions raised within the <code>ropt</code> library.</p>"},{"location":"reference/exceptions/#ropt.exceptions.ConfigError","title":"<code>ConfigError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an configuration error occurs.</p>"},{"location":"reference/exceptions/#ropt.exceptions.PlanError","title":"<code>PlanError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an error occurs in an optimization plan.</p>"},{"location":"reference/exceptions/#ropt.exceptions.PlanError.__init__","title":"<code>__init__(message)</code>","text":"<p>Initialize with a custom error message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message</p> required"},{"location":"reference/exceptions/#ropt.exceptions.PlanExprError","title":"<code>PlanExprError</code>","text":"<p>               Bases: <code>PlanError</code></p> <p>Raised when an error occurs in a plan expression.</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted","title":"<code>OptimizationAborted</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimization is aborted.</p> <p>When constructing the exception object an exit code must be passed that indicates the reason for aborting (see <code>OptimizerExitCode</code>).</p>"},{"location":"reference/exceptions/#ropt.exceptions.OptimizationAborted.__init__","title":"<code>__init__(exit_code)</code>","text":"<p>Initialize an exception that aborts the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>exit_code</code> <code>OptimizerExitCode</code> <p>The exit code indicating the reason for the abort</p> required"},{"location":"reference/function_transform_plugins/","title":"Function transforms","text":""},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform","title":"<code>ropt.plugins.function_transform</code>","text":"<p>Plugin functionality for adding function transforms.</p> <p>This package contains the abstract base classes for function transform plugins, and the default function transforms that are part of <code>ropt</code>.</p>"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base","title":"<code>ropt.plugins.function_transform.base</code>","text":"<p>This module defines the abstract base classes for function transforms.</p> <p>Function transforms can be added via the plugin mechanism to implement additional ways to functions and gradient ensembles. Any object that adheres to the <code>FunctionTransform</code> base class may be installed as a plugin.</p>"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base.FunctionTransform","title":"<code>FunctionTransform</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for function transforms.</p>"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base.FunctionTransform.__init__","title":"<code>__init__(enopt_config, transform_index)</code>  <code>abstractmethod</code>","text":"<p>Initialize the function transform object.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>transform_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base.FunctionTransform.calculate_function","title":"<code>calculate_function(functions, weights)</code>  <code>abstractmethod</code>","text":"<p>Combine functions from realizations into an expected function.</p> Calculation from merged realizations <p>Normally the gradient is calculated for each realization separately and then combined into an overall gradient with <code>calculate_gradient</code> method. The <code>merge_realizations</code> flag in the ensemble optimizer configuration directs the optimizer to calculate the overall gradient from all realizations directly. This yields a reasonable estimation if the function transform is an averaging operation, but may not be appropriate in other cases.</p> <p>At initialization, the <code>merge_realizations</code> flag should be checked, and if necessary a <code>ConfigError</code> with an appropriate message should be raised.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected function values.</p>"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base.FunctionTransform.calculate_gradient","title":"<code>calculate_gradient(functions, gradient, weights)</code>  <code>abstractmethod</code>","text":"<p>Combine gradients from realizations into an expected gradient.</p> <p>Parameters:</p> Name Type Description Default <code>functions</code> <code>NDArray[float64]</code> <p>The functions for each realization</p> required <code>gradient</code> <code>NDArray[float64]</code> <p>The gradient for each realization</p> required <code>weights</code> <code>NDArray[float64]</code> <p>The weight of each realization</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The expected gradients.</p>"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base.FunctionTransformPlugin","title":"<code>FunctionTransformPlugin</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>The function transform plugin base class.</p>"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.base.FunctionTransformPlugin.create","title":"<code>create(enopt_config, transform_index)</code>  <code>abstractmethod</code>","text":"<p>Initialize the function transform object.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>transform_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/function_transform_plugins/#ropt.plugins.function_transform.default","title":"<code>ropt.plugins.function_transform.default</code>","text":"<p>This module implements the default function transform plugin.</p>"},{"location":"reference/optimization/","title":"Optimization","text":""},{"location":"reference/optimization/#ropt.optimization","title":"<code>ropt.optimization</code>","text":"<p>The optimizer and event classes.</p> <p>The <code>EnsembleOptimizer</code> class runs ensemble based optimizations. It is not recommended to used them directly to run optimizations, the <code>Plan</code> functionality is usually more flexible and easier to use.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer","title":"<code>EnsembleOptimizer</code>","text":"<p>Optimizer class for running ensemble optimizations.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.is_parallel","title":"<code>is_parallel: bool</code>  <code>property</code>","text":"<p>Whether the optimization is parallelized.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the optimization is parallized.</p>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.__init__","title":"<code>__init__(enopt_config, ensemble_evaluator, plugin_manager, signal_evaluation=None, nested_optimizer=None)</code>","text":"<p>Initialize the ensemble optimizer class.</p> <p>This class requires at least three argument that together define a single optimization run:</p> <ol> <li>An <code>EnOptConfig</code> that contains all    configuration settings for the optimization.</li> <li>An <code>EnsembleEvaluator</code> object    that is responsible for evaluating functions.</li> <li>A <code>PluginManager</code> object that provides    access to optimizer plugins.</li> </ol> <p>In addition, two optional callbacks can be provided:</p> <ol> <li>A <code>SignalEvaluationCallback</code>    callback that is called before and after each function evaluation.</li> <li>A <code>NestedOptimizerCallback</code>    callback that is called at each function evaluation to run a nested    optimization.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The ensemble optimization configuration</p> required <code>ensemble_evaluator</code> <code>EnsembleEvaluator</code> <p>The evaluator object</p> required <code>plugin_manager</code> <code>PluginManager</code> <p>Plugin manager</p> required <code>signal_evaluation</code> <code>Optional[SignalEvaluationCallback]</code> <p>Optional callback to signal evaluations</p> <code>None</code> <code>nested_optimizer</code> <code>Optional[NestedOptimizerCallback]</code> <p>Optional nested optimization call</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.EnsembleOptimizer.start","title":"<code>start(variables)</code>","text":"<p>Start the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The initial variables for the optimization.</p> required <p>Returns:</p> Type Description <code>OptimizerExitCode</code> <p>An exit code indicating the reason for termination.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback","title":"<code>SignalEvaluationCallback</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the callback that is used to signal that an evaluation is occurring.</p>"},{"location":"reference/optimization/#ropt.optimization.SignalEvaluationCallback.__call__","title":"<code>__call__(results=None)</code>","text":"<p>Callback protocol for signaling that evaluations are occurring.</p> <p>When a function with this signature is provided to an ensemble optimizer, it is called before and after the optimizer finishes an evaluation.Before the evaluation starts, this method is called with the <code>results</code> argument set to <code>None</code>. When an evaluation is has finished, it is called with <code>results</code> set to the results of the evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Optional[Tuple[Results, ...]]</code> <p>The results produced by the evaluation.</p> <code>None</code>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback","title":"<code>NestedOptimizerCallback</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Run a nested optimization.</p>"},{"location":"reference/optimization/#ropt.optimization.NestedOptimizerCallback.__call__","title":"<code>__call__(variables)</code>","text":"<p>Callback protocol for running a nested optimization.</p> <p>When a function with this signature is provided to an ensemble optimizer, it is called at each function evaluation to run a nested optimization. It accepts the current variables as its arguments and returns a tuple consisting of the result (or <code>None</code> if no result is available), and a boolean value that indicates if the optimization was aborted by a user signal.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variables to start the nested optimization with</p> required <p>Returns:</p> Type Description <code>Tuple[Optional[FunctionResults], bool]</code> <p>The nested optimization results and whether the user aborted the optimization.</p>"},{"location":"reference/optimizer_plugins/","title":"Optimizer plugins","text":""},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer","title":"<code>ropt.plugins.optimizer</code>","text":"<p>Plugin functionality for adding optimization plugins.</p> <p>Optimization plugins are managed by a <code>PluginManager</code> object, which returns classes or factory functions to create objects that implement one or more optimization methods. These objects must adhere to the <code>Optimizer</code> abstract base class. This abstract base class allows <code>ropt</code> to provide the optimizer with the callback used for evaluating functions and gradients and allows it to be started from an optimizer step in the optimization plan.</p> <p>To support the implementation of the optimizer classes, the <code>ropt.plugins.optimizer.utils</code> module provides some utilities.</p> <p>By default the <code>SciPyOptimizer</code> plugin is installed which provides a number of methods from the <code>scipy.optimize</code> package.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base","title":"<code>ropt.plugins.optimizer.base</code>","text":"<p>This module defines base classes and protocols for optimization plugins.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer","title":"<code>Optimizer</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base for optimizer classes.</p> <p>Optimizers provided by optimizer plugins should derive from the <code>Optimizer</code> abstract base class, which specifies the requirements for the class constructor (<code>__init__</code>) and also includes a <code>start</code> method used to initiate the optimization process.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.allow_nan","title":"<code>allow_nan: bool</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return <code>True</code> if a <code>NaN</code> is a valid function value.</p> <p>If the optimizer can handle <code>NaN</code> function values, it may implement this method to return <code>True</code>. This enables handling cases where all function evaluations in an ensemble fail. By setting the <code>realization_min_success</code> configuration parameter to zero, the ensemble optimization plan can then be allowed to return a <code>NaN</code> value instead of raising an error.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>NaN</code> is allowed.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.is_parallel","title":"<code>is_parallel: bool</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Whether the current uses parallel evaluations.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if optimization is parallelized.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.__init__","title":"<code>__init__(config, optimizer_callback)</code>  <code>abstractmethod</code>","text":"<p>Initialize an optimizer object.</p> <p>The <code>config</code> object provides the desired configuration for the optimization process and should be used to set up the optimizer correctly before starting the optimization. The optimization will be initiated using the <code>start</code> method and will repeatedly require function and gradient evaluations at given variable vectors. The <code>optimizer_callback</code> argument provides the function that should be used to calculate the function and gradient values, which can then be forwarded to the optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.Optimizer.start","title":"<code>start(initial_values)</code>  <code>abstractmethod</code>","text":"<p>Start the optimization.</p> <p>This method must be implemented to run the optimization using the provided initial values, collecting function and gradient evaluations as needed by calling the callback passed via the <code>optimizer_callback</code> argument during initialization.</p> <p>Parameters:</p> Name Type Description Default <code>initial_values</code> <code>NDArray[float64]</code> <p>Vector of variables to start the optimization with.</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerCallback","title":"<code>OptimizerCallback</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the optimizer callback.</p> <p>Optimization plugins implement optimizer classes derived from the <code>Optimizer</code> abstract base class. Objects of these classes are initialized with a callback function that follows the call signature defined here. This callback should be used to request the function and gradient evaluations that the optimizer needs.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerCallback.__call__","title":"<code>__call__(variables, /, *, return_functions, return_gradients)</code>","text":"<p>The signature of the optimizer callback.</p> <p>The optimizer callback expects a vector or matrix with variables to evaluate. Discrete optimizers may request function evaluations for multiple variable vectors, passed as the rows of a matrix. Gradient-based methods may currently only pass a single variable vector at a time.</p> <p>The <code>return_functions</code> and <code>return_gradients</code> flags determine whether functions and/or gradients are to be evaluated. The results are returned as a tuple of arrays, one for functions and constraints, the other for gradients. If one of <code>return_functions</code> or <code>return_gradients</code> is <code>False</code>, the corresponding result is an empty array.</p> <p>Multiple function evaluations are returned as a matrix where the rows are the result vectors for each evaluation. The first element of a result vector is the value of the objective value, and the remaining elements are the values of the non-linear constraints.</p> <p>The gradients of the objective function and the non-linear constraints are returned as a matrix. The first row contains the gradient of the objective function, while the remaining rows contain the gradients of the non-linear constraints. Gradient-based methods currently support only a single evaluation, hence there is also only a single result.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The variable vector or matrix to evaluate</p> required <code>return_functions</code> <code>bool</code> <p>If <code>True</code>, evaluate and return functions</p> required <code>return_gradients</code> <code>bool</code> <p>If <code>True</code>, evaluate and return gradients</p> required <p>Returns:</p> Type Description <code>Tuple[NDArray[float64], NDArray[float64]]</code> <p>A tuple with function and gradient values.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin","title":"<code>OptimizerPlugin</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for optimizer plugins.</p> <p>Optimizers are implemented through optimizer plugins that must derive from this base class. Plugins can be built-in, installed via a plugin mechanism, or loaded dynamically. During execution of an optimization plan, the required optimizer plugin will be located via the <code>PluginManager</code> and used to create <code>Optimizer</code> objects via its <code>create</code> function.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.base.OptimizerPlugin.create","title":"<code>create(config, optimizer_callback)</code>  <code>abstractmethod</code>","text":"<p>Create an optimizer.</p> <p>This is a factory function for instantiating optimizer objects implemented in the plugin.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The optimizer configuration to used</p> required <code>optimizer_callback</code> <code>OptimizerCallback</code> <p>The optimizer callback</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils","title":"<code>ropt.plugins.optimizer.utils</code>","text":"<p>Utility functions for use by optimizer plugins.</p> <p>This module provides utility functions to validate supported constraints, filter linear constraints, and to retrieve the list of supported optimizers.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.filter_linear_constraints","title":"<code>filter_linear_constraints(config, variable_indices)</code>","text":"<p>Filter unnecessary constraints from a linear constraint configuration.</p> <p>In the case that the optimizer only optimizes a sub-set of the variables, linear constraints that are only formed from the unused variables are superfluous. This utility function removes those constraints from a  linear configuration constraint.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LinearConstraintsConfig</code> <p>The linear configuration constraint</p> required <code>variable_indices</code> <code>NDArray[intc]</code> <p>The indices of the variables used by the optimizer</p> required <p>Returns:</p> Type Description <code>LinearConstraintsConfig</code> <p>The filtered linear constraint configuration.</p>"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.validate_supported_constraints","title":"<code>validate_supported_constraints(config, method, supported_constraints, required_constraints)</code>","text":"<p>Check if the requested optimization features are supported or required.</p> <p>The keys of the supported_constraints and required_constraints dicts specify the type of the constraint as shown in the example below. The values are sets of method names that support or require the type of constraint specified by the key.</p> <p>For example: {     \"bounds\": {\"L-BFGS-B\", \"TNC\", \"SLSQP\"},     \"linear:eq\": {\"SLSQP\"},     \"linear:ineq\": {\"SLSQP\"},     \"nonlinear:eq\": {\"SLSQP\"},     \"nonlinear:ineq\": {\"SLSQP\"}, }</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>method</code> <code>str</code> <p>The method to check</p> required <code>supported_constraints</code> <code>Dict[str, Set[str]]</code> <p>Specify the supported constraints</p> required <code>required_constraints</code> <code>Dict[str, Set[str]]</code> <p>Specify the required constraints</p> required"},{"location":"reference/optimizer_plugins/#ropt.plugins.optimizer.utils.create_output_path","title":"<code>create_output_path(base_name, base_dir=None, name=None, suffix=None)</code>","text":"<p>Create an output path name.</p> <p>If the path already exists, an index is appended to it.</p> <p>Parameters:</p> Name Type Description Default <code>base_name</code> <code>str</code> <p>Base name of the path</p> required <code>base_dir</code> <code>Optional[Path]</code> <p>Optional directory to base the path in</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Optional optimization step name to include in the name</p> <code>None</code> <code>suffix</code> <code>Optional[str]</code> <p>Optional suffix for the resulting path</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>The constructed path</p>"},{"location":"reference/plan/","title":"Optimization plans","text":""},{"location":"reference/plan/#ropt.plan","title":"<code>ropt.plan</code>","text":"<p>Code to run optimization plans.</p> <p>Optimization plans consist of a series of steps that define an optimization workflow. This can be as simple as a single optimization run or involve multiple, potentially nested optimizations.</p> <p>These plans are configured using PlanConfig objects and executed by a Plan object. A plan is composed of ResultHandler objects, which process and store data generated during execution, and PlanStep objects that define the individual steps executed by the plan. Both handler and step objects are implemented through a plugin mechanism. The ropt library also offers several default plan objects to support various optimization workflows.</p> <p>A plan can store data identified by a name, known as plan variables. These variables can be accessed using the <code>[]</code> operator, and their existence can be checked with the <code>in</code> operator. Results handler and step objects typically store values in variables with their names set in their configuration.</p> <p>Result handler and step objects are configured using their corresponding configuration objects, <code>ResultHandlerConfig</code> and <code>StepConfig</code>, respectively. These are Pydantic classes initialized via dictionaries of configuration values. These can be strings that are interpolated with the variables stored in the plan. Plan variables, prefixed with the <code>$</code> sign, will be substituted with their corresponding values. Any part of a string enclosed by <code>${{</code> and <code>}}</code> will be parsed as a mathematical expression, with variables replaced by their corresponding values in the plan.</p> <p>To execute optimization plans, additional shared state may be required across all steps, such as a callable for function evaluations or a random number generator. For this purpose, an OptimizerContext object is supplied when creating the plan, which maintains this shared state.</p> <p>Initializing and executing a plan object for simple optimization cases can be cumbersome. The <code>OptimizationPlanRunner</code> provides a convenient way to build and execute such plans with ease.</p>"},{"location":"reference/plan/#ropt.plan.Plan","title":"<code>Plan</code>","text":"<p>The plan class for executing optimization workflows.</p>"},{"location":"reference/plan/#ropt.plan.Plan.aborted","title":"<code>aborted: bool</code>  <code>property</code>","text":"<p>Whether the plan was aborted by the user.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the user aborted the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.plugin_manager","title":"<code>plugin_manager: PluginManager</code>  <code>property</code>","text":"<p>Return the plugin manager used by the plan.</p> <p>Returns:</p> Type Description <code>PluginManager</code> <p>The plugin manager.</p>"},{"location":"reference/plan/#ropt.plan.Plan.optimizer_context","title":"<code>optimizer_context: OptimizerContext</code>  <code>property</code>","text":"<p>Return the optimizer context of the plan.</p> <p>Returns:</p> Type Description <code>OptimizerContext</code> <p>The optimizer context object used by the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.__init__","title":"<code>__init__(config, optimizer_context, plugin_manager=None, parent=None)</code>","text":"<p>Initialize a plan object.</p> <p>The plan requires a <code>PlanConfig</code> object and an <code>OptimizationContext</code> object. The <code>plugin_manager</code> argument is optional and allows you to specify plugins for the results handler and step objects that the plan may use. If not provided, only plugins installed via Python's standard entry points mechanism will be used.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>PlanConfig</code> <p>The optimizer configuration</p> required <code>optimizer_context</code> <code>OptimizerContext</code> <p>The context in which the plan executes</p> required <code>plugin_manager</code> <code>Optional[PluginManager]</code> <p>An optional plugin manager</p> <code>None</code> <code>parent</code> <code>Optional[Plan]</code> <p>Optional parent plan that spawned this plan</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.Plan.run","title":"<code>run(*args)</code>","text":"<p>Run the Plan.</p> <p>This method executes the steps of the plan. If a user abort event occurs, the method will return <code>True</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.abort","title":"<code>abort()</code>","text":"<p>Abort the plan.</p>"},{"location":"reference/plan/#ropt.plan.Plan.create_steps","title":"<code>create_steps(step_configs)</code>","text":"<p>Create step objects from step configs.</p> <p>Given a list of step configuration objects, this method returns a list of step objects, each configured according to its corresponding configuration.</p> <p>Parameters:</p> Name Type Description Default <code>step_configs</code> <code>List[StepConfig]</code> <p>A list of step configuration objects.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.run_steps","title":"<code>run_steps(steps)</code>","text":"<p>Execute a list of steps.</p> <p>This method executes a list of plan steps and returns <code>True</code> if the execution is aborted by the user.</p> <p>Parameters:</p> Name Type Description Default <code>steps</code> <code>List[PlanStep]</code> <p>A list of steps to execute.</p> required <p>Returns:</p> Type Description <code>None</code> <p><code>True</code> if the execution was aborted by the user; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.Plan.spawn","title":"<code>spawn(config)</code>","text":"<p>Spawn a new plan from the current plan.</p> <p>This method creates a new plan that shares the same optimization context and plugin manager as the current plan. However, it does not inherit other properties, such as variables.</p> <p>In addition, any signals that are emitted by the spawned plan are forwarded to the observers that are connected to this plan. In other words, signals emitted by the spawn plan 'bubble' up to the current plan.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>PlanConfig</code> <p>The configuration of the new plan</p> required"},{"location":"reference/plan/#ropt.plan.Plan.eval","title":"<code>eval(value)</code>","text":"<p>Evaluate the provided value as an expression.</p> <p>If the value is not  a string, it is returned unchanged. Otherwise, it is evaluates the expression and returns the result.</p> Note <p>The result of a mathematical expression is restricted to numerical values, lists, and numpy arrays. However, plan variables can contain values of any type, so expressions of the form <code>$identifier</code> may evaluate to a result of any type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The expression to evaluate.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The result of the expression.</p>"},{"location":"reference/plan/#ropt.plan.Plan.add_observer","title":"<code>add_observer(event, callback)</code>","text":"<p>Add an observer function.</p> <p>Observer functions will be called during optimization if an event of the given type occurs. The callable must accept an argument of the <code>Event</code> class that contains information about the event that occurred.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>EventType</code> <p>The type of events to react to</p> required <code>callback</code> <code>Callable[[Event], None]</code> <p>The function to call if the event is received</p> required"},{"location":"reference/plan/#ropt.plan.Plan.emit_event","title":"<code>emit_event(event)</code>","text":"<p>Emit an event of the given type with given data.</p> <p>All callbacks for the given event type, that were added by the <code>add_observer</code> method are called with the given event object as their argument.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Event</code> <p>The event to emit</p> required"},{"location":"reference/plan/#ropt.plan.Plan.__getitem__","title":"<code>__getitem__(name)</code>","text":"<p>Get the value of a plan variable.</p> <p>This method implements the <code>[]</code> operator on the plan object to retrieve the value of a plan variable.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value of the variable.</p>"},{"location":"reference/plan/#ropt.plan.Plan.__setitem__","title":"<code>__setitem__(name, value)</code>","text":"<p>Set a plan variable to the given value.</p> <p>This method implements the <code>[]</code> operator on the plan object to set the value of a plan variable.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable.</p> required <code>value</code> <code>Any</code> <p>The value to assign.</p> required"},{"location":"reference/plan/#ropt.plan.Plan.__contains__","title":"<code>__contains__(name)</code>","text":"<p>Check if a variable exists.</p> <p>This method implements the <code>in</code> operator on the plan object to determine if a plan variable exists.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the variable.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the variable exists; otherwise, <code>False</code>.</p>"},{"location":"reference/plan/#ropt.plan.OptimizerContext","title":"<code>OptimizerContext</code>","text":"<p>Context class for shared state across a plan.</p> <p>An optimizer context object holds the information and state shared across all steps in an optimization plan. This currently includes the following:</p> <ul> <li>An <code>Evaluator</code> callable for evaluating   functions.</li> <li>A seed for a random number generator used in stochastic gradient   estimation.</li> <li>An iterator that generates unique result IDs.</li> </ul>"},{"location":"reference/plan/#ropt.plan.OptimizerContext.__init__","title":"<code>__init__(evaluator, seed=None)</code>","text":"<p>Initialize the optimization context.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>Evaluator</code> <p>The callable for running function evaluations</p> required <code>seed</code> <code>Optional[int]</code> <p>Optional seed for the random number generator</p> <code>None</code>"},{"location":"reference/plan/#ropt.plan.Event","title":"<code>Event</code>  <code>dataclass</code>","text":"<p>The <code>Event</code> class stores optimization event data.</p> <p>While running an optimization plan, callbacks can be connected to react to events triggered during execution. These callbacks accept a single <code>Event</code> object containing information about the event.</p> <p>The actual data contained in the object depends on the nature of the event. Refer to the documentation of the <code>EventType</code> enumeration for more details.</p> <p>Attributes:</p> Name Type Description <code>event_type</code> <code>EventType</code> <p>The type of the event</p> <code>config</code> <code>EnOptConfig</code> <p>The current configuration object of the executing plan</p> <code>results</code> <code>Optional[Tuple[Results, ...]]</code> <p>Optional results passed with the event</p> <code>exit_code</code> <code>Optional[OptimizerExitCode]</code> <p>An optional exit code</p> <code>tags</code> <code>Set[str]</code> <p>Optional tags added to the results</p>"},{"location":"reference/plan_config/","title":"Optimization Plan configuration","text":""},{"location":"reference/plan_config/#ropt.config.plan","title":"<code>ropt.config.plan</code>","text":"<p>Configuration classes for optimization plans.</p> <p>Optimization plans are configured via <code>PlanConfig</code> objects and run by <code>Plan</code> objects and.</p>"},{"location":"reference/plan_config/#ropt.config.plan.PlanConfig","title":"<code>PlanConfig</code>","text":"<p>Configuration class for optimization plans.</p> <p>An optimization plan configuration consists of two sections: a event handlers section defined using the <code>handlers</code> attribute, and a section that defines the tasks to perform by the <code>steps</code> attribute.</p> <p>The <code>handlers</code> attribute contains the configuration of the objects that process events emitted by the steps. Result handler objects are initialized before creating and running the steps.</p> <p>When running a plan, arguments can be passed. The <code>inputs</code> attributes denotes a list of input variables, that will be initialized with the passed values.</p> <p>After the plan has finished, a tuple of outputs can be returned. The <code>outputs</code> attribute contains the names of the variables that will used to generate the output tuple.</p> <p>Variables can be created on the fly by the steps, or by the result handler objects, but can also be predefined by the <code>variables</code> attribute, giving their name and value.</p> <p>After initializing the result handler objects, the steps are configured by the entries given by the <code>steps</code> attribute and are initialized and executed in order.</p> <p>Attributes:</p> Name Type Description <code>inputs</code> <code>List[str]</code> <p>The names of input variables</p> <code>outputs</code> <code>List[str]</code> <p>The names of output variables</p> <code>variables</code> <code>Dict[str, Any]</code> <p>Names and values of preset variables.</p> <code>steps</code> <code>List[StepConfig]</code> <p>The steps that are executed by the plan</p> <code>results</code> <code>List[ResultHandlerConfig]</code> <p>The result handler objects to initialize</p>"},{"location":"reference/plan_config/#ropt.config.plan.ResultHandlerConfig","title":"<code>ResultHandlerConfig</code>","text":"<p>Configuration of a single result object.</p> <p>Results handler objects process events emitted by the steps of the optimization plan. They usually store information in plan variables that are accessible to the steps and to the user via the plan object.</p> <p>The <code>run</code> string identifies the code that is run to initialize the result handler object. It is used by the plugin manager to load the code.</p> <p>Additional parameters needed by the handler objects are configured using the <code>with_</code> attribute. The contents of the <code>with_</code> attribute depend on the type of the handler object.</p> <code>with</code> is an alias for <code>with_</code> <p>When parsing dictionaries into a <code>ResultHandlerConfig</code> object, the name of the <code>with_</code> attribute should be replaced by by <code>with</code>, i.e. without the <code>_</code> suffix.</p> <p>Attributes:</p> Name Type Description <code>run</code> <code>str</code> <p>Identifies the code that initializes the object</p> <code>with_</code> <code>Any</code> <p>Additional parameters passed to the object</p>"},{"location":"reference/plan_config/#ropt.config.plan.StepConfig","title":"<code>StepConfig</code>","text":"<p>Configuration of a single step.</p> <p>A step is a single action within an optimization plan. The <code>run</code> string identifies the code that executes te step. It is used by the plugin manager to load the code.</p> <p>Additional parameters needed by the step may be configured using the <code>with_</code> attribute. The content of the <code>with_</code> attribute depends on the type of the step.</p> <p>Execution of the step can be made conditional by providing an expression via the <code>if_</code> attribute. The expression will be parsed and evaluated, and the step will only be executed if the result is <code>True</code>.</p> <code>with</code> and <code>if</code> aliases <p>When parsing dictionaries into a <code>StepConfig</code> object, the name of the <code>with_</code> attribute should be replaced by by <code>with</code>, and the name of the <code>if_</code> attribute by <code>if</code>, i.e. without the <code>_</code> suffix</p> Conditional evaluation <p>Conditions defined via the <code>if_</code> attribute are evaluated by passing them to the <code>eval</code> method of the plan object that is executing the steps. Consult the documentation of the method for more details on the expressions that can be evaluated.</p> <p>Attributes:</p> Name Type Description <code>run</code> <code>str</code> <p>Identifies the code that runs the step</p> <code>with_</code> <code>Union[List[Any], Dict[str, Any], str]</code> <p>Additional parameters passed to the step</p> <code>if_</code> <code>Optional[str]</code> <p>Optional expression for conditional evaluation</p>"},{"location":"reference/plan_plugins/","title":"Plan objects","text":""},{"location":"reference/plan_plugins/#ropt.plugins.plan","title":"<code>ropt.plugins.plan</code>","text":"<p>Plugin functionality for adding plan objects.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base","title":"<code>ropt.plugins.plan.base</code>","text":"<p>This module defines the base classes for optimization plan objects.</p> <p>Optimization plan objects can be added via the plugin mechanism to implement additional functionality. This is done by creating a plugin class that derives from the <code>PlanPlugin</code> class. It needs to define a <code>create</code>.create method that generates the plan objects.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler","title":"<code>ResultHandler</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for results handler objects.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.handler_config","title":"<code>handler_config: ResultHandlerConfig</code>  <code>property</code>","text":"<p>Return the handler object configuration.</p> <p>Returns:</p> Type Description <code>ResultHandlerConfig</code> <p>The configuration object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.plan","title":"<code>plan: Plan</code>  <code>property</code>","text":"<p>Return the plan object.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The plan object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.__init__","title":"<code>__init__(config, plan)</code>","text":"<p>Initialize the results handler object.</p> <p>The <code>config</code> and <code>plan</code> arguments are accessible as <code>handler_config</code> and <code>plan</code> properties.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>ResultHandlerConfig</code> <p>The configuration of the handler object</p> required <code>plan</code> <code>Plan</code> <p>The parent plan that contains the object</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.ResultHandler.handle_event","title":"<code>handle_event(event)</code>  <code>abstractmethod</code>","text":"<p>Handle and propagate an event.</p> <p>Returns:</p> Type Description <code>Event</code> <p>The, possibly modified, event.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep","title":"<code>PlanStep</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for plan steps.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.step_config","title":"<code>step_config: StepConfig</code>  <code>property</code>","text":"<p>Return the step object config.</p> <p>Returns:</p> Type Description <code>StepConfig</code> <p>The configuration object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.plan","title":"<code>plan: Plan</code>  <code>property</code>","text":"<p>Return the plan object.</p> <p>Returns:</p> Type Description <code>Plan</code> <p>The plan object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.__init__","title":"<code>__init__(config, plan)</code>","text":"<p>Initialize the plan object.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>StepConfig</code> <p>The configuration of the plan object</p> required <code>plan</code> <code>Plan</code> <p>The parent plan</p> required"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanStep.run","title":"<code>run()</code>  <code>abstractmethod</code>","text":"<p>Run the step object.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanPlugin","title":"<code>PlanPlugin</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>The abstract base class for plan plugins.</p>"},{"location":"reference/plan_plugins/#ropt.plugins.plan.base.PlanPlugin.create","title":"<code>create(config, context)</code>  <code>abstractmethod</code>","text":"<p>Create the plan object.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[ResultHandlerConfig, StepConfig]</code> <p>The configuration of the plan object</p> required <code>context</code> <code>OptimizerContext</code> <p>The context in which the plan operates</p> required"},{"location":"reference/plan_runner/","title":"Optimization plan runner","text":""},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner","title":"<code>ropt.plan.OptimizationPlanRunner</code>","text":"<p>A class for running optimization plans.</p> <p><code>OptimizationPlanRunner</code> objects are designed for use cases where the optimization workflow comprises a single optimization run. Using this object can be more convenient than defining and running an optimization plan directly in such cases.</p> <p>This class provides the following features:</p> <ul> <li>Start a single optimization.</li> <li>Add observer functions connected to various optimization events.</li> <li>Attach metadata to each result generated during the optimization.</li> <li>Generate tables summarizing the optimization results.</li> </ul>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.results","title":"<code>results: Optional[FunctionResults]</code>  <code>property</code>","text":"<p>Return the optimal result.</p> <p>Returns:</p> Type Description <code>Optional[FunctionResults]</code> <p>The optimal result found during optimization.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.variables","title":"<code>variables: Optional[NDArray[np.float64]]</code>  <code>property</code>","text":"<p>Return the optimal variables.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The variables corresponding to the optimal result.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.exit_code","title":"<code>exit_code: OptimizerExitCode</code>  <code>property</code>","text":"<p>Return the exit code.</p> <p>Returns:</p> Type Description <code>OptimizerExitCode</code> <p>The exit code of the optimization run.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.__init__","title":"<code>__init__(enopt_config, evaluator, *, constraint_tolerance=1e-10, seed=None)</code>","text":"<p>Initialize an <code>OptimizationPlanRunner</code> object.</p> <p>An optimization configuration and an evaluation object must be provided, as they define the optimization to perform.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>Union[Dict[str, Any], EnOptConfig]</code> <p>The configuration for the optimization.</p> required <code>evaluator</code> <code>Evaluator</code> <p>The evaluator object used to evaluate functions.</p> required <code>constraint_tolerance</code> <code>float</code> <p>The tolerance level used to detect constraint violations.</p> <code>1e-10</code> <code>seed</code> <code>Optional[int]</code> <p>The seed for the random number generator used                   for stochastic gradient estimation.</p> <code>None</code>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.add_plugins","title":"<code>add_plugins(plugin_type, plugins)</code>","text":"<p>Add plugins.</p> <p>By default, plugins are installed via Python's entry point mechanism. This method allows you to install additional plugins.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of plugin to install.</p> required <code>plugins</code> <code>Dict[str, Plugin]</code> <p>A dictionary mapping plugin names to plugin objects.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>OptimizationPlanRunner</code> instance, allowing for method chaining.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.add_observer","title":"<code>add_observer(event_type, function)</code>","text":"<p>Add an observer.</p> <p>Observers are callables that are triggered when an optimization event occurs. This method adds an observer that responds to a specified event type.</p> <p>Parameters:</p> Name Type Description Default <code>event_type</code> <code>EventType</code> <p>The type of event to observe.</p> required <code>function</code> <code>Callable[[Event], None]</code> <p>The callable to invoke when the event is emitted.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>OptimizationPlanRunner</code> instance, allowing for method chaining.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.add_metadata","title":"<code>add_metadata(metadata)</code>","text":"<p>Add metadata.</p> <p>Add a dictionary of metadata that will be attached to each result object generated during optimization.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Dict[str, Any]</code> <p>The dictionary containing metadata to add to each result.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The <code>OptimizationPlanRunner</code> instance, allowing for method chaining.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.add_table","title":"<code>add_table(columns, path, table_type='functions', min_header_len=None, *, maximize=False)</code>","text":"<p>Add a table of results.</p> <p>This method instructs the runner to generate a table summarizing the results of the optimization. This is implemented via a <code>ResultsTable</code> object. Refer to its documentation for more details.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Dict[str, str]</code> <p>A mapping of column names for the results table.</p> required <code>path</code> <code>Path</code> <p>The location where the results file will be saved.</p> required <code>table_type</code> <code>Literal['functions', 'gradients']</code> <p>The type of table to generate.</p> <code>'functions'</code> <code>min_header_len</code> <code>Optional[int]</code> <p>The minimum number of header lines to generate.</p> <code>None</code> <code>maximize</code> <code>bool</code> <p>If <code>True</code>, interpret the results as a maximization             problem rather than the default minimization.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The <code>OptimizationPlanRunner</code> instance, allowing for method chaining.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.run","title":"<code>run()</code>","text":"<p>Run the optimization.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The <code>OptimizationPlanRunner</code> instance, allowing for method chaining.</p>"},{"location":"reference/plan_runner/#ropt.plan.OptimizationPlanRunner.abort_optimization","title":"<code>abort_optimization()</code>  <code>staticmethod</code>","text":"<p>Abort the current optimization run.</p> <p>This method can be called from within callbacks to interrupt the ongoing optimization plan. The exact point at which the optimization is aborted depends on the step that is executing at that point. For example, within a running optimizer, the process will be interrupted after completing the current function evaluation.</p>"},{"location":"reference/plugin_manager/","title":"Plugins","text":""},{"location":"reference/plugin_manager/#ropt.plugins","title":"<code>ropt.plugins</code>","text":"<p>The <code>plugins</code> module facilitates the integration of <code>ropt</code> plugins.</p> <p>The core functionality of <code>ropt</code> can be extended through plugins, which can either be builtin, separately installed, or dynamically added at runtime. Currently, <code>ropt</code> supports the following plugin types to implement specific types of functionality:</p> <code>optimizer</code>: Plugins that implement specific optimization methods. The builtin   <code>scipy</code> plugin utilizes the   <code>scipy.optimize</code> module to implement various optimization algorithms. <code>sampler</code>: Plugins responsible for generating perturbations for estimating gradients.   The builtin <code>scipy</code> plugin is based   on <code>scipy.stats</code>,   providing various sampling methods. <code>realization_filter</code>: These plugins implement filters for selecting a sub-set of realizations used   in calculating objective or constraint functions and their gradients. The   included   <code>default</code>   plugin provides filters based on ranking and for CVaR optimization. <code>function_transform</code>: These plugins calculate the final objective and gradient from sets of   objectives or constraints and their gradients for individual realizations. The   included   <code>default</code>   plugin supports objectives defined by the mean or standard deviation of these   values. <code>plan</code>: Plan plugins implement the objects that execute an optimization plan.   The built-in <code>default</code> plugin   offers a full set of optimization plan objects for executing complex   optimization plans. <p>Plugins are managed by the <code>PluginManager</code> class. This class is used to retrieve plugin objects that derive from an abstract base class defining the required functionality for each plugin type:</p> <ol> <li><code>OptimizerPlugin</code>:     Abstract base class for optimizer plugins.</li> <li><code>SamplerPlugin</code>:     Abstract base class for sampler plugins.</li> <li><code>RealizationFilterPlugin</code>:     Abstract base class for realization filter plugins.</li> <li><code>FunctionTransformPlugin</code>:     Abstract base class for function transform plugins.</li> <li><code>PlanPlugin</code>:     Abstract base class for optimization plan object plugins.</li> </ol> <p>Plugins can be built-in, installed separately using the standard entry points mechanism, or added dynamically using the <code>add_plugins</code> method.</p> <p>The plugin manager object provides the <code>get_plugin</code> method, which <code>ropt</code> uses to retrieve the necessary plugin based on its type and name. Given the plugin's type and name, this method returns a callable (either a class or a factory function) that <code>ropt</code> uses to instantiate the plugin when needed.</p> Plugin and method names <p>Plugins are registered by name by plugin manager objects. Plugins may implement multiple methods, each of which should also be identified by a name. <code>PluginManager.get_plugin</code> and <code>PluginManager.is_supported</code> accept method names and will search through the available plugins to find the correct plugin code. To refer to a method method-name of a given plugin plugin-name, a string in the form \"plugin-name/method-name\" can be used instead. In this case, the plugin manager will not search through all plugins for the requested method but will only inquire with the plugin plugin-name. By convention, using \"default\" for the method name in such a string will select the default method of the plugin.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager","title":"<code>PluginManager</code>","text":"<p>The plugin manager.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the plugin manager.</p> <p>The plugin manager object is initialized via the entry points mechanism (see <code>importlib.metadata</code>).</p> <p>For instance, to install an additional optimizer plugin, implemented in an independent package, and assuming installation via a <code>pyproject.toml</code> file, add the following:</p> <p><pre><code>[project.entry-points.\"ropt.plugins.optimizer\"]\nmy_optimizer = \"my_optimizer_pkg.my_plugin:MyOptimizer\"\n</code></pre> This will make the <code>MyOptimizer</code> class from the <code>my_optimizer_pkg</code> package available under the name <code>my_optimizer</code>. The <code>MyOptimizer</code> class will be used to create <code>Optimizer</code> objects and to facilitate this, it should derive from the <code>OptimizerPlugin</code> class.</p> <p>Plugins can also be added dynamically using the <code>add_plugins</code> method.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.add_plugins","title":"<code>add_plugins(plugin_type, plugins)</code>","text":"<p>Add a plugin at runtime.</p> <p>This method adds one or more plugins of a specific type to the plugin manager. The <code>plugins</code> argument maps the names of the new plugins to <code>Plugin</code> object.</p> <p>The plugin names are case-insensitive.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>Type of the plugin.</p> required <code>plugins</code> <code>Dict[str, Plugin]</code> <p>Dictionary of plugins.</p> required"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.get_plugin","title":"<code>get_plugin(plugin_type, method)</code>","text":"<p>Retrieve a plugin by type and method name.</p> <p>If the given method name does not contain a slash (/), the plugin manager will search through all plugins and return the first plugin that supports the requested method. If the method name is of the form \"plugin-name/method-name\", the method method-name will be retrieved from the given plugin plugin-name.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of the plugin to retrieve.</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin should provide.</p> required"},{"location":"reference/plugin_manager/#ropt.plugins.PluginManager.is_supported","title":"<code>is_supported(plugin_type, method)</code>","text":"<p>Check if a method is supported.</p> <p>If the given method name does not contain a slash (/), the plugin manager will search through all plugins and return <code>True</code> if a plugin is found that supports the requested method. If the method name is of the form \"plugin-name/method-name\", <code>True</code> will be returned if the method method-name is supported by the given plugin plugin-name.</p> <p>Parameters:</p> Name Type Description Default <code>plugin_type</code> <code>PluginType</code> <p>The type of the plugin to retrieve.</p> required <code>method</code> <code>str</code> <p>The name of the method the plugin should provide.</p> required"},{"location":"reference/plugin_manager/#ropt.plugins.PluginType","title":"<code>PluginType = Literal['optimizer', 'sampler', 'realization_filter', 'function_transform', 'plan']</code>  <code>module-attribute</code>","text":"<p>Plugin Types Supported by <code>ropt</code></p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin","title":"<code>Plugin</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for plugins.</p> <p><code>ropt</code>  plugins should derive from this base class, which specifies an <code>is_supported</code> method.</p>"},{"location":"reference/plugin_manager/#ropt.plugins.Plugin.is_supported","title":"<code>is_supported(method, *, explicit)</code>  <code>abstractmethod</code>","text":"<p>Check wether a given method is supported.</p> <p>If the <code>explicit</code> flag is set, then the method was explicitly requested for this plugin. If not, the caller does not know which plugin contains the requested method and is checking whether this plugin supports a method with this name. This can be used to return <code>False</code> if the plugin only wants to be specified explicitly using its name. In other cases, this argument can be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The method name</p> required <code>explicit</code> <code>bool</code> <p>Whether the plugin was requested explicitly</p> required <p>Returns:     True if the method is supported.</p>"},{"location":"reference/realization_filter_plugins/","title":"Realization filters","text":""},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter","title":"<code>ropt.plugins.realization_filter</code>","text":"<p>Plugin functionality for adding realization filters.</p> <p>This package contains the abstract base class for realization filter plugins, and the default realization filters that are part of <code>ropt</code>.</p> <p>Realization filters are used by the optimizer to determine how a set of realizations should be used to calculate objective and constraint function values. They do this by calculating the weights that should be used for each realization when calculating the values of a given set of objectives and constraints.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base","title":"<code>ropt.plugins.realization_filter.base</code>","text":"<p>This module defines the abstract base class for realization filters.</p> <p>Realization filters can be added via the plugin mechanism to implement additional ways to filter the realizations that are used to calculate functions and gradients. Any object that derives from the <code>RealizationFilter</code> abstract base class may be installed as a plugin.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter","title":"<code>RealizationFilter</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for realization filter classes.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter.__init__","title":"<code>__init__(enopt_config, filter_index)</code>  <code>abstractmethod</code>","text":"<p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>filter_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilter.get_realization_weights","title":"<code>get_realization_weights(objectives, constraints)</code>  <code>abstractmethod</code>","text":"<p>Return the updated weights of the realizations.</p> <p>This method is called by the optimizer with the current values of the objectives and constraints. Based on these values it must decide how much weight each realization should be given, and return those as a vector.</p> <p>The objectives and the constraints are passed as matrix, where the columns contain the values of the objectives or constraints. The index along the row axis corresponds to the number of the realization.</p> Normalization <p>The weights will be normalized to a sum of one by the optimizer before use, hence any non-negative weight value is permissable.</p> <p>Parameters:</p> Name Type Description Default <code>objectives</code> <code>NDArray[float64]</code> <p>The objectives of all realizations</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The constraints for all realizations</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>A vector of weights of the realizations.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin","title":"<code>RealizationFilterPlugin</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>Abstract base class for realizationFilter plugins.</p>"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.base.RealizationFilterPlugin.create","title":"<code>create(enopt_config, filter_index)</code>  <code>abstractmethod</code>","text":"<p>Initialize the realization filter plugin.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer</p> required <code>filter_index</code> <code>int</code> <p>The index of the transform to use</p> required"},{"location":"reference/realization_filter_plugins/#ropt.plugins.realization_filter.default","title":"<code>ropt.plugins.realization_filter.default</code>","text":"<p>This plugin contains realization filters that are installed by default.</p>"},{"location":"reference/reporting/","title":"Reporting","text":""},{"location":"reference/reporting/#ropt.report","title":"<code>ropt.report</code>","text":"<p>Classes for reporting optimization results.</p> <p>The classes in this module are designed to gather multiple results generated during the execution of an optimization plan. Currently, the results can be reported as a <code>pandas</code> DataFrame using the <code>ResultsDataFrame</code> class, or as a text file in a tabular format using the <code>ResultsTable</code> class.</p>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame","title":"<code>ResultsDataFrame</code>","text":"<p>Generate a results report in a <code>pandas</code> DataFrame.</p> <p>The class is intended to be used for gathering results from <code>Results</code> objects and storing them as a <code>pandas</code> DataFrame.</p> <p>New results can be added to the stored DataFrame as they become available using the <code>add_results</code> method. The content of the DataFrame is taken from the fields of the <code>Results</code> objects passed during each call to <code>add_results</code>. The updated table can be retrieved at any time via the <code>frame</code> property.</p>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame.frame","title":"<code>frame: pd.DataFrame</code>  <code>property</code>","text":"<p>Return the function results generated so far.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas data frame with the results.</p>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame.__init__","title":"<code>__init__(fields, *, table_type='functions')</code>","text":"<p>Initialize a ResultsDataFrame object.</p> <p>The set of fields used is determined by the <code>results_fields</code> argument passed when initializing the object. These can be any of the fields defined in a <code>FunctionResults</code> or a <code>GradientResults</code>. Most of the fields in these objects are nested, and the fields to export must be specified specifically in the form <code>field.subfield</code>. For instance, to specify the <code>variables</code> field of the <code>evaluations</code> field from a function result, the specification would be <code>evaluations.variables</code>.</p> <p>Note that many fields may, in fact, generate multiple columns in the resulting data frame. For instance, when specifying <code>evaluations.variables</code>, a column will be generated for each variable. If available, names specified in the optimizer configuration, such as variable names, will be used as column labels. Because the exported fields may be multi-dimensional with names defined along each axis, for instance, realizations and objectives, which both can be named, the final name may consist of a tuple of names.</p> <p>The <code>table_type</code> argument is used to determine which type of results should be reported: either function evaluation results (<code>functions</code>) or gradient results (<code>gradients</code>).</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Set[str]</code> <p>The fields of the results to store</p> required <code>table_type</code> <code>Literal['functions', 'gradients']</code> <p>The type of the table</p> <code>'functions'</code>"},{"location":"reference/reporting/#ropt.report.ResultsDataFrame.add_results","title":"<code>add_results(config, results)</code>","text":"<p>Add results to the table.</p> <p>This method can be called directly from any observers connected to events that produce results.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer generating the results</p> required <code>results</code> <code>Iterable[Results]</code> <p>The results to add</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if a result was added, else False</p>"},{"location":"reference/reporting/#ropt.report.ResultsTable","title":"<code>ResultsTable</code>","text":"<p>               Bases: <code>ResultsDataFrame</code></p> <p>Generate files containing tables of optimization results.</p> <p>This class derives from the <code>ResultsDataFrame</code> class and writes the generated data frame in a tabular format to a text file.</p>"},{"location":"reference/reporting/#ropt.report.ResultsTable.__init__","title":"<code>__init__(columns, path, *, table_type='functions', min_header_len=None)</code>","text":"<p>Initialize a results table.</p> <p>The <code>columns</code> parameter specifies which results are to be exported. The keys of the <code>columns</code> dictionary correspond to the <code>fields</code> parameter of the <code>ResultsDataFrame</code> parent class. The values are the corresponding titles of the columns of the table that is generated. As described in the documentation of the parent class, a single field may generate multiple columns, each with unique names (i.e., variable names). These are handled by adding the name to the column name below the main title. As a result, the header may consist of multiple lines, and the number of lines may vary according to requested fields. For a consistent result, the minimum number of header lines can be specified via the <code>min_header_len</code> argument. When needed, blank lines will be added to reach the specified minimum number of header lines.</p> Reading the generated file. <p>The resulting table can be read using a reader that can handle fixed-width columns, such as the read_fwf function of pandas. However, the header will need to skip a number of header lines. The min_header_len argument can be used to set the minimum number of lines in the header. If the generated header has fewer lines than min_header_len, empty lines will be added. For example:</p> <pre><code># For a table generated with `min_header_len=3`:\nresults = pd.read_fwf(\n    \"results.txt\",\n    header=list(range(3)),\n    skip_blank_lines=False,\n    skiprows=[3],\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Dict[str, str]</code> <p>Mapping of column names for the results table</p> required <code>path</code> <code>Path</code> <p>Optional location of the result file</p> required <code>table_type</code> <code>Literal['functions', 'gradients']</code> <p>Type of the table</p> <code>'functions'</code> <code>min_header_len</code> <code>Optional[int]</code> <p>Minimal number of header lines</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the pandas or tabulate modules are not                  available</p>"},{"location":"reference/reporting/#ropt.report.ResultsTable.add_results","title":"<code>add_results(config, results)</code>","text":"<p>Add results to the table.</p> <p>This method can be called directly from any observers connected to events that produce results.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer generating the results</p> required <code>results</code> <code>Iterable[Results]</code> <p>The results to add</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if a result was added, else False</p>"},{"location":"reference/results/","title":"Optimization results","text":""},{"location":"reference/results/#ropt.results","title":"<code>ropt.results</code>","text":"<p>Data classes for storing intermediate optimization results.</p> <p>During the optimization process, functions and gradients are calculated and need to be reported. To streamline this process, after new results become available, these are passed to callbacks as a tuple of <code>Results</code> objects. These may be instances of the derived <code>FunctionResults</code> or <code>GradientResults</code> classes, containing results for function and gradient evaluations, respectively.</p> <p>These classes are nested <code>dataclasses</code> with some added features:</p> <ul> <li>Variables may have scaling and offset factors associated with them. The   optimization will generally deal with scaled values. When the results object   is created, and variable scaling is configured, the values are scaled back and   added to the results object.</li> <li>Objective and constraint function values may also have a scaling factor   associated with them. These are generally handled in unscaled form, and when   the report object is created, scaled values are added.</li> <li>Methods are available to export the results to   <code>pandas</code> data frames or   <code>xarray</code> data sets.</li> <li>Methods are added to write and read netCDF version 4 files using the   <code>netcdf4</code> Python package.</li> </ul> <p>Much of the data stored in the result objects is of a multi-dimensional nature. For instance, the <code>objectives</code> field, which is part of the nested <code>evaluations</code> object in the <code>FunctionResults</code> object, is a two-dimensional <code>numpy</code> array. In this array, the columns correspond to the objectives, and the rows correspond to the realization number.</p> <p>To facilitate exporting and reporting the results, the identity of the axes in such multi-dimensional arrays is stored in metadata associated with the corresponding field. These fields derive from the <code>ResultField</code> class, which has a <code>get_axis_names</code> class method to retrieve the names. For the <code>objectives</code> example above, this retrieves the axis names:</p> <pre><code>&gt;&gt;&gt; from ropt.results import FunctionEvaluations\n&gt;&gt;&gt; FunctionEvaluations.get_axis_names(\"objectives\")\n(&lt;ResultAxisName.REALIZATION: 'realization'&gt;, &lt;ResultAxisName.OBJECTIVE: 'objective'&gt;)\n</code></pre> <p>Using this metadata, the exporting or reporting code can refer to the optimizer configuration to associate realization and objective names with any entry in the result matrix. For instance, the <code>pandas</code> exporting code will use this to construct a multi-index for the generated data frame and optionally unstack such multi-dimensional data into multiple columns.</p>"},{"location":"reference/results/#ropt.results.Results","title":"<code>ropt.results.Results</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The <code>Results</code> class serves as an abstract base class for storing results.</p> <p>This class contains the following generic information:</p> <ol> <li>The result ID, a unique integer value that is incremented as the    results become available.</li> <li>An optional batch ID, which may be generated by the function evaluator.    The interpretation of this ID depends on the evaluator code. It is    intended to be used as a unique identifier for the group of function    evaluations passed to the evaluator by the optimization code.</li> <li>A dictionary of metadata to be added by optimization steps. This contains    generic information, the nature of which depends on the steps producing    them. They are expected to be primitive values not interpreted by the    optimization code but can be exported and reported.</li> </ol> <p>The <code>Results</code> class is an abstract base class that is not intended to be instantiated by itself. Most data of interest will be stored in additional fields in one of the derived classes: <code>FunctionResults</code> or <code>GradientResults</code>. In addition to the attributes containing the data, a few methods are provided to export the data. These functions will only be useful when used with one of the derived classes:</p> <ol> <li>The <code>to_dataframe</code> method can be    used to export the contents, or a sub-set, of a single field to a    <code>pandas</code> data frame.</li> <li>The <code>to_dataset</code> method can be used to    export the contents, or a sub-set, of a single field to an    <code>xarray</code> data set.</li> <li>The <code>to_netcdf</code> method can be used to    export the entire results object to a    <code>netCDF</code> file.</li> </ol> <p>Attributes:</p> Name Type Description <code>result_id</code> <code>int</code> <p>The ID of the function/gradient evaluation.</p> <code>batch_id</code> <code>Optional[int]</code> <p>The ID of the evaluation batch that contains the result.</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>The metadata.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataframe","title":"<code>to_dataframe(config, field_name, select=None, unstack=None)</code>","text":"<p>Export a field to a pandas dataframe.</p> <p>The function exports the values of a single field to a pandas data frame. The field to export is selected by the <code>field_name</code> argument. In general such a field is another object with multiple sub-fields. By default, these are all exported as columns in the pandas data frame, but a sub-set can be selected using the <code>select</code> argument.</p> <p>Any of the sub-fields in the field that is exported may be a multi-dimensional array, which is exported in a stacked manner. Using the axis types found in the metadata, the exporter will construct a multi-index labeled with the corresponding names found in the optimizer configuration (if available, otherwise numerical indices are used). Such multi-indices can optionally be unstacked into multiple columns by providing the axis types to unstack via the <code>unstack</code> argument.</p> The data frame index <p>As noted above, the index of the resulting data frame may be a multi-index constructed from axis indices or labels. In addition, the <code>result_id</code> field, and the <code>batch_id</code> (if not None), are also prepended to the index of the resulting frame. This has the beneficial effect that the data frames exported from multiple results can be concatenated and identified in the frame by result ID and/or batch ID.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>field_name</code> <code>str</code> <p>The field to export</p> required <code>select</code> <code>Optional[Iterable[str]]</code> <p>Select the sub-fields to export, by default all fields</p> <code>None</code> <code>unstack</code> <code>Optional[Iterable[ResultAxisName]]</code> <p>Select axes to unstack, by default none</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the pandas module is not installed</p> <code>ValueError</code> <p>If the field name is incorrect</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas data frame containing the results.</p> Warning <p>This function is only available if <code>pandas</code> is installed.</p>"},{"location":"reference/results/#ropt.results.Results.to_dataset","title":"<code>to_dataset(config, field_name, select=None, *, add_metadata=False)</code>","text":"<p>Export a field to an xarray dataset.</p> <p>The function exports the values of a single field to an xarray dataset. The field to export is selected by the <code>field_name</code> argument. In general, such a field is another object with multiple sub-fields. By default, these are all exported as data arrays in the xarray dataset, but a subset can be selected using the <code>select</code> argument.</p> <p>Any of the sub-fields in the field that is exported may be a multi-dimensional array, which is exported directly as an xarray data array. Using the axis types found in the metadata, the exporter will add coordinate labels constructed from the corresponding names found in the optimizer configuration (if available).</p> <p>The result ID and the batch ID (if not None) are added to the attributes of the dataset, using the <code>result_id</code> and <code>batch_id</code> keys. If metadata is present in the results, and the <code>add_metadata</code> flag is set, it is also added under the <code>metadata</code> key.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>field_name</code> <code>str</code> <p>The field to export</p> required <code>select</code> <code>Optional[Iterable[str]]</code> <p>Select the fields to export; by default, all fields</p> <code>None</code> <code>add_metadata</code> <code>bool</code> <p>If true, add the metadata as a field in the dataset attrs</p> <code>False</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>xarray</code> module is not installed.</p> <code>ValueError</code> <p>If the field name is incorrect.</p> <p>Returns:</p> Type Description <code>Dataset</code> <p>An xarray dataset containing the results.</p> Warning <p>This function is only available if <code>xarray</code> is installed.</p>"},{"location":"reference/results/#ropt.results.Results.to_netcdf","title":"<code>to_netcdf(config, filename)</code>","text":"<p>Write the results to a netCDF4 file.</p> <p>The fields of the result are converted to xarray datasets and each stored as a group in a netCDF4 file, using the name of the field as the group name. In addition, a special <code>__metadata__</code> group is added that contains the result ID, the batch ID (if not None), and a JSON dump of the metadata.</p> <p>By default, a file is written with a <code>.nc</code> extension. The filename may contain a replacement field for a variable named <code>result_id</code> or <code>batch_id</code>, which will be replaced by the corresponding field using the <code>format</code> string method. For example: <code>filename=\"results-{result_id:04d}\"</code> will result in a file named <code>results-0001.nc</code> if the result ID equals 1.</p> Reading results from a netCDF4 file <p>The results may be read back using the <code>from_netcdf</code> class method of either <code>FunctionResults</code> or <code>GradientResults</code>. Currently, no information is written about whether the results were function or gradient results. Therefore, to read back the result with the correct class, its type must be known.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The configuration used to run the optimization.</p> required <code>filename</code> <code>Union[str, Path]</code> <p>The name of the file to write.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the <code>xarray</code> or the <code>netCDF4</code> module is not installed.</p> Warning <p>Use of this method requires that the <code>xarray</code> and <code>netCDF4</code> modules are installed.</p>"},{"location":"reference/results/#ropt.results.ResultField","title":"<code>ropt.results.ResultField</code>  <code>dataclass</code>","text":"<p>Base class for <code>Results</code> fields.</p>"},{"location":"reference/results/#ropt.results.ResultField.get_axis_names","title":"<code>get_axis_names(name)</code>  <code>classmethod</code>","text":"<p>Return the axis names of a field in the given field class or object.</p> <p>When used with the class or an instance of that class for one of the fields of a <code>Results</code> object, retrieve the names of the axes of the stored <code>numpy</code> array from the metadata and return them.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the sub-field in the instance or class</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if an unknown field name is passed.</p> <p>Returns:</p> Type Description <code>Tuple[ResultAxisName, ...]</code> <p>A tuple listing the names of the axes.</p>"},{"location":"reference/results/#ropt.results.FunctionResults","title":"<code>ropt.results.FunctionResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>The <code>FunctionResults</code> class stores function related results.</p> <p>This class contains  the following additional information:</p> <ol> <li>The results of the function evaluations.</li> <li>The parameters of the realizations, such as weights for objectives and    constraints, and realization failures.</li> <li>The calculated objective and constraint function values.</li> <li>Information on constraint values and violations.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>evaluations</code> <code>FunctionEvaluations</code> <p>Results of the function evaluations</p> required <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations</p> required <code>functions</code> <code>Optional[Functions]</code> <p>The calculated functions</p> required <code>bound_constraints</code> <code>Optional[BoundConstraints]</code> <p>Bound constraints</p> <code>None</code> <code>linear_constraints</code> <code>Optional[LinearConstraints]</code> <p>Linear constraints</p> <code>None</code> <code>nonlinear_constraints</code> <code>Optional[NonlinearConstraints]</code> <p>Nonlinear constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.FunctionResults.from_netcdf","title":"<code>from_netcdf(filename)</code>  <code>classmethod</code>","text":"<p>Read results from a netCDF4 file.</p> <p>Use of this method requires that the <code>xarray</code> and <code>netCDF4</code> modules are installed.</p> <p>The filename is assumed to have an \".nc\" extension, which will be added if not present.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>The name or path of the file to read.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the xarray or the netCDF4 module is not installed.</p> <p>Returns:</p> Type Description <code>Results</code> <p>The loaded result.</p> Warning <p>This function is only available if <code>xarray</code> and <code>netCDF4</code> are installed.</p>"},{"location":"reference/results/#ropt.results.FunctionEvaluations","title":"<code>ropt.results.FunctionEvaluations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class contains the results of evaluations for function calculation.</p> <p>This class stores the variables with the calculated objective and constraint functions. It contains the following information:</p> <ol> <li>The vector of variables at which the functions are evaluated.</li> <li>The calculated objectives and constraints for each realization: A    two-dimensional array, with the objective or constraint values arranged    along the second axis. The first axis index indicates the realization    number.</li> <li>Scaled versions of the variables if variable scaling was enabled.</li> <li>Scaled versions of the objective and constraint values if scaling was    enabled.</li> <li>Optional evaluation IDs that may have been passed from the evaluator,    identifying each calculated realization.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>The objective functions for each realization.</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The constraint functions for each realization.</p> <code>None</code> <code>scaled_variables</code> <code>Optional[NDArray[float64]]</code> <p>Optional variables after scaling.</p> <code>None</code> <code>scaled_objectives</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled objectives.</p> <code>None</code> <code>scaled_constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled constraints.</p> <code>None</code> <code>evaluation_ids</code> <code>Optional[NDArray[intc]]</code> <p>Optional id of each evaluated realization.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.Realizations","title":"<code>ropt.results.Realizations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores information on the realizations.</p> <p>The <code>failed_realizations</code> field is a boolean array that indicates for each realization whether the evaluation was successful or not.</p> <p>Depending on the type of objective or constraint calculation, the weights used for the realizations may change during optimization. This class stores for each objective and constraint a vector of weight values.</p> <p>All fields are two-dimensional matrices, where the first axis index denotes the function or constraint. The second axis index denotes the realization.</p> <p>Parameters:</p> Name Type Description Default <code>failed_realizations</code> <code>NDArray[bool_]</code> <p>Failed realizations</p> required <code>objective_weights</code> <code>Optional[NDArray[float64]]</code> <p>Realization weights for the objectives</p> <code>None</code> <code>constraint_weights</code> <code>Optional[NDArray[float64]]</code> <p>Realization weights for the constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.Functions","title":"<code>ropt.results.Functions</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>Store the calculated objective and constraint functions.</p> <p>The objective and constraint functions used by the optimizer are calculated from their values evaluated for all realizations, for instance by averaging. There may be multiple objectives and constraints. Multiple objectives are handled by the optimizer using a weighted sum, stored in the <code>weighted_objective</code> field. Multiple constraints are directly handled by the optimizer.</p> <p>If scaling of objectives and/or constraint functions is enabled, also scaled versions of the objective or constraint values are stored.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objectives</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each objective</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The value of each constraint</p> <code>None</code> <code>scaled_objectives</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled objectives.</p> <code>None</code> <code>scaled_constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled constraints.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.BoundConstraints","title":"<code>ropt.results.BoundConstraints</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores bound constraint values and violations.</p> <p>The following information is stored:</p> <ol> <li>Differences between the current variable and the lower or upper bounds.</li> <li>Violations of constraints, defined as the absolute value of the    difference if the constraint is violated, or else zero.</li> <li>If variable scaling is configured, scaled versions of all values.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>lower_values</code> <code>Optional[NDArray[float64]]</code> <p>Lower bound differences</p> <code>None</code> <code>lower_violations</code> <code>Optional[NDArray[float64]]</code> <p>Lower bound violations</p> <code>None</code> <code>upper_values</code> <code>Optional[NDArray[float64]]</code> <p>Upper bound differences</p> <code>None</code> <code>upper_violations</code> <code>Optional[NDArray[float64]]</code> <p>Upper bound violations</p> <code>None</code> <code>scaled_lower_values</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled lower bound differences</p> <code>None</code> <code>scaled_lower_violations</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled lower bound violations</p> <code>None</code> <code>scaled_upper_values</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled upper bound differences</p> <code>None</code> <code>scaled_upper_violations</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled upper bound violations</p> <code>None</code>"},{"location":"reference/results/#ropt.results.LinearConstraints","title":"<code>ropt.results.LinearConstraints</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores constraint values and violations.</p> <p>The following information is stored:</p> <ol> <li>Differences between the linear constraints and their right-hand-side    values.</li> <li>Violations of constraints, defined as the absolute value of the    difference if the constraint is violated, or else zero.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Optional[NDArray[float64]]</code> <p>Linear constraint values</p> <code>None</code> <code>violations</code> <code>Optional[NDArray[float64]]</code> <p>Violations of the linear constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.NonlinearConstraints","title":"<code>ropt.results.NonlinearConstraints</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores constraint values and violations.</p> <p>The following information is stored:</p> <ol> <li>Differences between the non-linear constraints and their right-hand-side    values.</li> <li>Violations of constraints, defined as the absolute value of the    difference if the constraint is violated, or else zero.</li> <li>Scaled versions for these values.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Optional[NDArray[float64]]</code> <p>Non-linear constraint values</p> <code>None</code> <code>violations</code> <code>Optional[NDArray[float64]]</code> <p>Violations of the nonlinear constraints</p> <code>None</code> <code>scaled_values</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled non-linear constraint values</p> <code>None</code> <code>scaled_violations</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled violations of the nonlinear constraints</p> <code>None</code>"},{"location":"reference/results/#ropt.results.GradientResults","title":"<code>ropt.results.GradientResults</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Results</code></p> <p>The <code>GradientResults</code> class stores gradient related results.</p> <p>This contains  the following additional information:</p> <ol> <li>The results of the function evaluations for perturbed variables.</li> <li>The parameters of the realizations, such as weights for objectives and    constraints, and realization failures.</li> <li>The gradients of the calculated objectives and constraints.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>evaluations</code> <code>GradientEvaluations</code> <p>Results of the function evaluations</p> required <code>realizations</code> <code>Realizations</code> <p>The calculated parameters of the realizations</p> required <code>gradients</code> <code>Optional[Gradients]</code> <p>The calculated gradients</p> required"},{"location":"reference/results/#ropt.results.GradientResults.from_netcdf","title":"<code>from_netcdf(filename)</code>  <code>classmethod</code>","text":"<p>Read results from a netCDF4 file.</p> <p>Use of this method requires that the <code>xarray</code> and <code>netCDF4</code> modules are installed.</p> <p>The filename is assumed to have an \".nc\" extension, which will be added if not present.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>The name or path of the file to read.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the xarray or the netCDF4 module is not installed.</p> <p>Returns:</p> Type Description <code>TypeResults</code> <p>The loaded result.</p> Warning <p>This function is only available if <code>xarray</code> and <code>netCDF4</code> are installed.</p>"},{"location":"reference/results/#ropt.results.GradientEvaluations","title":"<code>ropt.results.GradientEvaluations</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class contains the results of evaluations for gradient calculation.</p> <p>This class stores the variables with the calculated objective and constraints gradients. It contains the following information:</p> <ol> <li>The vector of variables at which the functions are evaluated.</li> <li>A three-dimensional array of perturbed variables, with variable values    arranged along the third axis. The second axis index indicates the    perturbation number, whereas the first axis index represents the    realization number.</li> <li>The objectives and constraints for each realization and perturbed    variable vector:  A three-dimensional array, with the objective or    constraint values arranged along the third axis. The second axis index    indicates the perturbation number, whereas the first axis index    represents the realization number.</li> <li>Scaled versions of the variables and perturbed variables if scaling    was enabled.</li> <li>Scaled versions of the objective and constraint values if scaling was    enabled.</li> <li>Optional evaluation IDs that may have been passed from the evaluator,    identifying each calculated realization and perturbation.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>NDArray[float64]</code> <p>The unperturbed variable vector.</p> required <code>perturbed_variables</code> <code>NDArray[float64]</code> <p>The variables for each realization and perturbation.</p> required <code>perturbed_objectives</code> <code>NDArray[float64]</code> <p>The objective functions for each realization and                           perturbation.</p> required <code>perturbed_constraints</code> <code>Optional[NDArray[float64]]</code> <p>The constraint functions for each realization and                           perturbation.</p> <code>None</code> <code>scaled_variables</code> <code>Optional[NDArray[float64]]</code> <p>Optional variables after scaling back.</p> <code>None</code> <code>scaled_perturbed_variables</code> <code>Optional[NDArray[float64]]</code> <p>Optional variables after scaling back.</p> <code>None</code> <code>scaled_perturbed_objectives</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled objectives.</p> <code>None</code> <code>scaled_perturbed_constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled constraints.</p> <code>None</code> <code>perturbed_evaluation_ids</code> <code>Optional[NDArray[intc]]</code> <p>Optional id of each evaluated realization.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.Gradients","title":"<code>ropt.results.Gradients</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ResultField</code></p> <p>This class stores the calculated objective and constraint gradients.</p> <p>The objective and constraint gradients used by the optimizer are calculated from their values evaluated for all realizations, for instance by averaging. There may be multiple objectives and constraints. Multiple objectives are handled by the optimizer using a weighted sum of the individual gradients, stored in the <code>weighted_objective</code> field. Multiple constraints are directly handled by the optimizer.</p> <p>If scaling of objectives and/or constraint functions is enabled, also scaled versions of the objective or constraint gradients are stored.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_objective</code> <code>NDArray[float64]</code> <p>The weighted sum of the objective gradients</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>The value of each objective gradient</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>The value of each constraint gradient</p> <code>None</code> <code>scaled_objectives</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled objective gradients.</p> <code>None</code> <code>scaled_constraints</code> <code>Optional[NDArray[float64]]</code> <p>Optional scaled constraint gradients.</p> <code>None</code>"},{"location":"reference/results/#ropt.results.convert_to_maximize","title":"<code>ropt.results.convert_to_maximize(results)</code>","text":"<p>Convert results to maximization results.</p> <p>The optimization process always assumes that the objective functions must be minimized. To perform a maximization, the negative of the objective functions can be passed instead. However, the result objects will then contain those negative values and all objective function values derived from it. Since this may be inconvenient for the application, this convenience function can be used make a copy of a result where all objective values are multiplied by -1, which would correspond to a maximization.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Results</code> <p>The result to convert</p> required <p>Returns:</p> Type Description <code>Results</code> <p>A copy of the result, modified to reflect maximization.</p>"},{"location":"reference/sampler_plugins/","title":"Sampler plugins","text":""},{"location":"reference/sampler_plugins/#ropt.plugins.sampler","title":"<code>ropt.plugins.sampler</code>","text":"<p>Plugin functionality for adding sampler plugins.</p> <p>Sampler plugins are managed by a <code>PluginManager</code> object, which returns classes or factory functions to create objects that implement one or more sampling methods to produce perturbations. These objects must adhere to the <code>Sampler</code> abstract base class.</p> <p>Samplers can be added via the plugin manager, by default the <code>SciPySampler</code> plugin is installed which provides a number of methods from the <code>scipy.stats</code> package.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base","title":"<code>ropt.plugins.sampler.base</code>","text":"<p>This module defines the abstract base class for samplers.</p> <p>Samplers can be added via the plugin mechanism to implement additional ways to generate perturbed variables. Any object that follows the <code>Sampler</code> abstract base class may be installed as a plugin.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler","title":"<code>Sampler</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for sampler classes.</p> <p><code>ropt</code> employs plugins to implement samplers that are called during an optimization plan to generate perturbed variable vectors. Samplers should derive from the <code>Sampler</code> base class, which specifies the requirements for the class constructor (<code>__init__</code>) and also includes a <code>generate_samples</code> method used to generate samples used to create perturbed values.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler.__init__","title":"<code>__init__(enopt_config, sampler_index, variable_indices, rng)</code>  <code>abstractmethod</code>","text":"<p>Initialize the sampler object.</p> <p>The <code>samplers</code> field in the <code>enopt_config</code> configuration used by the optimization is a tuple of sampler configurations (see <code>SamplerConfig</code>). The <code>sampler_index</code> field is used to identify the configuration to use to initialize this sampler.</p> <p>The sampler may be used for a subset of the variables. The <code>variable_indices</code> array lists the indices of the variables that are handled by this sampler.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler to use.</p> required <code>variable_indices</code> <code>Optional[NDArray[intc]]</code> <p>The indices of the variables to sample.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for use by stochastic samplers.</p> required"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.Sampler.generate_samples","title":"<code>generate_samples()</code>  <code>abstractmethod</code>","text":"<p>Return an array containing sampled values.</p> <p>The result should be a three-dimensional array of perturbation values. The variable values are stored along the last axis, for each realization and perturbation. The first axis indexes the realization, and the second axis indexes the perturbation.</p> <p>If the <code>shared</code> flag is set in the <code>SamplerConfig</code> configuration, the first dimension should have a length equal to one, since all realizations will use the same set of perturbations.</p> <p>The sampler may handle only a subset of the variables, as specified by the <code>variable_indices</code> argument of the constructor. In this case, only the corresponding values along the variables axis (the last axis) should be set, while other values should be zero.</p> Sample scaling <p>Samples will be multiplied by the values given by the <code>perturbation_magnitudes</code> field in the <code>gradients</code> section of the optimizer configuration. It makes therefore sense to generate samples that have an order of magnitude around one. For instance, by generating them on a <code>[-1, 1]</code> range, or with a unit standard deviation.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The sampled values.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin","title":"<code>SamplerPlugin</code>","text":"<p>               Bases: <code>Plugin</code></p> <p>Abtract base class for sampler plugins.</p>"},{"location":"reference/sampler_plugins/#ropt.plugins.sampler.base.SamplerPlugin.create","title":"<code>create(enopt_config, sampler_index, variable_indices, rng)</code>  <code>abstractmethod</code>","text":"<p>Create a sampler.</p> <p>Parameters:</p> Name Type Description Default <code>enopt_config</code> <code>EnOptConfig</code> <p>The configuration of the optimizer.</p> required <code>sampler_index</code> <code>int</code> <p>The index of the sampler to use.</p> required <code>variable_indices</code> <code>Optional[NDArray[intc]]</code> <p>The indices of the variables to sample.</p> required <code>rng</code> <code>Generator</code> <p>A random generator object for use by stochastic samplers.</p> required"},{"location":"reference/scipy_optimizer/","title":"SciPy Optimizer Plugin","text":""},{"location":"reference/scipy_optimizer/#ropt.plugins.optimizer.scipy.SciPyOptimizer","title":"<code>ropt.plugins.optimizer.scipy.SciPyOptimizer</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>Plugin class for optimization via SciPy.</p> <p>This class implements several optimizers provided by SciPy in the <code>scipy.optimize</code> package:</p> <ul> <li>Nelder-Mead</li> <li>Powell</li> <li>CG</li> <li>BFGS</li> <li>Newton-CG</li> <li>L-BFGS-B</li> <li>TNC</li> <li>COBYLA</li> <li>SLSQP</li> <li>differential_evolution</li> </ul> <p>The optimizer to use is selected by setting the <code>method</code> field in the <code>optimizer</code> field of <code>EnOptConfig</code> to the name of the algorithm. Most of these methods support the general options set in the <code>EnOptConfig</code> object. However, specific options that are normally passed as arguments in the SciPy functions can be provided via the <code>options</code> dictionary in the configuration object. Consult the <code>scipy.optimize</code> manual for details on these options.</p> <p>Not all constraints are supported by all optimizers:</p> <ul> <li>Bound constraints: Nelder-Mead, L-BFGS-B, SLSQP, TNC,   differential_evolution</li> <li>Linear constraints: SLSQP, differential_evolution</li> <li>Nonlinear constraints: COBYLA (only inequality), SLSQP,   differential_evolution</li> </ul> Info <ul> <li>The Nelder-Mead algorithm only supports bound constraints if SciPy   version &gt;= 1.7.</li> <li>Some SciPy algorithms that require a Hessian or a Hessian-vector   product are not supported. These include dogleg, trust-ncg,   trust-exact, and trust-krylov.</li> </ul>"},{"location":"reference/scipy_sampler/","title":"SciPy Sampler Plugin","text":""},{"location":"reference/scipy_sampler/#ropt.plugins.sampler.scipy.SciPySampler","title":"<code>ropt.plugins.sampler.scipy.SciPySampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Plugin class for producing sampling values via SciPy.</p> <p>This plugin implements the following sampling methods using the corresponding methods from the SciPy stats module:</p> <ul> <li> <p>Sampling from probability   distributions:</p> <code>uniform</code> Uniform distribution with a default range of [-1, 1]. <code>norm</code> Normal distribution with mean zero and standard deviation 1. <code>truncnorm</code> Truncated normal distribution with mean zero and standard   deviation 1 truncated a the range [-1, 1]. </li> <li> <p>Sampling using methods from the Quasi-Monte Carlo   submodule:</p> <code>sobol</code> Using Sobol sequences, scaled to -1 and 1. <code>halton</code> Using Halton sequences, scaled to -1 and 1. <code>lhs</code> Using Latin Hypercube sampling, scaled to -1 and 1. </li> </ul> <p>Specific options that are normally passed as arguments in the SciPy functions can be provided via the options dictionary in the configuration object. Consult the <code>scipy.stats</code> manual for details on these options.</p>"},{"location":"reference/utilities/","title":"Utilities","text":""},{"location":"reference/utilities/#ropt.utils","title":"<code>ropt.utils</code>","text":"<p>The <code>ropt.utils</code> module contains various utility functions.</p>"},{"location":"reference/utilities/#ropt.utils.update_dict","title":"<code>update_dict(mapping, values)</code>","text":"<p>Recursively update a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>Dict[str, Any]</code> <p>The dictionary to update</p> required <code>values</code> <code>Dict[str, Any]</code> <p>The values to be updated or added</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The updated dictionary.</p>"},{"location":"reference/utilities/#ropt.utils.scaling","title":"<code>ropt.utils.scaling</code>","text":"<p>Functions for scaling variables and functions.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_variables","title":"<code>scale_variables(config, variables, axis)</code>","text":"<p>Scale variables.</p> <p>Given an ensemble optimizer configuration object and a vector of variables, this function applies an offset and scale to the vector values.</p> <p>As the <code>variables</code> input may be a multi-dimensional array, the index of the axis that designates the variables should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>variables</code> <code>NDArray[float64]</code> <p>The scaled variables</p> required <code>axis</code> <code>int</code> <p>The variables axis</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The scaled variables, or <code>None</code> if no scaling is applied.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_back_variables","title":"<code>scale_back_variables(config, variables, axis, *, correct_offsets=True)</code>","text":"<p>Scale back variables.</p> <p>Given an ensemble optimizer configuration object and a vector of scaled variables, scale their values back to the original range. Normally this includes correcting for offsets, but if a difference value is being rescaled, the <code>correct_offsets</code> flag can be used to disable this.</p> <p>As the <code>variables</code> input may be a multi-dimensional array, the index of the axis that designates the variables should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>variables</code> <code>NDArray[float64]</code> <p>The scaled variables</p> required <code>axis</code> <code>int</code> <p>The variables axis</p> required <code>correct_offsets</code> <code>bool</code> <p>If True also correct for offsets</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The unscaled variables, or <code>None</code> if no scaling is applied.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_objectives","title":"<code>scale_objectives(config, objectives, scales, axis)</code>","text":"<p>Scale objective function values.</p> <p>Given an ensemble optimizer configuration object, this function scales the provided objective values. It divides them by the scale values given in the configuration object (if not <code>None</code>), and optionally also by the values given in the <code>scales</code> argument.</p> <p>As the <code>objectives</code> input may be a multi-dimensional array, the index of the axis that designates the objectives should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>objectives</code> <code>NDArray[float64]</code> <p>Objective functions</p> required <code>scales</code> <code>Optional[NDArray[float64]]</code> <p>Optional additional scales</p> required <code>axis</code> <code>int</code> <p>The objectives axis</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The scaled objectives or <code>None</code> if no scaling was applied.</p>"},{"location":"reference/utilities/#ropt.utils.scaling.scale_constraints","title":"<code>scale_constraints(config, constraints, scales, axis)</code>","text":"<p>Scale constraint function values.</p> <p>Given an ensemble optimizer configuration object, this function scales the provided constraint values. It divides them by the scale values given in the configuration object (if not <code>None</code>), and optionally also by the values given in the <code>scales</code> argument.</p> <p>As the <code>constraints</code> input may be a multi-dimensional array, the index of the axis that designates the constraints should be provided through the <code>axis</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnOptConfig</code> <p>The ensemble optimizer configuration object</p> required <code>constraints</code> <code>Optional[NDArray[float64]]</code> <p>Constraint functions</p> required <code>scales</code> <code>Optional[NDArray[float64]]</code> <p>Optional additional scales</p> required <code>axis</code> <code>int</code> <p>The constraints axis</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>The scaled constraints or <code>None</code> if no scaling was applied.</p>"},{"location":"usage/robust_optimization/","title":"Introduction: Ensemble-based robust optimization","text":"<p>Constraint optimization is the process of optimizing an objective function \\(f(\\mathbf{x})\\) with respect to a vector of variables \\(\\mathbf{x}\\) in the presence of one or more inequality constraints \\(g_j(\\mathbf{x})\\) and/or equality constraints \\(h_k(\\mathbf{x})\\).</p> \\[ \\begin{align} \\textrm{minimize} \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{subject to} \\quad &amp; g_j(\\mathbf{x}) \\le 0, \\quad j=1, \\ldots, J \\\\ &amp; h_k(\\mathbf{x}) = 0, \\quad k=1, \\ldots, K \\\\ &amp; \\mathbf{x}^L \\le \\mathbf{x} \\le \\mathbf{x}^U \\end{align} \\] <p>In this context, the function \\(f(\\mathbf{x})\\) is assumed to have a deterministic nature, meaning it is well-defined for given parameters. However, in realistic scenarios, \\(f(\\mathbf{x})\\) may be part of a larger set of functions, especially if it depends on uncertain parameters drawn from some, possibly unknown, probability distribution.</p> <p>Ensemble-based robust optimization aims to optimize an ensemble of functions \\(f_i(\\mathbf{x})\\) with respect to \\(\\mathbf{x}\\). The set of realizations \\(f_i\\) captures the uncertainty that may exist in the model, which can be, for instance, constructed by varying some parameters according to a given probability distribution. When given a set of realizations, ensemble-based optimization proceeds by combining the functions \\(f_i(\\mathbf{x})\\) into a single objective function. For example, using a weighted sum, the problem becomes (ignoring constraints):</p> \\[ \\textrm{minimize} \\quad \\sum_i w_i f_i(\\mathbf{x}), \\] <p>where \\(w_i\\) represents the weights assigned to the different realizations. In more complex settings, the realizations may also be combined in different ways, and the set of realizations may be modified during optimization. For instance, risk-aware objectives may be constructed by minimizing the standard deviation of the functions or by selecting some of the worst-performing realizations at each iteration.</p> <p>In practice, the optimization task often becomes complex due to additional factors. The evaluation of functions might be computationally expensive, and calculating their gradients analytically can be challenging or even impossible. For example, the functions may involve lengthy simulations of a physical process with numerous variables, utilizing numerical calculations that preclude straightforward analytical differentiation.</p> <p><code>ropt</code> leverages standard optimization algorithms, such as those available in the SciPy package. These methods typically follow an iterative approach, necessitating repeated assessments of the objective function and, in many cases, its gradient. Currently, it is assumed that the functions are not easily differentiated analytically. One of the core functions of <code>ropt</code> is to calculate gradients efficiently using stochastic methods.</p> <p><code>ropt</code> is responsible for configuring and executing the optimization algorithm, building the overall function and gradient values from individual realizations, and monitoring both intermediate and final optimization results. It also offers the flexibility to delegate the actual calculations of functions to external code, for example, utilizing distributed resources like HPC clusters. <code>ropt</code> optionally provides its own code for this purpose.</p> <p>While many optimization scenarios involve a single run of a particular method, there are cases where it proves beneficial to conduct multiple runs using the same or different algorithms. For example, when dealing with a mix of continuous and discrete variables, it might be advantageous to employ different methods for each variable type. <code>ropt</code> facilitates this by offering a mechanism to run a workflow containing multiple optimizers, potentially of different types, in an alternating or nested fashion.</p>"},{"location":"usage/running/","title":"Running a basic optimization script","text":"<p>To demonstrate basic optimization with <code>ropt</code>, consider the Rosenbrock function, a standard test problem:</p> \\[ f(x,y) = (a - x)^2 + b (y - x^2)^2, \\] <p>which has a global minimum of \\(f(x, y) = 0\\) at \\((x, y) = (a, a^2)\\) .</p> <p>Here's an example optimizing the Rosenbrock function for \\(a = 1\\) and \\(b = 100\\):</p> <pre><code>import numpy as np\nfrom numpy.typing import NDArray\n\nfrom ropt.evaluator import EvaluatorContext, EvaluatorResult\nfrom ropt.plan import OptimizationPlanRunner\n\n\ndef rosenbrock(\n    variables: NDArray[np.float64],                                   # (1)!\n    context: EvaluatorContext                                         # (2)!\n) -&gt; EvaluatorResult:\n    objectives = np.zeros((variables.shape[0], 1), dtype=np.float64)\n    for idx in range(variables.shape[0]):\n        x, y = variables[idx, :]\n        objectives[idx, 0] = (1.0 - x) ** 2 + 100 * (y - x * x) ** 2\n    return EvaluatorResult(objectives=objectives)                     # (3)!\n\nCONFIG = {                                                            # (4)!\n    \"variables\": {\"initial_values\": [0.5, 2.0]},\n    \"gradient\": {\"perturbation_magnitudes\": 1e-5}                     # (5)!\n}\n\noptimum = OptimizationPlanRunner(CONFIG, rosenbrock).run().results    # (6)!\n\nprint(optimum.evaluations.variables, optimum.functions.weighted_objective)\n</code></pre> <ol> <li>The variables to optimize (\\(x, y\\)) are passes as a single <code>numpy</code> array. The    function may receive multiple variable vectors to evaluate, hence the input    is a matrix where the variable vectors are the rows of the matrix.</li> <li>Additional information is passes via an    <code>EvaluatorContext</code> object. It is not    needed in this case.</li> <li>Results are returned via an    <code>EvaluatorResult</code> object. The objectives    result is a matrix since multiple input vectors and multiple objectives may    be evaluated.</li> <li>Create an optimizer configuration with default values except for initial    values and perturbation magnitudes.</li> <li>Set perturbation magnitudes to a small value for accurate gradient    estimation.</li> <li>Make an <code>OptimizationPlanRunner</code>    plan, run it, and retrieve the results.</li> </ol> <p>Running this will print the estimated optimal variables and the corresponding function value:</p> <pre><code>[1.00117794 1.0023715 ] 1.4078103983185034e-06\n</code></pre> <p>This example uses the OptimizationPlanRunner class which provides a simplified interface for running optimizations. More complex optimization workflows can be implemented using the plan functionality.</p>"}]}